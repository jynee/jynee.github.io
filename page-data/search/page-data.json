{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n\r\n\r\n# NLP\r\n\r\n\r\n\r\n## `BERT`\r\n\r\n* Bidirectional Encoder Representations Form Transformer\r\n\r\n* transformer의 encoder만 사용한다. \r\n\r\n* Pre-traning과 fine-tuning으로 활용한다.\r\n\r\n* 즉, transformer의 encoder을 사전학습(UL) 시킨 언어 모델로, AE처럼 목적에 맞게 활용할 수 있도록 해둔 것이다. **특정 과제의 성능을 더 좋게 할 수 있는 언어 모델이다.**\r\n\r\n  * transformer의 encoder 출력 = BERT의 출력\r\n\r\n  * transformer의 encoder 부분만 Pre-traning 하여 사용, **실제 사용할 때는 W만 빼내는 fine-tuning 방법으로 응용**한다. \r\n\r\n    > BERT등장 이전에는 데이터의 전처리 임베딩을 Word2Vec, GloVe, Fasttext 방식을 많이 사용했지만, 요즘의 고성능을 내는 대부분의 모델에서 BERT를 많이 사용하고 있다고 합니다.\r\n\r\n* BERT는 이미 총3.3억 단어(BookCorpus + Wikipedia Data)의 거대한 코퍼스를 정제하고, 임베딩하여 학습시킨 모델이 있다. 따라서 새로운 단어를 추가하거나 기타 등등등의 이유로 필요할 때 BERT 기법을 적용하기 위해 작동 원리를 배운다. \r\n\r\n* AR(Autoregressive) : 과거 데이터로부터 현재 데이터를 추정할 수 있다. \r\n\r\n  > 참고: 기존의 ELMO나 GPT는 left to right or right to left Language Model을 사용하여 pre-training을 하지만, BERT는 이와 다르게 2가지의 새로운 unsupervised prediction task로 pre-training을 수행합니다.\r\n  >\r\n  > 출처: [mino-park7. \"BERT 논문정리\"](https://mino-park7.github.io/nlp/2018/12/12/bert-%EB%85%BC%EB%AC%B8%EC%A0%95%EB%A6%AC/?fbclid=IwAR3S-8iLWEVG6FGUVxoYdwQyA-zG0GpOUzVEsFBd0ARFg4eFXqCyGLznu7w)\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### 알고리즘 원리\r\n\r\n#### Input 단계\r\n\r\n![img](https://blog.kakaocdn.net/dn/WFCfe/btqBWZ40Gmc/6FkuwsAGN9e7Uudmi03k4k/img.png)\r\n\r\n<br>\r\n\r\n> *BERT는 아래 세가지 임베딩을 합치고, Layer에 정규화와 Dropout을 적용하여 입력값으로 사용한다.*\r\n> 출처: [ebb and flow](https://ebbnflow.tistory.com/151)\r\n\r\n<br>\r\n\r\n* **`Token Embedding`** >\r\n\r\n  \"*[`Word Piece`]*. 임베딩 방식 사용한다. 즉, 각 Char(문자) 단위로 임베딩한다.\"\r\n\r\n  * SubWord\r\n\r\n    Step 1. 자주 등장하면서 가장 긴 길이로 단어를 분리한다.\r\n\r\n    Step 2. 자주 등장하지 않았던 단어도 분리한 후 'OOV'처리하여 모델링의 성능을 저하했던 'OOV'문제도 해결한다.\r\n\r\n  * 두 문장이 들어왔다는 걸 알려준다.\r\n\r\n    Step 3. 두 문장을 구분한단 의미에 구분자 \\[SEP]를 넣어 분리한다. \r\n\r\n  * pre-trained 일 경우 input을 2개 문장씩 넣어주고, fine-tuning 시 분류할 목적이라면 input에 문장을 하나만 넣어준다.\r\n\r\n  > 모든 sentence의 첫번째 token은 언제나 `[CLS]`(special classification token) 입니다. 이 `[CLS]` token은 transformer 전체층을 다 거치고 나면 token sequence의 결합된 의미를 가지게 되는데, 여기에 **간단한 classifier를 붙이면 단일 문장, 또는 연속된 문장의 classification을 쉽게 할 수 있게 됩니다**. 만약 classification task가 아니라면 이 token은 무시하면 됩니다.\r\n  >\r\n  > * 출처: [mino-park7. \"BERT 논문정리\"](https://mino-park7.github.io/nlp/2018/12/12/bert-%EB%85%BC%EB%AC%B8%EC%A0%95%EB%A6%AC/?fbclid=IwAR3S-8iLWEVG6FGUVxoYdwQyA-zG0GpOUzVEsFBd0ARFg4eFXqCyGLznu7w)\r\n\r\n<br>\r\n\r\n* **`Segment Embedding`** >\r\n\r\n  \"*[`Sentence Embedding`]*. 문장 순서 정보가 있다. 즉, 의미 있는 여러 subword(내부 단어)로 임베딩 한다.\"\r\n\r\n  Step 1. 위 Step 3에서 구분한 구분자로 두 문장을 하나의 Segment로 지정하여 입력한다. 토큰 시킨 단어들을 다시 하나의 문장으로 만든다.\r\n\r\n  > 첫 번째 문장 속 단어는 전부 1로, 두 번째 문장 속 단어는 전부 2로 임베딩한다.\r\n\r\n  > BERT에서는 이 한 세그먼트를 512 sub-word 길이로 제한하는데, 한국어는 보통 20 sub-word가 한 문장을 이룬다고 하며 대부분의 문장은 60 sub-word가 넘지 않는다고 하니 BERT를 사용할 때, 하나의 세그먼트에 128로 제한하여도 충분히 학습이 가능하다고 합니다.\r\n  >\r\n  > 출처: [ebb and flow](https://ebbnflow.tistory.com/151)\r\n\r\n<br>\r\n\r\n* **`Position Embedding`** >\r\n\r\n  \"*[Position Embedding]*. 단어 순서 정보\"\r\n\r\n  Step 1. 순서정보를 입력하면 저장 + 공식에 맞춰 벡터화(수치화) 시킨다. Token 순서 대로 인코딩 한다.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n#### Pre-Training 단계\r\n\r\n> 데이터들을 임베딩하여 훈련시킬 데이터를 모두 인코딩 하였으면, 사전훈련을 시킬 단계입니다. 기존의 방법들은 보통 문장을 왼쪽에서 오른쪽으로 학습하여 다음 단어를 예측하는 방식이거나, 예측할 단어의 좌우 문맥을 고려하여 예측하는 방식을 사용합니다.\r\n>\r\n> 하지만 BERT는 언어의 특성을 잘 학습하도록,\r\n>\r\n> - `MLM(Masked Language Model)`\r\n> - `NSP(Next Sentence Prediction)`\r\n>\r\n> 위 두가지 방식을 사용합니다. \r\n>\r\n> 논문에서는 기존(좌우로 학습하는 모델)방식과 비교하여 MLM방식이 더 좋은 성능을 보여주고 있다고 말합니다!\r\n>\r\n> 출처: [ebb and flow](https://ebbnflow.tistory.com/151)\r\n\r\n<br><br>\r\n\r\n##### Task 1. MLM\r\n\r\n* MLM: Masked LM\r\n* 양방향+단방향을 concatnate 한다.\r\n  * 이를 통하여 LM의 left-to-right을 통하여 문장 전체를 predict하는 방법론과는 달리, **[MASK] token 만을 predict**하는 pre-training task를 수행.\r\n  * 많은 training step이 필요하지만, 보통 LM보다 훨씬 빠르고 좋은 성능을 낸다. <br>\r\n\r\n###### Denoising ~ [mask]\r\n\r\n> * AE에서는 학습 시, 미리 잡음을 섞어 추후에 입력될지 모르는 잡음을 제거(Denoising)할 수 있도록 모델링을 해둔다. BERT에서도 \\[mask] 개념을 사용하여 Denoising AE와 같은 역할을 수행하도록 학습한다.\r\n> * I love you → I [mask] you\r\n>   * [mask]: noise 처리된 단어를 \\[mask] 처리함\r\n>   * 이때 주변단어를 이용하여 \\[mask]된 단어가 나오도록 알아맞추게 학습한다.\r\n>     * Pre-traning: \\[mask] 사용\r\n>     * Fine-tuning: \\[mask] 안 사용\r\n>     * 해당 token을 맞추어 내는 task를 수행하면서, BERT는 문맥을 파악하는 능력이 생긴다.\r\n> * 1. 80% 단어(token)을 [MASK]로 바꾼다. eg., my dog is hairy -> my dog is [MASK]\r\n>   2. 10% token을 random word로 바꾼다. eg., my dog is hariy -> my dog is apple\r\n>   3. 10%는 원래 token로 그대로 둔다. 이는 실제 관측된 단어를 bias해주기 위해 실시한다.\r\n> * TransFormer의 Encoder에서도 사용한다.\r\n\r\n<br>\r\n\r\n##### Task 2. NSP\r\n\r\n* 문장과 문장 간의 관계\r\n\r\n  * 두 문장 학습\r\n\r\n* NSP: Next Sentence prediction\r\n\r\n* input 단계에서 붙여진 \\[CLS], \\[SEP]를 확인한다. 그리고 두 문장을 이어 붙이곤, 이게 원래의 corpus에서도 바로 이어 붙여져 있던 문장인지를 맞추는 binarized next sentence prediction task를 수행한다.\r\n\r\n  * 연속된 2문장인 A문장과 B문장을 확인하고, A문장 뒤에 B문장이 이어서 나오는 구나,를 파악한다\r\n  * Special token: [CLS], [SEP]이 추가되어  있는 점이 Transformer와의 차이점이다.\r\n    * \\[CLS]: 문장 시작\r\n    * \\[SEP]: 단어 구분자\r\n\r\n  <br>\r\n\r\n* 원리: \r\n\r\n  * A 다음 B가 나오면 IsNEXT로 분류한다.\r\n  * A 다음 엉뚱하게 C가 나오면 NotNext로 분류한다.\r\n\r\n<br>\r\n\r\n### 주의\r\n\r\n* Transformer에서는 만든 SentencePiece를 입력값에 넣을 수 있었지만, BERT는 안된다.\r\n\r\n  * Input layer에서 자동으로 SentencePiece 처리를 해준다.\r\n\r\n    * code[Zhao HG keras-bert](https://github.com/CyberZHG/keras-bert) 中 **.encode()**\r\n\r\n      ```python\r\n      ids, segments = tokenizer.encode(text, max_len=SEQ_LEN)\r\n      ```\r\n\r\n  * Finetuning의 경우, pre-traing 당시 학습 안 된 단어는 OOV로 자동 처리한다.\r\n\r\n<br><br>\r\n\r\n### CODE\r\n\r\n* [SKTBrain. \"KoBERT\"](https://github.com/SKTBrain/KoBERT)\r\n* [Zhao HG. \"keras-bert\"](https://github.com/CyberZHG/keras-bert)\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### 활용\r\n\r\n* BERT 활용 방법: 대량의 코퍼스를 BERT 모델에 넣어 학습하고, BERT 출력 부분에 추가적인 모델(RNN, CNN 등의 ML/DL 모델)을 쌓아 목적을 수행한다. \r\n\r\n  > * BERT를 사용하지 않은 일반 모델링 > \r\n  >\r\n  >   분류를 원하는 데이터 → LSTM, CNN 등의 머신러닝 모델 → 분류\r\n  >\r\n  > * BERT를 사용한 모델링 > \r\n  >\r\n  >   **관련 대량 코퍼스 → BERT** →  분류를 원하는 데이터 → LSTM, CNN 등의 머신러닝 모델 → 분류\r\n  >\r\n  > * 이때 DNN을 이용하였을 때와 CNN등 과 같은 복잡한 모델을 이용하였을 때의 성능 차이가 거의 없다고 알려져 있다.\r\n\r\n![image-20200819161110447](markdown-images/image-20200819161110447.png)\r\n\r\n* QQP\r\n* Q&A\r\n* Classification\r\n* Tagging\r\n\r\n<br>\r\n\r\n#### QQP 예시\r\n\r\n* QQP : *\"Input된 Q1과 Q2가 얼마나 유사한가? 유사한 문장인가?\"* 를 따지는 것.\r\n\r\n<br>\r\n\r\n#### QA 예시\r\n\r\n* (챗봇) Qustion & Answer에 활용한다.\r\n\r\n* SQuAD 모델: \\<START>와 \\<END>가 나오도록 하는 모델\r\n\r\n* | 설명                                                         | 알고리즘 설명                   |\r\n  | ------------------------------------------------------------ | ------------------------------- |\r\n  | 지문이 주어지고, Where ~? 라는 질문을 받으면 Seoul Korea라고 y값을 내놓을 수 있게 지문의 위치를 strat = 13이고 end =14라고 학습한다. | [CLS] Question [SEP] 지문 [SEP] |\r\n  | 질문에 답을 달아놓을 수 있게, 지문의 몇 번째 있는 단어가 정답인지에 대해 학습을 한다. |                                 |\r\n\r\n<br>\r\n\r\n#### Stance Classification(분류)\r\n\r\n* 일반 LSTM은 문장 내에서 단어들의 흐름을 보지만, Stance classification은 여러 문장들의 서로의 **관련성**을 보고 classification를 한다.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n#### code ~ model.summary()\r\n\r\n* [Zhao HG](https://github.com/CyberZHG/keras-bert) 의 keras_BERT code 를 활용하였다.\r\n* Pre_trained data는 [Google Research](https://github.com/google-research/bert)를 활용하였다.\r\n\r\n![image-20200818172004055](markdown-images/image-20200818172004055.png)\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n-------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고:\r\n\r\n  > * 아마추어 퀀트, blog.naver.com/chunjein\r\n  > * mino-park7. 2018.10.12. \"BERT 논문정리\". https://mino-park7.github.io/nlp/2018/12/12/bert-%EB%85%BC%EB%AC%B8%EC%A0%95%EB%A6%AC/?fbclid=IwAR3S-8iLWEVG6FGUVxoYdwQyA-zG0GpOUzVEsFBd0ARFg4eFXqCyGLznu7w. Mino-Park7 NLP Blog\r\n  > * ebb and flow. 2020. 2. 12. \"[BERT] BERT에 대해 쉽게 알아보기1 - BERT는 무엇인가, 동작 구조\". https://ebbnflow.tistory.com/151\r\n  > * Zhao HG. \"keras-bert\". https://github.com/CyberZHG/keras-bert\r\n  > * Google Research. \"2/128 (BERT-Tiny)\". https://github.com/google-research/bert. bert\r\n  > * SKTBrain. \"KoBERT\". https://github.com/SKTBrain/KoBERT","excerpt":"NLP  Bidirectional Encoder Representations Form Transformer transformer의 encoder만 사용한다.  Pre-traning과 fine-tuning으로 활용한다. 즉, transformer…","fields":{"slug":"/NLP_BERT_1/"},"frontmatter":{"date":"Aug 18, 2020","title":"NLP BERT","tags":["NLP","BERT","XLNet"],"update":"Aug 20, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n\r\n\r\n# NLP\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `Sequence to Sequence`\r\n\r\n* NLP, Time Serise/Sin data 예측에 사용한다.<br>\r\n* 기법 종류:\r\n  * seq2seq (RNN) > SL(fine Tuning) → USL\r\n  * Attention: RNN 기반 > SL(fine Tuning) → USL\r\n  * Self Attention(TransFormer): RNN 제거하고 Attention만 사용 > SL(fine Tuning) → USL\r\n    * 이유: 병렬 처리 곤란(1 Step 끝나고 다음 Step 진행하기 때문에), GV 발생\r\n  * BERT<br>\r\n* RNN  Encoder - Decoder\r\n* Encoder : 발화자의 의도\r\n  * 최종 출력 context vector : h, c\r\n* Decoder : 청취자가 발화자의 의도 해석\r\n  * Decoder의 입력과 출력은 모두 Answer 문장이다.\r\n    * 다만 여기서 입력은 태그로 \\<start>가 붙고\r\n    * 출력은 \\<end>가 붙는다<br>\r\n* teacher forcing\r\n  * 학습 시에는 입력값과 출력값을 모두 알기 때문에 한꺼번에 넣어 학습시킨다. 한 음절씩 입력할 필요가 없다.\r\n  * predict 할 때는 출력값을 모르기 때문에 \\<start>만 넣고 1 step(음절)씩 출력되도록 for문을 돌린다. <br>\r\n\r\n![image-20200811115522365](markdown-images/image-20200811115522365.png)\r\n\r\n> 그림 출처: 아마추어 퀀트, blog.naver.com/chunjein\r\n\r\n|      | 설명                                                         | 특징                  |\r\n| ---- | ------------------------------------------------------------ | --------------------- |\r\n| h    | i와 f를 통해 나온 **결과값(출력값)을 얼만큼 사용할 것인가 조절** | f와 i의 가중평균 형태 |\r\n| c    | **이전(과거)과 현재 값들을 얼만큼 사용할 것인가 조절**       |                       |\r\n| i    | **이전**의 C를 얼마나 반영할 것인지 조절                     |                       |\r\n| f    | **현재 입력값(x)과 이전의 출력값(h)**를 얼마나 반영할 것인지 조절 |                       |\r\n\r\n\r\n\r\n![image-20200811182503171](markdown-images/image-20200811182503171.png)\r\n\r\n> 그림 출처: [아마추어 퀀트](blog.naver.com/chunjein)\r\n\r\n<br>\r\n\r\n## code & 원리\r\n\r\n* 입력 데이터가 2개, 출력 데이터는 1개로 총 3개의 데이터가 필요하다\r\n\r\n* | encoder     | decoder      |\r\n  | ----------- | ------------ |\r\n  | many-to-one | many-to-many |\r\n\r\n<br>\r\n\r\n* return_state\r\n\r\n  * |        | Seq2Seq의 LSTM                                               | 기존 LSTM                                | 차이                  |\r\n    | ------ | ------------------------------------------------------------ | ---------------------------------------- | --------------------- |\r\n    | LSTM() | LSTM(LSTM_HIDDEN, return_sequences=True, **return_state = True**) | LSTM(LSTM_HIDDEN, return_sequences=True) | *return_state = True* |\r\n\r\n  > *return_state = True* : 사용하면, 중간 뉴런들 각각의 값을 뜻하는, 결과값으로서의 계산된 h와 c가 함께 출력되어 **출력값이 3개**가 나오게 된다.\r\n\r\n    <br>\r\n\r\n* decoder는 입력을 한꺼번에 받았으나, chat module에선 한 단어씩 입력받아야 한다. 따라서 입력부분의 shape이 달라진다. \r\n\r\n  > n개 → 1\r\n\r\n  * 그래도 네트워크의 파라미터는 동일하다.\r\n\r\n  * 순서:\r\n\r\n    1. `encoder` & `decoder` 네트워크를 구성한다.\r\n\r\n    * `encoder`: many-to-one으로 구성한다. 중간 출력은 필요 없고 decoder로 전달할 h와 c만 필요하다. h와 c를 얻기 위해 `return_state = True`를 설정한다.\r\n\r\n    * `decoder`: many-to-many로 구성한다. target을 학습하기 위해서는 중간 출력이 필요하다. 그리고 초기 h와 c는 encoder에서 출력한 값을 사용한다\r\n\r\n    2. `chatting 용 모델` **따로** 빌드: *\"* 학습 모델(encoder & decoder)에서 나온 결과(w값)를 적용한다. *\"* \r\n\r\n  <br>\r\n\r\n   * *chatting 용 모델* > 사용자가 있는 ChatBot으로서 **실사용할 것.**\r\n\r\n     1. 네트워크 구성\r\n\r\n        * `encoder` & `decoder`  만들기.\r\n\r\n          학습 때와 달리 문장 전체를 받아 recurrent하는 것이 아니라, **단어 1개씩 입력 받아서 다음 예상** 단어를 확인한다\r\n\r\n          따라서, input shape의 변화 말고는 가중치를 뽑아내기 위해 실행했었던 '6-2. 파일' 속 encoder & decoder의 구성방식(층 개수, 정규화 했다면 정규화, loss 등)과 전부 같아야 한다.<br>\r\n\r\n        * `Chatting용 model` 만듦\r\n\r\n          * Chatting용 model은 encoder&decoder랑 달리 네트워크를 만드는 게 아니라, \r\n\r\n            실제 사용할 model을 만들므로 Encoder 및 decoder의 **w를 써야하므로 그 둘을 합쳐준다는 의미**에서 model을 만든다.\r\n\r\n            * 따라서 Encoder의 출력을 입력으로 받기 위한 입력 input(예: ih1, ic1)을 만들어준다.\r\n\r\n              ```py\r\n              ih1 = Input(batch_shape = (None, LSTM_HIDDEN))\r\n              ic1 = Input(batch_shape = (None, LSTM_HIDDEN))\r\n              ih2 = Input(batch_shape = (None, LSTM_HIDDEN))\r\n              ic2 = Input(batch_shape = (None, LSTM_HIDDEN))\r\n              ```\r\n\r\n                * Decoder에 넣으면 변하는 부분을 만든다.\r\n\r\n                  ```python\r\n                  dec_output1, dh1, dc1 = decLSTM1(decEMB, initial_state = [ih1, ic1]) \r\n                  ```\r\n\r\n              >앞에서 encoder&decoder model을 만들었으니, \r\n              >\r\n              >바로 위 code 中 Encoder의 입력 값(ih1, ic1)에서 w가 나올 텐데,  \r\n              >\r\n              >decoder의 가중치 값으로 쓴다(initial_state).\r\n\r\n              <br>\r\n\r\n     2. Question을 입력받아 Answer를 생성 해주는 알고리즘 작성(함수 만들기)\r\n\r\n        * 궁금한 부분 & 해소:\r\n\r\n          \"챗봇의 Answer에서 '그 사람도 그럴 거예요' 中 '거예요' 다음에 문장이 또 나올 수 있지 않나? 어떻게 멈추는 거지?\"\r\n\r\n          > 답변: 챗봇 알고리즘을 다음 예상 단어가 \\<END>이거나 \\<PADDING>이면 더 이상 예상할 게 없도록 만들었기 때문.\r\n\r\n          ```python\r\n          \r\n          ```\r\n\r\n        # argmax로 해당 단어를 채택한다.\r\n\r\n              nextWord = np.argmax(dY[0, 0])\r\n            \r\n              # 예상 단어가 <END>이거나 <PADDING>이면 더 이상 예상할 게 없다.\r\n              if nextWord == word2idx['<END>'] or nextWord == word2idx['<PADDING>']:\r\n\r\n          break\r\n\r\n          ```\r\n        \r\n          ```\r\n\r\n     3. Chatting 실행하는 함수 작성\r\n\r\n        * 글 쓰는 input과 글 나오는 output이 부분을 만듦\r\n\r\n<br>\r\n\r\n### SMT\r\n\r\n* Answer는 One-Hot encoding 형태로 출력\r\n  * 따라서 softmax 사용\r\n* 이전 단어들의 Sequence로 예측할 단어를 구함\r\n  * 식에선 이전 단어가 첫 번째로 위치할 확률 등을 구함\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `Seq2Seq` & `Attention` 메커니즘\r\n\r\n> 입력 문장이 긴 상황에서는 번역 품질이 떨어지는 현상이 나타났고, 이런 현상을 보정하기 위해 **중요한 단어에 집중**하여 Decoder에 바로 전달하는 Attention 기법이 등장했습니다. 기존 방식보다 **훨씬 더 많은 데이터를 Decoder에 전달**합니다.\r\n>\r\n> * 출처: [glee1228][https://glee1228.tistory.com/3]\r\n\r\n<br>\r\n\r\n* 그림:\r\n\r\n![image-20200812105423228](markdown-images/image-20200812105423228.png)\r\n\r\n> t = 단어 하나\r\n\r\n<br>\r\n\r\n* 원리 및 작동 순서:\r\n\r\n  > ![img](https://blog.kakaocdn.net/dn/dpU0Vu/btqCgQ0OkMG/EIEGd3xjvQaKfL3NJycww0/img.png)\r\n  >\r\n  > ![img](https://blog.kakaocdn.net/dn/k15cI/btqCevJR3nq/TRZBKaQyjylYdem3GZDjG0/img.png)\r\n  >\r\n  > 위 그림을 바탕으로 어떻게 Attention이 작용하는지 설명해보겠습니다.\r\n  >\r\n  > > 우선, Attention Decoder에서 나오는 첫 단어(위의 Je)를 만들기 위해 두가지를 준비해야합니다.\r\n  > >\r\n  > > 하나는 Attention Vector, 나머지 하나는 Step 5번째의 Decoder(빨간색)에서 나오는 hidden state입니다.\r\n  > >\r\n  > > 우선 Attention Decoder에 전달할 Context Vector를 만들어봅니다.\r\n  > >\r\n  > > 1. Encoder의 hidden state(h1,h2,h3,h4h1,h2,h3,h4)들을 step별로 구합니다.\r\n  > > 2. 각각 step의 hidden state(h1,h2,h3,h4h1,h2,h3,h4)에 이전 step 디코더의 hidden state인 si−1si−1 를 각각 dot-product하거나 다른 socre 함수들을 사용해서 점수를 부여합니다.이 점수가 바로 Attention Score입니다.\r\n  > > 3. 점수를 softmax합니다.(점수 합이 1)\r\n  > > 4. Softmax된 점수에 해당하는 각각의 hidden state들을 곱해줍니다.\r\n  > > 5. 점수에 곱해진 Vector들을 Sum up 해줍니다. => Context Vector\r\n  > >\r\n  > > Step 5번째의 첫 Decoder의 hidden state를 준비해줍니다.\r\n  > >\r\n  > > 여기까지 다 되었다면, 위 Je라는 Attention Decoder의 첫 hidden state를 내보낼 준비가 되었습니다.\r\n  >\r\n  > 어텐션의 기본 아이디어는 **디코더(Decoder)에서 출력 단어를 예측하는 매 시점(time-step)마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점** 입니다. 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중해서 보게됩니다. 이 내용을 알고 Decoder의 단계로 넘어갑니다.\r\n  >\r\n  > * 출처: [glee1228](https://glee1228.tistory.com/3)\r\n\r\n\r\n<br>\r\n\r\n### code\r\n\r\n* 순서\r\n\r\n  1. 단어 목록 dict를 읽어온다.\r\n\r\n  2. 학습 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 읽어온다.\r\n\r\n  3. 평가 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 만든다.\r\n\r\n     * 이때 쓸 attention layer 및 attention score 구하기\r\n\r\n       1. Encoder 출력과 decoder 출력으로 `attention value`를 생성하고,\r\n          decoder 출력 + attention value를 `concatenate`한다.\r\n\r\n          ```python\r\n          # LSTM time step = 4, SMB_SIZE = 3\r\n          def Attention(x, y): # x : encoder 출력, y : decoder 출력\r\n              # step-1:\r\n              # decoder의 매 시점마다 encoder의 전체 시점과 dot-product을 수행한다.\r\n              score = Dot(axes=(2, 2))([y, x])                   # (1, 4, 4)\r\n              \r\n              # step-2:\r\n              # dot-product 결과를 확률분포로 만든다 (softmax)\r\n              # 이것이 attention score이다.\r\n              dist = Activation('softmax')(score)                # (1, 4, 4)\r\n          \r\n              # step-3:   \r\n              # encoder 출력과 attention score를 각각 곱하는 단계 \r\n              # encoder의 전체 시점에 위의 확률 분포를 적용해서 가중 평균한다.\r\n              # 직접 계산이 어렵기 때문에 dist를 확장하고, 열을 복제해서\r\n              # Dot 연산이 가능하도록 trick을 쓴다.\r\n              # 이것이 attention value이다.\r\n              # dist_exp = K.expand_dims(dist, 2)                   # (1, 4, 1, 4)\r\n              # dist_rep = K.repeat_elements(dist_exp, EMB_SIZE, 2) # (1, 4, 3, 4)                                       \r\n              # dist_dot = Dot(axes=(3, 1))([dist_rep, x])          # (1, 4, 3, 3)\r\n              # attention = K.mean(dist_dot, axis = 2)              # (1, 4, 3)\r\n          \r\n              # step-4:\r\n              # 교재의 step-3을 계산하지 않고 step-4를 직접 계산했다.\r\n              attention = Dot(axes=(2, 1))([dist, x])\r\n              \r\n              # step-5:\r\n              # decoder 출력과 attention (score)을 concatenate 한다.\r\n              return Concatenate()([y, attention])    # (1, 4, 6)\r\n          ```\r\n\r\n     <br>\r\n\r\n  4. 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\r\n\r\n     * 공동으로 사용함을 가정\r\n\r\n       ```python\r\n       K.clear_session()\r\n       wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\r\n       ```\r\n\r\n     <br>\r\n\r\n5. Encoder\r\n\r\n   * many-to-many로 구성한다. Attention value를 계산하기 위해 중간 출력이 필요하고 (return_sequences=True), \r\n\r\n     * decoder로 전달할 h와 c도 필요하다 (return_state = True)\r\n\r\n     <br>\r\n\r\n  6. Decoder\r\n\r\n     * many-to-many로 구성한다. target을 학습하고 Attention을 위해서는 **중간 출력이 필요**하다. \r\n\r\n     * 그리고 초기 h와 c는 encoder에서 출력한 값을 사용한다(initial_state). \r\n\r\n     * 최종 출력은 vocabulary의 인덱스인 one-hot 인코더이다.\r\n\r\n     * Attention 함수를 삽입한다.\r\n\r\n       ```python\r\n       att_dy2 = Attention(ey2, dy2) # ey2: encoder 출력값 # dy2: decoder 출력값\r\n       ```\r\n\r\n     * activation='softmax'를 사용한다\r\n\r\n       ```python\r\n       decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\r\n       ```\r\n\r\n  <br>\r\n\r\n    7. Model\r\n\r\n       * loss='sparse_categorical_crossentropy'\r\n\r\n  <br>\r\n\r\n  8. 학습 (teacher forcing)\r\n\r\n     * 주의:\r\n\r\n       loss = sparse_categorical_crossentropy이기 때문에 target을 one-hot으로 변환할 필요 없이 integer인 trainYD를 그대로 넣어 준다. trainYD를 one-hot으로 변환해서 categorical_crossentropy로 처리하면 out-of-memory 문제가 발생할 수 있다.\r\n\r\n  <br>\r\n\r\n  9. 학습 결과를 저장한다\r\n\r\n     ```python\r\n     model.save_weights(MODEL_PATH)\r\n     ```\r\n\r\n     <br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고:\r\n\r\n  > 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  > ckdgus1433. 2019. 8. 7. \"Attention Mechanism(seq2seq)\". http://blog.naver.com/ckdgus1433/221608376139. 튜토리얼로 익히는 머신러닝/딥러닝\r\n  >\r\n  > ratsgo. 2017.05.12. \"Sequence-to-Sequence 모델로 뉴스 제목 추출하기\". https://ratsgo.github.io/natural language processing/2017/03/12/s2s/. ratsgo's blog for textmining","excerpt":"NLP  NLP, Time Serise/Sin data 예측에 사용한다. 기법 종류: seq2seq (RNN) > SL(fine Tuning) → USL Attention: RNN 기반 > SL(fine Tuning) → USL Self…","fields":{"slug":"/NLP_Seq2Seq/"},"frontmatter":{"date":"Aug 15, 2020","title":"NLP Sequence to Sequence","tags":["NLP","seq2seq"],"update":"Aug 18, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# NLP\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `Transformer`\r\n\r\n* CNN, RNN 대신 Self-Attention을 사용하는 모델\r\n\r\n> Transformer는 RNN, LSTM없이 time 시퀀스 역할을 하는 모델입니다. **RNN, LSTM 셀을 일체 사용하지 않았으나, 자체만으로 time 시퀀스 역할을 해줄 수 있는 굉장히 novel한 논문입니다.**\r\n>\r\n> 일반적인 Seq2Seq-Attention 모델에서의 번역 태스크의 문제는 원본 언어(Source Language), 번역된 언어(Target Language)간의 어느정도 대응 여부는 어텐션을 통해 찾을 수 있었으나, **각 자신의 언어만에 대해서는 관계를 나타낼수 없었습니다.** 예를 들면 `I love tiger but it is scare`와 `나는 호랑이를 좋아하지만 그것(호랑이)는 무섭다` 사이의 관계는 어텐션을 통해 매칭이 가능했지만 `it`**이 무엇을 나타내는지?**와 같은 문제는 기존 Encoder-Decoder 기반의 어텐션 메커니즘에서는 찾을 수 없었습니다.\r\n>\r\n> * 출처: [platfarm tech team](https://medium.com/platfarm/어텐션-메커니즘과-transfomer-self-attention-842498fd3225)\r\n\r\n![Image for post](https://miro.medium.com/max/619/1*FYsBESLkDO9yNtu0z0mhPw.png)\r\n\r\n* 순서:\r\n\r\n  1. Seq 처리: '`positional encoding`' (순서정보를 입력하면 저장되고 공식에 맞춰 벡터를 수치화 시키는 곳)\r\n     * 상대적/절대적인 정보를 넣어야 함 <br>\r\n  2. 그걸 (input) encoder의 attention으로 전달 <br>\r\n  3. 2의 결과를 FNN을 전달(단순 linear prejection(차원축소) 위함) <br>\r\n  4. 3의 결과를 Decoder의 attention으로 전달<br>\r\n  5. (`fine Tuning`) input Decoder에서 입력한 순서 정보(positional encoding) 출력<br>\r\n  6. 5의 결과를 attention으로 전달<br>\r\n  7. 4의 결과와 합침<br>\r\n  8. FNN으로 전달(linear, softmax 거침)<br>\r\n  9. 그 결과물을 일부(?) 다시 1로 전달<br>\r\n\r\n* `attention`: 입력된 값을 가중치로 조정하여 목적에 맞게 바꿔줌 \r\n\r\n* `self attention`: Q와 transposed K를 내적한후 Scaled with Softmax 함으로써 Self-Attention 시킵니다.(attention score)\r\n\r\n* `Masked`: Self-Attention시 자신의 time step 이후 word는 가려 Self-Attention 되는 것을 막는 역할. `np.triu`를 통해 한번 삼각형 행렬을 만들어 줍니다. 1이 Mask 역할.\r\n\r\n  ```python\r\n  '''\r\n  # make mask like this.\r\n  0 1 1\r\n  0 0 1\r\n  0 0 0\r\n  '''\r\n  \r\n  def get_attn_subsequent_mask(seq):\r\n    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\r\n    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\r\n    subsequent_mask = torch.from_numpy(subsequent_mask).byte()\r\n    return subsequent_mask\r\n  ```\r\n\r\n* `d_model` : 임베딩을 하기 위한 차원으로 보통 512를 사용. embedding vector table. <br>\r\n\r\n* `attention value`: 수치화된 table에서 중요한 정보를 골라 가중치를 줄 수 있음<br>\r\n\r\n<br><br>\r\n\r\n### Encoder\r\n\r\n| **`Positional Encoding`**                                    | **`Multi-Head Attention`**                                   | **`Scaled-Dot Product Attention`**                           |\r\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| ![Image for post](https://miro.medium.com/max/329/1*4HJt3iD5tbtf9wZFuDrM-Q.png)<br /> | <img src=\"https://miro.medium.com/max/254/1*4UvAIxzfkkUercHoGJuj3w.png\" alt=\"Image for post\" style=\"zoom:150%;\" /><br /> | ![image-20200815215109073](markdown-images/image-20200815215109073.png) |\r\n|                                                              |                                                              | 여기서 Mask(opt.) 부분은 <br />Decoder의 Masked MultiHead Attention과 <br />다른 Masking이고 Optional 한 부분. <br />단순히 아래와 같은 코드를 통해 <br />입력 dimension(=512) 중 word이 <br />아닌 경우를 구분하는 역할<br />(word 입력이 끝난 후 padding 처리와 동일) |\r\n\r\n* `Encoder` 기능 설명\r\n\r\n  | 이름                                                         | 기능                                                         | 설명                                                         | 매커니즘                                                     |\r\n  | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n  | **`Positional Encoding`**![Image for post](https://miro.medium.com/max/329/1*4HJt3iD5tbtf9wZFuDrM-Q.png) | 벡터로된 위치정보에다가 공식을 사용해서 **'서로 간격이 일정하도록&고르게 분포 하도록 반영**하면, 딥러닝이 이 정보를 분석해 어떤 pattern을 찾는다.<br />*서로 간격이 일정하도록 고르게 분포 : 모든 벡터가 거리 값이 같다.(아래 추가 설명 참고) | 문장은 일반적인 임베딩과 `Positional Encoding`을 <br />**더하여** Encoder의 Layer로 들어간다 |                                                              |\r\n  | **`Multi-Head Attention`**![Image for post](https://miro.medium.com/max/254/1*4UvAIxzfkkUercHoGJuj3w.png) | 1문장을 여러 head로 Self-Attention 시킴<br />                | ”Je suis étudiant”라는 문장의 임베딩 벡터가 512차원(`d_model`)이라면 8개 `head`로 나눠 64개의 벡터를 한 `Scaled Dot Attention`이 맡아 처리하는 것. <br />**이는 동일한 문장도 8명(8 heads)이 각각의 관점에서 보고 추후에 합치는 과정**이라고도 볼 수 있다.<br />*`d_model`은 임베딩을 하기 위한 차원으로 보통 512를 사용하고, `d_k`와 `d_v`는 64를 사용. <br /> | ![Image for post](https://miro.medium.com/max/2015/1*lsMX7fYhk55VCavim7GiMg.png)<br />동일한 [batch_size x len_q x d_model] shape의 동일한 `Q, K, V`를 만들어 [d_model, d_model] `linear`를 곱한 후, <br />**임베딩 차원을 8등분하여 `Scaled Dot Product Atttention`으로 넘겨준다.<br />**그리고 multi-head attention 그림에서의 h는 `n_heads`(number of head)를 나타내며 보통 8을 사용. 이는 64 * 8 = 512이기 때문. |\r\n  | **`Scaled-Dot Product Attention`** ![image-20200813150949039](markdown-images/image-20200813150949039.png) | `Self-Attention`이 일어나는 부분.<br />                      | - 한 `head`당 <br />(input 값) : Q(64), K(64), V(64)씩 가져가게 되는데, dimension(=512) 중 word가 아닌 경우를 구분하는 역할.<br />- 처음의 Q를 ResNet의 `Residual Shortcut`와 같은 컨셉으로 더해준다. 이는 층이 깊어지는 것을 더 잘 학습 시키기 위함 | ![Image for post](https://miro.medium.com/max/1433/1*Mj7Bdi0xVPPIqGbfu7cbSw.png)<br />*`Self-Attention `>*<br />1. Q와 transposed K 사이를 내적하여 어텐션을 Softmax를 통해 구하고,<br/>2. 그 후에 V를 내적하여 중요한 부분(Attention)을 더 살린다.<br />3. 이렇게 8개의 head(여러 관점)으로 본 것을 다시 `concate`하고<br />4. `PoswiseFeedForwardNet`로 보냄 |\r\n  | **`PoswiseFeedForwardNet`**                                  | 각 `head`가 만들어낸 `Self-Attention`을 치우치지 않게 **균등하게 섞는 역할** | FNN                                                          |                                                              |\r\n\r\n  >  출처: [platfarm tech team](https://medium.com/platfarm/어텐션-메커니즘과-transfomer-self-attention-842498fd3225)\r\n\r\n<br>\r\n\r\n* 추가 설명\r\n\r\n  * `positional encoding`:\r\n\r\n    ```python\r\n    PE = positional_encoding(50,5) # emb_size = dmodel = 2차원으로 표현 \r\n    ```\r\n\r\n    * > (5,6) 값을 변경해도 발산하지 않고 뱅글뱅글 돌면서 각 벡터들의 간격이 일정하게 유지된다.\r\n      >\r\n      > | positional_encoding(50,2)                                    | positional_encoding(50,5)                                    | positional_encoding(50,25)                                   | positional_encoding(50,5)                                    |\r\n      > | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n      > | ![image-20200813105755022](markdown-images/image-20200813105755022.png) | ![image-20200813105949594](markdown-images/image-20200813105949594.png) | ![image-20200813110009011](markdown-images/image-20200813110009011.png) | ![image-20200813145235361](markdown-images/image-20200813145235361.png) |\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### Decoder\r\n\r\n|                                                              | 설명                                                         |                                                              |\r\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| <br />![Image for post](https://miro.medium.com/max/440/1*q8Q-3t9ej6SPrCwTN4wmrA.png) | 인코더와 동일하지만, `Self-Attention`시, <br />**`'Masked'-Multi-Head Attention`**을 쓴다는 점이 다르다.<br />* **Masked**를 쓰는 이유: Self-Attention시 자신의 time step 이후의 word는 가려서 Self-Attention 되는 것을 막는 역할. |                                                              |\r\n| ![Image for post](https://miro.medium.com/max/440/1*64GKtTstp4zi3CEj5Y91iw.png) | 노란색 Box에서 왼쪽 2개 화살표가 Encoder의 K,V 오른쪽 화살표가 Self-Attention을 거친 Decoder의 Q | ![Image for post](https://miro.medium.com/max/779/1*y_oOzc5s7I6urwrXiIcQAA.png)<br />이렇게 나온 logistic을 일반적인Teacher Forcing을 통해 학습 |\r\n\r\n> * 출처 및 참고: [platfarm tech team](https://medium.com/platfarm/어텐션-메커니즘과-transfomer-self-attention-842498fd3225)\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### Inference(추론)\r\n\r\n| 전체 Inference                                               | Encoder Inference                                            |\r\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| 일반적인 Seq2Seq 모델과 동일하게 Inference시 Encoder의 들어오는 문장(번역할 문장)은 정확히 알지만, Decoder에 들어오는 문장(번역되어지는 문장)은 알지 못한다. <br />시작 표시를 나타내는 \\<S>를 사용해서 Seq2Seq와 동일하게 Inference 한다. | 이때 Encoder은 일반 학습시의 Encoder와 동일하고, Decoder만 순차적으로 진행하기 위해 Greedy Decoder 혹은 Beam Search를 사용.<br />inference word가 \\<E> (end point)이면 inference를 멈춘다. |\r\n| ![Image for post](https://miro.medium.com/max/946/1*JMTk-0Ky6fZh2RNFd8mghQ.png) | ![Image for post](https://miro.medium.com/max/1554/1*mmNgbfouHqgTQDY1vEAYNw.png) |\r\n\r\n> * 출처: [platfarm tech team](https://medium.com/platfarm/어텐션-메커니즘과-transfomer-self-attention-842498fd3225)\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### Chatbot Code\r\n\r\n* (2020-08-14) (data set)를 transformer 모델에 학습한 챗봇 만들기 미니 프로젝트\r\n\r\n  Created by jynee & [molo6379](https://github.com/molo6379) & [hh](https://github.com/hayjee) & [Dabi](https://github.com/Jude0124) \r\n\r\n  [Zhao HG](https://github.com/CyberZHG/keras-transformer) keras transformer 코드 응용\r\n\r\n  <br>\r\n\r\n* 데이터 입력\r\n\r\n```python\r\nfrom keras_transformer import get_model, decode\r\nimport pickle\r\nimport warnings\r\nwarnings.filterwarnings('ignore', 'tensorflow')\r\n\r\n# 단어 목록 dict를 읽어온다.\r\nwith open('./dataset/6-1.vocabulary.pickle', 'rb') as f:\r\n    word2idx,  idx2word = pickle.load(f)\r\n    \r\n# 학습 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 읽어온다.\r\nwith open('./dataset/6-1.train_data.pickle', 'rb') as f:\r\n    trainXE, trainXD, trainYD = pickle.load(f)\r\n\t\r\n# 평가 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 만든다.\r\nwith open('./dataset/6-1.eval_data.pickle', 'rb') as f:\r\n    testXE, testXD, testYD = pickle.load(f)\r\n```\r\n\r\n<br>\r\n\r\n* model 빌드\r\n\r\n```python\r\nmodel = get_model(\r\n    token_num=max(len(word2idx), len(word2idx)),\r\n    embed_dim=32,\r\n    encoder_num=2,\r\n    decoder_num=2,\r\n    head_num=4,\r\n    hidden_dim=128,\r\n    dropout_rate=0.05,\r\n    use_same_embed=False,  # Use different embeddings for different languages\r\n)\r\nmodel.compile('adam', 'sparse_categorical_crossentropy')\r\n```\r\n\r\n<br>\r\n\r\n* model load or fit(학습)\r\n\r\n```python\r\nLOAD_MODEL = True\r\nif LOAD_MODEL:\r\n    MODEL_PATH = './dataset/transformer.h5'\r\n    model.load_weights(MODEL_PATH)\r\n    \r\nelse:\r\n    model.fit(\r\n    x=[trainXE, trainXD],\r\n    y=trainYD,\r\n    epochs=1,\r\n    batch_size=32)\r\n    model.save_weights(MODEL_PATH)\r\n```\r\n\r\n<br>\r\n\r\n* predict 함수 정의\r\n\r\n```python\r\ndef ivec_to_word(q_idx):\r\n    decoded = decode(\r\n        model,\r\n        q_idx,\r\n        start_token=word2idx['<START>'],\r\n        end_token=word2idx['<END>'],\r\n        pad_token=word2idx['<PADDING>'],\r\n    )\r\n    decoded = ' '.join(map(lambda x: idx2word[x], decoded[1:-1]))\r\n    return decoded\r\n```\r\n\r\n<br>\r\n\r\n* chatbot \r\n\r\n```python\r\nMAX_SEQUENCE_LEN = 10\r\ndef chatting(n=100):\r\n    for i in range(n):\r\n        question = input('Q: ')\r\n        \r\n        if  question == 'quit':\r\n            break\r\n        \r\n        q_idx = []\r\n        for x in question.split(' '):\r\n            if x in word2idx:\r\n                q_idx.append(word2idx[x])\r\n            else:\r\n                q_idx.append(word2idx['<UNKNOWN>'])   # out-of-vocabulary (OOV)\r\n        \r\n        # <PADDING>을 삽입한다.\r\n        if len(q_idx) < MAX_SEQUENCE_LEN:\r\n            q_idx.extend([word2idx['<PADDING>']] * (MAX_SEQUENCE_LEN - len(q_idx)))\r\n        else:\r\n            q_idx = q_idx[0:MAX_SEQUENCE_LEN]\r\n        \r\n        answer = ivec_to_word(q_idx)\r\n        print('A: ', answer)\r\n\r\nchatting(100)\r\n```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## units of words\r\n\r\n* 등장 배경:\r\n\r\n  * FastText를 사용한다면,\r\n\r\n    * n-gram character 방식<br>\r\n\r\n      *단점 >*\r\n\r\n      * word2vec의 oov 문제를 해결하지만, **collision 문제 발생**<br>\r\n\r\n  * hash 사용한다면, hash-table 크기를 작게 잡으면 collision 발생\r\n\r\n    > 참고: DB에서는,\r\n    >\r\n    > 1. Collision 문제를 해결하기 위해서 **별도의 overflow page를 사용**한다\r\n    >\r\n    > 2. overflow page가 늘어나면 검색 속도가 떨어진다\r\n    >\r\n    > 3. overflow paee가 임계치를 초과하면 **hash-table을 늘려서** DB를 재구성\r\n    >\r\n    >    => \"Reorganization\" 따라서 기존의 **단어들의 위치가 변경**된다.\r\n    >\r\n    >    * NLP 분석 시엔 Reorganization하면 단어들의 위치가 변경되므로 다시 학습시켜야 한다. 따라서 근본적인 해결책이 되진 못한다.<br>\r\n\r\n    <br>\r\n\r\n* `Word Piece(WPM)`, **`Sentence Piece(SPM)`**\r\n\r\n  * NLP에서 Sub-word 구축할 때 사용\r\n\r\n  * 형태소 분석과 달리 언어의 특성에 구애 받지 않아 아무 언어나(한글/영어 등) 사용이 가능하다.\r\n\r\n  * 빈도가 높은 문자열들은 하나의 `unit`으로 취급하여 사전에 등록해 사용한다.\r\n\r\n    * 'unit': 의미를 가진 문자는 아니고 음절이라기엔 두 음절을 하나로 보니 unit이란 이름을 사용한다.\r\n\r\n  * > 구글은 자신들의 구글 번역기에서 WPM이 어떻게 수행되는지에 대해서 기술했다.\r\n    >\r\n    > ```python\r\n    > WPM을 수행하기 이전의 문장:\r\n    > Jet makers feud over seat width with big orders at stake\r\n    > WPM을 수행한 결과(wordpieces) :\r\n    > _J et _makers _fe ud _over _seat _width _with _big _orders _at _stake\r\n    > ```\r\n    >\r\n    > Jet는 J와 et로 나누어졌으며, feud는 fe와 ud로 나누어진 것을 볼 수 있다. WPM은 입력 문장에서 기존에 존재하던 띄어쓰기는 언더바로 치환하고, 단어는 내부단어(subword)로 통계에 기반하여 띄어쓰기로 분리한다.\r\n    >\r\n    > 기존의 띄어쓰기를 언더바로 치환하는 이유는 **차후 다시 문장 복원을 위한 장치**이다. WPM의 결과로 나온 문장을 보면, 기존에 없던 띄어쓰기가 추가되어 내부 단어(subwords)들을 구분하는 구분자 역할을 하고 있으므로 본래의 띄어쓰기를 언더바로 치환해놓지 않으면, 기존 문장으로 복원할 수가 없다.\r\n    >\r\n    > WPM이 수행된 결과로부터 다시 수행 전의 결과로 돌리는 방법은 현재 있는 띄어쓰기를 전부 삭제하여 내부 단어들을 다시 하나의 단어로 연결시키고, 언더바를 다시 띄어쓰기로 바꾸면 된다.\r\n    >\r\n    > * 출처: [정민수][https://medium.com/@omicro03/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-5%EC%9D%BC%EC%B0%A8-%EB%8B%A8%EC%96%B4-%EB%B6%84%EB%A6%AC-60b59f681eb7]\r\n\r\n  * pre-trained 된 [SKTBrain의 KoBert](https://github.com/SKTBrain/KoBERT)를  fine tuning으로 사용하면 쉽게 SentencePiece를 만들 수 있다.\r\n\r\n  <br>\r\n\r\n  * WPM, SPM\r\n\r\n    * SPM은 GOOGLE이 C++로 만들어서 속도가 빠르다.\r\n\r\n    * (단점) 조사도 쪼개서 보기 때문에 챗봇 만들 때 답변으로 잘못된 조사가 붙여 나올 수 있다.\r\n\r\n      * ex: 번역 api 사용 시 부자연스러운 조사\r\n      * 개선 방법: (1) 데이터 양을 늘린다. (2) BERT를 사용한다.\r\n\r\n      > [나는 학교에 간다]\r\n      >\r\n      > 1. 단어와 단어를 구분하는 단어의 띄어쓰기에만 언더바 붙이기 \"나는\\_학교에_간다\"\r\n      > 2. '_학교' → 사전에 등록\r\n      > 3. '_나' → 사전에 등록\r\n      > 4. '는' → 사전에 등록\r\n      > 5. '간다' → 사전에 등록\r\n      > 6. ['\\_학교', '_나', '는', '간다']\r\n      > 7. [5, 4, 61,12]\r\n\r\n  <br>\r\n\r\n* `BPE`\r\n\r\n  * 데이터 압축기술.\r\n\r\n    > 구글의 WPM에는 BPE(Byte Pair Encoding) 알고리즘이 사용되었다.\r\n    >\r\n    > BPE 알고리즘의 기본 원리는 가장 많이 등장한 문자열에 대하여 병합하는 작업을 반복하는 데, 원하는 단어 집합의 크기. 즉, 단어의 갯수가 될 때까지 이 작업을 반복한다.\r\n    >\r\n    > * 출처: [정민수][https://medium.com/@omicro03/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-5%EC%9D%BC%EC%B0%A8-%EB%8B%A8%EC%96%B4-%EB%B6%84%EB%A6%AC-60b59f681eb7]\r\n\r\n    <br>\r\n\r\n    >  예> \r\n    >\r\n    >  [abcabtabsta]\r\n    >\r\n    >  1. 'ab' → 사전에 등록\r\n    >  2. 'abc' → 사전에 등록\r\n    >  3. 'r' → 사전에 등록\r\n    >  4. 't' → 사전에 등록\r\n    >  5. 'u' → 사전에 등록\r\n\r\n<br>\r\n\r\n<br><br>\r\n\r\n<br>\r\n\r\n* 참고:\r\n\r\n  > * 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  > * platfarm tech team. 2019.05.11. \"어텐션 메커니즘과 transfomer(self-attention)\". https://medium.com/platfarm/어텐션-메커니즘과-transfomer-self-attention-842498fd3225\r\n  > * Zhao HG. \"keras-bert\". https://github.com/CyberZHG/keras-bert\r\n  > * 정민수. 2019.06.07. \"자연어처리(NLP) 5일차 (단어 분리)\". https://medium.com/@omicro03/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-5%EC%9D%BC%EC%B0%A8-%EB%8B%A8%EC%96%B4-%EB%B6%84%EB%A6%AC-60b59f681eb7. @omicro03","excerpt":"NLP  CNN, RNN 대신 Self-Attention을 사용하는 모델 Transformer는 RNN, LSTM없이 time 시퀀스 역할을 하는 모델입니다. RNN, LSTM 셀을 일체 사용하지 않았으나, 자체만으로 time…","fields":{"slug":"/NLP_Transfomer/"},"frontmatter":{"date":"Aug 15, 2020","title":"NLP Transformer & SentecePiece","tags":["NLP","transformer","SentencePiece"],"update":"Aug 20, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# GAN\r\n\r\n* 비지도학습(UL) 방식의 이미지, 문서, 음성 등의 데이터를 **생성(모방)하는 알고리즘**\r\n* **비모수적방법**으로도 비교적 정확한 **sampling이 가능**함 \r\n* 위조 데이터 생성 및 판별에 사용 \r\n  EX) 이미지 색깔(색칠) 해주는 프로그램, 딥페이크 영상\r\n\r\n\r\n\r\n![](image-20200728184326510.png)\r\n\r\n> 출처: https://www.naverlabs.com/storyDetail/44\r\n\r\n\r\n\r\n## 그림 보충 설명:\r\n\r\n1)  `Real`: 실제 데이터(이미지, 음성 등)\r\n\r\n2)  `Input`: 랜덤 데이터. **노이즈 섞인 것**. \t*But,* Generator 통과하면, Real data 같은 것으로 변환돼 나온다.\r\n\r\n3)  `Generator(network)`: 생성자. **진짜 같은 가짜(Fake) 생성**\r\n\r\n4)  `Discriminator(network)`: 판별자. **실제 데이터(Real)와 가짜 데이터(Fake)를 판별**함\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **즉, 총 2개의 네트워크 사용:**\r\n\r\n1)  `Discriminator`: real or fake 판별자\r\n\r\n2)  `Generator`: fake 생성자\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## Gan의 loss function:\r\n\r\n* minGmaxDV(D,G) = logD(x) + log(1-D(G(z)))``\r\n* 학습을 반복하여 (Pg = Pdata가 되어) Discriminator가 구별 불가능인 상태(‘D(x)=0.5’)로 수렴하도록 \r\n  → 마치 Generator가 x를 만들어낸 것처럼 됨 \r\n\r\n| Discriminator   | Generator       |\r\n| --------------- | --------------- |\r\n| 엔트로피 최대화 | 엔트로피 최소화 |\r\n\r\n> 엔트로피: 정보의 가치(정보량)과 ~\r\n\r\n**1)**  **`Discriminator`**(network): **`maxV(D, G)`**로 학습. D(x) = 1 and D(G(z)) = 0일 때 최대\r\n\r\n* *why?* D(G(z))가 1이 되고, D(x)가 1이 되니까\r\n\r\n2)  **`Generator`** network: **`minV(G)`**로 학습. D(G(z)) = 1 일 때 최소. 이때(D(x)는 상관 X)\r\n\r\n* *why?* D(G(z))가 0이 되니까\r\n\r\n<br>\r\n\r\n### 원리:\r\n\r\n![](image-20200728185621472.png)\r\n\r\n> 출처: Goodfellow 논문 공식\r\n\r\n<br>\r\n\r\n1. `Discriminator`를 k번 학습시키고, `Generator`를 1번 학습시킨다.\r\n\r\n   → D가 G보다 더 많이 학습된다.    * D: Discriminator / * G: Generator\r\n\r\n   <br>\r\n\r\n   *이에 따라* >\r\n\r\n   1) Real Data와 Fake Data를 구별해내는 `D loss`는 점점 더 작아져 영향력이 줄어들고,\r\n\r\n   2) `D`와 `G`는 점점 더 비슷해지며,\r\n\r\n   3) `KL`이 적어지고,   *****KL: G와 D의 정보량의 차이/분산의 차이\r\n\r\n   <br>\r\n\r\n   *이럴수록* >\r\n\r\n​\t3-1) G가 더 많은 영향력을 행사하고(역할을 하고),\r\n\r\n​\t3-2) `D loss`를 계산하는 공식 中 [-log4 + 2JSD(Pdata+||Pg)]에서 -log4의 값이 더욱더 1.38에 가까워진다. \r\n​    *[2JSD(Pdata+||Pg) ] : KL이라 보면 됨. (KL이 작아진다) = (D와 G의 분산이 적다) = (D loss가 1.38에 가깝다)\r\n\r\n   <br>\r\n\r\n   *따라서*  >\r\n\r\n   분별할 수 없이 실제와 가까운 Fake Data가 생성된다.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 위 원리에 따라,\r\n\r\n  *학습이 안 된 상태에선* >\r\n\r\n  G(z) ( = Fake Data. 이때 ‘z’는 input에서 들어온 random data임)의 분포가 오른쪽으로 치우친 상태로서 D(x)는 1에 가까운 값이 출력되고 D(G(z))는 0에 가까운 값이 출력된다.\r\n\r\n  이때 D와 G는 아래 함수와 같은 상태임![image-20200728190633284](image-20200728190633284.png)![image-20200728190622855](image-20200728190622855.png)\r\n\r\n  즉, D는 진짜 (X)와 가짜 G(z)를 잘 구별하고, `G`는 진짜 같은 가짜를 잘 못 만든다\r\n\r\n  <br>\r\n\r\n  *학습이 진행되면* > \r\n\r\n  가짜 데이터 G(z)의 분포가 점점 Real Data( = X)의 분포와 유사해지고 D(G(z)) 값도 점차 커져서 D(x)값은 점차 작아진다 \r\n\r\n  <br>\r\n\r\n  *학습이 완료되면* > \r\n\r\n  Real data와 G(z)의 분포가 잘 일치하고 “D(x) = D(G(z)) = 0.5 “로 수렴한다.\r\n\r\n  즉, 임의의 random data를 G에 입력해 나온 Fake data는 Real data와 유사한 분포 특성을 갖는 데이터가 출력된다.\r\n\r\n![](image-20200728190502482.png)\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고:\r\n\r\n  >  http://blog.skby.net/gan-generative-adversarial-networks/\r\n\r\n","excerpt":"GAN 비지도학습(UL) 방식의 이미지, 문서, 음성 등의 데이터를 생성(모방)하는 알고리즘 비모수적방법으로도 비교적 정확한 sampling이 가능함  위조 데이터 생성 및 판별에 사용 \nEX…","fields":{"slug":"/GAN_1/"},"frontmatter":{"date":"Aug 08, 2020","title":"GAN 이론","tags":["DL","GAN"],"update":"Aug 08, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# GAN\r\n\r\n</br>\r\n\r\n* 1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다.</br>\r\n\r\n* fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등)</br>\r\n\r\n* Discrimi의 loss는 max[log(Dx) + log(1 - DGz)]이고, Generator의 loss는 min[log(Dx + log(1 - DGz))]이다. </br>\r\n\r\n  </br>\r\n\r\n* Tensorflow에서는 이 loss 함수를 이용하여 직접 GAN을 학습할 수 있지만, </br>\r\n\r\n  Keras에서는 model.fit(), model.train_on_batch() 함수에서 target 값을 지정해야 하기 때문에 이 loss로 GAN을 학습할 수 없다 **Keras는 기본적으로 Supervised learning 목적이다.**</br>\r\n\r\n  * Keras에서는 supervised learning 방식으로 바꿔 binary_crossentropy loss 함수를 써서 GAN을 학습하는 것이 보통이다.</br>\r\n\r\n    <br>\r\n\r\n* 이 코드는 아래 자료를 참조해서 응용했다.</br>\r\n\r\n  1. Rowel Atienza, 2018, Advanced Deep Learning with Keras. Chap 4. p.107 ~ p.113</br>\r\n  2. 아마추어 퀀트, blog.naver.com/chunjein,  2020.04.08</br>\r\n\r\n* 함수들의 기능을 파악하기 쉽도록 순서를 변경하였다.</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n## Basic CODE\r\n\r\n</br>\r\n\r\n* Keras를 이용하여 기본 GAN 모델을 연습한다.</br>\r\n* file: 딥러닝 8-2.GAN(Kears)</br>\r\n\r\n</br>\r\n\r\n#### step1. 정규분포로부터 데이터를 샘플링한다</br>\r\n\r\n```python\r\nrealData = np.random.normal(size=1000)\r\nrealData = realData.reshape(realData.shape[0], 1)\r\n```\r\n\r\n</br>\r\n\r\n#### step2. Network 빌드\r\n\r\n```python\r\nnDInput = realData.shape[1] # nDInput.shape[1] = 1\r\nnDHidden = 32\r\nnDOutput = 1\r\nnGInput = 16\r\nnGHidden = 32\r\nnGOutput = nDInput\r\n\r\n## nDInput와 nGOutput는 값이 같아야 함\r\n```\r\n\r\n</br>\r\n\r\n```python\r\ndef getNoise(m, n=nGInput):\r\n    z = np.random.uniform(-1., 1., size=[m, n])\r\n    return z\r\n```\r\n\r\n```python\r\ndef MyOptimizer(a = 0.001):\r\n    return RMSprop(lr = a)\r\n```\r\n\r\n</br>\r\n\r\n#### step3. 모델 그림\r\n\r\n* Generator --> Discriminator를 연결한 모델을 생성한다.\r\n* 아래 네트워크로 z가 들어가면 DGz = 1이 나오도록 G를 학습한다.\r\n* D 네트워크는 업데이트하지 않고, G 네트워크만 업데이트한다.\r\n\r\n```mermaid\r\ngraph LR\r\nz[z] -->B{trainable}\r\n    B -->|trainable| C[G]\r\n    C -->|Gz| D[D]\r\n    B -->|NOT trainable| D\r\n\tD --> DGz\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step4. (객체지향) 함수 정의\r\n\r\n**0. K.clear_session()</br>**\r\n\r\n#####   1. Discriminator = BuildDiscriminator()</br>\r\n\r\n#####   2. Generator = BuildGenerator()</br>\r\n\r\n#####   3. GAN = BuildGAN(Discriminator, Generator)</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step5. 학습 세팅\r\n\r\n```python\r\nnBatchCnt = 3       # Mini-batch를 위해 input 데이터를 n개 블록으로 나눈다. # 333개, 333개, 334개로 쪼개짐 \r\nnBatchSize = int(realData.shape[0] / nBatchCnt)  # 블록 당 Size # nBatchSize: 333개, 333개, 334개 순으로 들어감 \r\nfor epoch in range(1000):\r\n    # Mini-batch 방식으로 학습한다\r\n    for n in range(nBatchCnt):\r\n        # input 데이터를 Mini-batch 크기에 맞게 자른다\r\n        nFrom = n * nBatchSize #for문 다 돌면 nFrom= 666\r\n        nTo = n * nBatchSize + nBatchSize #for문 다 돌면 nTo=1000\r\n        \r\n        # 마지막 루프이면 nTo는 input 데이터의 끝까지. \r\n        ## 왜 써주냐면 , n=2(마지막)일때 nTo = n * nBatchSize + nBatchSize는 999로 1000이 안되기 땜에.\r\n        if n == nBatchCnt - 1:\r\n            nTo = realData.shape[0]\r\n```\r\n\r\n</br>\r\n\r\n``` python\r\n        # 학습 데이터를 준비한다\r\n        bx = realData[nFrom : nTo] #진짜 data 형성\r\n        bz = getNoise(m=bx.shape[0], n=nGInput) # bx.shape[0]=333->333->334, nGInput=16\r\n        Gz = Generator.predict(bz) #진짜 data shape 맞춰서 noise 써가지고 가짜 data 형성(fake data)\r\n```\r\n\r\n![image-20200715110832016](image-20200715110832016.png)\r\n\r\n</br>\r\n\r\n##### Discriminator = BuildDiscriminator()\r\n\r\n```python\r\n    \t### < Discriminator를 학습한다. > ###\r\n        # Real data가 들어가면 Discriminator의 출력이 '1'이 나오도록 학습하고,\r\n        # Fake data (Gz)가 들어가면 Discriminator의 출력이 '0'이 나오도록 학습한다.\r\n        \"\"\"target data 만들기\"\"\"\r\n        target = np.zeros(bx.shape[0] * 2)\r\n        target[ : bx.shape[0]] = 0.9     # '1' 대신 0.9로 함\r\n        target[bx.shape[0] : ] = 0.1     # '0' 대신 0.1로 함\r\n        \"\"\"target data 형성 완료\"\"\"\r\n        \r\n        bx_Gz = np.concatenate([bx, Gz]) # D 학습 \r\n        Dloss = Discriminator.train_on_batch(bx_Gz, target) \r\n        #real data & fake data 모두가 D를 거치게 한다. \r\n        ##참고: fit 함수보다 train_on_batch 쓰는 게 더 속도가 빨라서 이거 씀\r\n \r\n```\r\n\r\n\r\n\r\n![image-20200715110841184](image-20200715110841184.png)\r\n\r\n</br>\r\n\r\n###### \tdef BuildDiscriminator()\r\n\r\n```python\r\n# Discriminator를 G. D 각각 생성한다\r\ndef BuildDiscriminator():\r\n    x = Input(batch_shape = (None, nDInput))\r\n    h = Dense(nDHidden, activation = 'relu')(x)\r\n    Dx = Dense(nDOutput, activation = 'sigmoid')(h) #0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 \r\n    model = Model(x, Dx)\r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.001)) \r\n    #sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 \r\n    \r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n##### GAN = BuildGAN(Discriminator, Generator)\r\n\r\n```python\r\n### < Generator를 학습한다. > ###\r\n# Fake data (z --> Gz --> DGz)가 들어가도 Discriminator의 출력이 '1'이 나오도록 Generator를 학습한다.\r\n\"\"\"target data 만들기\"\"\"\r\ntarget = np.zeros(bx.shape[0])\r\ntarget[:] = 0.9\r\n\"\"\"target data 형성 완료\"\"\"\r\n        \r\nGloss = GAN.train_on_batch(bz, target) \r\n## GAN 함수 참고: D는 위에서 학습해서 여기선 학습 안 하고 G만 학습 \r\n# 어떤 학습? 가짜 data가 들어가면 target이 전부 1로 출력되도록(Discriminator가 전부 진짜로 판별하도록)! \r\n```\r\n\r\n\r\n\r\n![image-20200715110850214](image-20200715110850214.png)\r\n\r\n</br>\r\n\r\n###### \tdef BuildGAN(D, G)\r\n\r\n``` python\r\ndef BuildGAN(D, G): # 전체 NETWORK Build \r\n    D.trainable = False     # Discriminator는 업데이트하지 않는다= 학습하지 않는다. 왜냐면 자체적으로 위에서 학습했으니까. 따라서 G만 학습됨 \r\n    z = Input(batch_shape=(None, nGInput))\r\n    Gz = G(z)\r\n    DGz = D(Gz)\r\n    \r\n    model = Model(z, DGz) #z가 들어가면 최종적으로 DGz가 나온다. \r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.0005)) # binary_crossentropy: 출력값이 0 아니면 1 나오도록\r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef BuildDiscriminator() = Discriminator\r\n\r\n```python\r\n# Discriminator를 G. D 각각 생성한다\r\ndef BuildDiscriminator():\r\n    x = Input(batch_shape = (None, nDInput))\r\n    h = Dense(nDHidden, activation = 'relu')(x)\r\n    Dx = Dense(nDOutput, activation = 'sigmoid')(h) #0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 \r\n    model = Model(x, Dx)\r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.001)) \r\n    #sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 \r\n    \r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef BuildGenerator() = Generator\r\n\r\n```python\r\n# Generator를 생성한다 \r\n# G는 여기서 학습 안 하므로 '.complie' 안 함 \r\ndef BuildGenerator(): \r\n    z = Input(batch_shape = (None, nGInput))\r\n    h = Dense(nGHidden, activation = 'relu')(z)\r\n    Gz = Dense(nGOutput, activation='linear')(h)\r\n    return Model(z, Gz)\r\n```\r\n\r\n</br>\r\n\r\n##### kd = KL(ralData, fakeData)\r\n\r\n```python\r\n    if epoch % 10 == 0:\r\n        z = getNoise(m=realData.shape[0], n=nGInput)\r\n        fakeData = Generator.predict(z)  \r\n        # Generator = BuildGenerator()에서 만든 Model(z, Gz)를 활용하여, \r\n        # \"model.predict(z=노이즈 data)\" 하라는 뜻 \r\n        kd = KL(realData, fakeData)\r\n        print(\"epoch = %d, D-Loss = %.3f, G-Loss = %.3f, KL divergence = %.3f\" % (epoch, Dloss, Gloss, kd))\r\n        # Dloss: 0.6932636 , Gloss: 0.6933405 , kd: 0.2189525518812676 = 분산이 적다\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef KL\r\n\r\n```python\r\n# 두 분포 (P, Q)의 KL divergence를 계산한다.\r\ndef KL(P, Q):\r\n    # 두 데이터의 분포를 계산한다\r\n    histP, binsP = np.histogram(P, bins=100)\r\n    histQ, binsQ = np.histogram(Q, bins=binsP)\r\n    \r\n    # 두 분포를 pdf로 만들기 위해 normalization한다.\r\n    histP = histP / (np.sum(histP) + 1e-8)\r\n    histQ = histQ / (np.sum(histQ) + 1e-8)\r\n\r\n    # KL divergence를 계산한다\r\n    kld = np.sum(histP * (np.log(histP + 1e-8) - np.log(histQ + 1e-8)))\r\n    return kld\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### plt\r\n\r\n```python\r\n# real data 분포 (p)와 fake data 분포 (q)를 그려본다\r\nz = getNoise(m=realData.shape[0], n=nGInput)\r\nfakeData = Generator.predict(z)\r\n\r\nplt.figure(figsize=(8, 5))\r\nsns.set_style('whitegrid')\r\nsns.kdeplot(realData[:, 0], color='blue', bw=0.3, label='Real')\r\nsns.kdeplot(fakeData[:, 0], color='red', bw=0.3, label='Fake')\r\nplt.legend()\r\nplt.title('Distibution of real and fake data')\r\nplt.show()\r\n```\r\n\r\n\r\n\r\n![image-20200809130155797](markdown-images/image-20200809130155797.png)\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n------\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n## CNN GAN (DCGAN) CODE\r\n\r\n</br>\r\n\r\n* 사용한 함수 총 5개:</br>\r\n\r\n  1. def build_generator(inputs, image_size)</br>\r\n\r\n  2. def build_discriminator(inputs)</br>\r\n\r\n  3. def train(models, x_train, params)</br>\r\n\r\n  4. def build_and_train_models(load_W = False, train_steps = 100)</br>\r\n\r\n  5. def plot_images():</br>\r\n\r\n</br>\r\n\r\n![image-20200809130207635](markdown-images/image-20200809130207635.png)\r\n\r\n</br>\r\n\r\n#### Base\r\n\r\n```python\r\n# load MNIST dataset\r\n(x_train, _), (_, _) = mnist.load_data()\r\n\"\"\" 비지도 방법으로 사용 \"\"\"\r\n\r\n# reshape data for CNN as (28, 28, 1) and normalize \r\n\"\"\" 2D CNN \"\"\"\r\nimage_size = x_train.shape[1] # x_train.shape (60000, 28, 28)\r\nx_train = np.reshape(x_train, [-1, image_size, image_size, 1]) # x_train.shape = (60000, 28, 28, 1)\r\nx_train = x_train.astype('float32') / 255 # 표준화\r\n\r\n# the latent or z vector is 100-dim\r\nlatent_size = 100 #latent: KNN 가기 전 층들\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 1. build_generator\r\n\r\n```python\r\ndef build_generator(inputs, image_size): # latent 층에 씀 \r\n    image_resize = image_size // 4\r\n    \r\n    # network parameters \r\n    kernel_size = 5\r\n    layer_filters = [128, 64, 32, 1]\r\n\r\n    x = Dense(image_resize * image_resize * layer_filters[0])(inputs)\r\n    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\r\n\r\n    for filters in layer_filters: # hidden 층을 for문으로 써줌(쫙 쌓아주는 것)\r\n        # first two convolution layers use strides = 2\r\n        # the last two use strides = 1\r\n        if filters > layer_filters[-2]:\r\n            strides = 2 # 따라서 layer_filters의 뒤에서 2번째까진 strides = 2\r\n        else:\r\n            strides = 1\r\n        x = BatchNormalization()(x)\r\n        x = Activation('relu')(x)\r\n        x = Conv2DTranspose(filters=filters,\r\n                            kernel_size=kernel_size,\r\n                            strides=strides,\r\n                            padding='same')(x) # data 양 뿔려줌 \r\n\r\n    x = Activation('sigmoid')(x)\r\n    generator = Model(inputs, x, name='generator') # 모방 모델이므로 y 자리엔 x 학습 결과를 써줌 \r\n    return generator # 요렇게 fake data 만들어서 전에 모델처럼 Discriminator에 넣어줌 \r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 2. build_discriminator\r\n\r\n```python\r\ndef build_discriminator(inputs):\r\n    kernel_size = 5\r\n    layer_filters = [32, 64, 128, 256]\r\n\r\n    x = inputs\r\n    for filters in layer_filters:\r\n        # first 3 convolution layers use strides = 2\r\n        # last one uses strides = 1\r\n        # 따라서 Discriminator를 더 많이 학습하게 됨 \r\n        if filters == layer_filters[-1]:\r\n            strides = 1\r\n        else:\r\n            strides = 2\r\n        x = LeakyReLU(alpha=0.2)(x)\r\n        x = Conv2D(filters=filters,\r\n                   kernel_size=kernel_size,\r\n                   strides=strides,\r\n                   padding='same')(x)\r\n\r\n    x = Flatten()(x)\r\n    x = Dense(1)(x)\r\n    x = Activation('sigmoid')(x)\r\n    discriminator = Model(inputs, x, name='discriminator')\r\n    return discriminator\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 3. build_and_train_models\r\n\r\n```python\r\ndef build_and_train_models(load_W = False, train_steps = 100):\r\n    model_name = \"dcgan_mnist\"\r\n    \r\n    # network parameters\r\n    batch_size = 64\r\n    lr = 2e-4\r\n    decay = 6e-8\r\n    input_shape = (image_size, image_size, 1)\r\n\r\n    # build discriminator model\r\n    inputs = Input(shape=input_shape, name='discriminator_input')\r\n    discriminator = build_discriminator(inputs)\r\n    \r\n    # [1] or original paper uses Adam, \r\n    # but discriminator converges easily with RMSprop\r\n    optimizer = RMSprop(lr=lr, decay=decay)\r\n    discriminator.compile(loss='binary_crossentropy',\r\n                          optimizer=optimizer,\r\n                          metrics=['accuracy'])\r\n    discriminator.summary()\r\n    \r\n    # 저장된 discriminator 모델을 읽어온다.\r\n    if load_W:\r\n        discriminator.load_weights(\"dataset/dcgan_D.h5\")\r\n\r\n    # build generator model\r\n    input_shape = (latent_size, )\r\n    inputs = Input(shape=input_shape, name='z_input')\r\n    generator = build_generator(inputs, image_size)\r\n    generator.summary()\r\n\r\n    # 저장된 generator 모델을 읽어온다.\r\n    if load_W:\r\n        generator.load_weights(\"dataset/dcgan_G.h5\")\r\n        \r\n    # build adversarial model\r\n    optimizer = RMSprop(lr=lr * 0.5, decay=decay * 0.5)\r\n    \r\n    # freeze the weights of discriminator during adversarial training\r\n    discriminator.trainable = False\r\n    \r\n    # adversarial = generator + discriminator\r\n    adversarial = Model(inputs, \r\n                        discriminator(generator(inputs)),\r\n                        name=model_name)\r\n    adversarial.compile(loss='binary_crossentropy',\r\n                        optimizer=optimizer,\r\n                        metrics=['accuracy'])\r\n    adversarial.summary() #adversarial: 최종모델\r\n\r\n    # train discriminator and adversarial networks\r\n    models = (generator, discriminator, adversarial)\r\n    params = (batch_size, latent_size, train_steps, model_name)\r\n    train(models, x_train, params)\r\n    \r\n    # 모델을 저장해 둔다\r\n    discriminator.save_weights(\"dataset/dcgan_D.h5\")\r\n    generator.save_weights(\"dataset/dcgan_G.h5\")\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 4. train\r\n\r\n```python\r\ndef train(models, x_train, params):\r\n    # the GAN component models\r\n    generator, discriminator, adversarial = models \r\n    \r\n    \r\n    # network parameters\r\n    batch_size, latent_size, train_steps, model_name = params \r\n    \r\n    \r\n    # number of elements in train dataset\r\n    train_size = x_train.shape[0]\r\n    for i in range(train_steps):\r\n        # train the discriminator for 1 batch\r\n        # 1 batch of real (label=1.0) and fake images (label=0.0)\r\n        # randomly pick real images from dataset\r\n        rand_indexes = np.random.randint(0, train_size, size=batch_size)\r\n        real_images = x_train[rand_indexes]\r\n        \r\n        # generate fake images from noise using generator \r\n        # generate noise using uniform distribution(모든 확률변수에 대해 균일한 확률을 가짐)\r\n        noise = np.random.uniform(-1.0,\r\n                                  1.0,\r\n                                  size=[batch_size, latent_size])\r\n        # generate fake images\r\n        fake_images = generator.predict(noise)\r\n        \r\n        # real + fake images = 1 batch of train data\r\n        x = np.concatenate((real_images, fake_images))\r\n        \r\n        # label real and fake images\r\n        # real images label is 1.0\r\n        y = np.ones([2 * batch_size, 1])\r\n        \r\n        # fake images label is 0.0\r\n        y[batch_size:, :] = 0.0\r\n        \r\n        # train discriminator network, log the loss and accuracy\r\n        loss, acc = discriminator.train_on_batch(x, y) \r\n        \"\"\"Q. loss: 인덱스??? \"\"\"\r\n        log = \"%d: [D-loss: %.4f, acc: %.4f]\" % (i, loss, acc)\r\n\r\n        # train the adversarial network for 1 batch\r\n        # 1 batch of fake images with label=1.0\r\n        # since the discriminator weights \r\n        # are frozen in adversarial network(adversarial network: 적대적 신경망(경쟁 속 반대편에 놓인 신경망))\r\n        # only the generator is trained\r\n        # generate noise using uniform distribution\r\n        noise = np.random.uniform(-1.0,\r\n                                  1.0, \r\n                                  size=[batch_size, latent_size])\r\n        \r\n        # label fake images as real or 1.0\r\n        y = np.ones([batch_size, 1])\r\n        # train the adversarial network \r\n        # note that unlike in discriminator training, \r\n        # we do not save the fake images in a variable\r\n        # the fake images go to the discriminator input of the adversarial\r\n        # for classification\r\n        # log the loss and accuracy\r\n        loss, acc = adversarial.train_on_batch(noise, y) \r\n        \"\"\"Q. adversarial 뜻???\"\"\"\r\n        log = \"%s [G-loss: %.4f, acc: %.4f]\" % (log, loss, acc)\r\n        print(log)\r\n   \r\n    # save the model after training the generator\r\n    # the trained generator can be reloaded for \r\n    # future MNIST digit generation\r\n    generator.save(model_name + \".h5\")\r\n\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 5. fake data를 화면에 표시\r\n\r\n```python\r\n# Generator가 생성한 이미지(fake data)를 화면에 표시한다.\r\ndef plot_images():\r\n    inputs = Input(shape=(latent_size, ), name='z_input')\r\n    generator = build_generator(inputs, image_size)\r\n    generator.load_weights(\"dataset/dcgan_G.h5\")\r\n    \r\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\r\n    images = generator.predict(noise_input) # Generator 통해 나온 fake data\r\n    plt.figure(figsize=(6, 6))\r\n    num_images = images.shape[0]\r\n    \r\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\r\n    rows = int(np.sqrt(noise_input.shape[0]))\r\n    for i in range(num_images):\r\n        plt.subplot(rows, rows, i + 1)\r\n        image = np.reshape(images[i], [image _size, image_size]) \r\n        \"\"\"why 3차원 reshape???\"\"\"\r\n        plt.imshow(image, cmap='gray')\r\n        plt.axis('off')\r\n    plt.show()\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### Final\r\n\r\n```python\r\n# 이미 학습된 weights를 읽어오고, 추가로 학습한다.\r\nbuild_and_train_models(load_W = True, train_steps = 10) # train_steps 만큼 반복 학습\r\n\r\n# Generator가 생성한 이미지를 화면에 표시한다.\r\nplot_images()\r\n```\r\n\r\n</br>\r\n\r\n|                                                         |                                                         |\r\n| ------------------------------------------------------- | ------------------------------------------------------- |\r\n| ![image-20200714193936268](image-20200714193936268.png) | ![image-20200714193941200](image-20200714193941200.png) |\r\n\r\n","excerpt":"GAN 1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다. fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등) Discrimi의 loss는 maxlog(Dx) + log…","fields":{"slug":"/GAN_2/"},"frontmatter":{"date":"Aug 08, 2020","title":"GAN 실전 응용","tags":["DL","GAN"],"update":"Aug 08, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n# NLP\r\n\r\n* Quora  : 질문 간 텍스트 유사도 분석\r\n* maLSTM : 맨하탄 거리 사용한 LSTM\r\n* GloVe : 빈도 + 맥락(Embedding) 고려한 워드 패키지\r\n* FastText : hash 값을 사용해 어딘가에 저장해두므로, 사전에 없는 단어를 입력해도 비슷한 걸 찾아 vector 값으로 나온다.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## GloVe & maLSTM\r\n\r\n* maLSTM = 맨하탄 거리 사용한 LSTM\r\n\r\n```python\r\n# Question-1, 2 입력용\r\nK.clear_session()\r\ninputQ1 = Input(batch_shape=(None, trainQ1.shape[1]))\r\ninputQ2 = Input(batch_shape=(None, trainQ2.shape[1]))\r\n\r\n# Question-1 처리용 LSTM\r\nembQ1 = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)(inputQ1)\r\nembQ1 = Dropout(rate=0.2)(embQ1)\r\nlstmQ1 = LSTM(HIDDEN_DIM)(embQ1)\r\nlstmQ1 = Dense(FEATURE_DIM, activation='relu', kernel_regularizer=regularizers.l2(REGULARIZER))(lstmQ1)\r\nlstmQ1 = Dropout(rate=0.2)(lstmQ1)\r\n\r\n# Question-2 처리용 LSTM\r\nembQ2 = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)(inputQ2)\r\nembQ2 = Dropout(rate=0.2)(embQ2)\r\nlstmQ2 = LSTM(HIDDEN_DIM)(embQ2)\r\nlstmQ2 = Dense(FEATURE_DIM, activation='relu', kernel_regularizer=regularizers.l2(REGULARIZER))(lstmQ2)\r\nlstmQ2 = Dropout(rate=0.2)(lstmQ2)\r\n```\r\n\r\n> 위 코드처럼 Embedding을 각각 해줄 땐, \r\n>\r\n> 1. 한글 사전 / 영어 사전 속 단어의 Vector 값을 각각 확인하는 것 처럼 사전의 근본이 다를 때\r\n>\r\n> 2. 챗봇 Q&A : Q는 형태소 분석을 하고, A는 형태소 분석을 하지 않을 때 처럼 결과값이 달라야 할 때.\r\n>\r\n>    \"달라야 할 필요가 있을 때만\" 이렇게 사용한다.\r\n\r\n<br>\r\n\r\n* 각각 embedding 값에서 맨하탄 거리 측정\r\n\r\n  ```py\r\n  # Question-1, 2의 출력으로 맨하탄 거리를 측정한다.\r\n  # lstmQ1 = lstmQ2 --> mDist = 1\r\n  # lstmQ1 - lstmQ2 = inf --> mDist = 0\r\n  # mDist = 0 ~ 1 사잇값이므로, trainY = [0, 1]과 mse를 측정할 수 있다.\r\n  mDist = K.exp(-K.sum(K.abs(lstmQ1 - lstmQ2), axis=1, keepdims=True))\r\n  ```\r\n\r\n  > * ex: \r\n  >   a=np.array(np.arange(20).reshape(4,5)\r\n  >   np.sum(a,axis=0, keepdims=true)\r\n  >   *keepdims=true쓰면 원래 1차원으로 나와야 할 것이 원래 a의 차원대로 2차원으로 나옴\r\n  > * Backend as k:네트워크 출력 결과에 어떤 연산을 취할 때\r\n  >   keepdims=true:원래 a값 구조대로 줌\r\n\r\n<br>\r\n\r\n* compile\r\n\r\n  ```py\r\n  model = Model([inputQ1, inputQ2], mDist)\r\n  model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.0005))\r\n  model.summary()\r\n  ```\r\n\r\n  \r\n\r\n<br><br>\r\n\r\n\r\n\r\n\r\n## GloVe & maLSTM & Quora  \r\n\r\n* 동시발생 확률 고려<br>\r\n\r\n* 빈도 기반 문장 , 맥락(context) 고려<br>\r\n\r\n* 순서\r\n\r\n  1. 전처리가 완료된 학습 데이터를 읽어온다.\r\n\r\n  2. Quora 데이터의 Vocabulary를 읽어온다.\r\n\r\n  3. maLSTM 모델을 빌드한다.\r\n\r\n  4. 저장된 WE를 읽어온다.\r\n\r\n     1. Pre-trained GloVe 파일을 읽어와서 GloVe dictionary를 생성한다\r\n\r\n        ```python\r\n            GloVe = {} #Vocabulary\r\n            for line in file: # 1라인씩 읽음. # line=['love','~','~'..]. vector가 300개 들어있다.\r\n                wv = line.split()\r\n                word = ''.join(wv[:-300]) # 앞부분 # word=wv[0] 워드만.\r\n                GloVe[word] = np.asarray(wv[-300:], dtype=np.float32) # 뒷부분 vector만.\r\n            file.close() # 뒷부분 300개 \r\n        ```\r\n\r\n        > GloVe['love']을  실행하면 아래 vector가 출력된다. shape = (300,)\r\n        > array([ 1.3949e-01,  5.3453e-01, -2.5247e-01, -1.2565e-01,  4.8748e-02,\r\n        >       1.5244e-01,  1.9906e-01, -6.5970e-02,  1.2883e-01,  2.0559e+00, ...\r\n\r\n        <br>\r\n\r\n     2. WE = np.zeros((VOCAB_SIZE, EMB_SIZE))\r\n\r\n        <br>\r\n\r\n     3. ```python\r\n            for word, i in word2idx.items(): #여기서 word2idx는 quora 용으로 우리가 만든 사전 \r\n              vec = GloVe.get(word) #300개짜리 vector # GloVe.get(word) : 있으면 나오고 없으면 null 값이 나와서 프로그램이 멈추지 않음(get)을 쓰면. # glove[word]라고만 쓸 땐, 있으면 나오고 없으면 error 뜸 \r\n                if vec is not None:\r\n                  WE[i] = vec\r\n        ```\r\n\r\n        <br>\r\n\r\n     4. 결과를 저장한다.\r\n\r\n        <br>\r\n\r\n  5. 학습 데이터와 시험 데이터로 나눈다.<br>\r\n\r\n  6. Question-1, 2 입력용(input)<br>\r\n\r\n  7. 공통으로 사용(범용)할 Embedding layer 빌드<br>\r\n\r\n  8. Question-1 처리용 LSTM model 빌드<br>\r\n\r\n  9. Question-2 처리용 LSTM model 빌드<br>\r\n\r\n  10. Question-1, 2의 출력으로 맨하탄 거리를 측정한다.\r\n\r\n    ```python\r\n      mDist = K.exp(-K.sum(K.abs(lstmQ1 - lstmQ2), axis=1, keepdims=True))\r\n    ```\r\n\r\n  > Question-1, 2의 출력으로 맨하탄 거리를 측정한다.\r\n  > lstmQ1 = lstmQ2 --> mDist = 1\r\n  > lstmQ1 - lstmQ2 = inf --> mDist = 0\r\n  > mDist = 0 ~ 1 사잇값이므로, trainY = [0, 1]과 mse를 측정할 수 있다.\r\n\r\n  <br>\r\n\r\n  11. 학습\r\n\r\n      ```python\r\n      model = Model([inputQ1, inputQ2], mDist)\r\n      model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.0005))\r\n      model.summary()\r\n      ```\r\n\r\n      <br>\r\n\r\n  12. 예측\r\n\r\n      ```python\r\n      trainY = trainY.reshape(-1, 1)\r\n      testY = testY.reshape(-1, 1)\r\n      hist = model.fit([trainQ1, trainQ2], trainY,\r\n                     validation_data = ([testQ1, testQ2], testY),\r\n                       batch_size = 1000, epochs = 10)\r\n      ```\r\n\r\n      <br>\r\n\r\n  13. 시험 데이터로 학습 성능을 평가\r\n\r\n      ```python\r\n      predicted = model.predict([testQ1, testQ2])\r\n      predY = np.where(predicted > 0.5, 1, 0)\r\n      accuracy = (testY == predY).mean()\r\n      print(\"\\nAccuracy = %.2f %s\" % (accuracy * 100, '%'))\r\n      ```\r\n\r\n      <br>\r\n\r\n<br>\r\n\r\n-------------------\r\n\r\n<br><br>\r\n\r\n\r\n\r\n## FastText & maLSTM & Quora  \r\n\r\n* subword 덕분에 어떤 단어라도 vector 형태로 만들어준다\r\n\r\n  > model.wv.vocab.keys()\r\n\r\n  <br>\r\n\r\n* 한글 hash도 있다\r\n\r\n  ```python\r\n  from gensim.models import fasttext\r\n  ```\r\n\r\n* 순서\r\n\r\n  1. 전처리가 완료된 학습 데이터를 읽어온다.<br>\r\n\r\n  2. Quora 데이터의 Vocabulary를 읽어온다.<br>\r\n\r\n  3. maLSTM 모델을 빌드한다.\r\n\r\n     ```python\r\n     # 이때, \r\n     EMB_SIZE = 300\r\n     # pre-trained FastText의 vector size = 300이므로, 이와 동일하게 맞춘다.\r\n     ```\r\n\r\n     1. 저장된 WE를 읽어온다\r\n\r\n     ```python\r\n     savedWeightEmbedding = True\r\n     ```\r\n\r\n     2. Pre-trained FastText 파일을 읽어와서 dictionary를 생성한다.\r\n\r\n     ```python\r\n     model = fasttext.load_facebook_vectors('./dataset/wiki.en.bin')\r\n     ```\r\n\r\n     3. 빈(zero) 가중치 파일 생성\r\n\r\n     ```python\r\n     WE = np.zeros((VOCAB_SIZE, EMB_SIZE))\r\n     ```\r\n\r\n     * Embedding의 w 값을 뽑아낼 수 있게 되었다. \r\n\r\n       ```py\r\n       for word, i in word2idx.items():\r\n       WE[i] = model.wv[word]\r\n       ```\r\n\r\n     * 결과 저장 <br>\r\n\r\n  4. 학습 데이터와 시험 데이터로 나눈다.<br>\r\n\r\n  5. Question-1, 2 입력용(input)<br>\r\n\r\n  6. 공통으로 사용할 Embedding layer 빌드<br>\r\n\r\n  7. Question-1 처리용 LSTM model 빌드<br>\r\n\r\n  8. Question-2 처리용 LSTM model 빌드<br>\r\n\r\n  9. Question-1, 2의 출력으로 맨하탄 거리를 측정\r\n\r\n     ```python\r\n     mDist = K.exp(-K.sum(K.abs(lstmQ1 - lstmQ2), axis=1, keepdims=True))\r\n     ```\r\n\r\n     > lstmQ1 = lstmQ2 --> mDist = 1\r\n     > lstmQ1 - lstmQ2 = inf --> mDist = 0\r\n     > mDist = 0 ~ 1 사잇값이므로, trainY = [0, 1]과 mse를 측정할 수 있다.\r\n\r\n     <br>\r\n\r\n  10. 학습   \r\n\r\n      ```python\r\n      model = Model([inputQ1, inputQ2], mDist)\r\n      model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.0005))\r\n      model.summary()\r\n      ```\r\n\r\n      <br>\r\n\r\n    11. 예측\r\n\r\n          ```python\r\n        trainY = trainY.reshape(-1, 1)\r\n          testY = testY.reshape(-1, 1)\r\n        hist = model.fit([trainQ1, trainQ2], trainY, validation_data = ([testQ1, testQ2], testY), batch_size = 1000, epochs = 10)\r\n          ```\r\n\r\n        <br>\r\n\r\n    12. 시험 데이터로 학습 성능을 평가\r\n\r\n          ```python\r\n        predicted = model.predict([testQ1, testQ2])\r\n          predY = np.where(predicted > 0.5, 1, 0)\r\n          accuracy = (testY == predY).mean()\r\n          print(\"\\nAccuracy = %.2f %s\" % (accuracy * 100, '%'))\r\n          ```\r\n\r\n<br>\r\n\r\n <br>\r\n\r\n\r\n### FastText 연습\r\n\r\n* 패키지\r\n\r\n  ```python\r\n  from gensim.models import FastText\r\n  from gensim.test.utils import common_texts # 9개 문장\r\n  ```\r\n\r\n  > [['human', 'interface', 'computer'],\r\n  > ['survey', 'user', 'computer', 'system', 'response', 'time'],\r\n  > ['eps', 'user', 'interface', 'system'],\r\n  > ['system', 'human', 'system', 'eps'],\r\n  > ['user', 'response', 'time'],\r\n  > ['trees'],\r\n  > ['graph', 'trees'],\r\n  > ['graph', 'minors', 'trees'],\r\n  > ['graph', 'minors', 'survey']]\r\n\r\n  <br>\r\n\r\n* 모델 빌드\r\n\r\n  ```python\r\n  model = FastText(size=5, window=3, min_count=1) \r\n  model.build_vocab(sentences=common_texts)\r\n  model.train(sentences=common_texts, total_examples=len(common_texts), epochs=10)\r\n  ```\r\n\r\n  > bucket=hash table. 따라서 100이라 주면, model.wv.vectors_ngrams.shape가 100, n이 됨. hashing trick을 통과시키고 나오는 값들이 들어가는 곳으로, bucket 값이 크면 collision을 방지한다\r\n  > size = EMB_SIZE\r\n  > window = 좌우 context 개수\r\n  > min_count = 빈도 1개 이상(그니까 전부 다)\r\n\r\n  <br>\r\n\r\n* word2vec 확인\r\n\r\n  * 어떤 단어라도 Hashing되어 vector값을 준다.\r\n\r\n  ```python\r\n  model.wv['human']\r\n  model.wv['klakasdfsdjf']\r\n  ```\r\n\r\n  > model.wv['human']\r\n  > Out[16]: \r\n  > array([-0.00893843, -0.03338013, -0.0210454 ,  0.03005639, -0.03349178], dtype=float32)\r\n  >\r\n  > model.wv['klakasdfsdjf']\r\n  > Out[17]: \r\n  > array([ 0.00078089, -0.01366953, -0.00929362,  0.00640602, -0.00282957], dtype=float32)\r\n\r\n  <br>\r\n\r\n* ```python\r\n  model.wv.vocab\r\n  model.wv.vocab.keys()\r\n  ```\r\n\r\n* ```python\r\n  model.wv.vectors_ngrams.shape\r\n  ```\r\n\r\n  > (2000000, 5)\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n* 참고: \r\n\r\n  >* 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  >* 전창욱, 최태균, 조중현. 2019.02.15. 텐서플로와 머신러닝으로 시작하는 자연어 처리 - 로지스틱 회귀부터 트랜스포머 챗봇까지. 위키북스","excerpt":"NLP Quora  : 질문 간 텍스트 유사도 분석 maLSTM : 맨하탄 거리 사용한 LSTM GloVe : 빈도 + 맥락(Embedding) 고려한 워드 패키지 FastText : hash…","fields":{"slug":"/NLP한글_4/"},"frontmatter":{"date":"Aug 07, 2020","title":"NLP maLSTM","tags":["NLP","maLSTM","Quora"],"update":"Aug 19, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# AUC\r\n\r\n* Area under the roc curve (AUC)\r\n\r\n* Confusion matix(Binaray classification)\r\n\r\n* |          | prediction<br />P | <br />N |\r\n  | -------- | ----------------- | ------- |\r\n  | actual P | TP                | FP      |\r\n  | N        | FN                | TN      |\r\n\r\n* TPR \r\n* FPR \r\n\r\n* Thes(임계치)가 작을수록 TPR이 높아진다.\r\n* ROC 면적이 클수록 좋다.\r\n  \r\n  * Area Under the ROC(AUC) : AUC 값을 0~1 사이의 값으로 표현.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## Kaggle Competition\r\n\r\n* 논문 분석: \r\n  * Alejandro Peláez외. Sring 2015. Sentiment analysis of IMDb movie reviews. Rutgers University \r\n\r\n<br>\r\n\r\n### `Negation Handling`\r\n\r\n* *새로운 접근* > ''**Negation Handling'**'\r\n  * hardly good → **neg**.good\r\n\r\n<br>\r\n\r\n### **`Mutual information(상호 정보량)`**\r\n\r\n* (쿡북에서) 사전 생성할 때, 전체 단어 中 6,000개만 썼다.\r\n\r\n  * 6,000개: most common() 빈도가 가장 높은 6,000개의 단어를 선택하여 vocab을 만들고, 이걸 가지고 문서 전처리를 했었음.\r\n    * 이때 핵심: **빈도가 가장 높은**\r\n    * 단어 빈도수를 수동 카운트\r\n      * collection.counter()\r\n      * counter.most_common()\r\n\r\n  * 하지만 이 분은 Mutual information(상호정보량)이라는 개념을 사용했다.<br>\r\n\r\n* *새로운 접근* > **Mutual information**\r\n\r\n  * class인 Y와 일정한 관계가 높은 순서를 vocab 생성\r\n\r\n  * 순서:\r\n\r\n    1. review 전처리\r\n\r\n       | review        | y    |\r\n       | ------------- | ---- |\r\n       | I like you    | 1    |\r\n       | I dislike you | 0    |\r\n       | ...           | ...  |\r\n\r\n    \t<br>\r\n\r\n    * 모든 단어의 Mutual information 계산\r\n\r\n      | 단어(Unigram) | y    | MI(공식에 의해 연산) |\r\n      | ------------- | ---- | -------------------- |\r\n      | I             | 1    | 0.1                  |\r\n      | I             | 0    |                      |\r\n      | like          | 1    | 0.8                  |\r\n      | dislike       | 0    | 0.7                  |\r\n\r\n      > * \"I\"와 y는 무관 → x, y는 독립\r\n      >\r\n      >   * P(x, y) = P(x|y) * P(y)\r\n      >\r\n      >   'like, dislike'와 y는 연관 → x, y는 종속 \r\n      >\r\n      >   * P(x, y) = P(x) * P(y)\r\n      >\r\n      > * ML에서 Entropy 공부 할 때, KL값으로 Cross Entropy 값을 구했었다.\r\n      >\r\n      >   * KL : 두 분포의 정보량의 차이(두 분포의 유사성)\r\n      >\r\n      > * Mutual Information의 KL\r\n      >\r\n      >   * KL(P(x, y) || P(x) * P(y))\r\n      >\r\n      >   * 예: MI('like') = ?\r\n      >\r\n      >     * P(x, y) = P(x|y) * P(y) = > \r\n      >\r\n      >     * P(x|y = 0) * P(y = 0)  + P(x|y = 1) * P(y = 1)\r\n      >\r\n      >     * P(like|y = 0) * P(y = 0)\r\n      >\r\n      >       P(like|y = 0) : label(y)가 0(neg)인 리뷰 中 'like' 단어가 등장한 비율\r\n      >\r\n      >       P(y = 0) : 리뷰 25,000개 中 y=0(neg)인 비율\r\n      >\r\n      >     * 따라서 MI('like') = 0.8\r\n      >\r\n      > * 'I'의 경우 긍/부정이 섞여 있어 MI 수치가 적다. \r\n      >\r\n      > * 'MI 수치가 적다'는 말은, 긍/부정이 명확하지 않다는 뜻이고, 이는 리뷰의 긍/부정을 분류하기 애매하다는 뜻이므로 실질적으로 목적을 이루는 데엔 도움이 되진 않는단 뜻이다.\r\n  \r\n      <br>\r\n\r\n    2. MI 높은 순서로 Sort\r\n    \r\n    | 단어    | MI   |\r\n    | ------- | ---- |\r\n  | like    | 0.8  |\r\n    | dislike | 0.7  |\r\n\r\n      <br>\r\n    \r\n    3. 상위 N% 선택하여 vocab 생성\r\n\r\n       * 상위만 선택한 이유: 분석에 별로 도움되지 않는 단어도 vocab에 포함해 생성해봤자 연산량만 늘어나고 분석에 실질적인 도움은 되지 않으니까 후순위로 밀어낸다.<br>\r\n\r\n    4. TF - IDF\r\n\r\n       * 예: movie → 여러 리뷰에 등장 DF 가 높다 IDF가 낮다<br>\r\n    \r\n    5. 감정분석\r\n    \r\n       * 학습 기반(신경망 속 Embedding)이 아닌 사전 기반의 감정분석(VADER 알고리즘) 사용\r\n         * VADER 알고리즘\r\n       * 리뷰 속 단어들을 사전에 등재된 단어에 따라 VADER Score를 매기고, 그 하나의 리뷰의 VADER Score 값을 평균낸 것<br>\r\n       * 각 단어마다 score를 매겨 양수/음수에 따라 positive and negative를 구분한다\r\n     * score 식 > label = 1인 리뷰 中 'like'의 개수 - label = 0인 리뷰 中 'like'의 개수\r\n         * 평균, top k, bottom 값을 matrix로 해서 구해봄<br>\r\n    \r\n6. word2vec\r\n   \r\n   * 단어 vector들을 평균 내서 이걸 문장 vector로 쓰는 것\r\n         * 문제: 정보가 손실되어 별로 좋은 방법은 아니다.<br>\r\n   \r\n    7. doc2vec\r\n\r\n       * 단어를 50~60% 선택할 때 score가 가장 좋았다.\r\n   * 하지만 대체적으로 많은 단어를 선택할 때 score가 좋아지긴 한다.\r\n       * doc2vec + TF-IDF : 의미적관계+구조적 관계를 보기 위해 CONCAT or average 등을 사용하여 두 값을 합침<br>\r\n\r\n    8. 감정분석\r\n\r\n       * 학습 기반<br>\r\n   \r\n    9. 결과 ROC : 0.99259<br>\r\n   \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n# 사전 만들기\r\n\r\n* 패키지 다운 경로: C:\\Users\\콘다경로\\Lib\\site-packages\\konlpy\\java\r\n  * 그 中 사전 파일: open-korean-text-2.1.0.jar\r\n  * open-korean-text-2.1.0.jar ← 여기에 단어 등록하기<br>\r\n\r\n* 단어 등록 방법\r\n\r\n  * 작업 폴더 생성\r\n\r\n    * 폴더 이름: aaa ←  라고 생성함 <br>\r\n\r\n  * cmd 창에다가\r\n\r\n    * cd C:\\Users\\콘다경로\\Lib\\site-packages\\konlpy\\java\\aaa 입력\r\n\r\n    * jar xvf ../open-korean-text-2.1.0.jar 입력\r\n\r\n      > * jar xvf  :묶음파일 풀기\r\n      >   ../ : 이전 폴더에 있는\r\n      >   open-korean-text-2.1.0.jar : 이 파일을 풀어라\r\n      > * jar cvf : 묶기\r\n      > * \\* : 와일드카드\r\n    \r\n      <br>\r\n\r\n  * 사전들이 있는 폴더: C:\\Users\\콘다경로\\Lib\\site-packages\\konlpy\\java\\aaa\\org\\openkoreantext\\processor\\util\r\n\r\n    <br>\r\n  \r\n  * 그 中 명사 사전이 들은 파일: C:\\Users\\콘다경로\\Lib\\site-packages\\konlpy\\java\\aaa\\org\\openkoreantext\\processor\\util\\noun\r\n\r\n    * 이름 정의된 파일: 'names.txt' or 'company_names.txt'\r\n    * 여기에 단어 하나 추가해보기\r\n        * '이자용' 이라고 추가하였음<br>\r\n\r\n  * cmd 창에 jar cvf open-korean-text-2.1.0.jar * 입력<br>\r\n\r\n  * 다시 'aaa' 폴더로 가기: C:\\Users\\콘다경로\\Lib\\site-packages\\konlpy\\java\\aaa<br>\r\n  \r\n  * 'aaa' 폴더에 생긴 open-korean-text-2.1.0.jar ← ctrl+c해서, 상위 폴더인 'java'에 붙여넣기(ctrl+v)<br>\r\n  \r\n  * 적용 완료<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고: \r\n\r\n  >* 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n\r\n","excerpt":"AUC Area under the roc curve (AUC) Confusion matix(Binaray classification)  predictionP N actual P TP FP N FN TN TPR  FPR  Thes…","fields":{"slug":"/NLP한글_3/"},"frontmatter":{"date":"Aug 06, 2020","title":"NLP Kaggle competition 우승자가 제안한 새로운 접근방법을 배워보자","tags":["NLP","논문 분석"],"update":"Aug 19, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n# 텍스트 분류\r\n\r\n* Skip-Gram\r\n* SGNS\r\n* Hirarchical softmax\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `Hirarchical softmax`\r\n\r\n* 연산이 많아진단 단점의 softmax를 개선하여 Binary Tree 사용<br>\r\n* Binary Tree\r\n  * iForest 알고리즘, DB indexing\r\n  * 각 트리마다 나눠서 연산을 함 <br>\r\n* 순서\r\n  * vocab 생성 단계에서 단어들을 sort\r\n  * 출력층을 binary (huffman) tree\r\n  * y와 yHat 사이의 차이를 줄이는 방향으로 역전파 \r\n    * 기존 softmax는 yHat(확률분포 형태)를 구하는 부분에서 계산량이 많다. 이걸 binary tree를 사용하는 것.\r\n    * 그렇게 되면 기존 yHat은 0.01, 0.03 ... 등으로 출력됐는데, 0.6, 0.42 등으로 출력되어 기존의 방법보다 계산량이 작아져 속도도 빨라진다.\r\n    \r\n      <br>\r\n\r\n* word2vec\r\n  * **의미 공간이라는 고차원의 공간에 각 단어의 좌표값(벡터)을 부여한다**\r\n  * 기준점이 달라지면 숫자도 달라지는 상대적인 거리로 단어 간의 유사도/차이를 분석할 수 있다.\r\n\r\n    <br>\r\n\r\n<br>\r\n\r\n# `PV-DM`\r\n\r\n* paragraph vector<br>\r\n* `doc2vec`에 사용됨\r\n  * distributed word representation(분포확률/가설 이론 사용)\r\n    * 한 문장에 같이 쓰인 단어들끼리의 유사성이 높을 것이란 가설 이론<br>\r\n* word vector 가 아닌 paragraph 단위의 vector 표현\r\n  * paragraph : 문장, 문서 단위<br>\r\n* word2vec → (발전 시킴) Doc2vec\r\n* USL\r\n* 유사도 계산에 순서 고려까지 하는 알고리즘 \r\n\r\n![image-20200805181033974](image-20200805181033974.png)\r\n\r\n> 그림 출처: 아마추어 퀀트, blog.naver.com/chunjein<br>\r\n\r\n* concat 후 lstm 넣으면 정보가 조금은 유실된 채로 넣어지는 것이라 우리는 지금까지 embeding layer 거친 것을 바로 lstm으로 넣었음.\r\n\r\n<br>\r\n\r\n* 원리: \r\n  * 문장 -1 \"doc#1\" : the cat sat on the table 가 있을 때,\r\n\r\n  * 문장마다 unique한 ID(Paragraph id)를 붙여놓고 이것도 하나의 문장으로 취급함.\r\n    * `paragraph vector `\r\n      * 이것들이 추후엔 word가 됨\r\n      * 즉, paragraph token은 또 다른 word라 생각하면 됨 \r\n      * 모든 문장의 paragraph vector를 공유함 <br>\r\n\r\n* 따라서\r\n\r\n  * concat으로 합쳐져서 y 값이 나오도록 역전파\r\n  * x의 fix value는 3, y는 1라면, window size = 4로 설정\r\n\r\n  | context      | x(vocab의 index로 입력) | y(vocab의 index로 출력) | missing value |\r\n  | ------------ | ----------------------- | ----------------------- | ------------- |\r\n  | doc - # 1(7) | the(1), cat(3), sat(4)  | on(13)                  |               |\r\n  | doc - # 1(7) | cat(3), sat(4), on(13)  | table(8)                | the(1)        |\r\n\r\n  이렇게 학습 시킨다.\r\n\r\n  > *'이렇게 학습' : Distributed memory model of paragraph vector(PV-DM): missing된 값을 기억한다\r\n\r\n\r\n<br>\r\n\r\n* 학습 후에는 paragraph vector가 1개의 colum vector(word vector)가 됨<br>\r\n\r\n* 단점: 학습 단계는 괜찮은데, prediction 단계에서는 새 문장에 paragraph id를 알 수 없어 값을 넣지 못한다는 점<br>\r\n\r\n* 해결: inference step(추론 단계) 필요\r\n\r\n  * 학습에 사용되지 않은 문장에 대해서는 inference step이 필요하다.\r\n  * GD 방법에 의해 얻을 수 있다.<br>\r\n\r\n* 따라서 알고리즘 순서: \r\n\r\n  * 2개의 주 Stage가 있다.\r\n    1. W, D, U 결정(학습단계) 및 고정\r\n    2. **inferece stage**가 필요\r\n       * GD(학습) 통해 알아냄. \r\n         * 위에서 학습 완료된 W(embedding layer 거친 word vector), U(softmax 가중치), b(softmax의 bias) 고정 시킴\r\n         * 일반적으론 model.fit(x, y)로 학습 한 후, model.predict(x)로 예측했는데 \r\n         * inference 때에는 D(paragraph Matrix) 값을 모르니 D를 random하게 둔다\r\n           * 따라서 model.fit(x, y)로 학습 한 후, model.predict(new x) 수행\r\n           * advantage paragraph vector \r\n\r\n  > PV-DM에서는 다음과 같은 크게 두 가지 단계를 거쳐서 문장의 발화 의 도를 예측한다. \r\n  > 1) 주어진 데이터로 W(word vectors), U(softmax weights), b(softmax weights), D(paragraph vectors)를 학습한다. \r\n  > 2) 새로운 문장에 대해서 이미 학습했던 W, U, b는 유지하면서 D에 column을 추가하고 기울기 하강기법(gradient descent)을 적용하여 새로운 문장에 대한 벡터(D’)을 만들게 된다. \r\n  > 두 번째 단계에서 얻은 D’은 인식기를 통해 미리 정의한 발화 의도 집합 중 하나로 분류된다\r\n  >\r\n  > 출처: 최성호, 김은솔, 장병탁. 2016. Paragraph Vector를 이용한 문장 의도 예측 기법. 2016년 한국컴퓨터종합학술대회 논문집\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n# `PV-DBOW\t`\r\n\r\n* PV-DM과 반대 \r\n\r\n<br>\r\n\r\n## CNN & LSTM\r\n\r\n![image-20200805175130043](markdown-images/image-20200805175130043.png)\r\n\r\n> 그림 출처: 아마추어 퀀트, blog.naver.com/chunjein\r\n\r\n<br>\r\n\r\n* `Word2vec` : LSTM/CNN\r\n  \r\n  * 위 그림 中 1번 그림이다.\r\n  \r\n  * 1개 문장 안에서 단어들의 sequence 분석한다.\r\n    * 즉, 순서/흐름에 주목한 모델이다.<br>\r\n* 부족한 부분은 padding 처리하며 time step을 통일 시켜주었다.\r\n    * *근데 \"time step의 크기를 굳이 통일시킬 필요가 있나?\" \"어떤 batch는 부족하면 안 되나? \"*\r\n      \r\n      * 부족해도 된다. 경우에 따라 padding을 써주는데 쓰는 게 일반적이다. \r\n      \r\n      <br>\r\n    \r\n    <br>\r\n  \r\n* `Doc2vec`: \r\n\r\n  * 위 그림 中 2번 그림일 때, batch가 문장 1개라 sequence 분석이 불가능\r\n\r\n    * 기계가 입력값을 기억하지 못한다.\r\n\r\n    * 인공지능 로봇으로 따지면, \r\n\r\n      나: \"지니야 내가 방금 뭐라고 그랬지?\"\r\n\r\n      기계: \"무슨 말씀인지 모르겠어요.\"<br>\r\n\r\n  * 따라서 3번 그림. `Episodic stroy `개념 사용하여 episode가 batch 역할을 한다. \r\n\r\n    * 기계가 입력값을 기억할 수 있다. \r\n\r\n    * 인공지능 로봇으로 따지면, \r\n\r\n      나: \"지니야 내가 방금 뭐라고 그랬지?\"\r\n\r\n      기계: \"오늘 날씨가 어떠냐고 물어봤죠?\"\r\n\r\n    * 현재 개발이 되고는 있지만 쉽지 않은 영역이라 발전은 더딘 편이다.\r\n      \r\n    * 만약 개발이 된다면, A 작가의 40년치 소설을 모델에 넣어 학습 시켜 가지고 그 작가의 문체적 특징을 파악할 수 있지 않을까*?*\r\n    \r\n    <br>\r\n  \r\n* 원리: \r\n  \r\n    1. 1개 episodic내에서 문장(문단)의 sequence 분석 시행\r\n  2. LSTM layer에 입력\r\n  \r\n  * chatbot의 경우: 대화 내용의 흐름이 존재. 이걸 학습하기 위해 (내가 챗봇과 대화하는 하나의 세션(대화주제) 개념으로의)episodic story 활용 \r\n  \r\n  * 이때, time step을 굳이 지정해서 길이를 통일시키지 않아도 된다. \r\n  \r\n      > x.shape = (None, 문장 개수, vector_size)\r\n      >\r\n      > xInput = Input(batch_shape = (None, **None**, vector_size))\r\n      >\r\n      > * 다만, 입력된 문장 개수에 따라 recurrent 횟수가 가변적이다.\r\n      > * 추후 학습 시: model.fit(x,y, batch_size=1) 필요.\r\n      > * 단점: 학습 시간이 오래 걸린다.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고: \r\n\r\n  >* 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  >* 코드 출처: 전창욱, 최태균, 조중현. 2019.02.15. 텐서플로와 머신러닝으로 시작하는 자연어 처리 - 로지스틱 회귀부터 트랜스포머 챗봇까지. 위키북스\r\n\r\n","excerpt":"텍스트 분류 Skip-Gram SGNS Hirarchical softmax  연산이 많아진단 단점의 softmax를 개선하여 Binary Tree 사용 Binary Tree iForest 알고리즘, DB indexing…","fields":{"slug":"/NLP한글_2/"},"frontmatter":{"date":"Aug 05, 2020","title":"NLP Doc2Vec","tags":["NLP","Doc2Vec"],"update":"Aug 18, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# NLP 분야에서 딥러닝의 고급 응용\r\n\r\n* DMN\r\n* Ask Me Anything\r\n  * attention score layer\r\n  * story layer\r\n  * episodic memory layer\r\n  * answer layer\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 텍스트 자동 생성\r\n\r\n예제 문장: I love you very much\r\n\r\n* 문자 단위의 시계열 데이터 생성\r\n\r\n  * 아래처럼 되도록 생성: 보통의 시계열 Batch data처럼 생성\r\n  \t| x          | y(one-hot encoding) |\r\n  | ---------- | ------------------- |\r\n  | I love you | (공백)              |\r\n  | love you   | v                   |\r\n  | ove you v  | e                   |\r\n| ...        | ...                 |\r\n    \r\n\t\t>  y값을 word 단위가 아니고 characters(ex: a, b, c, ... z) 로 설정<br>\r\n\r\n* LSTM으로 학습\r\n\r\n  * I love you를 넣어도 v가 나오게끔 신경망 속 activation은 softmax 함수를 쓴다.\r\n    * compile 시, loss 함수는 categorical_crossentropy 사용<br>\r\n\r\n* 순서:\r\n\r\n  1. **문장으로 이루어진 raw data 불러오기**\r\n\r\n  2. **전처리**\r\n\r\n     1. word 아니고 character 단위로 분류\r\n     2. 시계열 x data 생성. (위 예시의 x 처럼)\r\n     3. Converting indices into vectorized format\r\n        * X, Y를 np.zeros \r\n\r\n  3. **Model Building**\r\n\r\n     * softmax: 출력층의 값이 [0.3, 0.4, 0.8] 등으로 나오면 이 총합이 1이 나오게끔 확률분포 다시 계산. \r\n       이때 나온 값들의 차이를 더 크게 조작하고 싶을 때, 베타가 들어간 식을 사용하여 계산. \r\n       이렇게 하면 model.predict(x) 시, 원하는 문자의 수치가 나올 확률이 높아진다\r\n       (역으로 원하지 않는 단어가 나올 확률은 적어진다.)\r\n     * softmax 함수를 쓰는 skip-gram은 계산량이 많단 단점이 있는데, 이를 SGNS가 보완한다.\r\n\r\n  4. **예측치를 softmax 확률로 뽑아 다시 역연산(exp) 하는 함수 생성**\r\n\r\n     * np.random.multinomial로 sampling\r\n\r\n       ```python\r\n       def pred_indices(preds, metric=1.0):\r\n           preds = np.asarray(preds).astype('float64')\r\n           preds = np.log(preds) / metric\r\n           exp_preds = np.exp(preds)\r\n           preds = exp_preds/np.sum(exp_preds)\r\n           probs = np.random.multinomial(1, preds, 1)\r\n           return np.argmax(probs)\r\n       ```\r\n\r\n     \t> * 다항 분포 (Multinomial distribution):\r\n     \t>\r\n     \t>   다항 분포는 여러 개의 값을 가질 수 있는 독립 확률변수들에 대한 확률분포로, 여러 번의 독립적 시행에서 각각의 값이 특정 횟수가 나타날 확률을 정의한다. 다항 분포에서 차원이 2인 경우 이항 분포가 된다.\r\n     \t>\r\n     \t>   > 출처: [위키백과. 다항분포]([https://ko.wikipedia.org/wiki/%EB%8B%A4%ED%95%AD_%EB%B6%84%ED%8F%AC](https://ko.wikipedia.org/wiki/다항_분포))\r\n\r\n  5. **Train & Evaluate the Model**\r\n\r\n     1. batch\r\n        \r\n        1. randint로 random하게 시작하도록 설정\r\n     2. 확률 임의 설정 후 단어 생성\r\n\r\n        * [0.2, 0.7,1.2] 처럼 \r\n\r\n          ```python\r\n        for diversity in [0.2, 0.7,1.2]:\r\n          ```\r\n\r\n          > ```python\r\n          > a = np.array([0.9, 0.2, 0.4])\r\n          > b = 1.0\r\n          > e = np.exp(a/b)\r\n          > \r\n          > print(e/np.sum(e))\r\n          > ```\r\n          >\r\n          > '0.9'처럼 유독 하나의 값이 클 경우 다른 값들과의 차이가 더 커짐 \r\n          >\r\n          > | print(e/np.sum(e))<br/>[0.40175958 0.2693075  0.32893292]    | print(e/np.sum(e))<br/>[0.47548496 0.23611884 0.2883962 ]    |\r\n          > | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n          > | a = np.array([0.6, 0.2, 0.4])<br/>b = 1.0<br/>e = np.exp(a/b) | a = np.array([0.9, 0.2, 0.4])<br/>b = 1.0<br/>e = np.exp(a/b) |\r\n\r\n     3. model.predict(x):\r\n\r\n        * 예측(predict): model.predict(x) = > [0.01, 0.005, 0.3, 0.8 ...]\r\n\r\n     4. 문자 추출:\r\n\r\n        ```python\r\n        sys.stdout.write(pred_char)\r\n        sys.stdout.flush()\r\n        ```\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `DMN`\r\n\r\n* Dynamic Memory Networks\r\n\r\n  * 아래 5가지의 N/W가 결합되어 있는 모습\r\n\r\n  1. `Input Module`\r\n  2. `Question Module`\r\n  3. `Episodic Memory Module`\r\n  4. `Answer Module`\r\n  5. **`attention score N/W`** (FNN)<br>\r\n\r\n### `Ask Me Anything`\r\n\r\n* Q → A: Question & Answering\r\n\r\n* DL 사용\r\n  \r\n* 논문 저자는 GRU 사용\r\n  \r\n* 특징: Q&A를 기억하는 하나의 경험 단위인 Episode를 기억하는 장치가 있다.\r\n\r\n* [x] 순서:\r\n\r\n  1. Input 문장(text sequence)과 \r\n  2. attention 연산이 들어간 question 받아 \r\n     * attention 연산: attention score\r\n  3. episodic memory 구성한 후, \r\n  4. 일반적인 답변을 줄 수 있게끔 구성한 네트워크\r\n\r\n  * ![image-20200731122306179](markdown-images/image-20200731122306179.png)\r\n\r\n    > 출처: Ankit Kumar외, 2016.05, Ask Me Anything: Dynamic Memory Networks for Natural Language Processing. 에서 'attention score' 추가<br>\r\n\r\n* [x] **attention process**\r\n\r\n* attention score 계산\r\n\r\n  * attention score\r\n  * 여러 문장에 Epsodic stroy가 있고 이것에 대한 답을 찾을 때 질문과 가장 관련이 높은 (저장된) 문장에 점수를 매기기 위한 계산을 수행함 \r\n  * 즉, 답을 내기 위해 어떤 문장에 attention을 해야 하는지 attention score로 계산하는 알고리즘\r\n\r\n* 기계번역, test 분류, part-of-speech tagging, image captioning, Dialog system(chatbot) 가능\r\n\r\n* mission: 주어진 Question의 의미를 파악할 수 있도록 네트워크를 구성해야 한다.\r\n\r\n  * '의미를 파악할 수 있도록' : 조응어(Anaphora resolution) 해석.\r\n\r\n  <br>\r\n\r\n* [x] `input module` = story module\r\n\r\n  1. Input에 넣을 문장들을 1행으로 붙이고, [EOS] 로 구분\r\n\r\n     | 문장 1                          |        | 문장 2                    |        | 문장3                                             |\r\n     | ------------------------------- | ------ | ------------------------- | ------ | ------------------------------------------------- |\r\n     | When I was young, I passed test | \\<EOS> | But, Now Test is so crazy | \\<EOS> | Because The test level pretty hard more and more. |\r\n\r\n  2. Embedding layer 투입\r\n\r\n  3. RNN 거쳐서\r\n\r\n  4. Hidden layer 출력은 다시 n개의 문장(c1, c2, c3 등)으로 출력\r\n\r\n  5. episodic memory module 투입\r\n\r\n<br>\r\n\r\n* [x] `Question module`\r\n  1. Question 문장 투입\r\n  2. Embedding layer 투입\r\n  3. RNN 거쳐서\r\n  4. episodic memory module 투입\r\n\r\n<br>\r\n\r\n* [x] `episodic memory module`\r\n\r\n  * input module(문장마다)+Question module+ atttention mechanism출력된 걸 반복해서 내부의 episodic memory를 반복 update\r\n\r\n  * \"어떻게 update?\"\r\n\r\n    1. input module의  embedding value과 atttention score 계산하여 RNN layer에 통과 시키기\r\n\r\n       * 이때, `atttention score`: \r\n         atttention score layer의 출력층에서 나온 w인`g`를 input module의 출력값인 c1,c2,c3 등과 계산한 값\r\n\r\n    2. Question module의 embedding value 값을 RNN layer에 통과 시키기\r\n\r\n       * 이때, w = `Q`\r\n\r\n    3. 2를 answer을 output할 Answer Module의 RNN layer에 통과 시킴\r\n\r\n       * 이때, w = `m`\r\n\r\n    4. episodic memory module의 RNN layer를 반복할 때마다 `attetion score `계산\r\n\r\n    5. 그렇게 해서 나온 attetion score 값 중 가장 높은 것(g) 찾음\r\n\r\n       > * `atttention mechanism`\r\n       >\r\n       > 1. 그렇게 해서 나온 attetion score 값 중 가장 높은 것(g) 찾고\r\n       > 2. g로 다시 네트워크 형성\r\n       >    * 2층 구조가 됨 \r\n       >\r\n       > * memory update mechanism\r\n       >   * attention score로 가중 평균\r\n\r\n<br>\r\n\r\n* 용어: \r\n\r\n  * `c`: Input의 출력\r\n  * `m`: episodic memory module 출력값이자 attention score의 입력값\r\n  * `q`: question layer의 출력값\r\n  * `g`: attention score의 출력값\r\n\r\n  <br>\r\n\r\n<br>\r\n\r\n### code:\r\n\r\n![image-20200812161218399](markdown-images/image-20200812161218399.png)\r\n\r\n* 순서\r\n\r\n  1. **패키지 불러오기 <br>**\r\n  2. **전처리**\r\n  * 2-1. Document Data processing(raw data)<br>\r\n  3. **데이터 불러오기**\r\n  * 3-1. Raw Document Data 불러오기 \r\n  * 3-2. train/test data split 해서 가져오기<br>\r\n  4. **vocab 만들기**\r\n    * 4-1. Train & Test data를 한꺼번에 묶어서 vocab을 만듦\r\n      * `collections.Counter()`\r\n    * 4-2. word2indx / indx2word 만듦\r\n      * `padding`<br>\r\n  5. **벡터화**\r\n    * 5-1. vocab_size 변수 설정\r\n      * `len(word2indx)`\r\n    * 5-2. story와 question 각각의 max len 변수 설정\r\n      * 뒤에서 padding 맞춰 주려고 max len 설정해줌\r\n    * 5-3. 벡터화 시킴\r\n      * `raw data`와 `word2indx`, 각 모듈(story, question)의 `maxlen`을 함수에 넣어 `padding`, `categorical` 등을 진행함<br>\r\n  6. **모델 빌드**\r\n    * 6-1. train/test data split\r\n    * 이때, Xstrain, Xqtrain, Ytrain = `data_vectorization`(data_train, word2indx, story_maxlen, question_maxlen) 이고,\r\n      data_vectorization의 return 값은 \r\n      * `pad_sequences(Xs, maxlen=story_maxlen)`\r\n      * `pad_sequences(Xq, maxlen=question_maxlen)`\r\n      * `to_categorical(Y, num_classes=len(word2indx))`\r\n    * 6-2. Model Parameters 설정\r\n    * 6-3. Inputs\r\n    * 6-4. Story encoder embedding\r\n    * 6-5. Question encoder embedding\r\n    * 6-6. 모듈 만들어줌\r\n      * Question module는 위에서 만들어준 걸로 사용함\r\n        1. attention score layer\r\n           * **dot**으로 만듦\r\n        2. story module\r\n           * 이 layer는 story layer의 input에서 시작하여 question layer는 건너뛰고 또 다른 embedding layer를 거쳐, 추후에 dot layer와 add를 **해주려고 만듦**\r\n        3. episodic memory module\r\n           * dot한 layer와 바로 위의 story_encoder_c를 **add**해서 만들어지게 됨\r\n        4. answer module\r\n           * episodic memory layer(response) + quetion layer<br>\r\n  7. **compile**\r\n\r\n     > model = Model(inputs=**[story_input, question_input]**, outputs=output)\r\n     >\r\n     > * input에 story와 question 두 개 써줬단 것!<br>\r\n  8. **fit **\r\n  9. **loss plot**\r\n  10. **정확도 측정(predict)**\r\n  11. **적용**\r\n\r\n![image-20200803190130197](markdown-images/image-20200803190130197.png)\r\n\r\n<br>\r\n\r\n* 패키지 불러오기\r\n\r\n  ```python\r\n  import collections\r\n  import itertools\r\n  import nltk\r\n  import numpy as np\r\n  import matplotlib.pyplot as plt\r\n  import random\r\n  from tensorflow.keras.layers import Input, Dense, Activation, Dropout\r\n  from tensorflow.keras.layers import LSTM, Permute\r\n  from tensorflow.keras.layers import Embedding\r\n  from tensorflow.keras.layers import Add, Concatenate, Dot\r\n  from tensorflow.keras.models import Model\r\n  from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n  from tensorflow.keras.utils import to_categorical\r\n  ```\r\n\r\n<br>\r\n\r\n#### 전처리\r\n\r\n* Raw Document Data processing \r\n\r\n  ```python\r\n  # 문서 내용 예시 : 3문장의 story(episodic story)\r\n  # 현재까지 NLP는 한 문장 안에서 단어들의 의미를 파악하고 이를 통해 한 개의 문장을 분석하는 수준에 그쳐있다(step1 수준).\r\n  # 이때, episodic story는 '한 문장 안'이 아니라 문장 '간'의 단어들의 관계(=문장 간의 관계)를 파악하는 데에 의의가 있으며 따라서 매우 분석이 어렵다(이는 시의 영역이다. step2). 나아가 문단(Paragrape) 간의 관계까지 파악할 필요가 있다(이는 소설의 영역이다. step3).  \r\n  \"\"\"\r\n  data 생김새\r\n  # 1 Mary moved to the bathroom.\\n\r\n  # 2 Daniel went to the garden.\\n\r\n  # 3 Where is Mary?\\tbathroom\\t1 \r\n  \"\"\"\r\n  ## Question과 answer은 #\\t : tab 으로 구분되어 있다.\r\n  # Return: # 3개(Stories, question, answer)를 return 해줌 \r\n  # Stories = ['Mary moved to the bathroom.\\n', 'John went to the hallway.\\n']\r\n  # questions = 'Where is Mary? '\r\n  # answers = 'bathroom'\r\n  #----------------------------------------------------------------------------\r\n  def get_data(infile):\r\n      stories, questions, answers = [], [], []\r\n      story_text = []\r\n      fin = open(infile, \"r\") \r\n      for line in fin:\r\n          lno, text = line.split(\" \", 1)\r\n          if \"\\t\" in text: # >data 생김새<에서 \\t가 있는 3번을 말하는 것임 \r\n              question, answer, _ = text.split(\"\\t\") #\\t으로 구분해서 quetion과 answer 구분  # 숫자(ex:1)\r\n              stories.append(story_text) \r\n              questions.append(question)\r\n              answers.append(answer) # >data 생김새< 에서 3번의 \\t 앞의 answer문 \r\n              story_text = []\r\n          else:\r\n              story_text.append(text) # 사실상 해당 함수는 else 부터 시작하는 것. \r\n      fin.close()\r\n      return stories, questions, answers\r\n  ```\r\n\r\n<br>\r\n\r\n#### 데이터 불러오기\r\n\r\n* Raw Document Data 불러오기 \r\n\r\n  ```python\r\n  Train_File = \"./dataset/qa1_single-supporting-fact_train.txt\"\r\n  Test_File = \"./dataset/qa1_single-supporting-fact_test.txt\"\r\n  ```\r\n\r\n  <br>\r\n\r\n* get the data\r\n\r\n  ```python\r\n  data_train = get_data(Train_File) # 출력: stories, questions, answers\r\n  data_test = get_data(Test_File)\r\n  print(\"\\n\\nTrain observations:\",len(data_train[0]),\"Test observations:\", len(data_test[0]),\"\\n\\n\")\r\n  ```\r\n\r\n  > Train observations: 10000 Test observations: 1000 \r\n\r\n\r\n<br>\r\n\r\n#### vocab 만들기\r\n\r\n* Building Vocab dictionary from Train & Test data \r\n\r\n  * Train & Test data를 한꺼번에 묶어서 vocab을 만듦 \r\n\r\n  ```python\r\n  dictnry = collections.Counter() # collections.Counter() 이용하여 단어들이 사용된 count 조회할 예정 \r\n  for stories, questions, answers in [data_train, data_test]:\r\n      for story in stories:\r\n          for sent in story:\r\n              for word in nltk.word_tokenize(sent):\r\n                  dictnry[word.lower()] +=1\r\n      for question in questions:\r\n          for word in nltk.word_tokenize(question):\r\n              dictnry[word.lower()]+=1\r\n      for answer in answers:\r\n          for word in nltk.word_tokenize(answer):\r\n              dictnry[word.lower()]+=1\r\n  ```\r\n\r\n* word2indx / indx2word 만듦\r\n\r\n  ```python\r\n  # collections.Counter()과 구조는 같은데, 단어 index는 1부터 시작하게 바꿔줌.  \r\n  word2indx = {w:(i+1) for i,(w,_) in enumerate(dictnry.most_common())} \r\n  word2indx[\"PAD\"] = 0 # padding\r\n  indx2word = {v:k for k,v in word2indx.items()} \r\n  # 위에서 word2indx[\"PAD\"] 해줘서 print(indx2word) 하면, 맨 마지막에 ',0: 'PAD'' 가 들어가 있다. \r\n  ```\r\n\r\n<br>\r\n\r\n#### 벡터화\r\n\r\n* `vocab_size` 변수 설정\r\n\r\n  ```python\r\n  vocab_size = len(word2indx) # vocab_size = 22 -> 즉 21개 단어만이 쓰인 것(하나는 패딩)\r\n  print(\"vocabulary size:\",len(word2indx))\r\n  print(word2indx)\r\n  ```\r\n\r\n  > * vocabulary size: 22\r\n  > * {'to': 1, 'the': 2, '.': 3, 'where': 4, 'is': 5, '?': 6, 'went': 7, 'john': 8, 'sandra': 9, 'mary': 10, 'daniel': 11, 'bathroom': 12, 'office': 13, 'garden': 14, 'hallway': 15, 'kitchen': 16, 'bedroom': 17, 'journeyed': 18, 'travelled': 19, 'back': 20, 'moved': 21, 'PAD': 0}<br>\r\n\r\n* story와 question 각각의 `max len` 변수 설정\r\n\r\n  ```python\r\n  story_maxlen = 0\r\n  question_maxlen = 0\r\n  \r\n  for stories, questions, answers in [data_train, data_test]:\r\n      for story in stories:\r\n          story_len = 0\r\n          for sent in story:\r\n              swords = nltk.word_tokenize(sent)\r\n              story_len += len(swords)\r\n          if story_len > story_maxlen:\r\n              story_maxlen = story_len # story 중 가장 긴 문장 찾기(=단어가 가장 많은 거)\r\n              \r\n      for question in questions:\r\n          question_len = len(nltk.word_tokenize(question))\r\n          if question_len > question_maxlen: \r\n              question_maxlen = question_len # question 중 가장 긴 문장 찾기 \r\n              \r\n  print (\"Story maximum length:\", story_maxlen, \"Question maximum length:\", question_maxlen)\r\n  ```\r\n\r\n  > Story maximum length: 14 Question maximum length: 4<br>\r\n\r\n* Converting data into `Vectorized` form \r\n\r\n  * 위의 문장을 수치화함\r\n\r\n  ```python\r\n  def data_vectorization(data, word2indx, story_maxlen, question_maxlen):  \r\n      Xs, Xq, Y = [], [], []\r\n      stories, questions, answers = data\r\n      for story, question, answer in zip(stories, questions, answers):\r\n          xs = [[word2indx[w.lower()] for w in nltk.word_tokenize(s)] for s in story] # vocab의 index로 단어를 표시한다(수치화한다)\r\n          xs = list(itertools.chain.from_iterable(xs)) # chain.from_iterable(['ABC', 'DEF']) --> ['A', 'B', 'C', 'D', 'E', 'F']\r\n          xq = [word2indx[w.lower()] for w in nltk.word_tokenize(question)]\r\n          Xs.append(xs)\r\n          Xq.append(xq)\r\n          Y.append(word2indx[answer.lower()]) # Y = answer\r\n      return pad_sequences(Xs, maxlen=story_maxlen), pad_sequences(Xq, maxlen=question_maxlen),\\\r\n             to_categorical(Y, num_classes=len(word2indx))\r\n             # 가장 긴 문장(maxlen=story_maxlen))을 기준으로 문장의 길이를 통일시킨다. 이것보다 짧은 부분은 padding(0)으로 채움\r\n             # y: anwser이고, 여기선 한 단어로 나온다. 즉, 한 단어 = 숫자 1개 \r\n             # to_categorical: 안 쓰고 sparse categorical을 써도 ok \r\n  ```\r\n\r\n  > * 함수 data_vectorization() 中\r\n  >\r\n  > 1. xs = [[word2indx[w.lower()] for w in nltk.word_tokenize(s)] for s in story]\r\n  >\r\n  >    *xs* >\r\n  >    Out[19]: [[8, 7, 20, 1, 2, 13, 3], [10, 19, 1, 2, 17, 3]]\r\n  >    *story* >\r\n  >    Out[20]: ['John went back to the office.\\n', 'Mary travelled to the bedroom.\\n']\r\n  >\r\n  > 2. xs = list(itertools.chain.from_iterable(xs))\r\n  >    *xs* >\r\n  >    Out[22]: [8, 7, 20, 1, 2, 13, 3, 10, 19, 1, 2, 17, 3]\r\n  >\r\n  > 3. Xs.append(xs) 해줌으로써 \r\n  >    for문 통해서 output 된 것들을 list 형태로 축적해줌 \r\n  >\r\n  > 4. padding 해줌\r\n  >    pad_sequences(Xs, maxlen=story_maxlen) # story_maxlen = 14 \r\n  >    Out[31]: array([[ 0,  8,  7, 20,  1,  2, 13,  3, 10, 19,  1,  2, 17,  3]])\r\n  >\r\n  > * pad_sequences(Xs, maxlen=story_maxlen)\r\n  >   Out[31]: array([[ 0,  8,  7, 20,  1,  2, 13,  3, 10, 19,  1,  2, 17,  3]])\r\n  >\r\n  > * pad_sequences(Xq, maxlen=question_maxlen)\r\n  >   Out[32]: array([], shape=(0, 4), dtype=int32)\r\n  >\r\n  > * to_categorical(Y, num_classes=len(word2indx))\r\n  > Out[33]: array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)\r\n  >\r\n\r\n<br>\r\n\r\n#### 모델 빌드\r\n\r\n* train/test data split \r\n\r\n  ```python\r\n  Xstrain, Xqtrain, Ytrain = data_vectorization(data_train, word2indx, story_maxlen, question_maxlen)\r\n  Xstest, Xqtest, Ytest = data_vectorization(data_test, word2indx, story_maxlen, question_maxlen)\r\n  \r\n  print(\"Train story\",Xstrain.shape,\"Train question\", Xqtrain.shape,\"Train answer\", Ytrain.shape)\r\n  print( \"Test story\",Xstest.shape, \"Test question\",Xqtest.shape, \"Test answer\",Ytest.shape)\r\n  ```\r\n\r\n  > *print* > \r\n  > Train story (10000, 14) Train question (10000, 4) Train answer (10000, 22)\r\n  > Test story (1000, 14) Test question (1000, 4) Test answer (1000, 22)\r\n\r\n  <br>\r\n\r\n* Model Parameters 설정\r\n\r\n  ```python\r\n  EMBEDDING_SIZE = 128\r\n  LATENT_SIZE = 64\r\n  BATCH_SIZE = 64\r\n  NUM_EPOCHS = 40\r\n  ```\r\n\r\n<br>\r\n\r\n* Inputs\r\n\r\n  ```python\r\n  story_input = Input(shape=(story_maxlen,)) # story_maxlen = 14\r\n  question_input = Input(shape=(question_maxlen,))\r\n  ```\r\n\r\n  <br>\r\n\r\n* `Story encoder embedding`\r\n\r\n  ```python\r\n  story_encoder = Embedding(input_dim=vocab_size, # vocab_size: 22\r\n                            output_dim=EMBEDDING_SIZE, # EMBEDDING_SIZE* = 128(한 단어를 128개의 vector로 표시, embedding layer의 colum 담당)\r\n                            input_length=story_maxlen)(story_input) # story_maxlen = 14\r\n  story_encoder = Dropout(0.2)(story_encoder)\r\n  ```\r\n\r\n  <br>\r\n\r\n* `Question encoder embedding`\r\n\r\n  ```python\r\n  question_encoder = Embedding(input_dim=vocab_size,\r\n                               output_dim=EMBEDDING_SIZE,\r\n                               input_length=question_maxlen)(question_input)\r\n  question_encoder = Dropout(0.3)(question_encoder)\r\n  ```\r\n\r\n<br><br>\r\n\r\n##### `attention score layer`\r\n\r\n* attention score layer\r\n\r\n  ```python\r\n  match = Dot(axes=[2, 2])([story_encoder, question_encoder]) \r\n  ```\r\n\r\n  > * Match between story and question: story and question를 dot 연산 수행.\r\n  >   * 여기서 dot 연산은 attention score로 사용함 \r\n  > * story_encoder = [None, 14, 128], question_encoder = [None, 4, 128]\r\n  >   * match = [None, 14, 4]\r\n  > * axes=[2, 2]?  story D2(=128 = embedding vector)와 question D2(=128 = embedding vector)를 dot 해라\r\n  >   * 즉, (x, 128)과 (128,y)로 한쪽을 transpose 시켜서 연산 수행\r\n  > * 우선 story input의 embedding layer의 출력은 story_encoder = (None, 한 story에 사용된 최대 단어 개수(=14), embedding vector(128)) 이다. \r\n  > * question input의 embedding layer의 출력은 question_encoder = (None, 한 question에 사용된 최대 단어 개수(=14), embedding vecotr(128)) 이다. \r\n  > * dot -> (None)을 빼고 (row, colum)끼리(=14, 128)과 (128, 14)가 연산 수행 \r\n\r\n<br><br>\r\n\r\n##### `story layer`\r\n\r\n* story layer\r\n\r\n  ```python\r\n  story_encoder_c = Embedding(input_dim=vocab_size, # vocab_size = 22\r\n                              output_dim=question_maxlen, # question_maxlen = 4 \r\n                              input_length=story_maxlen)(story_input) # story_maxlen = 14 \r\n  \r\n  story_encoder_c = Dropout(0.3)(story_encoder_c) # story_encoder_c.shap=(14, 4)\r\n  ```\r\n\r\n  > * 이 layer는 story layer의 input에서 시작하여 question layer는 건너뛰고 또 다른 embedding layer를 거쳐, 추후에 dot layer와 add를 하게 됨  \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n##### `episodic memory layer`\r\n\r\n* episodic memory layer\r\n\r\n  ```python\r\n  response = Add()([match, story_encoder_c]) # dot한 layer와 바로 위의 story_encoder_c를 add함 => (14, 4)\r\n  response = Permute((2, 1))(response) # 결론 shape = (4, 14) # Permute((2, 1)): (D2, D1)으로 transpose. permute가 transpose보다 더 축이동이 자유로움 \r\n  ```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n##### `answer layer`\r\n\r\n* episodic memory layer(response) + quetion layer\r\n\r\n  ```python\r\n  answer = Concatenate()([response, question_encoder])\r\n  answer = LSTM(LATENT_SIZE)(answer) # LATENT_SIZE = 64\r\n  answer = Dropout(0.2)(answer)\r\n  answer = Dense(vocab_size)(answer) # shape=(None, 22) # 마지막 dense는 vocab_size=22(단어들의 총 개수)로!\r\n  output = Activation(\"softmax\")(answer) # shape=(None, 22)\r\n  ```\r\n\r\n<br>\r\n\r\n\r\n##### compile\r\n\r\n* 모델 빌드 마지막\r\n\r\n  ```python\r\n  model = Model(inputs=[story_input, question_input], outputs=output) # 합쳤으니 input을 []로 써주는 것 \r\n  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\") # 처음에 to_categorial 안 해줬으면 loss=\"sparse_categorical_crossentropy\" 해야함 \r\n  print (model.summary())\r\n  ```\r\n\r\n<br>\r\n\r\n\r\n##### fit\r\n\r\n* 모델 학습\r\n\r\n  ```python\r\n  # Model Training\r\n  history = model.fit([Xstrain, Xqtrain], [Ytrain], # Ytrain: answer\r\n                      batch_size = BATCH_SIZE, \r\n                      epochs = NUM_EPOCHS,\r\n                      validation_data=([Xstest, Xqtest], [Ytest])) # ytest??? fit 하면 0,0,0 이던 게 13,14 등지로 바뀜\r\n  ```\r\n\r\n  > * Ytest.shape\r\n  >   Out[78]: (1000, 22)\r\n  > * Ytest\r\n  >   Out[79]: \r\n  >   array([[0., 0., 0., ..., 0., 0., 0.],\r\n  >          [0., 0., 0., ..., 0., 0., 0.],\r\n  >          [0., 0., 0., ..., 0., 0., 0.],\r\n  >          ...,\r\n  >          [0., 0., 0., ..., 0., 0., 0.],\r\n  >          [0., 0., 0., ..., 0., 0., 0.],\r\n  >          [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\r\n  >\r\n  > * ytest.shape\r\n  >   Out[87]: (1000,)\r\n  > * ytest\r\n  >   Out[92]: \r\n  >   array([15, 12, 16, 15, 16, 15, 14 ... ])\r\n\r\n<br>\r\n\r\n#### loss plot\r\n\r\n* loss plot\r\n\r\n  ```python\r\n  plt.title(\"Episodic Memory Q & A Loss\")\r\n  plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\r\n  plt.plot(history.history[\"val_loss\"], color=\"r\", label=\"validation\")\r\n  plt.legend(loc=\"best\")\r\n  plt.show()\r\n  ```\r\n\r\n<br>\r\n\r\n\r\n#### 정확도 측정\r\n\r\n* get predictions of labels\r\n\r\n  ```python\r\n  ytest = np.argmax(Ytest, axis=1)\r\n  Ytest_ = model.predict([Xstest, Xqtest])\r\n  ytest_ = np.argmax(Ytest_, axis=1)\r\n  ```\r\n\r\n<br>\r\n\r\n#### 적용\r\n\r\n* 적용\r\n\r\n  * Select Random questions and predict answers\r\n\r\n  ```python\r\n  NUM_DISPLAY = 10\r\n     \r\n  for i in random.sample(range(Xstest.shape[0]),NUM_DISPLAY):\r\n      story = \" \".join([indx2word[x] for x in Xstest[i].tolist() if x != 0])\r\n      question = \" \".join([indx2word[x] for x in Xqtest[i].tolist()])\r\n      label = indx2word[ytest[i]]\r\n      prediction = indx2word[ytest_[i]]\r\n      print(story, question, label, prediction)\r\n  ```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 출력층\r\n\r\n* 출력층이 0 or 1 처럼 하나일 때\r\n\r\n  * Binary classification. 따라서 sigmoid - binary-crossentropy 사용\r\n\r\n  * | y    | yHat |\r\n    | ---- | ---- |\r\n    | 0    | 0    |\r\n    | 0    | 1    |\r\n    | 1    | 1    |\r\n\r\n    > 정확도: 2/3<br>\r\n\r\n* 출력층이 두 개 이상 나올 때\r\n\r\n  * multi-classification. 따라서 softmax - categorical-crossentropy 사용\r\n\r\n  * one-hot 구조\r\n\r\n  * | y     | yHat  |\r\n    | ----- | ----- |\r\n    | 0 1 0 | 0 1 0 |\r\n    | 0 0 1 | 0 1 0 |\r\n    | 1 0 0 | 1 0 0 |\r\n\r\n    > 정확도: 2/3<br>\r\n\r\n* 출력층에 '1'이 여러 개인 구조. one-hot 구조가 아닐 때\r\n\r\n  * multi-labeled classification. 따라서 sigmoid - binary-crossentropy 사용\r\n\r\n  * 입력 뉴런 각각에 대해 binary-classification 해야 함\r\n\r\n  * | y     | yHat  |\r\n    | ----- | ----- |\r\n    | 0 1 0 | 0 1 0 |\r\n    | 0 0 1 | 0 1 0 |\r\n    | 1 0 0 | 1 0 0 |\r\n\r\n    > 정확도: 9개 중 7개 맞춤.  따라서 7/9\r\n    >\r\n    > * 위에처럼 row 전체가 다 맞았을 때 맞았다고 보는 게 아니고, row+colum으로 각각 개별로 봄 <br>\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고: \r\n\r\n  >* 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  >* 코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘\r\n  >\r\n  >* https://frhyme.github.io/python-libs/ML_multilabel_classfication/\r\n\r\n","excerpt":"NLP 분야에서 딥러닝의 고급 응용 DMN Ask Me Anything attention score layer story layer episodic memory layer answer layer 텍스트 자동 생성 예제 문장: I love you…","fields":{"slug":"/NLP응용_4/"},"frontmatter":{"date":"Aug 05, 2020","title":"NLP Ask Me Anything","tags":["NLP","attention","ask_me_anything"],"update":"Aug 18, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# one-hot 인코딩\r\n\r\n* categorical 변환 방법\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `keras`\r\n\r\n* Keras를 이용한 one-hot encoding\r\n\r\n  ```python\r\n  data = ['남자', '여자', '아빠', '엄마', '삼촌', '이모']\r\n  values = np.array(data)\r\n  print(values)\r\n  print(sorted(values))\r\n  ```\r\n\r\n  > ['남자' '여자' '아빠' '엄마' '삼촌' '이모']\r\n  > ['남자', '삼촌', '아빠', '엄마', '여자', '이모']\r\n\r\n  <br>\r\n  \r\n  ```python\r\n  from tensorflow.keras.utils import to_categorical\r\n  encoded = to_categorical(integer_encoded)\r\nprint(encoded)\r\n  ```\r\n  \r\n  > [[1. 0. 0. 0. 0. 0.]\r\n  >  [0. 0. 0. 0. 1. 0.]\r\n  >  [0. 0. 1. 0. 0. 0.]\r\n  >  [0. 0. 0. 1. 0. 0.]\r\n  >  [0. 1. 0. 0. 0. 0.]\r\n  >  [0. 0. 0. 0. 0. 1.]]\r\n\r\n<br>\r\n\r\n## `sklearn`\r\n\r\n* sklearn의 preprocessing을 이용한 one-hot encoding 방법\r\n\r\n  ```python\r\ndata = ['남자', '여자', '아빠', '엄마', '삼촌', '이모']\r\n  values = np.array(data)\r\n  print(values)\r\n  print(sorted(values))\r\n  ```\r\n  \r\n  > ['남자' '여자' '아빠' '엄마' '삼촌' '이모']\r\n  > ['남자', '삼촌', '아빠', '엄마', '여자', '이모']\r\n\r\n  <br>\r\n\r\n  * label 인코딩 필요\r\n\r\n  ```python\r\n  import sklearn.preprocessing as sk\r\n  \r\n  label_encoder = sk.LabelEncoder()\r\n  integer_encoded = label_encoder.fit_transform(values)\r\n  print(integer_encoded)\r\n  ```\r\n  \r\n  > [[0]\r\n  >  [4]\r\n\t>  [2]\r\n\t>  [3]\r\n\t>  [1]\r\n\t>  [5]]\r\n\t\r\n\t<br>\r\n\t\r\n\t* OneHotEncoding\r\n\t\r\n\t```python\r\n\t# integer encoding\r\n\tprint(integer_encoded)\r\n\t\r\n\t# binary encoding\r\n\tinteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\r\n\tonehot_encoder = sk.OneHotEncoder(sparse=False, categories='auto')\r\n\tonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\r\n\tprint(onehot_encoded)\r\n\t```\r\n\t> [[1. 0. 0. 0. 0. 0.]\r\n\t>  [0. 0. 0. 0. 1. 0.]\r\n\t>  [0. 0. 1. 0. 0. 0.]\r\n\t>  [0. 0. 0. 1. 0. 0.]\r\n\t>  [0. 1. 0. 0. 0. 0.]\r\n\t>  [0. 0. 0. 0. 0. 1.]]\r\n\t\r\n\t<br>\r\n\r\n\r\n* 단점: OOV 문제\r\n  * 해결을 위한 노력: 페이스북의 FastText\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n--------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n# `Hash`\r\n\r\n<br>\r\n\r\n## Indexing \r\n\r\n* 예) 견출지\r\n* SQL의 내부 알고리즘\r\n* 단점: 견출지 붙일 때, 몇 장마다 붙일지 미리 정해야 됨\r\n  \r\n  * Key의 범위가 넓다면 Memory 비효율성\r\n* 장점: 나중에 찾을 때, 빠르다\r\n  \r\n* 검색 속도는 빠르다\r\n  \r\n    <br>\r\n\r\n\r\n## Hashing\r\n\r\n* 예) apple이란 단어를 수치변환하여 84 page의 36번째 line에 기록한다\r\n* 다른 단어를 입력할 때, apple에 적용했던 방법을 답습하여 손쉽게 기록할 수 있다\r\n* 단점: collision 발생\r\n  * apple과 tiger 단어가 우연히 같은 line에 기록될 수 있다. \r\n  * 단점 해결: overflow 처리\r\n* 장점: 메모리 효율성\r\n  * 특히 넓은 key 영역에서 효율적이다.\r\n\r\n<br>\r\n\r\n## Hashing을 단어 표현에 적용\r\n\r\n* Hashing trick을 위한 word emgedding 방법\r\n  * vocabulary 크기를 미리 지정(hash table)하고, 단어들을 hash table에 대응 시키는 방식\r\n\r\n* hash('apple') or md5('apple') % 8 = 1\r\n  * '% 8' : 모듈러 연산을 취해준다\r\n  * '1' : vetor화 시킨 것 => 1번째 line에 있다\r\n\r\n* 현업에선 \"collision 발생 확률을 몇 프로로 줄이기 위해 hash table의 크기를 몇으로 둘 것인가?\" 에 관해 논의 후 설계하기도 함\r\n\r\n* code: 3-2. hashing_trick.py\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n----------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n# 카운트 기반 방법(`Co-occurrence matrix`)\r\n\r\n* Co-occurrence matrix: 동시 발생(출현) 행렬\r\n* 같이 쓰인 횟수(인접 사용한 횟수)를 matrix에 기록하는 것 \r\n* 학습 기반이 아닌 **빈도 기반**의 단어들 간의 관계 정보(단어 간 유사도)를 내포하고 있다.\r\n* 모든 단어를 vocabulary라고 할 때, one-hot의 size(개수) = vocabulary의 size(개수) = 단어 벡터\r\n* one-hot 인코딩이 아니다.\r\n  * 예) 0 0 0  2 1 0 0 0 \r\n* 대칭 행렬, 희소 행렬('0'이 많음)\r\n* 긴 단어일수록 차원이 크다\r\n  * SVD(특이값 분해)를 사용해 단어 벡터의 차원을 줄일 수 있다.\r\n    * 약 25% 정도 줄일 수 있다.\r\n    * vocab 사이즈를 줄이고 embedding layer에 쓴 것처럼.<br>\r\n* (Documnet Term Freq 2개) Xt와 X의 곱행렬을 하면, 일일이 빈도를 구하지 않아도 문장 간 공통된 단어가 쓰인 횟수를 행렬로 만들 수 있다.\r\n  * 그렇게 만들어진 행렬이 Co-occurrence matrix<br>\r\n* Unigram(1단어), Bigram(2단어)까지 vocab을 만들 수 있다.\r\n  * 조합이 더 많아진다.<br>\r\n* Glove: \r\n  * 아래 2개의 단점을 고려해 장점을 합친 것 \r\n  * Co-occurrence matrix: (빈도 기반) 전체 단어를 고려했다.\r\n  * Skip-gram: (학습 기반)주변 단어에 한정했다.\r\n  * 두 단어를 Embedding layer에 통과시키고(학습기반) 각 vector의 내적의 합(빈도기반)을 구해 거리를 구한다.\r\n    * log(P(도서관, 갔다)) = 0.33 \r\n    * 기계 : 도서관은... 가는 곳이다.... 라고 기계가 인식함 <br>\r\n* 단점: 계산량이 많다\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `특이값 분해(SVD: 차원축소)` code\r\n\r\n> * LSA : 잠재 의미 분석 \r\n>   * U, S, VT 행렬의 의미 --> Latent Semantic Analysis (LSA)\r\n>   * U 행렬 ~ 차원 = (문서 개수 X topic 개수) : 문서당 topic 분포\r\n>   * S 행렬 ~ 차원 = (topic 개수 X topic 개수) : 대각성분. 나중에 행렬에 넣을 땐 대각성분만 빼면 0\r\n>   * VT 행렬. 차원 = (topic 개수 X 단어 개수) : topic 당 단어 빈도의 분포\r\n>\r\n> => 이를 여기선 **문장과 단어 사이의 관계로 해석**\r\n\r\n<br>\r\n\r\n* ![image-20200722094819751](image-20200722094819751.png)\r\n\r\n  <br>\r\n\r\n```py\r\nfrom sklearn.feature_extraction.text import CountVectorizer\r\n```\r\n\r\n```python\r\ndocs = ['성진과 창욱은 야구장에 갔다',\r\n        '성진과 태균은 도서관에 갔다',\r\n        '성진과 창욱은 공부를 좋아한다']\r\n```\r\n\r\n<br>\r\n\r\n* Vocab 만들기 \r\n\r\n```python\r\ncount_model = CountVectorizer(ngram_range=(1,1)) # gram_range=(1,1): Unigram 단어 1개씩 동시 발생. # CountVectorizer: 문장의 단어를 단어 하나씩 자른단 뜻 \r\nx = count_model.fit_transform(docs)\r\n```\r\n\r\n<br>\r\n\r\n* 문서에 사용된 사전을 조회한다.\r\n\r\n```python\r\nprint(count_model.vocabulary_)\r\n```\r\n\r\n> {'성진과': 3, '창욱은': 6, '야구장에': 4, '갔다': 0, '태균은': 7, '도서관에': 2, '공부를': 1, '좋아한다': 5}\r\n\r\n<br>\r\n\r\n* Compact Sparse Row(CSR) format: 단어별 빈도를 표현한다.\r\n\r\n```python\r\n# (row, col) value\r\nprint(x)\r\n```\r\n\r\n>   (0, 3)\t1\r\n>   (0, 6)\t1\r\n>   (0, 4)\t1\r\n>   (0, 0)\t1\r\n>   (1, 3)\t1\r\n>   (1, 0)\t1\r\n>   (1, 7)\t1\r\n>   (1, 2)\t1\r\n>   (2, 3)\t1\r\n>   (2, 6)\t1\r\n>   (2, 1)\t1\r\n>   (2, 5)\t1\r\n\r\n<br>\r\n\r\n* 행렬 형태로 표시한다. (Document-Term Freq)\r\n\r\n```python\r\nprint(x.toarray())\r\nprint()\r\nprint(x.T.toarray())\r\n```\r\n\r\n> *print(x.toarray())* >\r\n>\r\n> [[1 0 0 1 1 0 1 0]\r\n>  [1 0 1 1 0 0 0 1]\r\n>  [0 1 0 1 0 1 1 0]]\r\n\r\n> *print(x.T.toarray())* >\r\n>\r\n> [[1 1 0]\r\n>  [0 0 1]\r\n>  [0 1 0]\r\n>  [1 1 1]\r\n>  [1 0 0]\r\n>  [0 0 1]\r\n>  [1 0 1]\r\n>  [0 1 0]]\r\n>\r\n> * x.T의 의미 > \r\n>   \t\t\t   1 2 3  - 문장\r\n>   갔다    [[1 1 0] - '갔다'라는 단어는 문장-1과 문장-2에 쓰였음.\r\n>   공부를   [0 0 1] - '공부를'은 문장-3에만 쓰였음.\r\n>   도서관에 [0 1 0]\r\n>   성진과   [1 1 1]\r\n>   야구장에 [1 0 0]\r\n>   좋아한다 [0 0 1]\r\n>   창욱은   [1 0 1]\r\n>   태균은   [0 1 0]]\r\n\r\n<br>\r\n\r\n```python\r\nxc = x.T * x # this is co-occurrence matrix in sparse csr format\r\nxc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\r\nprint(xc.toarray())\r\n```\r\n\r\n> |            | 0<br />갔다 | 1<br />공부를 | 2<br />도서관에 | 3<br />성진과 | 4<br />야구장에 | 5<br />좋아한다 | 6<br />창욱은 | 7<br />태균은 |\r\n> | ---------- | ----------- | ------------- | --------------- | ------------- | --------------- | --------------- | ------------- | ------------- |\r\n> | 0 갔다     | 0           | 0             | 1               | 2             | 1               | 0               | 1             | 1             |\r\n> | 1 공부를   | 0           | 0             | 0               | 1             | 0               | 1               | 1             | 0             |\r\n> | 2 도서관에 | 1           | 0             | 0               | 1             | 0               | 0               | 0             | 1             |\r\n> | 3 성진과   | 2           | 1             | 1               | 0             | 1               | 1               | 2             | 1             |\r\n> | 4 야구장에 | 1           | 0             | 0               | 1             | 0               | 0               | 1             | 0             |\r\n> | 5 좋아한다 | 0           | 1             | 0               | 1             | 0               | 0               | 1             | 0             |\r\n> | 6 창욱은   | 1           | 1             | 0               | 2             | 1               | 1               | 0             | 0             |\r\n> | 7 태균은   | 1           | 0             | 1               | 1             | 0               | 0               | 0             | 0             |\r\n\r\n<br>\r\n\r\n* *참고* > ngram_range(min_n = 1, max_n = 2)인 경우\r\n\r\n  * 즉,  ngram_range=(1,2):unigram과 bigram 둘다 동시에 조회하는 경우\r\n\r\n    <br>\r\n\r\n* \t```python\r\n    count_model = CountVectorizer(ngram_range=(1,2))\r\n    x = count_model.fit_transform(docs)\r\n    \r\n    # 문서에 사용된 사전을 조회\r\n    print(count_model.vocabulary_)\r\n      \r\n\txc = x.T * x # this is co-occurrence matrix in sparse csr format\r\n\txc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\r\n\tprint(xc.toarray())\r\n\t```\r\n\t\r\n\t  > {'성진과': 5, '창욱은': 11, '야구장에': 8, '갔다': 0, '성진과 창욱은': 6, '창욱은 야구장에': 13, '야구장에 갔다': 9, '태균은': 14, '도서관에': 3, '성진과 태균은': 7, '태균은 도서관에': 15, '도서관에 갔다': 4, '공부를': 1, '좋아한다': 10, '창욱은 공부를': 12, '공부를 좋아한다': 2}\r\n\t\r\n\t> [[0 0 1 2 1 0 1 1]\r\n\t> [0 0 0 1 0 1 1 0]\r\n\t> [1 0 0 1 0 0 0 1]\r\n\t> [2 1 1 0 1 1 2 1]\r\n\t> [1 0 0 1 0 0 1 0]\r\n\t> [0 1 0 1 0 0 1 0]\r\n\t> [1 1 0 2 1 1 0 0]\r\n\t> [1 0 1 1 0 0 0 0]]\r\n\t\r\n\r\n<br>\r\n\r\n### *변수 정리* > x / x.T / xc\r\n\r\n* x: 단어별 빈도\r\n* x.T: Sparse 해주려고 x를 transpose함\r\n* xc : x와 x.T의 곱행렬이자, 처음에 쓸 땐 co-occurrence matrix 만들기 위한 csr 형태. \r\n  * 여기에 \r\n    1. xc.setdiag(0) 해주고, \r\n    2. xc.toarray() 해주면\r\n    3. co-occurrence matrix 완성\r\n\r\n  <br>\r\n\r\n### numpy를 이용한 SVD 예시\r\n\r\n* Co-occurrence matrix를 SVD로 분해한다.\r\n* C = **U** , **S**, **VT**\r\n\r\n```python\r\nimport numpy as np\r\nC = xc.toarray()\r\nU, S, VT = np.linalg.svd(C, full_matrices = True) # np.linalg.svd 써주면 U, S, VT로 자동 분배됨\r\nprint(np.round(U, 2), '\\n')\r\nprint(np.round(S, 2), '\\n')\r\nprint(np.round(VT, 2), '\\n')\r\n```\r\n\r\n>[[-0.44 -0.39 -0.58  0.41  0.35  0.   -0.   -0.19]\r\n> [-0.24 -0.12  0.29  0.41 -0.24  0.65 -0.29  0.35]\r\n> [-0.24 -0.12 -0.29 -0.41 -0.24 -0.29 -0.65  0.35]\r\n> [-0.56  0.8   0.   -0.    0.19  0.    0.    0.02]\r\n> [-0.27 -0.01 -0.   -0.   -0.7   0.   -0.   -0.66]\r\n> [-0.24 -0.12  0.29  0.41 -0.24 -0.65  0.29  0.35]\r\n> [-0.44 -0.39  0.58 -0.41  0.35 -0.    0.   -0.19]\r\n> [-0.24 -0.12 -0.29 -0.41 -0.24  0.29  0.65  0.35]] \r\n\r\n> [5.27 2.52 1.73 1.73 1.27 1.   1.   0.53] \r\n\r\n> [[-0.44 -0.24 -0.24 -0.56 -0.27 -0.24 -0.44 -0.24]\r\n>  [ 0.39  0.12  0.12 -0.8   0.01  0.12  0.39  0.12]\r\n>  [-0.    0.5  -0.5  -0.    0.    0.5  -0.   -0.5 ]\r\n>  [-0.71  0.   -0.    0.    0.    0.    0.71 -0.  ]\r\n>  [-0.35  0.24  0.24 -0.19  0.7   0.24 -0.35  0.24]\r\n>  [-0.   -0.65  0.29 -0.    0.    0.65  0.   -0.29]\r\n>  [-0.    0.29  0.65 -0.    0.   -0.29 -0.   -0.65]\r\n>  [-0.19  0.35  0.35  0.02 -0.66  0.35 -0.19  0.35]] \r\n\r\n<br>\r\n\r\n* S를 **정방행렬**로 바꾼다.\r\n  * S\r\n    * 정방행렬이므로, 같은 수의 행과 열을 가지는 행렬\r\n    * 대각행렬이므로, 대각 성분을 제외한 원소는 모두 0 인 행렬\r\n\r\n```python\r\ns = np.diag(S) # s는 대각행렬이자 정방행렬\r\nprint(np.round(s, 2))\r\n```\r\n\r\n> [[5.27 0.   0.   0.   0.   0.   0.   0.  ]\r\n>  [0.   2.52 0.   0.   0.   0.   0.   0.  ]\r\n>  [0.   0.   1.73 0.   0.   0.   0.   0.  ]\r\n>  [0.   0.   0.   1.73 0.   0.   0.   0.  ]\r\n>  [0.   0.   0.   0.   1.27 0.   0.   0.  ]\r\n>  [0.   0.   0.   0.   0.   1.   0.   0.  ]\r\n>  [0.   0.   0.   0.   0.   0.   1.   0.  ]\r\n>  [0.   0.   0.   0.   0.   0.   0.   0.53]]\r\n\r\n<br>\r\n\r\n* A = **U.s.VT**를 계산하고, **A와 C가 일치**하는지 확인한다.\r\n\r\n```python\r\nA = np.dot(U, np.dot(s, VT))\r\nprint(np.round(A, 1))\r\nprint(C)\r\n```\r\n\r\n> [[ 0.  0.  1.  2.  1.  0.  1.  1.]\r\n>  [-0.  0.  0.  1.  0.  1.  1.  0.]\r\n>  [ 1. -0.  0.  1.  0. -0.  0.  1.]\r\n>  [ 2.  1.  1.  0.  1.  1.  2.  1.]\r\n>  [ 1.  0. -0.  1.  0.  0.  1. -0.]\r\n>  [ 0.  1.  0.  1.  0. -0.  1.  0.]\r\n>  [ 1.  1.  0.  2.  1.  1.  0. -0.]\r\n>  [ 1. -0.  1.  1. -0. -0. -0.  0.]]\r\n\r\n> [[0 0 1 2 1 0 1 1]\r\n>  [0 0 0 1 0 1 1 0]\r\n>  [1 0 0 1 0 0 0 1]\r\n>  [2 1 1 0 1 1 2 1]\r\n>  [1 0 0 1 0 0 1 0]\r\n>  [0 1 0 1 0 0 1 0]\r\n>  [1 1 0 2 1 1 0 0]\r\n>  [1 0 1 1 0 0 0 0]]\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### sklearn을 이용한 SVD 예시\r\n\r\n* Co-occurrence matrix를 SVD로 분해한다.\r\n\r\n```python\r\nfrom sklearn.decomposition import TruncatedSVD\r\n```\r\n\r\n<br>\r\n\r\n* 특이값 (S)이 큰 4개를 주 성분으로 C의 차원을 축소한다. \r\n\r\n```python\r\nsvd = TruncatedSVD(n_components=4, n_iter=7)\r\nD = svd.fit_transform(xc.toarray()) # fit_transform : 학습 시키고 transpose도 한꺼번에 시킴 \r\n\r\nU = D / svd.singular_values_ # svd.singular_values_ : 대각 성분의 값 \r\nS = np.diag(svd.singular_values_) # np.diag: '대각행렬'로, 대각 성분의 값만을 행렬 형태로 추출한 것. 정방행렬의 형태를 띄고 있음 \r\nVT = svd.components_\r\n```\r\n\r\n> *print(np.round(U, 2), '\\n')* >\r\n>\r\n> [[ 0.44 -0.39  0.41 -0.58]\r\n>  [ 0.24 -0.12  0.41  0.29]\r\n>  [ 0.24 -0.12 -0.41 -0.29]\r\n>  [ 0.56  0.8  -0.    0.  ]\r\n>  [ 0.27 -0.01 -0.   -0.  ]\r\n>  [ 0.24 -0.12  0.41  0.29]\r\n>  [ 0.44 -0.39 -0.41  0.58]\r\n>  [ 0.24 -0.12 -0.41 -0.29]] \r\n\r\n> *print(np.round(S, 2), '\\n')* >\r\n>\r\n> [[5.27 0.   0.   0.  ]\r\n>  [0.   2.52 0.   0.  ]\r\n>  [0.   0.   1.73 0.  ]\r\n>  [0.   0.   0.   1.73]] \r\n\r\n> *print(np.round(VT, 2), '\\n')* >\r\n>\r\n> [[ 0.44  0.24  0.24  0.56  0.27  0.24  0.44  0.24]\r\n>  [ 0.39  0.12  0.12 -0.8   0.01  0.12  0.39  0.12]\r\n>  [-0.71  0.   -0.    0.    0.    0.    0.71 -0.  ]\r\n>  [-0.    0.5  -0.5  -0.    0.    0.5  -0.   -0.5 ]] \r\n\r\n<br>\r\n\r\n* C를 4개 차원으로 축소: truncated (U * S)\r\n  \r\n  * U * S * VT 하면 원래 C의 차원과 동일해 진다. \r\n  * U * S가 축소된 차원을 의미하고, \r\n  * V는 **축소된 차원을 원래 차원으로 되돌리는** 역할을 한다 (mapping back)\r\n  \r\n  ```python\r\n  print(np.round(D, 2))\r\n  ```\r\n\t> [[ 2.31 -0.97  0.71 -1.  ]\r\n\t>   [ 1.24 -0.3   0.71  0.5 ]\r\n\t>   [ 1.24 -0.3  -0.71 -0.5 ]\r\n\t>   [ 2.97  2.03 -0.    0.  ]\r\n\t>   [ 1.44 -0.03 -0.   -0.  ]\r\n\t>   [ 1.24 -0.3   0.71  0.5 ]\r\n\t>   [ 2.31 -0.97 -0.71  1.  ]\r\n\t>   [ 1.24 -0.3  -0.71 -0.5 ]]\r\n\r\n<br>\r\n\r\n### *변수 정리* > C / D / Vt\r\n\r\n* 원래 행렬: C\r\n* 차원축소: D = U*S\r\n  * 이때, U, S는 중요한 부분만 추림 U(truncated), S(truncated))\r\n* Vt = S를 기준으로 Vt를 truncated함 \r\n\r\n<br>\r\n\r\n### `SVD` : Numpy & sklearn 비교\r\n\r\n* Co-occurrence matrix를 SVD로 분해\r\n* 여기서 말하는 '차원 축소': 한 문장 내 다른 문장과 쓰이는 중요 단어만 추출함\r\n\r\n|      | Numpy                                                        | sklearn                                                      |\r\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| Code | import numpy as np                                           | from sklearn.decomposition import TruncatedSVD               |\r\n|      | > **C = U.S.VT**<br />C = xc.toarray()<br/>U, S, VT = np.linalg.svd(C, full_matrices = True) | > **특이값 (S)이 큰 4개를 주 성분으로 C의 차원을 축소**<br />svd = TruncatedSVD(n_components=4, n_iter=7)<br/>D = svd.fit_transform(xc.toarray())<br />U = D / svd.singular_values_<br/>S = np.diag(svd.singular_values_)<br/>VT = svd.components_ |\r\n|      | > **S를 정방행렬로 바꾼다.**<br/>s = np.diag(S)              |                                                              |\r\n|      | > **A = U.s.VT를 계산하고, A와 C가 일치하는지 확인**<br/>A = np.dot(U, np.dot(s, VT)) |                                                              |\r\n| 특징 | 알아서 주성분을 추출해 차원 축소할 수 있다.                  | 원하는 수의 주성분으로 차원을 축소할 수 있다.                |\r\n\r\n> - U * S * VT 하면 원래 C의 차원과 동일해 진다. \r\n> - U * S가 축소된 차원을 의미하고, \r\n> - V는 **축소된 차원을 원래 차원으로 되돌리는** 역할(mapping back)을 한다\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n---------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n# 텍스트 유사도(거리 측정)\r\n\r\n<br>\r\n\r\n## Step 1. word의 vector화\r\n\r\n* `TfidfVectorizer` 사용\r\n\r\n```python\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\n\r\nsent = (\"휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다.\", \r\n        \"폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니다.\") \r\n\r\ntfidf_vectorizer = TfidfVectorizer()\r\ntfidf_matrix = tfidf_vectorizer.fit_transform(sent).toarray()\r\nprint(np.round(tfidf_matrix, 3))\r\n```\r\n\r\n> [[0.    0.324 0.    0.    0.324 0.324 0.324 0.324 0.324 0.324 0.    0.231\r\n>   0.324 0.231 0.    0.    0.231]\r\n>  [0.365 0.    0.365 0.365 0.    0.    0.    0.    0.    0.    0.365 0.259\r\n>\r\n>   0.    0.259 0.365 0.365 0.259]]\r\n\r\n<br>\r\n\r\n* `HashingVectorizer` 사용\r\n\r\n```python\r\nfrom sklearn.feature_extraction.text import HashingVectorizer\r\n\r\nsent = (\"휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다.\", \r\n        \"폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니다.\") \r\n\r\nVOCAB_SIZE = 20 # 사용자가 직접 지정해야 하는 값\r\nhvectorizer = HashingVectorizer(n_features=VOCAB_SIZE,norm=None,alternate_sign=False)\r\nhash_matrix = hvectorizer.fit_transform(sent).toarray()\r\nprint(hash_matrix)\r\n```\r\n\r\n> [[0. 2. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 2. 2. 0. 1. 0. 0. 0. 0.]\r\n>  [0. 2. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0.]]\r\n\r\n<br>\r\n\r\n## `자카드 유사도`\r\n\r\n* 문장 中 중복되는 단어의 개수를 센다.\r\n\r\n* 두 문장에 겹친 단어 개수 / 사전의 전체 단어 개수\r\n\r\n* code\r\n\r\n  * (수치화(vector)화 안 하고) 문장 간의 겹치는 단어만 세는 것도 가능하다.\r\n\r\n  ```python\r\n  sent_1 = set(sent[0].split())\r\n  sent_2 = set(sent[1].split())\r\n  print(sent_1)\r\n  print(sent_2)\r\n  \r\n  # 합집합과 교집합을 구한다.\r\n  hap_set = sent_1 | sent_2 # | : or\r\n  gyo_set = sent_1 & sent_2 # & : and\r\n  print(hap_set, '\\n')\r\n  print(gyo_set, '\\n')\r\n  \r\n  jaccard = len(gyo_set) / len(hap_set)\r\n  print(jaccard)\r\n  ```\r\n\r\n  > {'폭염', '있습니다.', '비', '휴일', '을'} \r\n\r\n  <br>\r\n\r\n  * (수치화(vector)화 하고) jaccard_score 패키지\r\n  \r\n  ```python\r\n  count_model = CountVectorizer(ngram_range=(1,1)) # bigram은 ngram_range=(1,2) : (from, to) = 1에서 2까지\r\n  x = count_model.fit_transform(sent).toarray()\r\n  \r\n  from sklearn.metrics import jaccard_score\r\njaccard_score(x[0], x[1])\r\n  ```\r\n  \r\n  > 0.17647058823529413\r\n\r\n<br>\r\n\r\n## `코사인 유사도`\r\n\r\n* 코사인 유사도는 클수록 유사도가 높다\r\n* 코사인 거리는 작을수록 거리가 좁다\r\n\r\n* code\r\n\r\n  ```python\r\n  from sklearn.metrics.pairwise import cosine_similarity\r\n  d = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\r\n  print(d)\r\n  ```\r\n\r\n  > [[0.17952266]]\r\n\r\n<br>\r\n\r\n## `유클리디안 거리`\r\n\r\n* L2 - Distance\r\n\r\n* code\r\n\r\n  ```python\r\n  from sklearn.metrics.pairwise import euclidean_distances\r\n  euclidean_distances(tfidf_matrix[0:1], tfidf_matrix[1:2])\r\n  ```\r\n\r\n  > array([[1.28099753]])\r\n\r\n<br>\r\n\r\n## `맨하탄 거리`\r\n\r\n* L1 - Distance\r\n\r\n* 유클리디안 거리와의 비교: 거리 값은 유클리디안 거리가 작게 나오지만, 대각선의 길을 선택할 수 있다는 건 현실성이 떨어지기 때문에 맨하탄 거리를 선택하는 경우도 있다. \r\n\r\n* code\r\n\r\n  ```python\r\n  from sklearn.metrics.pairwise import manhattan_distances\r\n  d = manhattan_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2])\r\n  ```\r\n\r\n  > [[0.77865927]]\r\n\r\n<br>\r\n\r\n## `정규화`(l1 & l2)\r\n\r\n* `l1`\r\n\r\n  * 유클리디안/맨하탄 거리는 '거리'라 값이 1이 넘어갈 수 있기 때문에 가시적인 효과를 위해 0~1 사이의 값을 갖도록 L1 정규화를 수행한 후, 각각의 유클리디안/맨하탄 거리를 수행할 수도 있다.\r\n\r\n  * 함수\r\n\r\n    ```python\r\n    def l1_normalize(v):\r\n         \t\treturn v / np.sum(v)\r\n      \r\n    \t\ttfidf_norm_l1 = l1_normalize(tfidf_matrix)\r\n    \t\td = euclidean_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2])\r\n    \t\tprint(d)\r\n    ```\r\n\r\n  * numpy 패키지\r\n\r\n    ```python\r\n    L1_norm = np.linalg.norm(x, axis=1, ord=1)\r\n    print(L1_norm)\r\n    ```\r\n\r\n  <br>\r\n\r\n* `l2 `\r\n\r\n  * l2 + HashingVectorizer 패키지\r\n\r\n    ```python\r\n    VOCAB_SIZE = 20\r\n    hvectorizer = HashingVectorizer(n_features=VOCAB_SIZE,norm='l2',alternate_sign=False)\r\n    hash_matrix = hvectorizer.fit_transform(sent).toarray()\r\n    print(np.round(hash_matrix, 3))\r\n    ```\r\n\r\n  * numpy 패키지\r\n\r\n  \t```python\r\n\timport numpy as np\r\n  \tL2_norm = np.linalg.norm(x, axis=1, ord=2)\r\n  \tprint( L2_norm)\r\n  \t```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고: \r\n\r\n  >* 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  >* 코드 출처 및 내용 공부: 전창욱, 최태균, 조중현. 2019.02.15. 텐서플로와 머신러닝으로 시작하는 자연어 처리 - 로지스틱 회귀부터 트랜스포머 챗봇까지. 위키북스\r\n\r\n","excerpt":"one-hot 인코딩 categorical 변환 방법  Keras를 이용한 one-hot encoding '남자' '여자' '아빠' '엄마' '삼촌' '이모'\n'남자', '삼촌', '아빠', '엄마', '여자', '이모' [1. 0. 0. 0.…","fields":{"slug":"/NLP한글_1/"},"frontmatter":{"date":"Aug 05, 2020","title":"NLP 카운트 기반 방법의 텍스트 유사도 측정","tags":["NLP","SVD","거리 측정"],"update":"Aug 18, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n<br>\r\n\r\n`JyneeEarth git blog`\r\n\r\n```batch\r\nML\r\nDL\r\nNLP\r\nContents\r\nJapanese\r\netc \r\n```\r\n\r\n<br>\r\n\r\n안녕하세요.\r\n\r\n이곳엔 다양한 포스팅이 올라옵니다.\r\n\r\n#태그로 동일 관심분야를 검색해주세요.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n> 안하면 모를테고, 하면 늘겠지\r\n\r\n싶은 마음으로 일단 파고들었던 모든 것들을 이곳에 올릴 예정입니다.\r\n\r\n<br>\r\n\r\n*이런 것까지...?* \r\n\r\n> \r\n\r\n이런 것까지... 올라올 거예요.\r\n\r\n<br>\r\n\r\n\r\n\r\nML/DL/NLP\r\n\r\n서비스기획\r\n\r\n콘텐츠\r\n\r\n","excerpt":"안녕하세요. 이곳엔 다양한 포스팅이 올라옵니다. 태그로 동일 관심분야를 검색해주세요. 안하면 모를테고, 하면 늘겠지 싶은 마음으로 일단 파고들었던 모든 것들을 이곳에 올릴 예정입니다. 이런 것까지...?  이런 것까지... 올라올 거예요. ML/DL…","fields":{"slug":"/main/"},"frontmatter":{"date":"Aug 02, 2020","title":"처음 방문했다면 블로그 소개를","tags":["1st"],"update":"Aug 22, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n# W(weights)\r\n\r\n* 네트워크 및 model build까지 완성해서 실행되어 역전파 되었을 때 형성된다.\r\n* `compile에서 w`: 네트워크 만들고 난 후 model build하는 과정. optimizer & loss 값을 정의해주는 부분임. w는 만들어져있지 않다.\r\n* `fit에서 w`: fit은 train data 사용. A 다음 B가 **나온다고 저장** \r\n* `predict에서 w`: predict(예측)는 test data 사용. 예측 모델 기준으로 A를 넣으면 B가 **나오게 하는** 어떤 것(Thing)\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n# Hyper parameter\r\n\r\n* `weight decay`(annealing): epoch(alpha)를 처음에는 적당히 높게 했다가, 점차 줄여 나가는 방법\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n# Dense\r\n\r\n* `Dense`: fully connected\r\n\r\n* `ANN(FNN)`에서는 여러 `Dense`를 써도 되지만, `RNN(LSTM)`에선 마지막 층에서만 `Dense`를 써야함.\r\n  * `CNN`에서는 여러 `Dense` 써도 될까?\r\n  * => 일단... `lstm`에서 `lstm() → Dense → lstm()`은 `lstm 네트워크가 2개` 만들어진다고 보면 된다. `lstm() → Dense` 했을 때, `1개의 네트워크`가 형성된 것\r\n  * => 그리고 `CNN`은 일종의 잘 짜여진 레시피라서 `con1D → pooling → Dense → con1D → pooling`은 위 `lstm`처럼 좀 이상한 네트워크 구조가 되는 거라 생각함...\r\n\r\n* Dense(1, activation='sigmoid')\r\n\r\n* **LSTM에서 FNN으로 보내는 마지막 Dense에선 relu 쓰면 안됨**\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n# FNN(순방향 신경망)\r\n\r\n* ↔ RNN\r\n\r\n* hidden 층에서\r\n\r\n  * Dense(4, `activation` = 'sigmoid', `kernel_regularizer`=regularizers.l2(0.0001), activation='relu')\r\n  * `Dropout`(rate=0.5)\r\n\r\n  <br>\r\n\r\n* `BatchNormalization`(momentum=0.9, epsilon=0.005, center=True, scale=True, moving_variance_initializer='ones')\r\n\r\n<br>\r\n\r\n* `predict`까지 끝낸 **연속형** `yHat` 값을, `np.where` 써줘서 **바이너리 형태**로 변환 \r\n\r\n  ``` python\r\n  np.where(yHat > 0.5, 1, 0)\r\n  # 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기_커스텀loss.py\r\n  ```\r\n\r\n<br>\r\n\r\n* `history` 활용\r\n\r\n  ```python\r\n  hist.history['loss']\r\n  hist.history['val_loss']\r\n  # 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기.py\r\n  ```\r\n\r\n<br>\r\n\r\n* 학습/평가/예측용 model로 나누었을 때 **평가 데이터 활용**\r\n\r\n  ```python\r\n  model.fit(trainX, trainY, validation_data=(evlX, evlY), epochs=200, batch_size=50)\r\n  ```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n\r\n# LSTM\r\n\r\n* long term(장기기억, 전체적 흐름), short term(단기기억, 최근의 흐름)\r\n\r\n* |                 | 설명                                                         |\r\n  | --------------- | ------------------------------------------------------------ |\r\n  | 2층             | `lstm()`을 2번 써준다                                        |\r\n  | 양방향          | `bidirectional` + `merge_mode = ‘concat’` <br />FNN, BFN 값을 merge_mode 형태로 합쳐서 list형으로 되돌려줌<br />단방향(FBN)은 ‘이후’만 기억, 양방향(FBN+BFN)은 ‘이전’+’이후’ 모두 기억 |\r\n  | many-to-many    | `return-sequences = True`<br />LSTM 뉴런 **각각의 중간 스텝에서 나오는 각각의 출력(h)**을 (바로 위 뉴런으로도) 사용(전파)한다는 뜻 |\r\n  | timedistributed | `timedistributed()`<br /> **FFN으로 가기 전** LSTM 마지막 층에서 각 뉴런의 각 지점에서 계산한 오류를 다음 층으로 전파 |\r\n\r\n<br>\r\n\r\n* LSTM이 many-to-many 상태에서 FNN으로 가면 각각의 Output 값이 나온다\r\n* NLP의 챗봇, 기계번역 등에서 사용함.\r\n    * Input > 안녕 만나서 반가워\r\n    * Output > 저도 반갑습니다\r\n    * 3개의 출력층. 비어 있는 1개는 padding \r\n    * Q. ... padding은 어디로?\r\n\r\n<br>\r\n\r\n* LSTM에서 사용되는 h와 c\r\n\r\n  |      | 역할              | 특징                                                  |\r\n  | ---- | ----------------- | ----------------------------------------------------- |\r\n  | h    | **위, 왼쪽** 전파 | LSTM이 1층일 땐 c랑 똑같이 왼쪽으로 밖에 전파 못한다. |\r\n  | c    | **왼쪽** 전파     |                                                       |\r\n\r\n  > h와 c 둘다 처음엔 0으로 시작한다.\r\n\r\n  \r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n# CNN\r\n\r\n* 이미지를 대표할 수 있는 특성들을 도출해서 FNN에 넣어줌\r\n\r\n* | code                                                         | 설명                                                         |\r\n  | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n  | `Input`(batch_shape = (None, nStep, nFeature, nChannel))     |                                                              |\r\n  | `Conv2D`(filters=30, kernel_size=(8,3), strides=1, padding = 'same', activation='relu') |                                                              |\r\n  | `MaxPooling2D`(pool_size=(2,1), strides=1, padding='valid')  | - 경우에 따라 conv2D, pooling 더 써줄 수 있음<br />- `GlobalMaxPooling1D()`도 있음 |\r\n  | `Flatten()`                                                  | 2D는 4차원이라 shape 맞추려고 보통 flatten을 써줌<br />1d는 안 써도 되는 듯(?) |\r\n  | `Dense`(nOutput, activation='linear')                        |                                                              |\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n## LSTM과 CNN의 차이\r\n\r\n* 둘다 (흐름을 보는)시계열 데이터에 사용할 수 있다.\r\n* LSTM과 CNN1D는 기능은 비슷하지만 CNN1D는 table 中 **(colum 전체+n row)아래 방향으로의 흐름**을 보는 거고, \r\n* LSTM은 bidirectional 을 사용해서 table 中 **위/아래로 흐름**을 이동시켜서 볼 수 있다.\r\n* CNN2D는 kernel_size, pooling 등을 통해 tabel 中 **(n colum(일부분) + n row(일부분) = 내가 focus를 맞춰 보고 싶은 부분)에 따라 그 흐름을 볼 수 있다는 데**서 차이가 있다.\r\n\r\n![image-20200805122723206](markdown-images/image-20200805122723206.png)\r\n\r\n<br>\r\n\r\n<br><br>\r\n\r\n# activation\r\n\r\n* | activation(비선형 함수) | loss                                                         |\r\n  | ----------------------- | ------------------------------------------------------------ |\r\n  | `softmax`               | `sparse_categorical_crossentropy`                            |\r\n  | `sigmoid`               | `binary_crossentropy`                                        |\r\n  | `linear`                | `mse`                                                        |\r\n  | `relu`                  | ← Hidden layer에 씀. 기울기가 0이기 때문에 뉴런이 죽을 수 있는 단점 有 |\r\n  |                         |                                                              |\r\n  | Leakly ReLU             | 뉴런이 죽을 수 있는 현상 해결                                |\r\n  | PReLU                   | x<0 에서 학습 가능                                           |\r\n  | granger causality       | 통제된 상황에서 인과관계가 가능하다고 말할 수 있음. 시계열 데이터에서 쓰일 수 있음 |\r\n\r\n  > * sparse_categorical_crossentropy\r\n  >\r\n  > ```python\r\n  > model = Model([encoderX, decoderX], outputY)\r\n  > model.compile(optimizer=optimizers.Adam(lr=0.001), loss='sparse_categorical_crossentropy')\r\n  > ```\r\n  >\r\n  > * sparse 안 쓸 거면 위에 'outputY'를 to_categorical()로 변형 후, loss 함수로 \"categorical_crossentropy\" 사용\r\n  > * target이 one-hot encoding되어 있으면 categorical_crossentropy,\r\n  >   target이 integer로 되어 있으면 sparse_categorical_crossentropy를 쓴다.\r\n  >   sparse_categorical_entropy는 integer인 target을 one-hot으로 바꾼 후에 categorical_entropy를 수행한다.\r\n\r\n  <br>\r\n  \r\n* 딥러닝 네트워크(DN)의 노드는 입력값을 전부 더한 후, 활성화 함수(Activation function)를 통과시켜 다음 노드에 전달한다.\r\n\r\n  * 이때 사용하는 활성화 함수는 비선형 함수를 쓴다. \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## softmax - sigmoid\r\n\r\n| 구분           | 함수                           | code                                                         |\r\n| -------------- | ------------------------------ | ------------------------------------------------------------ |\r\n| 회귀           | 항등함수(출력값을 그대로 반환) |                                                              |\r\n| 분류(0/1)      | sigmoid                        | # 시험 데이터로 학습 성능을 평가한다<br/>predicted = model.predict(test_input)<br/>test_pred = np.where(predicted > 0.5, 1, 0)<br/>accuracy = (test_label == test_pred).mean() |\r\n| 분류(multiple) | softmax                        |                                                              |\r\n\r\n>  Cross-Entropy : 예측한 값과 실제값의 차를 계산. entropy 값이 감소하는 방향으로 진행하다 보면 최저 값을 찾을 수 있다. \r\n>\r\n>  * 출처: sshkim Sh.TK. 2017. 8. 23. \"[모두의딥러닝] Softmax Regression (Multinomial Logistic Regression)\". \"https://sshkim.tistory.com/146\"\r\n\r\n>  argmax 을 사용하면 2라는 값이 나온다. 가장 큰 값의 위치가 2번째에 있는 1이기 때문\r\n>\r\n>  * 출처: JINSOL KIM. 2017. 12. 24. \"Softmax vs Sigmoid\". https://blog.naver.com/infoefficien/221170205067\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## ReLu\r\n\r\n* 히든층에 자주 쓰임\r\n\r\n* 그냥 CNN이든 LSTM이든 출력층 Dense에 Relu 쓰지 말자\r\n\r\n  * LSTM에선 Relu 안 쓰는 게 좋음. 특히 출력층엔 쓰면 안 됨.\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n# 학습(compile), 예측(predict)\r\n\r\n\r\n\r\n## optimizer\r\n\r\n* | 종류(빈도순)               |\r\n  | -------------------------- |\r\n  | `adam`                     |\r\n  | Adadelta, RMSprop, Adagrad |\r\n  | `momentum`                 |\r\n  | GD, NAG                    |\r\n\r\n* 최적화가 잘 안 되면 글로벌 minmun을 찾지 못하고 로컬 minimum에 빠진다. 이때 로컬 minimum을 **어떻게 빨리** 탈출할 수 있을지 U턴 메소드를 쓸지, 다른 1차 미분방법(GD)를 쓸 지 결정하게 된다. \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## epoch\r\n\r\n* `epoch` 수치가 커지면 `optimizer`가 일을 해서 local이 아닌 global을 찾아간다.\r\n* 그런데 너무 크면 overfitting\r\n* 따라서 적당한 `epoch` 설정이 필요 \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## Batch_size\r\n\r\n* data가 크면 `batch_size`도 크게\r\n  * 25,000개의 raw data라면 `batch_size` = 20 보다 300 이 정도로 설정\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n-----------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n# NLP & DL\r\n\r\n\r\n\r\n## SGNS\r\n\r\n| 용어          | 설명                      | CODE                                | 참고                             |\r\n| ------------- | ------------------------- | ----------------------------------- | -------------------------------- |\r\n| pre-trained   | SGNS에서 학습한 We를 적용 | model.layers[1]**.set_weights**(We) | 해당 code 적용 후 model fit 진행 |\r\n| fine-training |                           |                                     |                                  |\r\n\r\n<br>\r\n\r\n* SGNS에 모델 학습(fit) 시, 학습을 따로 시키는 이유?\r\n\r\n  ```python\r\n  # 학습\r\n  hist = model.fit([X[:, 0], X[:, 1]], X[:, 2], \r\n                   batch_size=BATCH_SIZE,\r\n                   epochs=NUM_EPOCHS)\r\n  ```\r\n\r\n  > *  각기 연결된 가중치 선이 구분되어 있기 때문에\r\n\r\n<br>\r\n\r\n* SGNS 모델 만들 때 dot을 한다면, \r\n\r\n  1. **axis=2**    *@2*\r\n\r\n     → 후에\r\n\r\n  2. reshape**(())**    *@괄호 두 개*\r\n\r\n<br>\r\n\r\n* SGNS로 만든 Embedding의 w(가중치)를 basic한 word data에 적용할 때, load_weights 사용하는 방법도 있다.\r\n\r\n  * 근데 이땐 shape을 맞춰줘야 한다.\r\n\r\n  ```python\r\n  w = encoder.load_weights('model_w.h5') # 가중치(w) 불러온 후,\r\n  emb = Embedding(max_features, embedding_dims, load_weights = w)(xInput) # embedding layer에 바로 적용\r\n  ```\r\n\r\n  * 보통 이런 느낌으로 씀\r\n\r\n    ```python\r\n    weights = load_weights()\r\n    embedding_layer = Embedding(input_dim=V,\r\n                                output_dim=embedding_dim,\r\n                                input_length=input_length,\r\n                                trainable=False,\r\n                                weights=weights,\r\n                                name='embedding')\r\n    ```\r\n\r\n    \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## Embedding & pad_sequences\r\n\r\n<br>\r\n\r\n### word2vec 기준\r\n\r\n| word2vec      | code                                                         | input                                                  | output                                                 |\r\n| ------------- | ------------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ |\r\n| tokenizer     | tokenizer = Tokenizer()<br />tokenizer.fit_on_texts(clean_train_review)<br />train_sequences = tokenizer.texts_to_sequences(clean_train_review) | [안녕, 만나서, 반가워]                                 | [13, 4, 3]                                             |\r\n| pad_sequences | train_inputs = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post') | [13, 4, 3]                                             | ([0,0...1,..],<br />[0,0,0,1,0,...],<br />[0,0,1,...]) |\r\n| Embedding     | embedding_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE) | ([0,0...1,..],<br />[0,0,0,1,0,...],<br />[0,0,1,...]) | [0,0...1,..] -> ANN layer                              |\r\n\r\n> embedding_layer 는 결국 pad_sequence된 단어들끼리 모임. 즉, 1개 문장에 대한 임베딩 행렬이 됨 \r\n>\r\n> 1개 단어 = 1개 임베딩 레이어=벡터값\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### doc2vec 기준\r\n\r\n| doc2vec        | code                                                         | input                                                        | output                                                       |\r\n| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| TaggedDocument | documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)] | [...,'laughabl',<br/>  'horror'],<br/> ...]                  | TaggedDocument(words=['move', 'last', ... 'horror'], tags=[999]) |\r\n| Embedding      | model = Doc2Vec(vector_size=300, alpha=0.025, min_alpha=0.00025, min_count=10, workers=4, dm =1) | TaggedDocument(words=['move', 'last', ... 'horror'], tags=[999]) | [벡터값]                                                     |\r\n\r\n> tags=[999] : 999번 째 문장\r\n>\r\n> Embedding은 model.build_vocab, model.train 거치면 한 문장에 대한 하나의 벡터가 나온다.\r\n>\r\n> (word2vec의 경우 한 문장에 있는 각각의 단어 수만큼 벡터가 나온다.)\r\n>\r\n> 1개 문장 = 1개 임베딩 레이어 = 1개 벡터값\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n\r\n\r\n# ChatBot\r\n\r\n<br>\r\n\r\n## Sequence to Sequence\r\n\r\n| encoder | decoder | 가능/불가능 |\r\n| ------- | ------- | ----------- |\r\n| 1층     | 2층     | *불가능*    |\r\n| 1층     | 1층     | 가능        |\r\n| 2층     | 1층     | 가능        |\r\n| 2층     | 2층     | 가능        |\r\n\r\n> \"굳이 2층으로 할 필요가 있는가?\"\r\n>\r\n> → 1층으로 하는 건 선형의 개념. 2층은 비선형의 개념이다.\r\n>\r\n> 비선형이 분류를 더 잘해낼 수도 있지만, overfitting의 위험이 있다. \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n-----------\r\n\r\n<br>\r\n\r\n# 기타\r\n\r\n<br>\r\n\r\n## 유클리디안 거리\r\n\r\n* 거리 계산할 때, 비교하고 싶은 건 `[]`를 쳐서 넣어주기  \r\n\r\n  ```python\r\n  euclidean_distances([father, mother])\r\n  ```\r\n\r\n<br>\r\n\r\n## 가중치 저장(Save)\r\n\r\n* Embedding (left side) layer의 W를 저장할 때, [2]를 저장한단 사실 알아두기\r\n\r\n  ```python\r\n  with open('data/embedding_W.pickle', 'wb') as f:\r\n      pickle.dump(model.layers[2].get_weights(), f, pickle.HIGHEST_PROTOCOL)\r\n  ```\r\n\r\n<br>\r\n\r\n## 영역별 code & 논문 참고하기 좋은 site\r\n\r\n* SOTA site\r\n\r\n  https://paperswithcode.com/sota\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>","excerpt":"W(weights) 네트워크 및 model build까지 완성해서 실행되어 역전파 되었을 때 형성된다. : 네트워크 만들고 난 후 model build하는 과정. optimizer & loss 값을 정의해주는 부분임. w…","fields":{"slug":"/TQT(The question I asked the teacher today.)/"},"frontmatter":{"date":"Aug 01, 2020","title":"TQT(The question I asked the teacher today)","tags":["TQT"],"update":"Aug 06, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# NLP & DL\r\n\r\n* 특수 목적이 아닌, **범용적(일반적)으로 쓰일 Word Embedding**을 만든다.\r\n\r\n* embedding의 방법\r\n  * 따라서 문장 속 단어의 맥락(의미)를 파악할 줄 안다.\r\n  * 즉, semantic 방법을 사용한다.\r\n  \r\n\r\n<br>\r\n\r\n* 참고: \r\n\r\n  * 분포 가설:\r\n    * 같은 문맥의 단어, 즉 비슷한 위치에 나오는 단어는 비슷한 의미를 가진다. 따라서 어떤 글에서 비슷한 위치에 존재하는 단어는 단어 간의 유사도가 높다고 판단.\r\n  \r\n  | 빈도 기반의 문서 수치화                | 학습 기반의 문서 수치화                     |\r\n| -------------------------------------- | ------------------------------------------- |\r\n  | 카운트 기반 방법                       | 예측 방법                                   |\r\n  | 빠르다<br />                           | 단어들의 복잡한 특징까지 잘 파악할 수 있다. |\r\n  | Bag of word(BOW), TF-IDF 활용한 SVD 등 | Word Embedding / Word2Vec                   |\r\n  \r\n  <br>\r\n\r\n</br>\r\n\r\n## `Word2Vec`\r\n\r\n| Word2Vec                                                     | Word Embedding                                               |\r\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| 특정 목적이 아닌 범용적인 목적으로 사용된다.<br />- 방대한 양의 아무문서나 코퍼스를 학습하여 **단어들이 어떤 관계를 갖도록 벡터화(수치화)하는 기술**이다.<br />- 따라서 단어들의 의미가 범용적이다.<br /> | classification 등의 특정 목적을 달성하기 위해 그때마다 학습하는 방식. <br /> - 단어들이 특정 목적에 맞게 벡터화된다. |\r\n| 사후적으로 결정되는 **Word Embedding 과 달리 사전에 학습**하여 단어의 **맥락을 참조**한 **벡터화**를 진행한다.<br />- 분포가설 이론 사용: ''주변 단어들을 참조하는 등 단어들의 분포를 통해 해당 단어의 의미를 파악한다'', 란 뜻단어의 - 주변 단어(맥락:context)를 참조하여 해당 단어를 수치화한다. 그러면 해당 단어는 인접 단어들과 관계가 맺어지고 인접 단어들 간에는 단어 벡터의 유사도가 높다. | Word Embedding 벡터는 사후적으로 결정되고, **특정 목적의 용도에 한정**된다. |\r\n| 방법: continuous back of word (`CBOW`), `Skip-gram`          |                                                              |\r\n\r\n<br>\r\n\r\n* *대표적인 Word2Vec* >\r\n\r\n  | CBOW                                                         | Skip-Gram                                                    |\r\n  | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n  | 문장을 단어로 전처리한다.                                    | 문장을 단어로 전처리한다.                                    |\r\n  | 수치화하고 싶은 단어가 output 되도록 <br />네트워크 구성주변 단어를 <br />* 순서:<br />input<br />ex: (input) alic, bit 등 여러 개 ... →  <br />hidden layer → <br />(output) hurt<br />따라서:  hidden layer =  중간출력. <br /> | CBOW 를 거꾸로 한 것. <br />- input 1개 , <br />- output 여러 개  <br />* 순서: <br />(input) hurt → <br />hidden layer → <br />(output) alic, bit 등 여러 개 ... <br />- AE 배울 때, 모델 전체 학습 시킨 후, <br />autoencoding 부문만 따로 빼서 <br />목적에 맞게 돌린 것처럼 <br />Skip-Gram도 그렇게 진행함. |\r\n  | 즉, 여러 개로 한 개 예측                                     | 즉, 한 개로 여러 개 예측                                     |\r\n\r\n<br>\r\n\r\n* *원리* > \r\n\r\n  예를 들어 \r\n\r\n  * (input) hurt를 one-hot encoding해서 hurt의 위치(index) 를 파악한 후, \r\n  * (output) alic를 넣었을 때 hurt의 위치(index)를 찾도록 함\r\n\r\n* 예측 시, 더 편리한 건 Skip-Gram.\r\n\r\n* 단어 하나만 넣으면 output이 나오므로\r\n\r\n<br>\r\n\r\n* *단점* >\r\n\r\n1. **동음이의어를 제대로 파악하지 못한다.**\r\n   * 실제 word2vec의 위치를 계산할 때 가까운 거리에 있는 값들의 평균으로 계산하기 때문에\r\n   * 해결방법: `ELMo`\r\n   * embedding 할 때, 문맥에 따라 가변적으로 vector를 만든다. 즉, 맥락화된 단어 임베딩\r\n\r\n2. 출력층을 **'softmax'**를 사용해서 **계산량이 많다.**\r\n     * softmax를 사용하는 이유: one-hot 인코딩 위해서\r\n     * 그런데 softmax를 사용하기 위해선 전체 단어를 0~1사이의 값으로 표현하기 위해 전부 계산을 진행하는데, 이때 전체 단어가 3만 개 등지가 넘어가는 정도로 큰 vocab일 땐 계산량이 많다.\r\n     * 해결 방법: `Skip-Gram Negative Sampling(SGNS)` \r\n       * SGNS는 sigmoid 사용\r\n  3. **OOV**(Out Of Vocbulary)\r\n     * 해결방법: `FastText`\r\n       * 빈도수가 적은 단어에 대해서도 OOV 문제에 해결 가능성이 높다\r\n  4. **문서 전체**에 대해선 고려 못한다.\r\n     * 해결방법: `GloVe`\r\n       * 빈도기반(TF-IDF) + 학습기반(Embedding) 방법 혼용\r\n         * TF-IDF: 문서 전체에 대한 통계를 사용하지만, 단어별 의미는 고려하지 못한다는 단점과\r\n           Word2Vec: 주변 단어만을 사용하기 때문에 문서 전체에 대해서는 고려하지 못한다.\r\n\r\n<br>\r\n\r\n</br>\r\n\r\n* ### CODE\r\n  * SGNS + CNN\r\n\r\n  * 소설 alice in wonderland에 사용된 단어들을 2차원 feature로 vector화 한다.\r\n\r\n  * #### 그림으로 먼저 보기:\r\n\r\n  * ![image-20200729173124866](/image-20200729173124866.png)\r\n\r\n  * ![image-20200729173147483](/image-20200729173147483.png)\r\n\r\n    > 네트워크에는 center값 넣음\r\n\r\n  * ![image-20200729173218124](/image-20200729173218124.png)\r\n\r\n  * ![image-20200729173227834](/image-20200729173227834.png)\r\n\r\n    > * x값인 7을 input 했을 때 output이 y값으로 8이 나올 때의 네트워크다.\r\n    >\r\n  \t> * 2개 뉴런으로 줄였을 때의 latent layer를 전체 학습 후 따로 빼내고,\r\n    > * 이때 나온 x좌표와 y좌표로 2D상의 plt에 그림으로 나타내면, 맥락 상 가까운 의미를 가진 단어들끼리 뭉쳐져 있음을 확인할 수 있다.\r\n\r\n  * ![image-20200729173233038](/image-20200729173233038.png)\r\n\r\n  \r\n\r\n  </br>\r\n\r\n### code\r\n\r\n#### STEP 1\r\n\r\n  * 패키지 불러오기\r\n\r\n    ```python\r\n    from sklearn.model_selection import train_test_split\r\n    from sklearn.preprocessing import OneHotEncoder\r\n    import matplotlib.pyplot as plt\r\n    import nltk\r\n    import numpy as np\r\n    import pandas as pd\r\n    from nltk.corpus import stopwords\r\n    from nltk.stem import WordNetLemmatizer\r\n    import string\r\n    from nltk import pos_tag\r\n    from nltk.stem import PorterStemmer\r\n    import collections\r\n    from tensorflow.keras.layers import Input, Dense, Dropout\r\n    from tensorflow.keras.models import Model\r\n    ```\r\n\r\n  <br>\r\n\r\n  * 전처리\r\n\r\n    ```python\r\n    def preprocessing(text): # 한 line(sentence)가 입력됨 \r\n        \r\n        # step1. 특문 제거\r\n        text2 = \"\".join([\" \" if ch in string.punctuation else ch for ch in text]) \r\n        # for ch in text: 한 sentence에서 하나의 character를 보고, string.punctuation:[!@#$% 등]을 공백처리('')=제거 함  \r\n        tokens = nltk.word_tokenize(text2)\r\n        tokens = [word.lower() for word in tokens] # 위 제거에서 살아남은 것들만 .lower() = 소문자로 바꿔서 word에 넣어줌 \r\n    \r\n    \t# step2. 불용어 처리(제거)\r\n    \tstopwds = stopwords.words('english')\r\n    \ttokens = [token for token in tokens if token not in stopwds] # stopword에 없는 것만 token 변수에 저장 \r\n    \r\n    \t# step3. 단어의 철자가 3개 이상인 것만 저장 \r\n    \ttokens = [word for word in tokens if len(word)>=3] \r\n    \r\n    \t# step4. stemmer: 어간(prefix) 추출(어미(surffix) 제거)  ex: goes -> go / going -> go\r\n    \tstemmer = PorterStemmer()\r\n    \ttokens = [stemmer.stem(word) for word in tokens]\r\n    \r\n    \t# step5. 단어의 품사 태깅(tagging)\r\n    \ttagged_corpus = pos_tag(tokens) # ex: (alic, NNP), (love, VB)\r\n    \r\n    \tNoun_tags = ['NN','NNP','NNPS','NNS']\r\n    \tVerb_tags = ['VB','VBD','VBG','VBN','VBP','VBZ']\r\n    \r\n    \t# 단어의 원형(표제어,Lemma)을 표시한다 \r\n    \t## 표제어(Lemma)는 한글로는 '표제어' 또는 '기본 사전형 단어' 정도의 의미. 동사와 형용사의 활용형 (surfacial form) 을 분석\r\n    \t## 참고: https://wikidocs.net/21707\r\n    \t## 걍 형용사/동사를 사전형 단어로 만들었다 생각하기.... \r\n    \t# ex: belives -> (stemmer)believe(믿다) // belives -> (lemmatizer)belief(믿음) \r\n    \t# (cooking, N) -> cooking / (cooking, V) -> cook\r\n    \t## 한국어 예시:\r\n        \"\"\"\r\n        lemmatize 함수를 쉽게 만들 수 있습니다. \r\n        띄어쓰기가 지켜진 단어가 입력되었을 때 Komoran 을 이용하여 형태소 분석을 한 뒤, \r\n        VV 나 VA 태그를 가진 단어에 '-다'를 붙입니다. \r\n        단, '쉬고싶다' 와 같은 복합 용언도 '쉬다' 로 복원됩니다.\r\n        출처: https://lovit.github.io/nlp/2019/01/22/trained_kor_lemmatizer/\r\n        \"\"\"\r\n    \tlemmatizer = WordNetLemmatizer()\r\n    \t\r\n    \t# 품사에 따라 단어의 lemma가 달라진다 \r\n    \t# (cooking, N) -> cooking / (cooking, V) -> cook\r\n    \tdef prat_lemmatize(token,tag):\r\n        \tif tag in Noun_tags:\r\n            \treturn lemmatizer.lemmatize(token,'n')\r\n        \telif tag in Verb_tags:\r\n            \treturn lemmatizer.lemmatize(token,'v')\r\n        \telse:\r\n            \treturn lemmatizer.lemmatize(token,'n')\r\n    \r\n    \tpre_proc_text =  \" \".join([prat_lemmatize(token,tag) for token,tag in tagged_corpus])      \r\n        \r\n        return pre_proc_text\r\n    ```\r\n\r\n<br>\r\n\r\n  * 소설 alice in wonderland를 읽어온다.\r\n\r\n    ```python\r\n    lines = []\r\n    fin = open(\"./dataset/alice_in_wonderland.txt\", \"r\")\r\n    for line in fin:\r\n        if len(line) == 0: \r\n            continue # 소설 txt내 엔터 없애기\r\n        lines.append(preprocessing(line))\r\n    fin.close()\r\n    ```\r\n\r\n<br>\r\n\r\n  * 단어들이 사용된 횟수를 카운트 한다.\r\n\r\n    ```python\r\n    counter = collections.Counter()\r\n    \r\n    for line in lines:\r\n        for word in nltk.word_tokenize(line):\r\n          counter[word.lower()] += 1\r\n    ```\r\n\r\n<br>\r\n\r\n  * 사전을 구축한다.\r\n\r\n    * 가장 많이 사용된 단어를 1번으로 시작해서 번호를 부여한다.\r\n\r\n    ```python\r\n    word2idx = {w:(i+1) for i,(w,_) in enumerate(counter.most_common())} # ex: [(apple:50), (cat: 43), ...]\r\n    idx2word = {v:k for k,v in word2idx.items()} # ex: [(50: apple), (43: cat), ...]\r\n    ```\r\n\r\n<br>\r\n\r\n  * Trigram으로 학습 데이터를 생성한다.\r\n\r\n    ```python\r\n    xs = []     # 입력 데이터\r\n    ys = []     # 출력 데이터\r\n    for line in lines:\r\n        # 사전에 부여된 번호로 단어들을 표시한다.\r\n        ## 각 문장을 tokenize해서 소문자로 바꾸고 word2idx로 변환 \r\n        embedding = [word2idx[w.lower()] for w in nltk.word_tokenize(line)] # word2idx: value값인 index번호가 나옴 \r\n        \r\n        \r\n        # Trigram으로 주변 단어들을 묶는다.\r\n        ## .trigrams(=3)만큼 끊어서 연속된 문장으로 묶기 ex: triples = [(1,2,3), (3,5,3), ...]\r\n        triples = list(nltk.trigrams(embedding))\r\n        \r\n        \r\n        # 왼쪽 단어, 중간 단어, 오른쪽 단어로 분리한다. \r\n        w_lefts = [x[0] for x in triples]   # [1, 2, ...8]\r\n        w_centers = [x[1] for x in triples] # [2, 8, ...13]\r\n        w_rights = [x[2] for x in triples]  # [8, 13, ...7]\r\n        \r\n        # 입력 (xs)      출력 (xy)\r\n        # ---------    -----------\r\n        # 1. 중간 단어 --> 왼쪽 단어\r\n        # 2. 중간 단어 --> 오른쪽 단어\r\n        xs.extend(w_centers)\r\n        ys.extend(w_lefts)\r\n        xs.extend(w_centers)\r\n        ys.extend(w_rights)\r\n    ```\r\n\r\n    <br>\r\n\r\n  * 학습 데이터를 one-hot 형태로 바꾸고, 학습용과 시험용으로 분리한다.\r\n\r\n    ```python\r\n    vocab_size = len(word2idx) + 1  # 사전의 크기 # vocab_size = 1787 # + 1 해줘야 밑에 ohe 할 때, vocab 끝까지 전부를 ohe 할 수 있음 \r\n    \r\n    ohe = OneHotEncoder(categories = [range(vocab_size)]) # ohe = OneHotEncoder(categories=[range(0, 1787)])\r\n    X = ohe.fit_transform(np.array(xs).reshape(-1, 1)).todense() # .todense = .toarray()와 동일함: 결과를 배열 형태로 변환 \r\n    Y = ohe.fit_transform(np.array(ys).reshape(-1, 1)).todense()\r\n    ```\r\n    \r\n    > X.shape = (13868, 1787) / y.shape = (13868, 1787)\r\n\r\n  \r\n\r\n  </br>\r\n\r\n  #### STEP 2. 학습용/시험용 data로 분리 \r\n\r\n  ```python\r\nXtrain, Xtest, Ytrain, Ytest, xstr, xsts = train_test_split(X, Y, xs, test_size=0.2) \r\n# xs를 쓴 이유? => 뒤에서 가까운 단어끼리 그림(plt) 그릴 때 쓰려고\r\n  ```\r\n> shape 참고 > \r\n>\r\n> |                                                   |                                                 |\r\n> | ------------------------------------------------- | ----------------------------------------------- |\r\n>| np.array(xs).shape<br />Out[19]: (13868,)         |                                                 |\r\n> | np.array(xstr).shape<br/>Out[20]: (11094,)        | np.array(xsts).shape<br/>Out[21]: (2774,)       |\r\n> | np.array(Xtrain).shape<br/>Out[22]: (11094, 1787) | np.array(Xtest).shape<br/>Out[23]: (2774, 1787) |\r\n>| np.array(Ytrain).shape<br/>Out[24]: (11094, 1787) | np.array(Ytest).shape<br/>Out[25]: (2774, 1787) |\r\n\r\n<br>\r\n\r\n\r\n* 딥러닝 모델을 생성한다. \r\n\r\n  ```python\r\n  BATCH_SIZE = 128\r\n  NUM_EPOCHS = 20\r\n  \r\n  input_layer = Input(shape = (Xtrain.shape[1],), name=\"input\") # shape = batch(None) 빼고 y feature의 shape만 넣어주면 됨 \r\n  first_layer = Dense(300, activation='relu', name = \"first\")(input_layer)\r\n  first_dropout = Dropout(0.5, name=\"firstdout\")(first_layer)\r\n  second_layer = Dense(2, activation='relu', name=\"second\")(first_dropout)\r\n  third_layer = Dense(300,activation='relu', name=\"third\")(second_layer)\r\n  third_dropout = Dropout(0.5,name=\"thirdout\")(third_layer)\r\n  fourth_layer = Dense(Ytrain.shape[1], activation='softmax', name = \"fourth\")(third_dropout)\r\n                      # Ytrain.shape[1] = Xtrain의 shape과 동일해야 함 \r\n                      # activation='softmax': one-hot이 출력되기 때문에 softmax여야 함 \r\n  model = Model(input_layer, fourth_layer)\r\n  model.compile(optimizer = \"rmsprop\", loss=\"categorical_crossentropy\") \r\n  ```\r\n\r\n\t> loss=\"`categorical_crossentropy`\": 만약 one-hot이 아니라, 숫자(vocab의 index)가 출력된다면, loss=\"`sparse_categorical_crossentropy`\"\r\n\r\n<br>\r\n\r\n* 학습\r\n\r\n  ```python\r\n  hist = model.fit(Xtrain, Ytrain, \r\n                   batch_size=BATCH_SIZE,\r\n                   epochs=NUM_EPOCHS,\r\n               validation_data = (Xtest, Ytest))\r\n  ```\r\n\r\n<br>\r\n\r\n* Loss history를 그린다\r\n\r\n  ```python\r\n  plt.plot(hist.history['loss'], label='Train loss')\r\n  plt.plot(hist.history['val_loss'], label = 'Test loss')\r\n  plt.legend()\r\n  plt.title(\"Loss history\")\r\n  plt.xlabel(\"epoch\")\r\n  plt.ylabel(\"loss\")\r\nplt.show()\r\n  ```\r\n\r\n  > ![image-20200729170655602](/image-20200729170655602.png)\r\n\r\n</br>\r\n\r\n#### STEP3. 단어들끼리의 거리를 그림으로 나타내는 code\r\n\r\n* Word2Vec 수치 확인\r\n\r\n  ```python\r\n  # Extracting Encoder section of the Model for prediction of latent variables\r\n  # 학습이 완료된 후 중간(hidden layer)의 결과 확인: = Word2Vec layer확인. \r\n  # (word2vec: word를 vec(수치)로 표현. 저번 수업에서 w의 값을 '.get_weight()'해서 확인했을 때의 값이 나올 듯)\r\n  encoder = Model(input_layer, second_layer)\r\n  \r\n  # Predicting latent variables with extracted Encoder model\r\n  reduced_X = encoder.predict(Xtest) # Xtest 넣은 것처럼 임의의 단어를 입력하면 reduced_X = 해당 단어의 Word2Vec형태로 출력됨 \r\n  \r\n  # 시험 데이터의 단어들에 대한 2차원 latent feature(word2vec 만드는 layer)인 reduced_X를 데이터 프레임(표)으로 정리한다.\r\n  final_pdframe = pd.DataFrame(reduced _X)\r\n  final_pdframe.columns = [\"xaxis\",\"yaxis\"]\r\n  final_pdframe[\"word_indx\"] = xsts # test 용이므로 train/test split 할 때 같이 나눴던 xstr, xsts 중 y값인 xsts 사용 \r\n  final_pdframe[\"word\"] = final_pdframe[\"word_indx\"].map(idx2word) # index를 word로 변환함 \r\n  \r\n  # 데이터 프레임에서 100개를 샘플링한다.\r\n  rows = final_pdframe.sample(n = 100)\r\n  labels = list(rows[\"word\"])\r\n  xvals = list(rows[\"xaxis\"])\r\n  yvals = list(rows[\"yaxis\"])\r\n  ```\r\n\r\n  > [final_pdframe] > \r\n  > Out[26]: \r\n  >       xaxis     yaxis  word_indx    word\r\n  > 0     0.301799  0.000000         25    take\r\n  > 1     0.590210  0.810300        468    pick\r\n  > 2     0.672298  0.000000          1     say\r\n  > 3     0.408792  0.520896          9    know\r\n  > 4     0.387678  0.605502         30    much\r\n  >     ...       ...        ...     ...\r\n  > 2769  1.309759  0.851837         27    mock\r\n  > 2770  0.000000  0.423953        622  master\r\n  > 2771  0.196061  0.299570         83    good\r\n  > 2772  0.000000  0.024289       1516  deserv\r\n  > 2773  0.470771  0.550808        497    plan\r\n  >\r\n  > [2774 rows x 4 columns]\r\n  \r\n* 샘플링된 100개 단어를 2차원 공간상에 배치\r\n\r\n  * 거리가 가까운 단어들은 서로 관련이 높은 것\r\n\r\n  ```python\r\n  plt.figure(figsize=(15, 15))  \r\n  \r\n  for i, label in enumerate(labels):\r\n      x = xvals[i]\r\n      y = yvals[i]\r\n      plt.scatter(x, y)\r\n      plt.annotate(label,xy=(x, y), xytext=(5, 2), textcoords='offset points',\r\n                   ha='right', va='bottom', fontsize=15)\r\n  plt.xlabel(\"Dimension 1\")\r\n  plt.ylabel(\"Dimension 2\")\r\n  plt.show()\r\n  ```\r\n\r\n  > ![image-20200729170642147](/image-20200729170642147.png)\r\n\r\n\r\n\r\n<br>\r\n\r\n</br>\r\n\r\n## `Skip-Gram Negative Sampling`(SGNS)\r\n\r\n* Skip-Gram의 softmax를 활용했기 때문에 계산량이 많다는 단점을 sigmoid 사용하여 보완함\r\n\r\n  * 값이 0~1사이 값이 아니라, 0 아니면 1인 이진 분류로 나옴 \r\n  * 따라서 계산량 감소 \r\n\r\n  <br>\r\n\r\n* 방법:\r\n\r\n  `Skip-Gram Negative Sampling`: \r\n\r\n  1.  n-gram으로 선택한 단어 쌍에는 label = 1을 부여하고, 랜덤하게 선택한 단어 쌍에는 label = 0을 부여해서 이진 분류 \r\n\r\n     > N-gram으로 선택한 단어 쌍은 서로 연관된 단어로 인식됨 \r\n\r\n  2.  2개의 input에 각각의 input, target 값 입력\r\n\r\n  3. 각각 vector 값 계산\r\n\r\n  4. 두 값 concat(or dot or add) \r\n\r\n  5. sigmoid 계산하여\r\n\r\n  6. label(0 or 1) 값이 나오게 \r\n\r\n  7. 학습이 완료된 후에는 아래의 왼쪽 네트워크에 특정 단어를 입력하면, 그 단어에 대한 word vector를 얻을 수 있다.\r\n\r\n  </br>\r\n\r\n### skip-gram과 skip-Gram Negative Sampling 차이\r\n\r\n| `Skip-Gram`                                                  | `Skip-Gram Negative Sampling`                                |\r\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| input 1개<br />input: input data<br />output: target data    | input 2개<br />input[1] : input data<br />input[2] : target data<br />output: label |\r\n| label 無                                                     | label 有: 1 or 0으로 이루어져 있음(이진분류)<br />n-gram으로 선택한 단어 쌍에는 label = 1 <br />랜덤하게 선택한 단어 쌍에는 label = 0 |\r\n| 출력층: **softmax** 사용하여 0~1사이의 값 <br /> loss='categorical_crossentropy'<br />따라서 argmax() 함 | 출력층: **sigmoid** 사용하여 이진분류<br />loss=\"binary_crossentropy\" |\r\n| 거리 연산(cosine 등)을 하지 않는다. <br />latent layer에서 벡터 연산을 통해 나온 x,y 좌표로 그림을 그리던가 해서 <br />맥락 상 비슷한 의미를 가진 단어들을 찾아낼 수 있다. | 거리 연산을 할 수 있다. <br />두 개의 input 값에서 나온 vector 값을 하나로 합칠 때 dot 함수를 쓰면 거리 연산을 하는 것과 같다. 이때 cosine 거리 함수를 쓸 수도 있다. <br />그런데, concate 이나 add 함수를 쓰면 거리 계산을 못한다. |\r\n\r\n  <br>![image-20200729151904052](/image-20200729151904052.png)\r\n\r\n\r\n\r\n</br>\r\n\r\n### SGNS의 Embedding 활용\t\t\t\r\n\r\n1. raw data **전처리**\r\n2. Trigram으로 **학습할 data 생성**\r\n3. **긍정(1), 부정(0) data 생성:SGNS용 학습 데이터를 생성**\r\n\r\n\t ```python\r\n\trand_word = np.random.randint(1, len(word2idx), len(xs))\r\n\tx_pos = np.vstack([xs, ys]).T\r\n\tx_neg = np.vstack([xs, rand_word]).T\r\n\r\n\ty_pos = np.ones(x_pos.shape[0]).reshape(-1,1)\r\n\ty_neg = np.zeros(x_neg.shape[0]).reshape(-1,1)\r\n\t```\r\n\r\n\t ```python\r\n\tx_total = np.vstack([x_pos, x_neg])\r\n\ty_total = np.vstack([y_pos, y_neg])\r\n\tX = np.hstack([x_total, y_total])\r\n\tnp.random.shuffle(X)\r\n\t ```\r\n\r\n4. SGNS 모델 **빌드**\r\n\r\n* `embedding`, `dot`, `reshape`, `sigmoid`, `binary_crossentropy` 등\r\n\r\n5. SGNS 모델 **학습**\r\n\r\n6.  SGNS의 Embedding 모델 만들고, **그 모델의 가중치(w)만 따로 빼서 저장**함\r\n   * 여기까지가 범용 목적의 SGNS의 Embedding을 만든 절차.\r\n   * 아래부턴 불특정 word data에 SGNS로 학습한 Embedding 기법을 적용해보는 것임\r\n\r\n7. raw data로 train/test **data split**\r\n8. 활용할 CNN 모델 빌드(complie 까지)\r\n9. CNN 모델 학습 **전**에 SGNS의 Embedding의 가중치(w) load(불러오기)\r\n10. CNN 모델 fit 할 때, SKNS에서 학습한 W를 적용: `model.layers[1].set_weights(We)`\r\n11. plt 그리거나 성능 확인\r\n\r\n* 성능 확인: \r\n\r\n    ```python\r\n    y_pred = model.predict(x_test)\r\n    y_pred = np.where(y_pred > 0.5, 1, 0)\r\n    print (\"Test accuracy:\", accuracy_score(y_test, y_pred))\r\n    ```\r\n\r\n<br>\r\n\r\n\r\n* Google's trained Word2Vec model:\r\n  * SGNS 방식\r\n  * Pre-trained 방식\r\n  * 문서 → Vector화(수치화) → 일반 DL로 바로 학습 가능\r\n\r\n\r\n\r\n<br>\r\n\r\n</br>\r\n\r\n# 응용 및 발전에 있어 궁금한 점\r\n\r\n* Word2Vec의 code 中 빈도순으로 index를 부여했었다.\r\n\r\n  ```python\r\n  word2idx = {w:(i+1) for i,(w,_) in enumerate(counter.most_common())} \r\n  ```\r\n\r\n* 그런데 바로 다음, trigram으로 학습 데이터를 구성할 땐\r\n\r\n  ```python\r\n  embedding = [word2idx[w.lower()] for w in nltk.word_tokenize(line)]\r\n  ```\r\n\r\n  정말 단순히 word2idx를 단어 찾는 용도로만 썼다.\r\n\r\n  ```python\r\n  triples = list(nltk.trigrams(embedding))\r\n  ```\r\n\r\n* 만약, 위 embedding을 sort 해서 idx number를 재정렬하거나, pre-processing 단계에 embedding을 넣는다. \r\n\r\n  그리고 CNN, LSTM 모델을 돌린다면, 빈도가 비슷한 단어들끼리 묶일 것이다.\r\n\r\n  그럼 단어의 중요도 순으로 거리를 측정할 텐데, 그럼 index number 1인 단어를 찾고, 그 단어와 다른 단어 사이의 거리를 계산해 특정 점수 구간 이외의 것들을 따로 모아둔다면?\r\n\r\n* 예를 들어 가장 많이 나온 단어 happy와 다른 단어들 사이의 거리를 측정하고, 0.5 이하의 코사인 유사도인 것들을 따로 빼서 Another_vocab에 모아둔다. 기존 vocab의 것들은 해당 Document, Sentence의 핵심 keyword 들일 거고, 주인공들이겠지(경우에 따라선 필요가 없는 단어일수도 있겠다.)\r\n\r\n  이렇게 다른 문서도 이러한 process를 진행해 Another_vocab_2를 만든다.\r\n\r\n  그 다음 Another_vocab와 Another_vocab_2의 cosine 유사도를 다시 구해 axis로 통합했을 때의 유사도는 해당 문서 사이의 겹치는 단어들 수치겠지.\r\n\r\n* 이걸 100년치 신문 data에 년별로 적용한다면, 1988년 신문과 2020년 신문이 유사도가 높을 때, 1988년 및 2020년의 국민들의 관심사가 일치한다고 볼 수 있지 않을까?\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n* 참고: \r\n\r\n  >  아마추어 퀀트, blog.naver.com/chunjein\r\n\r\n  > 코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘","excerpt":"NLP & DL 특수 목적이 아닌, 범용적(일반적)으로 쓰일 Word Embedding을 만든다. embedding의 방법 따라서 문장 속 단어의 맥락(의미)를 파악할 줄 안다. 즉, semantic…","fields":{"slug":"/NLP응용_3/"},"frontmatter":{"date":"Jul 29, 2020","title":"NLP Word2Vec/SGNS","tags":["NLP","Word2Vec","SGNS"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# NLP & 딥러닝\r\n\r\n핵심 문제: \"단어를 어떻게 수치화할 것인가?\"\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## Email - Classification\r\n\r\n* 딥러닝을 이용하여 20개의 카테고리로 분류된 이메일 데이터를 학습하고, 시험 이메일을 20개 카테고리 중 하나로 분류한다. \r\n* Email별 카테고리(20개. 총 2,000개) → (1:1 대응: label 매겨 학습 시킴) email 데이터 2,000개 → text 추출 → pre-processing → 수치화 → TF-IDF(10,000개의 Feature) → 신경망에 넣기 (10,000개 뉴런 → 1,000개 히든 뉴런 → 20개 출력 뉴런) → 20개 category (softmax)\r\n* ![image-20200722170909820](/image-20200722170909820.png)\r\n  * `pre-processing`: 지도학습. pos_tag, token, stemer(어근) 등의 방법으로 전처리. 이게 오래 걸림\r\n\r\n\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n----------------------\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n## `Embedding layer`\r\n\r\n* 수치화 방법\r\n\r\n|      | 빈도기반                                                     | 학습 기반                                                    |\r\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| ex:  | `TF-IDF`, `BOW`, `Doc2Bow`, `Co-occurtance`, `Matrix`<br />SVD(특이값 분해), 잠재의미분석(LSA), HAL, PCA | `word2vec` , `WordEmbedding`, <br />NNLM, RNNLM              |\r\n| 특징 | 통계 기반                                                    | 학습 기반<br />딥러닝을 통해 수치화 시켜서 **단어에 의미를 부여**할 수 있는 개념 |\r\n|      | '의미'란 개념이 없다                                         | '의미'란 개념이 있다<br />단어에 의미를 부여할 수 있음       |\r\n|      | 기본적으로 동시 등장 횟수를 하나의 행렬로 나타낸 뒤 그 행렬을 수치화해서 단어 벡터로 만드는 방법 |                                                              |\r\n\r\n> 단어의 의미: 맥락을 분석할 수 있음\r\n\r\n</br>\r\n\r\n* '단어' 기반의 NLP\r\n  * 현재의 NLP의 기본 원리\r\n    * EX: `Token`, `pos-tag`, `stemmer`</br>\r\n* 단어 자체로는 의미를 갖지 못하고, 단어가 조합을 이루어야 의미를 형성할 수 있음 \r\n  \r\n  * `character-based NLP`도 연구 중이긴 함 \r\n\r\n![image-20200722170909820](image-20200722170909820.png)\r\n\r\n* `Embedding` 방법도 위 그림과 같은데, 다만 단어에 의미를 부여하지 못하는 count based인 `TF-IDF` → `Embedding`으로 바꿈 \r\n  * `Embedding` 위치: 입력층과 은닉층 사이에 끼어든다\r\n\r\n\r\n\r\n</br>\r\n\r\n### `Embedding` 방법\r\n\r\n1. 문서의 단어 `Vocabulary` 딕셔너리 형성\r\n\r\n   > ![image-20200723102118222](image-20200723102118222.png) \r\n   >\r\n   > 이 과정을 거치면\r\n   >\r\n   > 문서-1 : [1,2,3,0]\r\n   >\r\n   > 문서-2 : [4,2,3,5]로 변환됨\r\n   >\r\n   > * 문서-1의 [1,2,3,0] '0'은 문서 길이를 맞추기 위한 `padding`\r\n   > * `padding`: 비교하려는 문서마다 문장의 길이가 다르므로 `.pad_sequences` 사용하면,`vocabulary` 자체에 `padding`이 삽입됨\r\n\r\n   <br>\r\n\r\n2. 문서별로 `one-hot encoding`\r\n\r\n   > ![image-20200723102329504](/image-20200723102329504.png) \r\n   >\r\n   > * one-hot encoding한 이유:\r\n   >\r\n   >   vector 내적의 합이 0인 직교행렬을 만들기 위함. \r\n   >\r\n   >   내적 0 = 유사도 0\r\n   >\r\n   >   따라서 먼저 모든 단어의 의미를 초기화한다.\r\n   >\r\n   >   이후 Embedding layer를 거치면 각 word vector들이 **어떤 의미를 갖는 수치 vector로 환원된다.**\r\n   >\r\n   > * 이때 생각해야 하는 부분은 **'단어를 몇 byte의 수치로 표현할 것인가?'** 이며, 이건 사람이 결정해야 함 \r\n\r\n   <br>\r\n\r\n3. `Embedding layer`에 넣어 학습하기\r\n\r\n   > ![image-20200723102500632](/image-20200723102500632.png) \r\n   >\r\n   > * `Embedding layer`: 일반 layer에 `Embedding layer`를 넣은 것 → 학습할 수 있게 되었음 \r\n   > * `Embedding layer`의 입력층의 뉴런 개수: 사전에 등록된 단어 개수(뉴런 개수는 임의적으로 설정 가능)\r\n   > * 단어 1개의 `latent feature` 형성. \r\n   >   * `latent feature`: 차원이 늘어나거나 줄어든 채로 데이터를 잘 설명할 수 있는 잠재 공간에서의 벡터\r\n\r\n   <br>\r\n\r\n   * `Embedding layer` 자세히 보기:\r\n\r\n     > 학습을 통한 문서-1 의 word embedding 표현\r\n     >\r\n     > ![image-20200723103020209](/image-20200723103020209.png) \r\n     >\r\n     > * 입력된 단어는 one-hot으로 단어간 유사도 = 0(직교행렬)이었으나, Embedding vector로 표현된 단어들에는 유사도가 존재한다. 의미적으로 가까운 단어들은 유사도가 높다\r\n     >\r\n     >   * ex: love you / love hate 中 love you의 유사도가 더 높다. \r\n     >\r\n     >   * ex: wine __  __  __  __ objok\r\n     >\r\n     >     ​      __ __ __ __ __ objok\r\n     >\r\n     >     ​\t 모델을 돌리면 여기서 objok는 wine의 종류라고 알 수 있다\r\n     >\r\n     > * `Embedding layer`가 하는 일:\r\n     >\r\n     > 1. (수치화된 word data로 `one-hot vector`를 생성한다)\r\n     > 2. 위의 1의 one-hot vector와 w행렬을 곱한다 \r\n     >    1. one hot * W\r\n     >       * ex) (5,500) * (500,64) = (5,64)\r\n     >    2. 의문: 1번대로라면 보통 \"vocabulary는 3만개가 되어 곱행렬의 수가 늘어나기 때문에 줄어줄 필요가 있다 *?* \"\r\n     >       * 아니다. 직교 행렬(one-hot vector)일 경우 곱행렬을 할 필요가 없다.\r\n     >       * 따라서 행렬이 아무리 커도 곱행렬(곱셈)이 필요 없다 \r\n     >       * look-up 사용\r\n     \r\n     <br>\r\n\r\n4. `Embedding layer`를 `DL layer`에 넣고 학습 + 역전파\r\n\r\n   > ![image-20200723105340770](/image-20200723105340770.png) \r\n\r\n</br>\r\n\r\n* `embedding` → 일반적인 `DL` N/W(`LSTM`, `CNN`등) → 출력층  → W 역전파  →  `embedding` 단어들이 의미를 갖게됨\r\n\r\n  * 역전파되어 의미를 갖게된 수치벡터들은 우리가 공유하는 일반적인 단어의 의미가 아니라, 어떤 특정 목적을 위한 의미가 된다.\r\n    * ex) '어떤 특정 목적' : Email classification 등\r\n\r\n  \r\n\r\n</br>\r\n\r\n\r\n#### `Embedding` 그림 총 정리\r\n\r\n![image-20200723105226275](/image-20200723105226275.png)\r\n\r\n\r\n\r\n<br>\r\n\r\n</br>\r\n\r\n-----------------------------------\r\n\r\n</br>\r\n\r\n<br>\r\n\r\n### 실습\r\n\r\n\r\n\r\n####  Word Embedding + CNN 개념\r\n\r\n![image-20200723114609507](/image-20200723114609507.png)\r\n\r\n* Word Embedding: \r\n\r\n  * 특정한 목적을 위한 Word Embedding 방법\r\n    \r\n  * 예를 들어 IMDB 파일처럼 영화 리뷰를 긍정적/부정적인 것으로 분류(classification)할 때 쓸 word를 embedding 한다.\r\n    \r\n  * 범용적인 embedding을 위한 Word Embedding 방법\r\n\r\n    * 다음 시간에 배움\r\n\r\n    </br>\r\n\r\n* Word Embedding&CNN, LSTM의 `단점`: \r\n\r\n1. 단어에 의미를 부여하지만, 맥락상의 의미가 다른 단어를 구분하지는 못함\r\n   * 동의어 구분 못함\r\n     * bank: 은행과 bank:둑을 구분하지 못한다\r\n   * 형태적으로 같은 단어는 모두 동일한 `Embedding vector`를 갖는다\r\n     * 이유: 같은 w를 공유하기 때문 ex: ~의 love\r\n\r\n</br>\r\n\r\n2. 계속 `vocabulary`를 업데이트 할 수 없는데, `vocabulary`의 업데이트 주기와 새로운 `말뭉치(corpus)` 투입 사이의 간극으로, 새로운 말뭉치가 과거의 `vocabulary`을 고려하기 때문에 문제가 발생한다\t\t\t\t\r\n  \r\n   * 없는 단어가 발생한다\r\n   \r\n     * out of vocabulary(`OOV`)\r\n   \r\n       * 따라서, 모르는 단어는 1로 coding한다\r\n   \r\n         * | idx  |              |\r\n           | ---- | ------------ |\r\n           | 0    | ← padding 용 |\r\n           | 1    | ← OOV용      |\r\n   \r\n           > 사용자가 임의 설정해야 함 \r\n       \r\n     \r\n      </br>\r\n  \r\n3. `padding`: 문장마다 길이가 다르므로 맞추기 위해 계속 `padding`을 해줘야 한다\r\n  \r\n   * LSTM에서\r\n   \r\n     * `time step`을 고정시키면 반드시 n개가 필요하여 부족하면 `padding`으로 채워줘야 함\r\n   \r\n         * 이때 `padding` 귀찮으면, \r\n   \r\n           > x = Input(batch_size = (None, None, f=8))로 None을 2번 써도 됨\r\n           >\r\n           > 근데 이렇게 하면, 학습 시킬 때가 문제다. `.fit` 할 때, `batch_size`를 따로 또 적어줘야 한다.\r\n           >\r\n           > model.fit(A, batch_size = 64) \r\n           >\r\n           > model.fit(B, batch_size = 1)\r\n           \r\n     \r\n     <br>\r\n\r\n</br>\r\n\r\n#### Embeddin + cnn-lstm 적용\r\n\r\n1. `단어 간 유사도 파악`\r\n   1. CNN or LSTM 모델 학습(fit) 후\r\n   2. embedding layer만 따로 빼서\r\n   3. 유클리디안 거리(유사도) 분석 진행\r\n   4. 유클리디안 거리의 숫자가 작을수록 두 단어 사이의 거리가 가깝다.\r\n\r\n```python\r\n### model의 embedding layer = model.layers[0]\r\n### embedding layer의 선이자 가중치 확인법: .get_weights()\r\n\r\na = np.array(model.layers[0].get_weights()) # a.shape = (1, 6000, 60)\r\nfather = a[0,wind['father']] # a[0].shape = (6000, 60)\r\nmother = a[0,wind['mother']]\r\ndaughter = a[0,wind['daughter']]\r\n\r\nfrom sklearn.metrics.pairwise import euclidean_distances # 숫자가 작을수록 유사한 것 \r\n\r\nf_m_e_e = euclidean_distances([father, mother]) # 거리 계산할 때, 비교하고 싶은 건 []를 쳐서 넣어주기  \r\nf_d_e_e = euclidean_distances([father, daughter])\r\nm_d_e_e = euclidean_distances([mother, daughter])\r\neuclidean_distances([father, mother, daughter])\r\n\r\nfor i in [f_m_e_e, f_d_e_e, m_d_e_e]:\r\n    print(i.mean())\r\n```\r\n\r\n</br>\r\n\r\n2. `CNN Embedding과 LSTM Embedding` 따로 구해서 성과 분석 = `병렬 처리`\r\n\r\n   * `CNN`이 느끼는 단어의 의미와 `LSTM`이 느끼는 단어의 의미가 다르다, 라는 관점에\r\n    `Embedding layer`를 같이 쓸까(직렬), 따로 쓸까(병렬) 구분 <br>\r\n   \r\n1. 학습 **데이터 구성**<br>\r\n   \r\n2. 문장 **padding**<br>\r\n   \r\n5. (편의를 위해) CNN, LSTM **변수 정의**\r\n\r\n   * 각각 **모델 빌드**\r\n     1. input\r\n     2. embedding\r\n     3. lstm / cnn(→ pooling → flatten → Dense)<br>\r\n\r\n6. **Concat**<br>\r\n\r\n7. **성능 확인**<br>\r\n\r\n```python\r\ny_pred = model.predict(x_test)\r\ny_pred = np.where(y_pred > 0.5, 1, 0)\r\nprint (\"Test accuracy:\", accuracy_score(y_test, y_pred))\r\n```\r\n\r\n```python\r\ny_train_predclass = model.predict_classes(x_train, batch_size=batch_size)\r\ny_test_predclass = model.predict_classes(x_test, batch_size=batch_size)\r\n```\r\n* predict는 probability를 predict_class는 label을 제공\r\n\r\n  >  | predict의 경우     | predict_classes의 경우 |\r\n  >   | ------------------ | ---------------------- |\r\n  >   | [[0.22520512]      | [[0]                   |\r\n  >   | [0.9520419 ]       | [1]                    |\r\n  >   | [0.9672848 ]       | [1]                    |\r\n  >   | [0.02690617]]      | [0]]                   |\r\n  >   | functional keras() | sequential keras()     |\r\n\r\n</br><br>\r\n\r\n##### 학습 데이터 구성\r\n\r\n### code\r\n\r\n* imdb data 기준 code<br>\r\n\r\n* imdb.load_data: 빈도별 내림차순으로 정렬된 총 88,584 단어(vocabulary) 中 6,000개의 단어에 index가 표시되어 있다.(제작자가 만들어 둔 것임)\r\n\r\n  * 6,000번째 이후 데이터는 out-of-vocabulary 표시인 '2'로 표시되어 있음\r\n  * y_train/test: (binary data) 긍정적 리뷰: 1, 부정적 리뷰: 0\r\n  * num_words=max_features 설정했기 때문에 vocabulary의 6,000번째 이후 데이터는 out-of-vocabulary 표시인 '2'가 표시돼 있다.\r\n\r\n  ```python\r\n  max_features = 6000    # max_features : 최대 단어수\r\n  (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\r\n  ```\r\n\r\n  > 0 : padding, 1 : start, 2 : OOV, 3 : Invalid를 의미\r\n\r\n  <br>\r\n\r\n* vocabulary를 생성\r\n\r\n  * word2idx : {'단어' : idx} 구조\r\n  * idx2word : {idx : '단어'} 구조\r\n\r\n  ```python\r\n  word2idx = imdb.get_word_index()\r\n  idx2word = dict((v,k) for k,v in word2idx.items())\r\n  ```\r\n\r\n<br>\r\n\r\n* volcaburary idx는 1부터 시작한다. idx2word[1] = 'the'</br>\r\n  x_train에는 단어들이 vocabulary의 index로 표시돼 있다.</br>\r\n  그러나 idx2word에는 padding=0, start=1, OOV=2, Invalid=3은 **포함돼 있지 않다.**</br>\r\n  따라서 idx2word의 idx를 3증가 시키고, 아래와 같이 0, 1, 2, 3을 **추가한다.</br>**\r\n  즉, **실제 사용된 단어는 idx 4번부터다. **</br>\r\n\r\n  ```python\r\n  idx2word = dict((v+3, k) for k, v in word2idx.items()) # word2idx.items() = (idx, 단어)순으로 나옮\r\n  idx2word[0] = '<PAD>'  # padding 문자 표시\r\n  idx2word[1] = '<START>'  # start 문자 표시\r\n  idx2word[2] = '<OOV>'  # OOV 문자 표시\r\n  idx2word[3] = '<INV>'  # Invalid 문자 표시\r\n  word2idx = dict((k, v) for v, k in idx2word.items()) # 요걸 실제 사용\r\n  ```\r\n\r\n<br>\r\n\r\n* 숫자로 표시된 x_train을 실제 단어로 변환해서 육안으로 확인해 본다.\r\n  (학습과는 무관하다.)\r\n\r\n  ```python\r\n  \"\"\"\r\n  x_train은 idx 값만으로 구성된 list이므로, \r\n  이를 (idx, word)로 되어 있는 word2idx에 넣는다면 딕셔너리의 key값이 일치하는 x_train을 찾고, \r\n  그것의 value값을 뽑으면 x_train의 idx가 무슨 단어를 뜻하는지 알 수 있다.\r\n  (x_train은 0, 1, 2, 3 전처리를 거친 파일이므로 위의 idx2word, word2idx 작업을 통해 두 파일의 길이를 맞춰주었다.\r\n   이제 각 idx의 word만 확인하면 된다.)\r\n  \"\"\"\r\n  def decode(review):\r\n      x = [idx2word[s] for s in review] \r\n      return ' '.join(x)\r\n  decode(x_train[0])\r\n  \r\n  ####### 여기까지가 주어진 데이터에 관한 부분이다.\r\n  ```\r\n\r\n<br>\r\n\r\n</br>\r\n\r\n\r\n##### Embedding + CNN\r\n\r\n* 1개 리뷰 문서의 단어 개수를 max_length = 400으로 맞춘다.\r\n  400개 보다 작으면 padding = 0을 추가하고, **400개 보다 크면 뒷 부분을 자른다(← index 번호 400 이후는 안 본단 뜻).**\r\n\r\n```python\r\nmax_length = 400       # 한 개 리뷰 문서의 최대 단어 길이\r\nx_train = sequence.pad_sequences(x_train, maxlen=max_length)\r\nx_test = sequence.pad_sequences(x_test, maxlen=max_length)\r\n```\r\n\r\n</br>\r\n\r\n* Deep Learning architecture parameters\r\n\r\n```python\r\nbatch_size = 32\r\nembedding_dims = 60 #단어 1개를 60개의 수치(feature)로 표현 \r\nnum_kernels = 260        # convolution filter 개수\r\nkernel_size = 3          # convolution filter size\r\nhidden_dims = 300\r\nepochs = 1\r\n\r\nxInput = Input(batch_shape = (None, max_length))\r\nemb = Embedding(max_features, embedding_dims)(xInput) #(400,6) 한 단어(row)당 60개의 wordvector로 수치화한 것 \r\nemb = Dropout(0.5)(emb)\r\nconv = Conv1D(num_kernels, kernel_size, padding='valid', activation='relu', strides=1)(emb)\r\nconv = GlobalMaxPooling1D()(conv)\r\nffn = Dense(hidden_dims)(conv)\r\nffn = Dropout(0.5)(ffn)\r\nffn = Activation('relu')(ffn)\r\nffn = Dense(1)(ffn)\r\nyOutput = Activation('sigmoid')(ffn)\r\n\r\nmodel = Model(xInput, yOutput)\r\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\r\nprint(model.summary())\r\n```\r\n\r\n</br>\r\n\r\n* 학습\r\n\r\n```python\r\nhist = model.fit(x_train, y_train, \r\n                 batch_size=batch_size, \r\n                 epochs=epochs,\r\n                 validation_data = (x_test, y_test))\r\n```\r\n\r\n</br>\r\n\r\n* 성능 확인\r\n\r\n```python\r\ny_pred = model.predict(x_test)\r\ny_pred = np.where(y_pred > 0.5, 1, 0)\r\nprint (\"Test accuracy:\", accuracy_score(y_test, y_pred))\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n* 참고: \r\n\r\n  >  아마추어 퀀트, blog.naver.com/chunjein\r\n\r\n  >  코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘","excerpt":"NLP & 딥러닝 핵심 문제: \"단어를 어떻게 수치화할 것인가?\" Email - Classification 딥러닝을 이용하여 20개의 카테고리로 분류된 이메일 데이터를 학습하고, 시험 이메일을 20개 카테고리 중 하나로 분류한다.  Email…","fields":{"slug":"/NLP응용_2/"},"frontmatter":{"date":"Jul 22, 2020","title":"NLP Embedding","tags":["NLP","Embedding"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n<br>\r\n\r\n# 고급 NLP 레시피\r\n\r\n* 자연어 기초 용어\r\n* 편집거리\r\n* 주제식별\r\n* 감성분석\r\n\r\n<br><br>\r\n\r\n## 자연어 관련 용어\r\n\r\n- `Document`(문서)\r\n\r\n- `Corpus`(말뭉치): 텍스트(문서)의 집합\r\n\r\n- `Token`(토큰): 단어처럼 의미를 가지는 요소\r\n\r\n- `Morphemes`(형태소): 의미를 가지는 언어에서 최소 단위\r\n\r\n- `POS`(품사): ex) Nouns, Verbs\r\n\r\n- `Stopword`(불용어): I, my, me, 조사, 접미사와 같이 자주 나타나지만 실제 의미에 큰 기여를 하지 못하는 단어들\r\n\r\n- `Stemming`(어간 추출): 어간만 추출하는 것을 의미(running, runs, run -> run)\r\n\r\n- `Lemmatization`(음소표기법): 앞뒤 문맥을 보고 단어를 식별하는 것\r\n\r\n  > 출처: hero4earth. 2018.01.17. \"자연어(NLP) 처리 기초 정리\". http://hero4earth.com/blog/learning/2018/01/17/NLP_Basics_01/\r\n\r\n<br>\r\n\r\n-----------------\r\n\r\n<br>\r\n\r\n## 편집거리(Edit distance)\r\n\r\n- 두 단어 간의 **형태적인 거리**\r\n\r\n  - 의미적 거리 X\r\n    - 의미적인 거리는 Word Embedding을 통해 구현\r\n\r\n- 문자 교정, 추천단어에 사용\r\n\r\n  - ex: 타자기에 appie를 쳤을 때, 기계 내에서 apple로 추천 단어를 보여주는 시스템\r\n\r\n  - 이때 A와 B의 편집거리가 작은 순서로 추천을 해준다\r\n\r\n    - 그렇다면, \"A와 B 사이의 거리를 어떻게 측정할 것인가?\"\r\n\r\n      → Edit distance = Levenshtein distance\r\n\r\n<br>\r\n\r\n>  이하 코드는 크리슈나 바브샤 외 2. 자연어 처리 쿡북 with 파이썬. 에이콘. 2019.01.31에 기반을 두고 있다.\r\n\r\n<br>\r\n\r\n* 편집 거리를 계산하기 위해선,\r\n\r\n  1. 자체 알고리즘 작성<br>\r\n\r\n  2. `nltk.metrics.distance.edit_distance()`와 비교하여 온전성 검사 수행\r\n\r\n     ``` python\r\n     from nltk.metrics.distance import edit_distance\r\n     \r\n     def my_edit_distance(str1, str2): #두 개의 문자열을 입력 받는다\r\n         # 두 문자열의 길이를 구한다\r\n         m = len(str1)+1 \r\n         n = len(str2)+1\r\n         \r\n         # mXn을 할 테이블을 만들고 첫 번째 행과 열을 초기화한다.\r\n         table = {}\r\n         for i in range(m): table[i,0] = i\r\n         for j in range(n): table[0,j] = j\r\n             \r\n         for i in range(1,m):\r\n             for j in range(1,n):\r\n                 cost = 0 if str1[i-1] == str2[j-1] else 1\r\n                 table[i,j] = min(table[i, j-1]+1, table[i-1, j]+1, table[i-1, j-1]+cost)\r\n         return table[i,j]\r\n     \r\n     \r\n     print(\"Our Alorithm:\", my_edit_distance(\"hand\",\"and\"))\r\n     print(\"NLTK Alorithm:\", edit_distance(\"hand\",\"and\"))\r\n     \r\n     ```\r\n\r\n     > * print(\"Our Alorithm:\", my_edit_distance(\"hand\",\"and\"))\r\n     >\r\n     >   Our Alorithm: 1\r\n     >\r\n     > * print(\"NLTK Alorithm:\", edit_distance(\"hand\",\"and\"))\r\n     >\r\n     >   NLTK Alorithm: 1  \r\n\r\n     > cost는 str1과 str2가 동일하거나 편집됐는지, 삭제 또는 삽입인지에 따라 계산됨\r\n     >\r\n     > 다음 행의 수식은 행렬에 있는 셀의 값을 계산하고 첫 번째 두 개는 대체를 처리하고 세 번째는 대체를 위한 것\r\n     >\r\n     \t> 이전 단계의 비용을 추가하고 최소 세 단계를 취한다\r\n\r\n     |      | 0    | H     | A     | N    |\r\n     | ---- | ---- | ----- | ----- | ---- |\r\n     | 0    | 0    | 1     | 2     | 3    |\r\n     | A    | 1    | **1** | **1** | 3    |\r\n     | N    | 2    | `2`   | **2** | 1    |\r\n     | D    | 3    | 3     | 3     | 2    |\r\n     >  ex: **AN(열)~H(행): 같게 만들기 위해** \r\n     >\r\n     > 1. A를 삭제 2. N→H 치환. 따라서 **2단계** 취해서 \r\n     > 2. action : 두 문자를 같게 만들기 위한 문자 1개를 1. 삭제 2. 치환 3. 삽입. 이때 최소 action의 개수를 table에 써줌\r\n\r\n     <br>\r\n\r\n  3. 위에 굵은 글씨 (1,1/2,2) 설명하기 위해 따로 뺌\r\n\r\n  |      | C1   | C2   |\r\n  | ---- | ---- | ---- |\r\n  | C1   | `A`  | B    |\r\n  | C2   | C    | `D`  |\r\n\r\n   * 알고리즘:\r\n\r\n     * C2 == C2\r\n\r\n       → D = A\r\n\r\n       따라서 이동할 필요 없다. cost = 0\r\n\r\n       > cost = 0 if str1[i-1] == str2[j-1] else 1\r\n\r\n       * C2 =/= C2\r\n\r\n         → A+1, B+1, C+1\r\n\r\n         > table[i,j] = min(table[i, j-1]+1, table[i-1, j]+1, table[i-1, j-1]+cost)\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### `TF-IDF`\r\n\r\n* Text 문서를 수치로 표현할 때\r\n\r\n  1. 단어의 빈도 기반(카운트 기반): `TF-IDF`\r\n  2. `Embedding` 기반\r\n\r\n* `TF-IDF` 용어: \r\n  \r\n  * `TF`: 단어 빈도, term frequency\r\n  * `DF`: 문서 빈도, document frequency\r\n* `IDF`: DF값의 역수. 역문서 빈도, inverse document frequency\r\n  \r\n* TF-IDF 생성 순서\r\n\r\n* ![image-20200722100557200](markdown-images/image-20200722100557200.png)\r\n\r\n  1. `Vocabulary` 생성\r\n  2. Term - Document Matrix(`TDM`) 생성\r\n     * Term : 행 / Document : 열\r\n     * 행열 반전시킨 Document - Term Matrix(DTM) 으로도 가능\r\n     * **Term이 각 Document에 몇 번 쓰였는지 카운트**\r\n  3. Term Frequency(`TF`) 계산\r\n     \r\n     * TDM에서 **문서길이 표준화**\r\n  4. `DF` 계산: **각 Vocabulary가 총 몇 개의 Document에 쓰였는지 카운트**\r\n     * 이때, 검색문서는 카운트에서 제외하고\r\n     * **단어가 쓰인 횟수가 아닌, Document 개수로 작성**\r\n     * DF 大 ~ 여러 문서에 나타나는 General한 단어 → 중요도 小\r\n     * 따라서 단어의 중요성 \r\n       * =1/DF → 반비례 관계\r\n       * =TF → 비례 관계\r\n  5. Inverse DF(`IDF`) (즉, = 1/DF)  계산\r\n     * DF에 log 취해서 계산\r\n   * **단어의 중요도는 IF에 비례, IDF에 비례**\r\n  \r\n6. TF*IDF = `TF-IDF`\r\n  \r\n7. TF-IDF 상의 검색문 Vector와 Document Vector 값을 \r\n  \r\n     1. **norm**(l1,l2 등) \r\n        * l1: 벡터의 요소에 대한 절댓값의 합\r\n        * l2: 해당 차원의 좌표평면에서 원점에서 벡터 좌표까지의 최단거리\r\n     2. 검색문과 각 Document의 내적 \r\n   3. cosin 거리 \r\n  \r\n     등으로 **유사도 측정**\r\n\r\n<br>\r\n\r\n* ## code\r\n\r\n* sklearn 패키지 활용\r\n  * 대표적인 Python 머신러닝 라이브러리에서는 문서 전처리용 클래스를 제공한다.\r\n  * 기능\r\n    - `DicVectorizer` : 단어의 수를 세어놓은 사전에서 BOW 벡터를 만든다.\r\n    - `CountVectorizer`: 문서 집합으로부터 단어의 수를 세어 BOW 벡터를 만든다.\r\n    - `Tfidfvectorizer`: 문서 집합으로부터 단어의 수를 세고 TF-IDF 방식으로 단어의 가중치를 조정한 BOW 벡터를 만든다.(CounterVectorizer의 서브클래스로 CountVectorizer를 이용해 BOW를 만들고 TfidTransformer를 사용해 tf-idf로 변환)\r\n    - `HashingVectorizer`: hashing trick을 사용하여 빠르게 BOW 벡터를 만든다.\r\n\r\n```python\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\n```\r\n\r\n<br>\r\n\r\n* TF-IDF matrix를 생성한다\r\n  * 아래 Code 中 `tfidf_vect_simple.fit_transform(statements)` 참고\r\n\r\n``` python\r\nstatements = [문장1, 문장2, 문장3]\r\nTfidfVectorizer(max_features = 500) # 빈도 높은 순으로 500개 단어만 # 변환된 행렬은 희소 행렬\r\nwords = tfidf_vect_simple.fit_transform(statements) # 각 문서들에 대한 단어들이 나오는 빈도수를 log 처리 시켜서 table로 만듦(행렬로 만듦) # transform 써서 단어가 feature(열)로 바뀜 \r\n\r\nvocab = tf_vector.get_feature_names() # shape=(500,) 단어 500개.\r\n```\r\n\r\n<br>\r\n\r\n* cosin 분석한다\r\n\r\n```python\r\nfrom sklearn.metrics.pairwise import cosine_similarity\r\ncosine_similarity(words,words) # tf-idf 처리된 행렬로 word 전체의 cosin-distance 구함\r\n```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### `코사인 유사도`(거리)\r\n\r\n* 벡터와 벡터 간의 유사도를 두 벡터 간의 각도로 나타낸 것\r\n  * 각도=**방향**인 셈.\r\n> 1. 방향이 비슷할수록 두 벡터는 서로 유사하며, \r\n> 2. 벡터 방향이 90도 일때는 두 벡터 간의 관련성이 없으며, \r\n> 3. 벡터 방향이 반대가 될수록 두 벡터는 반대 관계\r\n\r\n![img](https://blog.kakaocdn.net/dn/cluYST/btqBUUjgX1Z/6j4dN9FjuoNhIvKhA9F19k/img.png)\r\n\r\n>  그림 출처: 딥 러닝을 이용한 자연어 처리 입문\r\n\r\n<br>\r\n\r\n* 유클리디안 거리와 달리, cosin distance(유사도)는 방향만 고려하기 때문에 개인 맞춤 추천 솔루션(협업 필터링)에 활용된다.\r\n  * 협업 필터링 기법에서는 한 '제품' 을 하나의 벡터로 취급한다.\r\n    * 세부 특징 하나하나가 벡터가 되지 않는단 것이다\r\n\r\n<br>\r\n\r\n* > 출처 및 참고:\r\n  >\r\n  > * 데이터 파수꾼 Baek Kyun Shin. 2020. 2. 17. \"NLP - 8. 코사인 유사도(Cosine Similarity)\". https://bkshin.tistory.com/entry/NLP-8-문서-유사도-측정-코사인-유사도\r\n  > * 데이타광 DNA구너. 2020. 5. 20. \"[스팀 2부 - 이론] 협업 필터링 - 스팀, 넷플릭스, 아마존이 당신을 사로잡기 위해 부리는 마법 이해하기\". https://dnagooner.tistory.com/51\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n-------------\r\n\r\n<br><br>\r\n\r\n* ### Text를 수치 Vector로 표현할 때\r\n\r\n1. 통계적 기반, 빈도 기반, 카운트 기반:\r\n\r\n   * `TF-IDF`: \r\n\r\n     1. Vocabulary(Dictionary) 생성\r\n     2. Term - Document Matrix(`TDM`) 생성\r\n     3. Term Frequency(`TF`) 계산\r\n     4. `DF` 작성: **각 Vocabulary가 총 몇 개의 Document에 쓰였는지 카운트**\r\n     5. Inverse DF(`IDF`) (즉, = 1/DF) 작성\r\n     6. TF*IDF = `TF-IDF`\r\n        \r\n        + 나아가, TF-IDF 상의 검색문 Vector와 Document Vector 값을 가공하여 유사도 측정\r\n        \r\n        <br>\r\n\r\n   * **`BOW(Bag of word)`**: \r\n\r\n     * 쿡북 p. 235~\r\n\r\n     * 방법: 수치로 형상화하여 추출 시 사용 \r\n\r\n     * `doc2bow` 생성\r\n\r\n       ex: I love you very much, you love me too.\r\n\r\n       1. Vocabulary(Dictionary) 생성\r\n\r\n          > 여러 문서로 부터 생성함\r\n          >\r\n          > I : 0\r\n          >\r\n          > love : 1\r\n          >\r\n          > you : 2\r\n          \r\n           >...(이하 생략)\r\n          \r\n       2. 문서를 doc2bow로 생성\r\n\r\n          > 1. bow: 워드를 수치화(I love you~를 Vocabulary에서 정의한 숫자로 적어줌)\r\n          >\r\n          >    [0, 1, 2, ... 2, 1, ...] ← vector\r\n          >\r\n          > 2. Doc2Bow: 수치화된 워드별 빈도\r\n          >\r\n          >    [(0,1), (1,2), (2,2), ...] ← vector\r\n\r\n           >   (0,1)에서 '1' = 빈도 \r\n\r\n       3. LDA 모형 사용 \r\n\r\n          1. 문서별 Topic 번호 확인\r\n          2. topic별 문서 확인 \r\n          \r\n          <br>\r\n\r\n   * `TF-IDF`와 `BOW`의 차이점:\r\n\r\n     * Vocabulary 만들고 시작하는 건 같지만, \r\n\r\n       * 1. BOW는 TF까지, TF-IDF는 IDF와 TF*IDF까지 구함\r\n         2. BOW의 TF와 TF-IDF의 TF값은 다름\r\n            \r\n            * 이유: TF-IDF의 TF는 표준화 시킨 값이고, BOW의 TF는 빈도만 세었기 때문\r\n            \r\n              > TF-IDF:\r\n              >\r\n              > **어떤 단어가 하나의 문서에서도 많이 사용되었다고 하더라도, 다른 모든 문서에서 널리 쓰이는 흔해 빠진 단어라면 이 단어는 특정성(specificity)이 떨어지는 것이다.**\r\n              >\r\n              > 그래서 단순 단어 빈도로 접근하는 게 아니라, 어떤 단어가 한 문서에서 많이 나타난 동시에 다른 문서에서는 잘 나타나지 않는 것까지 고려하기 위한 개념이 등장하는 데 이게 바로 **TF-IDF(Term Frequency-Inverse Document Frequency)**다. \r\n              >\r\n              > 아무튼 TF-IDF는 단순한 단어 빈도가 아니라 일종의 가중치를 적용한 개념이라고 이해하면 된다. 그래서 이 TF-IDF를 활용해서 문서-단어 행렬을 만들고 분석을 하는 경우도 매우 많다.\r\n              >\r\n              > 그래서 파이썬 라이브러리 scikit-learn에서는 아예 단순 빈도로 접근하는 `CountVectorizer`말고, TF-IDF로 접근하는 `TfidfVectorizer `클래스를 제공하기도 한다.\r\n              >\r\n              > * 출처: 아무튼워라밸. 2020.01.24. \"Bag-of-Words(BoW) 쉽게 이해하기\". http://hleecaster.com/nlp-bag-of-words-concept/\r\n\r\n         * 따라서 BOW와 TF-IDF의 쓰임새는 상황에 따라 다르다.\r\n       \r\n         <br>\r\n\r\n     * `BOW`: 주어진 말뭉치에서 사용된 각각의 단어의 빈도를 센다\r\n     \r\n       > 주어진 말뭉치에서 사용된 각각의 단어에 인덱스를 매겨서 사전처럼 만든다. (==Vocabulary==)\r\n       >\r\n     > 그리고 입력된 문서의 각 단어가 해당 단어 사전(단어 주머니)에서 해당 인덱스에 얼마나 나타나는지 표시하는 방식으로 입력된 문장을 분석한다. (==TF==)\r\n     \r\n       <br>\r\n     * `TF-IDF`: `BOW`와 같이 각각의 문서에서 단어의 개수를 세는 것은 같다. 그치만 여기에 전체 말뭉치(Corpus)에서 단어의 갯수도 함께 센다.\r\n     \r\n       > 특정 단어가 문서 내에 얼마나 자주 등장하는 지를 나타내는 ==TF(단어 빈도)==와\r\n       >\r\n       > 어떤 단어가 문서 전체 집합에서 얼마나 많이 나오는지를 나타내는 ==IDF(역문서 빈도)==로 \r\n       >\r\n       > 이 둘의 곱으로 TF-IDF를 값을 구할 수 있다.\r\n       \r\n       <br>\r\n\r\n2. Embedding 기반\r\n\r\n   * Word Embedding: 벡터화\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### \t`Bow`\r\n\r\n* code에 `TF-IDF` 없음\r\n\r\n* 한계: \r\n\r\n  > Bow 모델은 그 빈도만 세기 때문에 맥락을 충분히 고려해야 하는 상황, 즉 **텍스트를 생성한다거나 예측하는 등의 장면에는 활용이 어렵다.**\r\n  >\r\n  > 게다가 학습된 단어 사전을 기반으로 하기 때문에 사전에 없는 새로운 단어가 나타났을 때 그걸 처리할 방법이 없다. 학습 데이터에 지나치게 의존하기 때문에 **오버피팅(overfitting)**이 발생하는 거다.\r\n  >\r\n  > 출처: 아무튼워라밸. 2020.01.24. \"Bag-of-Words(BoW) 쉽게 이해하기\". http://hleecaster.com/nlp-bag-of-words-concept/\r\n\r\n  <br>\r\n\r\n* ## Code:\r\n\r\n  * `gensim` 패키지 활용\r\n    * **문서 사이의 유사도 계산과 텍스트 분석을 돕는** 라이브러리\r\n    * 기능\r\n      - **Topic Modeling**\r\n        - `LDA(Latent Dirichlet Allocation)`\r\n        - LSI(Latent Semantic Indexing)\r\n        - HDP(Hierarchical Dirichlet Process)\r\n      - **Word Embedding**\r\n        - `word2Vec`\r\n    * Latent Dirichlet Allocation (`LDA`) using `gensim`\r\n  \r\n\r\n```python\r\nimport numpy as np\r\nimport re\r\nimport pickle\r\nfrom nltk.corpus import stopwords\r\n**from gensim import corpora**\r\n**from gensim.models.ldamodel import LdaModel as LDA**\r\n```\r\n\r\n\r\n```python\r\n# 1. 저장된 news data를 읽어온다.\r\n# 2. 첫 번째 news를 조회해 본다.\r\n# 3. news 별로 분류된 target을 확인해 본다.\r\n  \r\n# 4. preprocessing.\r\n# 4-1. 영문자가 아닌 문자를 모두 제거한다.\r\n# 4-2. 불용어를 제거하고, 모든 단어를 소문자로 변환하고, 길이가 3 이하인 단어를 제거한다\r\n```\r\n\r\n  > 밑에 주제식별 > LSA , LDA code 참고\r\n\r\n<br>\r\n\r\n  ```python\r\n# doc2bow 생성\r\n## vocabulary \r\nvocab = corpora.Dictionary(news2)\r\ndict(list(vocab.items())[:10]) # list-> dic 변환하는 거 복습 시 다시 확인하기\r\n  ```\r\n\r\n  > {0: 'acts',\r\n  > 1: 'atrocities',\r\n  > 2: 'austria',\r\n  > 3: 'away',\r\n  > 4: 'biased',\r\n  > 5: 'blessing',\r\n  > 6: 'clearly',\r\n  > 7: 'commited',\r\n  > 8: 'daily',\r\n  > 9: 'degree'}\r\n\r\n<br>\r\n\r\n  ```python\r\n## bow & doc2bow\r\nnews_bow = [vocab.doc2bow(s) for s in news2] \r\nprint(news_bow[0])\r\n  ```\r\n\r\n  > [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 4), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1)]\r\n\r\n<br>\r\n\r\n  ```python\r\n# Latent Dirichlet Allocation (LDA)\r\n# ---------------------------------\r\nmodel = LDA(news_bow,\r\n            num_topics = len(newsData.target_names), # len(newsData.target_names) = 20\r\n            id2word=vocab) # vocab = vocabulary 만든 것 \r\n  ```\r\n\r\n<br>\r\n\r\n  * 이하부턴 TF-IDF의 LDA 코드와 동일함\r\n\r\n```python\r\n# 문서 별 Topic 번호를 확인한다. (문서 10개만 확인)\r\ndoc_topic = model.get_document_topics(news_bow)\r\nfor i in range(10):\r\n    dp = np.array(doc_topic[i])\r\n    most_likely_topic = int(dp[np.argmax(dp[:, 1]), 0])\r\n    print('문서-{:d} : topic = {:d}'.format(i, most_likely_topic))\r\n```\r\n\r\n> 문서-0 : topic = 3\r\n> 문서-1 : topic = 3\r\n> 문서-2 : topic = 3\r\n> 문서-3 : topic = 2\r\n> 문서-4 : topic = 3\r\n> 문서-5 : topic = 3\r\n> 문서-6 : topic = 14\r\n> 문서-7 : topic = 2\r\n> 문서-8 : topic = 2\r\n> 문서-9 : topic = 5\r\n\r\n<br>\r\n\r\n  ```python\r\n# topic_term 행렬에서 topic 별로 중요 단어를 표시한다\r\ntopic_term = model.get_topic_terms(0, topn=10)\r\nfor i in range(len(newsData.target_names)):\r\n    topic_term = model.get_topic_terms(i, topn=10)\r\n    idx = [idx for idx, score in topic_term]\r\n    print('토픽-{:2d} : '.format(i+1), end='')\r\n    for n in idx:\r\n        print('{:s} '.format(vocab[n]), end='')\r\n    print()\r\n  ```\r\n\r\n> 토픽- 1 : would keyboard program problem like number medical also health available \r\n> 토픽- 2 : available file program window information mail version server info thanks \r\n> 토픽- 3 : would people like think know time could well something make \r\n> 토픽- 4 : would people think know jesus even like said time believe \r\n> 토픽- 5 : state would pain many like people case could also court \r\n>\r\n> ....\r\n\r\n<br>\r\n\r\n  ```python\r\n# 문서별로 분류된 코드를 확인해 본다.\r\n# x, y : 문서 번호\r\ndef checkTopic(x, y):\r\n    print(\"문서 %d의 topic = %s\" % (x, newsData.target_names[newsData.target[x]]))\r\n    print(\"문서 %d의 topic = %s\" % (y, newsData.target_names[newsData.target[y]]))\r\n  \r\ncheckTopic(2, 5)\r\ncheckTopic(7, 9)\r\n  ```\r\n\r\n> 문서 2의 topic = talk.politics.mideast\r\n> 문서 5의 topic = soc.religion.christian\r\n> 문서 7의 topic = talk.politics.mideast\r\n> 문서 9의 topic = sci.electronics\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n-----------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 주제 식별 (Topic Model)\r\n\r\n* 주제별 clustering 실행<br>\r\n* 수많은 text document 를 주제별로 군집화(clustering)\r\n  * ex: 문학/경제 ... 등의 주제별로 나눔<br>\r\n* 대표 알고리즘: `LDA`\r\n  * ML:\r\n    1. SL(지도학습)\r\n    2. UL(비지도학습)\r\n    3. 통계적 추론: `HMM`(`Baum welch` 등), **`LDA 모형`**\r\n    4. RL(강화학습)<br>\r\n\r\n* Topic Model 발전 순서: SVD → LSA 모형 → LDA 알고리즘 \r\n\r\n<br>\r\n\r\n----------\r\n\r\n<br>\r\n\r\n### Topic Model(LSA vs LDA)\r\n\r\n* `LSA `\r\n\r\n  * SVD 원리\r\n\r\n* `LDA`\r\n\r\n  * **결합확률 분포** 취급\r\n  * 문서, 단어 조합이 많아 결합확률 분포가 굉장히 복잡하기 때문에 `Sampling 기법`으로 **근사적으로 계산**함(특히 `Gibb's sampling 기법` 사용)\r\n  \r\n* > `LSA` : ==DTM을 **차원 축소** 하여 축소 차원에서 근접 단어들을 **토픽으로 묶는다.**==\r\n  > `LDA` : ==단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 **결합확률**로 추정하여 **토픽을 추출한다.**==\r\n  >\r\n  > * 출처: [딥 러닝을 이용한 자연어 처리 입문, \"2) 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)\"](https://wikidocs.net/30708)\r\n\r\n<br>\r\n\r\n### `SVD`\r\n\r\n* 차원축소\r\n\r\n  1. `PCA`\r\n     * 고유값 분해\r\n\r\n  2. `SVD`\r\n     * 특이값 분해, Topic Model에도 쓰임(특히 LSA: 잠재 의미 분석)\r\n\r\n* PCA, SVD 모두 sklearn에서 사용할 수 있음\r\n\r\n<br>\r\n\r\n* ## Code:\r\n\r\n  ```python\r\n  import numpy as np\r\n  from sklearn.feature_extraction.text import TfidfVectorizer\r\n  ```\r\n<br>\r\n  ```python\r\n  # TF-IDF matrix를 SVD로 분해한다.\r\n  # C = U.S.VT\r\n  statements = [\r\n              'ruled india',\r\n              'Chalukyas ruled Badami',\r\n              'So many kingdoms ruled India',\r\n              'Lalbagh is a botanical garden in India'\r\n          ]\r\n  ```\r\n<br>\r\n  ```python\r\n  # TF-IDF matrix를 생성한다.\r\n  tf_vector = TfidfVectorizer(max_features = 8) # max_features = 8 최대 단어 개수(빈도 높은 8개 단어만 추출)\r\n  tfidf = tf_vector.fit_transform(statements) #.toarray 써주면 배열 형태로 출력 \r\n  print(tfidf.shape)\r\n  ```\r\n<br>\r\n  ```python\r\n  # SVD (Singular Vector Decomposition)으로 TF-IDF를 분해한다.\r\n  # U, S, VT 행렬의 의미 --> Latent Semantic Analysis (LSA)\r\n  # U 행렬 ~ 차원 = (문서 개수 X topic 개수) : 문서당 topic 분포\r\n  # S 행렬 ~ 차원 = (topic 개수 X topic 개수) : 대각성분. 나중에 행렬에 넣을 땐 대각성분만 빼면 0\r\n  # VT 행렬. 차원 = (topic 개수 X 단어 개수) : topic 당 단어 빈도 (분포)\r\n  U, S, VT = np.linalg.svd(tfidf.toarray(), full_matrices = True)\r\n  \r\n  print(U.round(2), '\\n') # 모든 열벡터들의 내적 = 0\r\n  print(S.round (2), '\\n') # 왼->오로 갈 수록 수치가 작아짐. 따라서 성분이 큰 것(=수치가 큰 것)이 앞에 나옴 \r\n  print(VT.round(2), '\\n')\r\n  ```\r\n<br>\r\n  > **print(U.round(2), '\\n')**\r\n  >\r\n  > [[ 0.65 -0.   -0.02  0.76]\r\n  >  [ 0.33 -0.79 -0.42 -0.29]\r\n  >  [ 0.53 -0.    0.72 -0.44]\r\n  >  [ 0.43  0.61 -0.55 -0.38]] \r\n<br>\r\n  > **print(S.round (2), '\\n')**\r\n  >\r\n  > [1.34 1.   0.88 0.66] \r\n<br>\r\n  > **print(VT.round(2), '\\n')**\r\n  > [[ 0.16  0.16  0.65  0.2   0.27  0.2   0.57  0.2 ]\r\n  >  [-0.51 -0.51  0.33 -0.    0.51 -0.   -0.33 -0.  ]\r\n  >  [-0.31 -0.31 -0.08  0.42 -0.52  0.42  0.06  0.42]\r\n  >  [-0.28 -0.28  0.29 -0.34 -0.48 -0.34  0.42 -0.34]\r\n  >  [ 0.24 -0.45 -0.33  0.56  0.21 -0.28  0.33 -0.28]\r\n  >  [ 0.25 -0.35 -0.16 -0.41  0.1   0.71  0.16 -0.29]\r\n  >  [-0.6   0.3  -0.47 -0.12  0.3   0.06  0.47  0.06]\r\n  >  [ 0.25 -0.35 -0.16 -0.41  0.1  -0.29  0.16  0.71]] \r\n<br>\r\n  ```python\r\n  # S를 행렬 형태로 변환한다.\r\n  s = np.zeros(tfidf.shape)\r\n  s[:S.shape[0], :S.shape[0]] = np.diag(S) # 대각선에 정방행렬(S)를 집어 넣어라 \r\n  print(s.round(2), '\\n')\r\n  ```\r\n<br>\r\n  > **print(s.round(2), '\\n')**\r\n  > [[1.34 0.   0.   0.   0.   0.   0.   0.  ]\r\n  >  [0.   1.   0.   0.   0.   0.   0.   0.  ]\r\n  >  [0.   0.   0.88 0.   0.   0.   0.   0.  ]\r\n  >  [0.   0.   0.   0.66 0.   0.   0.   0.  ]] \r\n\r\n\r\n\r\n<br>\r\n\r\n### `LSA`\r\n\r\n* LSA : 잠재 의미 분석 \r\n\r\n* ![image-20200722094819751](image-20200722094819751.png)\r\n\r\n  <br>\r\n\r\n* ## code\r\n\r\n```python\r\nimport numpy as np\r\nimport re\r\nimport pickle\r\nfrom nltk.corpus import stopwords\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\nfrom sklearn.decomposition import TruncatedSVD\r\n```\r\n\r\n``` python\r\n# 저장된 news data를 읽어온다.\r\nwith open('./dataset/news.data', 'rb') as f:\r\n    newsData  = pickle.load(f)\r\n\r\n# 첫 번째 news를 조회해 본다.\r\nnews = newsData.data\r\nprint(len(news)) \r\nprint(news[0])\r\n```\r\n\r\n> 11314\r\n>\r\n> Well i'm not sure about the story nad it did seem biased. What...\r\n\r\n<br>\r\n\r\n```python\r\n# news 별로 분류된 target을 확인해 본다.\r\nprint(newsData.target_names)\r\nprint(len(newsData.target_names))\r\n```\r\n\r\n> ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', ...\r\n>\r\n> 20\r\n\r\n<br>\r\n\r\n``` python\r\n# preprocessing.\r\n# 1. 영문자가 아닌 문자를 모두 제거한다.\r\nnews1 = []\r\nfor doc in news:\r\n    news1.append(re.sub(\"[^a-zA-Z]\", \" \", doc))\r\n    \r\n# 2. 불용어를 제거하고, 모든 단어를 소문자로 변환하고, 길이가 3 이하인 단어를 제거한다\r\nstop_words = stopwords.words('english')\r\nnews2 = []\r\nfor doc in news1:\r\n    doc1 = []\r\n    for w in doc.split():\r\n        w = w.lower()\r\n        if len(w) > 3 and w not in stop_words:\r\n            doc1.append(w)\r\n    news2.append(' '.join(doc1))\r\n    \r\nprint(news2[0])\r\n```\r\n\r\n> well sure story seem biased disagree statement media ruin israels reputation...\r\n\r\n<br>\r\n\r\n```python\r\n# TF-IDF matrix를 생성한다.\r\ntf_vector = TfidfVectorizer(max_features = 500) # 변환된 행렬은 희소 행렬\r\ntfidf = tf_vector.fit_transform(news2)\r\nprint(tfidf.shape) # (11314, 500)\r\n\r\nvocab = tf_vector.get_feature_names() # shape=(500,)\r\nprint(vocab[:20])\r\n```\r\n\r\n> ['able', 'access', 'actually', 'address', 'advance', 'agree', 'allow', 'almost', 'already', 'also', 'although', 'always', 'american', 'among', 'anonymous', 'another', 'answer', 'anti', 'anybody', 'anyone']\r\n\r\n<br>\r\n\r\n```python\r\n# Latent Semantic Analysis (LSA)\r\n```\r\n<br>\r\n```python\r\nsvd = TruncatedSVD(n_components = len(newsData.target_names), n_iter=1000) # svd.shape = (20,)\r\nsvd.fit(tfidf) # tfidf.shape = (11314, 500)\r\n\r\nU = svd.fit_transform(tfidf) / svd.singular_values_ # svd.fit_transform(tfidf) = (11314, 20) # svd.singular_values_ = (20,) # U.shape = (11314, 20)\r\nVT = svd.components_ # VT.shape = (20,500) # VT: 직교행렬(내적 0 이라 서로 독립적이다)\r\nS = np.diag(svd.singular_values_) # S.shape = (20, 20) # S: 대각 성분을 제외한 원소는 모두 0 \r\n```\r\n<br>\r\n```python\r\n# 문서 별 Topic 번호를 확인한다. (문서 10개만 확인)\r\nfor i in range(10):\r\n    print('문서-{:d} : topic = {:d}'.format(i, np.argmax(U[i:(i+1), :][0])))\r\n    ## 해석: 0문서엔 17번이란 이름으로 부여된 topic(단어..)가 있고, 2문서에도 같은 게 있다. 그럼 0문서랑 2문서랑 clustering 해도 되겠다 < 라고 판단하는 알고리즘임 \r\n    \r\n# VT 행렬에서 topic 별로 중요 단어를 표시한다 \r\n# topic: 주요 성분(내림차순 배열). \"tf_vector = TfidfVectorizer(max_features = 500)\" 해서 자주 나오는 단어만 500개 남겼잖슴? 거기서 남긴 500개가 주요성분이란 뜻이고 그게 즉 topic임 \r\nfor i in range(len(VT)):\r\n    idx = np.flipud(VT[i].argsort())[:10] # np.flipud(): 위아래 반전 # .argsort(): 오름차순 배열 => 문서순이 아니라 토픽순으로 정렬하겠단 뜻 => flipud+argsort: 따라서 내림차순 배열이 됨 \r\n    print('토픽-{:2d} : '.format(i+1), end='')\r\n    for n in idx:\r\n        print('{:s} '.format(vocab[n]), end='') # 토픽을 차원축소=묶었으므로 vocab[n] 하면 응축된(topic)이 1개씩 나오게 됨 \r\n    print()\r\n```\r\n<br>\r\n```python\r\nnewsData.keys()\r\n```\r\n\r\n> dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\r\n\r\n<br>\r\n\r\n```python\r\n# 문서별로 분류된 코드를 확인해 본다.\r\n# x, y : 문서 번호\r\ndef checkTopic(x, y):\r\n    print(\"문서 %d의 topic = %s\" % (x, newsData.target_names[newsData.target[x]]))\r\n    print(\"문서 %d의 topic = %s\" % (y, newsData.target_names[newsData.target[y]]))\r\n\r\ncheckTopic(1, 6)\r\ncheckTopic(0, 2)\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### `LDA`\r\n\r\n* 잠재 디디클레 할당\r\n\r\n* 비지도학습\r\n\r\n* LDA를 사용함으로써 문서 내에서 토픽을 찾을 수 있다.\r\n\r\n  > LDA의 가장 큰 장점은 각각의 문서를 토픽들의 집합으로 본것이다. (즉 Document는 Mixture of Topic이라는 말이다.)\r\n  >\r\n  > 만약 내가 \"김제동, 외압으로 '김제동 쇼'하차\" 라는 기사를 본다고 생각해보자.\r\n  >\r\n  > 이 기사에는 김제동이 어떤 정치적 이유 때문에 김제동 쇼에서 하차하게 되었다는 내용이 적혀있을것이다.  일반적으로 '김제동'이라는 단어를 '연예'라는 토픽에 속해 있다고 봤을때 이 기사는 '연예'라는 토픽만을 다룬 것이 아니라 '외압' 즉 어떤 '정치'에 연관된 토픽 또한 다루고 있다.\r\n  >\r\n  > 이와 같이 모든 문서는 하나의 토픽에만 속하는 것이 아니라 두세가지의 다른 토픽들의 혼합(Mixture)으로 정의 할 수 있는데 이것이 LDA가 가지는 가장 큰 가설중 하나이다.\r\n  >\r\n  > * 출처: arongdari. 2010. 6. 2. \"Latent Dirichlet Allocation\". https://arongdari.tistory.com/entry/Latent-Dirichlet-Allocation. \r\n\r\n  <br>\r\n\r\n* 현실: 오로지 문서만 주어지고, Topic은 주어지지 않아 추정해서 문서를 해당 Topic으로 할당해야 한다.\r\n\r\n  * 추정 방법: 두 개의 다항분포를 측정하고, 해당 문서를 특정 Topic에 할당\r\n    * 1. Topic의 문서 분포\r\n      2. 문서의 Topic 분포<br>\r\n\r\n* 문서 집합에서 Topic 분포 등을 추정\r\n\r\n  * 추정 순서:\r\n\r\n    * 1. 문서 집합에서\r\n\r\n      2. 토픽 추출\r\n\r\n      3. 토픽 추정\r\n\r\n         * 토픽의 주요 단어 추정\r\n\r\n      4. (1) 토픽별 문서 분포 추출 \r\n\r\n         (2) 문서별 토픽 분포 추출\r\n\r\n      5. 시간대 별 토픽의 변화 추정 \r\n\r\n         * 시간에 따라 어떤 토픽이 관심을 받는지, 신규 문서가 어느 토픽에 대한 것인지 등을 추정할 수 있다.\r\n\r\n         * ![image-20200721170724695](image-20200721170724695.png)\r\n\r\n         * (시간대 별 토픽의 변화 추정 그림 中) Topic2에 대한 문서들이 점차 증가했다\r\n\r\n           → 관심이 점점 늘어나는 주제인가 보다,를 알 수 있음 \r\n\r\n<br>\r\n\r\n* Topic 모델링: 다수의 문서를 유사한 주제별로 분류\r\n\r\n  * 비지도학습\r\n\r\n  * 처음은 유사도에 의해 Clustering\r\n\r\n  * 새로운 문서가 등장하면, K-Means or SOM처럼 중점의 좌표를 찾는 알고리즘을 통해\r\n\r\n    1. 거리 측정\r\n\r\n    2. 가까운 거리에 있는 Cluster로 할당\r\n\r\n       ex: 새로운 뉴스가 발생했을 때, 유사도가 높은 중심 토픽을 찾으면 해당 뉴스가 어느 토픽에 속하는지 판별할 수 있다.\r\n       \r\n       <br>\r\n\r\n* LDA 모형으로 Topic 모델링:\r\n\r\n  * `Generative Model`\r\n\r\n    >\"데이터가 어떻게 발생되었느냐?\" 의 측면에서 문제를 접근해 나가는 것\r\n    >\r\n    >어떤 데이터들이 주어졌을 경우 이 데이터가 생기기 위해서 내부적으로 어떤과정과 어떠한 원인을 통해 이런 데이터가 생성되었느냐의 측면에 초점을 맞추는 것\r\n\r\n    <br>\r\n\r\n  * `Discriminative Model`\r\n  \r\n    > 발생된 데이터들을 바탕으로 \"이를 나누는 기준이 무엇인가? \"에 초점을 맞춘 접근방식이며 \r\n  >\r\n    > 데이터가 발생한 원인이나 과정등을 직접적으로 다루지는 않는다.\r\n\r\n    > * 출처: arongdari. 2010. 6. 2. \"Latent Dirichlet Allocation\". https://arongdari.tistory.com/entry/Latent-Dirichlet-Allocation. \r\n\r\n    <br>\r\n\r\n  * 문서 집합(Corpus)에서 관측된 W(Word)를 이용하여 Hidden 상태의 세타와 베타를 추론한다.\r\n  \r\n  * ![image-20200721171735402](image-20200721171735402.png)\r\n  \r\n    > * Color: \r\n    >\r\n    >   * gray: 관측된 상태(얘만 알고 있는 상태)\r\n    >   * white: 아무것도 모르는 상태 \r\n  \t>* 세타는 LSA Model에서 U*S or U에 해당하며, Topic이 열이다\r\n    > * 베타는 LSA Model에서 Vt에 해당하며, Topic은 각 첫 번째 행이다(1열)\r\n  \r\n    <br><br>\r\n  \r\n  * ## code: \r\n\r\n```python\r\n# TF-IDF matrix를 생성한다. < 까지 LSD와 같음\r\n```\r\n\r\n```python\r\n# Latent Dirichlet Allocation (LDA) 여기서부터 다름!!!!\r\n# ---------------------------------\r\n# Return 값이 Document-Topic distribution이다.\r\n# iteration 횟수가 max_iter까지 가면 아직 수렴하지 않은 것이다.\r\n# 아직 수렴하지 않은 경우 mat_iter를 증가시켜야 한다.\r\n# mat_iter를 증가시켜도 수렴하지 못하는 경우는 preprocessing 등을 좀 더 정밀하게 해야 한다.\r\n# evaluate_every=5: 5Step마다 성능 평가 결과 출력. 비지도학습인 만큼, 이때는 perplexity 지표 사용 \r\n# perplexity: LDA에서 깁스 샘플링 관련하여 공식을 형성함. 작거나 작아질수록 Good \r\n# n_compoenets가 적절치 못하면 샘플링이 터진다 \r\nmodel = LDA(n_components = len(newsData.target_names), \r\nlearning_method='online', \r\nevaluate_every=5, \r\nmax_iter=1000, \r\nverbose=1)\r\n\r\ndoc_topic = model.fit_transform(tfidf)    \r\n```\r\n\r\n\r\n​    <br>\r\n\r\n* 문서 별 Topic 번호를 확인한다. (문서 10개만 확인)\r\n\r\n```python\r\n    for i in range(10):\r\n        print('문서-{:d} : topic = {:d}'.format(i, np.argmax(doc_topic[i:(i+1), :][0])))\r\n```\r\n\r\n<br>\r\n\r\n* topic_term 행렬에서 topic 별로 중요 단어를 표시한다\r\n  \r\n```python\r\n    topic_term = model.components_\r\n    for i in range(len(topic_term)):\r\n        idx = np.flipud(topic_term[i].argsort())[:10]\r\n        print('토픽-{:2d} : '.format(i+1), end='')\r\n        for n in idx:\r\n            print('{:s} '.format(vocab[n]), end='')\r\n        print()\r\n    \r\n    newsData.keys()\r\n```\r\n\r\n\r\n<br>\r\n* 문서별로 분류된 코드를 확인해 본다.\r\n  \r\n```python\r\n    # x, y : 문서 번호\r\n    def checkTopic(x, y):\r\n        print(\"문서 %d의 topic = %s\" % (x, newsData.target_names[newsData.target[x]]))\r\n        print(\"문서 %d의 topic = %s\" % (y, newsData.target_names[newsData.target[y]]))\r\n```\r\n\r\n> 토픽- 1 : like article would people second period perhaps nothing called someone \r\n    > 토픽- 2 : space nasa soon earth cost much idea talking make high **#문서-0은 topic2일 가능성이 높다. 따라서 확인해보니, 이메일 관련 서류인 것 같다.**\r\n    > 토픽- 3 : hear read news white heard going long ever keep goes \r\n    > 토픽- 4 : drive disk system scsi apple memory hard computer drives controller \r\n    > 토픽- 5 : year games last game season team would good years time\r\n\r\n>...(토픽 - 20까지 있음)\r\n\r\n```python\r\n    checkTopic(1, 5)\r\n    checkTopic(0, 2)\r\n    checkTopic(4, 7)\r\n```\r\n\r\n> 문서 1의 topic = alt.atheism\r\n    > 문서 5의 topic = soc.religion.christian\r\n    > 문서 0의 topic = talk.politics.mideast\r\n    > 문서 2의 topic = talk.politics.mideast\r\n    > 문서 4의 topic = rec.sport.hockey\r\n    > 문서 7의 topic = talk.politics.mideast\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n----------------------------\r\n\r\n<br><br>\r\n\r\n## `PageRank 알고리즘`\r\n\r\n* 구글 search 엔진 원리<br>\r\n\r\n* damping-factor (d):\r\n\r\n  * d: 사람들이 D라는 문서(Hypertext)를 볼 때 거기에 연결된 BAC를 반드시 클릭한다고 가정하는 정도\r\n\r\n    * Hypertext: 구글에서 searching 하려는 검색어\r\n    * 문서: 검색어(Hypertext)입력했을 때 나오는 페이지<br>\r\n\r\n  * 즉, d는 일종의 가중치 역할(0~1값) = Hyper parameter\r\n\r\n    * d=0 : 해당 페이지에서 클릭하지 않음\r\n      + D 문서에 관심 X이면 여기에 연결된 Link인 BAC Link들은 안 보고 나간다 → D 문서는 별로 쓸모 없음 \r\n    * d=1 : 계속 클릭함\r\n    * 논문에선 d = 0.85로 설정함<br>\r\n\r\n  * PageRank 업데이트 순서:\r\n\r\n    1. 각 페이지의 PageRank  초기화\r\n    2. 공식 써서 각 문서의PageRank  계산 ← 반복\r\n       * PageRank가 높은 문서가 더 중요한 문서라 판단함 <br>\r\n3. damping-factior(d) 적용시 값은 또 달라짐\r\n\r\n<br><br>\r\n\r\n### `TextRank`\r\n\r\n* PageRank 알고리즘 활용<br>\r\n\r\n* 문서 → 중요 문장 추출(유사도 계산)\r\n\r\n* 문장 → 중요 단어 추출(유사도 계산)\r\n\r\n  * 근데 '단어' 를 추출하는 건 보통 Word Embedding 사용함 <br>\r\n\r\n* 키워드 추출, 문장 추출 시 활용\r\n\r\n  * TextRank가 가장 높은 문서의 대표 문장을 뽑아내어 문서 Summary 역할도 수행함 <br>\r\n\r\n* TextRank 업데이트 순서:\r\n\r\n  1. 각 문장의 TextRank 초기화<br>\r\n  2. 문장간 유사도(w) 측정\r\n     * ==한 문서를 문장별로 나누고, 그 문장들에 공통적으로 등장하는 단어(w)의 개수를 세어, 이 수치를 문장 간의 유사도라 측정한다==\r\n     * w: word. 단어.\r\n     * 문장 간의 공통된 단어가 없으면 유사도(w)는 0 \r\n     * 공식: 분모 >> 특정 단어가 i번째 문장과 j번째 문장에도 속하는 개수<br>\r\n\r\n  3. 공식으로 각 문장의 TextRank 계산 ← 반복\r\n     * B의 TextRank가 A보다 높으면 B가 A보다 더 중요한 문장이라 판단함.\r\n       * 따라서 B를 다음 문장으로 선택함\r\n     * 내가(문장이) 중요하면 링크된 문장도 중요해짐 <br>\r\n     \r\n     <br>\r\n\r\n* ### code\r\n\r\n* TextRank 패키지\r\n\r\n  ```python\r\n  from gensim.summarization.summarizer import summarize\r\n  ```\r\n\r\n  > 문서 내 중요한 문장만을 뽑아 연결<br>\r\n\r\n* text 정의\r\n\r\n  ```python\r\n  text = [~]\r\n  ```\r\n\r\n<br>\r\n\r\n* summary\r\n\r\n  ```python\r\n  s = summarize(text, ratio = 0.2) # 전체 문장 중에 20% 정도 추출\r\n  ```\r\n\r\n  > And she won't eat her dinner - rice pudding again -\r\n  > I've promised her dolls and a daisy-chain,\r\n  > I've promised her sweets and a ride in the train,\r\n  > And it's lovely rice pudding for dinner again!\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n------------------\r\n\r\n<br><br>\r\n\r\n## Anaphora Resolution(`조응어 해석`) : 대용어 처리\r\n\r\n* 이름을 구별하기 위해서는 문장 구조를 분해해야 하고(Chunk)<br>\r\n\r\n* 이름의 성별을 구별하기 위해서는 name corpus를 사용한 학습이 필요하다<br>\r\n\r\n* > John is a man. He walks. : He는 John을 가리킴 \r\n  >\r\n  > John and Mary are married. They have two kids. : They는 John과 Mary를 가리킴 \r\n  \r\n  <br>\r\n  \r\n  ```python\r\n  # Anaphora resolution 예시\r\n  import nltk\r\n  from nltk.chunk import tree2conlltags\r\n  from nltk.corpus import names\r\n  import random\r\n  \r\n  # name의 마지막 철자를 리턴한다.\r\n  def feature(word):\r\n      return {'last(1)' : word[-1]}\r\n  \r\n  # name corpus를 읽어온다.\r\n  males = [(name, 'male') for name in names.words('male.txt')]\r\n  females = [(name, 'female') for name in names.words('female.txt')]\r\n  \r\n  print(males[:10])\r\n  print(females[:10])\r\n  \r\n  combined = males + females\r\n  random.shuffle(combined)\r\n  \r\n  # supervised learning용 학습  데이터를 생성한다.\r\n  # 이름의 마지막 철자로 성별 (male or female)을 학습하기 위한 것이다.\r\n  training = [(feature(name), gender) for (name, gender) in combined]\r\n  print(training[:10])\r\n  \r\n  # Naive Bayes로 학습한다.\r\n  classifier = nltk.NaiveBayesClassifier.train(training)\r\n  \r\n  sentences = [\r\n      \"John is a man. He walks\",\r\n      \"John and Mary are married. They have two kids\",\r\n      \"In order for Ravi to be successful, he should follow John\",\r\n      \"John met Mary in Barista. She asked him to order a Pizza\"\r\n  ]\r\n  \r\n  # name의 마지막 철자로 성별을 예상한다.\r\n  def gender(word):\r\n      return classifier.classify(feature(word))\r\n  \r\n  # 문장을 chunk로 분해해서 사람과 연관된 대명사를 찾는다.\r\n  for sent in sentences:\r\n      chunks = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)), binary=False)\r\n      stack = []\r\n      print(sent)\r\n      items = tree2conlltags(chunks)\r\n      for item in items:\r\n          if item[1] == 'NNP' and (item[2] == 'B-PERSON' or item[2] == 'O'):\r\n              stack.append((item[0], gender(item[0])))\r\n          elif item[1] == 'CC':\r\n              stack.append(item[0])\r\n          elif item[1] == 'PRP':\r\n              stack.append(item[0])\r\n      print(\"\\t {}\".format(stack))\r\n  \r\n  print(items)\r\n  print(chunks)\r\n  ```\r\n  \r\n  \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n-------------------------\r\n\r\n<br><br>\r\n\r\n## `WSD` 단어의 중의성 분석\r\n\r\n* Word Sense Disambiguation<br>\r\n\r\n* 문장 내에서 단어들의 의미를 파악함\r\n\r\n  * 이를 위해 단어 사전(WordNet 등)이 필요하고, 주변 단어(context, 문맥)과의 비교가 필요<br>\r\n\r\n    > | 문장                                                         | 설명                                                         |\r\n    > | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n    > | She is my **date**.                                          | date는 달력의 날짜를 의미하는 것이 아니라 인간 관계를 의 미한다. |\r\n    > | You have taken too many **leaves** to skip cleaning **leaves** in the garden. | 첫 번째 'leaves'는 휴식을 의미하고, 두 번째 'leaves'는 나뭇잎 을 의미한다. |\r\n\r\n<br><br>\r\n\r\n* ### `Lesk 알고리즘`\r\n\r\n  * 문장에 사용된 단어를 사전에서 찾고, 사전의 뜻풀이, 예제 문장들에 등장하는 단어와 분석할 문장의 단어들을 비교해서 겹치는 단어가 많은 뜻풀이를 선택해 단어의 의미를 파악한다.<br>\r\n\r\n  * 활용:\r\n\r\n    * 워드넷을 써서 단어가 사용된 문장에,\r\n\r\n    * 중의적 단어가 있을 때, \r\n\r\n    * 단어 주변의 문맥을 살펴,\r\n\r\n    * 이 문장에 사용된 단어의 뜻을 찾아냄\r\n\r\n      > | 워드넷을 써서 단어가 사용된 문장에, | 중의적 단어가 있을 때, | 단어 주변의 문맥을 살펴, 이 문장에 사용된 단어의 뜻을 찾아냄 |\r\n      > | ----------------------------------- | ---------------------- | ------------------------------------------------------------ |\r\n      > | wind →                              | wind.n.01 →            | trees bent under the fierce winds  → 분석할 문장에 tree, bent 같은 단어가 들어 있다면 wind는 이 의미로 쓰였을 것이다. |\r\n      > | wind →                              | wind.n.01 →            | when there is no wind, row                                   |\r\n      > | wind →                              | wind.n.02 →            | the winds of change → 분석할 문장에 change (trend) 같은 단어가 들어 있다면 wind는 이 의미 (분위기?)로 쓰였을 가능성이 있다. |\r\n      >\r\n  \r\n  <br>\r\n  \r\n* 시소러스 사전. 언어들의 관계까지 정의해놓은 사전. WordNet과 비슷 \r\n  \r\n  ```python\r\n    # Word Sense Disambiguation (WSD)\r\n    import nltk\r\n    \r\n    def understandWordSenseExamples():\r\n        words = ['wind', 'date', 'left']\r\n        print(\"-- examples --\")\r\n        for word in words:\r\n            syns = nltk.corpus.wordnet.synsets(word)\r\n            for syn in syns[:2]:\r\n                for example in syn.examples()[:2]:\r\n                    print(\"{} -> {} -> {}\".format(word, syn.name(), example))\r\n    \r\n    understandWordSenseExamples()\r\n    \r\n    def understandBuiltinWSD():\r\n        print(\"-- built-in wsd --\")\r\n        maps = [\r\n            ('Is it the fish net that you are using to catch fish ?', 'fish', 'n'),\r\n            ('Please dont point your finger at others.', 'point', 'n'),\r\n            ('I went to the river bank to see the sun rise', 'bank', 'n'),\r\n        ]\r\n        for m in maps:\r\n            print(\"Sense '{}' for '{}' -> '{}'\".format(m[0], m[1], \r\n                  nltk.wsd.lesk(m[0], m[1], m[2])))\r\n    \r\n    understandBuiltinWSD()\r\n    \r\n    nltk.corpus.wordnet.synsets('fish')\r\n    nltk.corpus.wordnet.synset('pisces.n.02').lemma_names()\r\n    nltk.corpus.wordnet.synset('pisces.n.02').definition()\r\n  ```\r\n  \r\n  \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n------------\r\n\r\n<br><br>\r\n\r\n## 감성분석\r\n\r\n* 딥러닝 써서 분석한 건 추후에.\r\n\r\n  ```python\r\n  # 감정 분석\r\n  import nltk\r\n  import nltk.sentiment.sentiment_analyzer\r\n  \r\n  def wordBasedSentiment():\r\n      positive_words = ['love', 'hope', 'joy']\r\n      text = 'Rainfall this year brings lot of hope and joy to Farmers.'.split()\r\n      analysis = nltk.sentiment.util.extract_unigram_feats(text, positive_words)\r\n      print(' -- single word sentiment --')\r\n      print(analysis)\r\n      \r\n  def multiWordBasedSentiment():\r\n      word_sets = [('heavy', 'rains'), ('flood', 'bengaluru')]\r\n      text = 'heavy rains cause flash flooding in bengaluru'.split()\r\n      analysis = nltk.sentiment.util.extract_bigram_feats(text, word_sets)\r\n      print(' -- multi word sentiment --')\r\n      print(analysis)\r\n  \r\n  def markNegativity(text):\r\n      negation = nltk.sentiment.util.mark_negation(text.split())\r\n      print(' -- negativity --')\r\n      print(negation)\r\n  \r\n  wordBasedSentiment()\r\n  multiWordBasedSentiment()\r\n  \r\n  # 주어진 문장에서 부정적 의미를 가진 모든 단어에 대해 접미사 _NEG를 표시한다.\r\n  markNegativity('Rainfall last year did not bring joy to Farmers')\r\n  markNegativity(\"I didn't like this movie . It was bad.\")\r\n  ```\r\n\r\n  <br><br>\r\n\r\n### `VADER`\r\n\r\n* 규칙 기반 알고리즘<br>\r\n\r\n* 10명이 느끼는 감정 상태를 survey해서 얻은 score(-4 ~ +4)<br>\r\n\r\n  ```python\r\n  # VADER-Sentiment-Analysis\r\n  import nltk\r\n  import nltk.sentiment.util\r\n  import nltk.sentiment.sentiment_analyzer\r\n  from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n  \r\n  nltk.downloader.download('vader_lexicon', download_dir='./dataset/')\r\n  \r\n  def mySentimentAnalyzer():\r\n      def score_feedback(text):\r\n          positive_words = ['love', 'genuine', 'liked']\r\n          if '_NEG' in ' '.join(nltk.sentiment.util.mark_negation(text.split())):\r\n              score = -1\r\n          else:\r\n              analysis = nltk.sentiment.util.extract_unigram_feats(text.split(), positive_words)\r\n              if True in analysis.values():\r\n                  score = 1\r\n              else:\r\n                  score = 0\r\n          return score\r\n  \r\n      feedback = \"\"\"I love the items in this shop, very genuine and quality is well maintained.\r\n      I have visited this shop and had samosa, my friends liked it very much.\r\n      ok average food in this shop.\r\n      Fridays are very busy in this shop, do not place orders during this day.\"\"\"\r\n      \r\n      print(' -- custom scorer --')\r\n      for text in feedback.split(\"\\n\"):\r\n          print(\"score = {} for >> {}\".format(score_feedback(text), text))\r\n  \r\n  def advancedSentimentAnalyzer():\r\n      sentences = [\r\n          ':)',\r\n          ':(',\r\n          'She is so :(',\r\n          'I love the way cricket is played by the champions',\r\n          'She neither likes coffee nor tea',\r\n      ]\r\n      \r\n      senti = SentimentIntensityAnalyzer()\r\n      print(' -- built-in intensity analyser --')\r\n      for sentence in sentences:\r\n          print('[{}]'.format(sentence), end=' --> ')\r\n          kvp = senti.polarity_scores(sentence)\r\n          for k in kvp:\r\n              print('{} = {}, '.format(k, kvp[k]), end='')\r\n          print()\r\n  \r\n  mySentimentAnalyzer()\r\n  advancedSentimentAnalyzer()\r\n  ```\r\n\r\n  <br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n*  참고: \r\n  >아마추어 퀀트, blog.naver.com/chunjein\r\n  >코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘\r\n  >\r\n  >* 참고 및 유용한 블로그:\r\n  >\r\n  >* NLP 기초 용어 및 TF-IDF, BOW의 차이 등 아주 쉽게 정리해주심\r\n  >\r\n  >  > hero4earth. 2018.01.17. \"자연어(NLP) 처리 기초 정리\". http://hero4earth.com/blog/learning/2018/01/17/NLP_Basics_01/\r\n  >\r\n  >* NLP 패키지 메소드 활용시 참고\r\n  >\r\n  >  > 데이터사이언스스쿨. 2016.06.14. \"Scikit-Learn의 문서 전처리 기능\". https://datascienceschool.net/view-notebook/3e7aadbf88ed4f0d87a76f9ddc925d69/\r\n  >\r\n  >* 코사인 유사도:\r\n  >\r\n  >  > 데이터 파수꾼 Baek Kyun Shin. 2020. 2. 17. \"NLP - 8. 코사인 유사도(Cosine Similarity)\". https://bkshin.tistory.com/entry/NLP-8-문서-유사도-측정-코사인-유사도\r\n  >  >\r\n  >  > 데이타광 DNA구너. 2020. 5. 20. \"[스팀 2부 - 이론] 협업 필터링 - 스팀, 넷플릭스, 아마존이 당신을 사로잡기 위해 부리는 마법 이해하기\". https://dnagooner.tistory.com/51\r\n  >\r\n  >* 토픽 모델:\r\n  >\r\n  >  >  원준. \"잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)\". https://wikidocs.net/30708\r\n\r\n\r\n\r\n","excerpt":"고급 NLP 레시피 자연어 기초 용어 편집거리 주제식별 감성분석  자연어 관련 용어 (문서) (말뭉치): 텍스트(문서)의 집합 (토큰): 단어처럼 의미를 가지는 요소 (형태소): 의미를 가지는 언어에서 최소 단위 (품사): ex) Nouns…","fields":{"slug":"/NLP응용_1/"},"frontmatter":{"date":"Jul 20, 2020","title":"NLP 편집거리/주제식별/자연어분석","tags":["NLP","LDA","PageRank"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n# NLP\r\n\r\n* 정규표현식\r\n\r\n* 청킹\r\n\r\n* 칭킹\r\n\r\n\r\n<br><br>\r\n\r\n## 문서 정보 추출\r\n\r\n<br>\r\n\r\n### `정규표현식`\r\n\r\n* 정해진 패턴을 사용해서 패턴에 일치하는 데이터 검색을 지원하는 표현식\r\n* 정규표현식에 쓰이는 특수문자\r\n\r\n  * `<.*>+` : 아무 문자나 여러 개 \r\n  * `} {` : } { 안의 내용 제외   \r\n  * `\"\\\\n\"` = `r\"\\n\"`\r\n\r\n* 읽어보기\r\n  * [DEVHolic. \"정규표현식에 쓰이는 특수문자\"](http://www.devholic.net/1000238)\r\n  * [Jungwoon. \"파이썬으로 데이터 분석하기 #2\"](https://jungwoon.github.io/python/2018/03/15/Data-Analysis-With-Python-2/)\r\n\r\n<br>\r\n\r\n ### re 모듈 함수\r\n\r\n* 읽어보기\r\n\r\n[devanix. \"파이썬 – 정규식표현식(Regular Expression) 모듈\"](https://devanix.tistory.com/296)\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### `청킹(Chunking)`\r\n\r\n* 여러 개의 품사로 **구(pharase)를 만드는 것을 Chunking**이라 하고, 이 **구(pharase)를 chunk**라 한다.\r\n\r\n* 문장을 각 품사로 구분하고, Chunking에 의해 구로 구분하면 문장의 의미를 파악하기 용이해 진다.\r\n\r\n* 문장에서 (DT + JJ + NN), (DT + JJ + JJ + NN), (JJ + NN), 등의 시퀀스는 모두 명사구 (NP : Noun phrase)로 판단한다\r\n\r\n* If a tag pattern matches at overlapping locations, the leftmost match takes precedence\r\n\r\n  ![image-20200816015803693](markdown-images/image-20200816015803693.png)\r\n\r\n<br>\r\n\r\n* 순서\r\n\r\n  1. grammar 정의\r\n\r\n  2. 딕셔너리 정의: \r\n     cp = nltk.RegexpParser(grammar)\r\n\r\n  3. sentence data 불러오기(혹은 테스트를 위해서라면 만들기)\r\n\r\n  4. 딕셔너리에 따라 sentence 분석:\r\n\r\n     cp.parse(sentence)\r\n\r\n<br>\r\n\r\n* Base code\r\n\r\n  ```python\r\n  import nltk\r\n  grammar = \r\n  \"\"\"\r\n  NP: {<DT|PP\\$>?<JJ>*<NN>}\t  # rule 1\r\n      {<NNP>+}                  # rule 2\r\n  \"\"\"\r\n  \r\n  cp = nltk.RegexpParser(grammar)\r\n  \r\n  \r\n  sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\",\r\n  \"RP\"), (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"),\r\n  (\"hair\", \"NN\")]\r\n  \r\n  \r\n  cp.parse(sentence)\r\n  ```\r\n\r\n  > (S\r\n  > (NP Rapunzel/NNP)\r\n  > let/VBD\r\n  > down/RP\r\n  > (NP her/PP$ long/JJ golden/JJ hair/NN))\r\n\r\n  ``` python\r\n  result.draw()\r\n  ```\r\n\r\n![image-20200816015725145](markdown-images/image-20200816015725145.png)\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### `칭킹(Chinking)`\r\n\r\n* 특정 부분을 chunk 밖으로 빼내는 것을 chinking이라 한다. \r\n  Chink는 문장에서 chunk를 제외한 나머지 부분을 의미한다\r\n\r\n* 문장 전체를 chunk로 정의하고, 특정 부분을 chinking하면 나머지 부분이 chunk가 된다. \r\n  Chinking을 이용해서 chunking을 할 수도 있다\r\n\r\n* code:\r\n\r\n\r\n``` python\r\ngrammar = \r\n r\"\"\"\r\nNP:\r\n{<.*>+}              # Chunk everything\r\n}<VBD|IN>+{          # Chink sequences of VBD and IN(빼내는 부분)\r\n\"\"\"\r\n\r\nsentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\r\n(\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),\r\n(\"the\", \"DT\"), (\"cat\", \"NN\")]\r\n\r\ncp = nltk.RegexpParser(grammar)\r\ncp.parse(sentence)\r\n```\r\n\r\n> ![image-20200717135504838](image-20200717135504838.png)\r\n\r\n<br>\r\n\r\n### Chunk의 구조 - `IOB tags`\r\n\r\n* Chunk내의 각 품사의 위치에 따라 B (Begin), I (Inside), O (Outside)를 붙인다 (chunk tag). \r\n* B-NP는 NP chunk의 시작 부분을 의미하고, I-NP는 NP chunk의 내부 부분을 의미한다. \r\n* Chunk 구조는 IOB tags로 표현할 수도 있고, 트리 구조로 표현할 수도 있다. \r\n  * NLTK에서는 트리 구조를 사용한다.\r\n\r\n> ![image-20200717142504374](image-20200717142504374.png)\r\n\r\n<br>\r\n\r\n* *code* >\r\n\r\n  * conll2000**.iob_sents**('train.txt')[99]\r\n\r\n    > [('Over', 'IN', 'B-PP'), ('a', 'DT', 'B-NP'), ('cup', 'NN', 'I-NP'), ('of', 'IN', 'B-PP'), ('coffee', 'NN', 'B-NP'), (',', ',', 'O'), ('Mr.', 'NNP', 'B-NP'), ('Stone', 'NNP', 'I-NP'), ('told', 'VBD', 'B-VP'), ('his', 'PRP$', 'B-NP'), ('story', 'NN', 'I-NP'), ('.', '.', 'O')]\r\n\r\n<br>\r\n\r\n* 절(Clause)\r\n\r\n  * 문법에 clause (절)를 정의하면 문장을 아래와 같이 분석 (chunking) 할 수 있다.\r\n\r\n  * **Recursion in Linguistic Structure**\r\n\r\n    ``` python\r\n    grammar = r\"\"\"\r\n    NP: {<DT|JJ|NN.*>+} # Chunk sequences of DT, JJ, NN\r\n    PP: {<IN><NP>} # Chunk prepositions followed by NP\r\n    VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\r\n    CLAUSE: {<NP><VP>} # Chunk NP, VP\r\n    \"\"\"\r\n    cp = nltk.RegexpParser(grammar)\r\n    sentence = [(\"Mary\", \"NN\"), (\"saw\", \"VBD\"), (\"the\", \"DT\"), (\"cat\", \"NN\"),\r\n    (\"sit\", \"VB\"), (\"on\", \"IN\"), (\"the\", \"DT\"), (\"mat\", \"NN\")]\r\n    print(cp.parse(sentence))\r\n    ```\r\n\r\n    > (S\r\n    > (NP Mary/NN)\r\n    > saw/VBD\r\n    > (CLAUSE\r\n    > (NP the/DT cat/NN)\r\n    > (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))\r\n    >\r\n    > ![image-20200717162332408](image-20200717162332408.png)\r\n\r\n  * `.RegexpParser()`에 **loop = 2**를 지정하면 아래와 같이 clause 안에 또 다른 clause를 재귀적(recursion)으로 분석한다.\r\n    이와 같이 문장에 맞게 트리를 깊게 구성하는 것을 `cascaded chunking (계단식 chunk)` 이라 한다.\r\n\r\n    ``` python\r\n    cp = nltk.RegexpParser(grammar, loop=2)\r\n    print(cp.parse(sentence))\r\n    ```\r\n\r\n    > loop 걸어주면 절 속의 절이 들어가는 형태로 구분해준다.\r\n\r\n    > (S\r\n    > (NP John/NNP)\r\n    > thinks/VBZ\r\n    > (CLAUSE\r\n    > (NP Mary/NN)\r\n    > (VP\r\n    > saw/VBD\r\n    > (CLAUSE\r\n    > (NP the/DT cat/NN)\r\n    > (VP sit/VB (PP on/IN (NP the/DT\r\n    > mat/NN)))))))\r\n    >\r\n    > ![image-20200717162643660](image-20200717162643660.png)\r\n\r\n\r\n\r\n<br>\r\n\r\n### Named Entity Recognition (`NER`) - 개체명 인식\r\n\r\n* NER 붙여놓으면 Q&A 가능하다(답을 찾아 제시해주는 챗봇 같은 거 만들 수 있음)\r\n\r\n  ``` python\r\n  sent = nltk.corpus.treebank.tagged_sents()[22]\r\n  print(nltk.ne_chunk(sent, binary=True))\r\n  ```\r\n\r\n  > (S\r\n  > The/DT\r\n  > (**NE** U.S./NNP)\r\n  > is/VBZ\r\n  > one/CD\r\n  > of/IN\r\n  > ...\r\n  > according/VBG\r\n  > to/TO\r\n  > (**NE** Brooke/NNP)\r\n  > T./NNP\r\n  > ...\r\n  > the/DT\r\n  > (**NE** University/NNP)\r\n  > of/IN\r\n  > (**NE** Vermont/NNP College/NNP)\r\n  > of/IN\r\n  > (**NE** Medicine/NNP)\r\n  > ./.)\r\n  * `binary=True` 안 쓰고 그냥하면 \r\n\r\n    ``` python\r\n    (nltk.ne_chunk(sent))\r\n    ```\r\n\r\n    > (S\r\n    > The/DT\r\n    > (**GPE** U.S./NNP)\r\n    > is/VBZ\r\n    > one/CD\r\n    > of/IN\r\n    > ...\r\n    > according/VBG\r\n    > to/TO\r\n    > (**PERSON** Brooke/NNP T./NNP Mossman/NNP)\r\n    > ...\r\n    > the/DT\r\n    > (**ORGANIZATION** University/NNP)\r\n    > of/IN\r\n    > (**PERSON** Vermont/NNP College/NNP)\r\n    > of/IN\r\n    > (**GPE** Medicine/NNP)\r\n    > ./.)\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* reference: \r\n\r\n  >* 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  >* 코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘\r\n  >\r\n","excerpt":"NLP 정규표현식 청킹 칭킹  문서 정보 추출  정해진 패턴을 사용해서 패턴에 일치하는 데이터 검색을 지원하는 표현식 정규표현식에 쓰이는 특수문자  : 아무 문자나 여러 개   : } { 안의 내용 제외     =  읽어보기 DEVHolic…","fields":{"slug":"/NLP기초_3/"},"frontmatter":{"date":"Jul 17, 2020","title":"(NLP 기초) 문서 정보 추출","tags":["NLP","기초"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n# NLP\r\n\r\n* 형식언어 이론\r\n  * Context-free Grammar\r\n  * Context-sensitive Grammar\r\n  * Natural Language\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 문장 구조 분석\r\n\r\n* Word-salad(말비빔): 문법적으로는 완벽히 맞지만 의미가 없는 문장\r\n\r\n<br>\r\n\r\n### 형식언어 이론 : Formal Language Theory\r\n\r\n* 언어란?\r\n\r\n  * (형식적 측면) 유한개의 철자로 무한개의 단어와 문장을 조합한 것\r\n  * (의미적 측면) 무한한 의미를 생성할 수 있는 것 <br>\r\n\r\n* 촘스키의 계층 구조 (Chomsky Hierarchy)\r\n\r\n  * 의미 없이 문장이 형성되는 과정을 형식으로 설명 : `형식언어(formal language theory)`\r\n  \r\n  * groucho_grammar = `nltk.CFG.fromstring(\"\"\" V와 T로 문법 정의 \"\"\")`\r\n    * V : `Variable`\r\n  * T : `Terminal`\r\n  \r\n  * ![image-20200717161151561](image-20200717161151561.png)\r\n    \r\n    \r\n  \r\n    \r\n  * `derivation`: Context-free grammar에서, 우변 → 좌변(Variable, Terminal)일 때 `→` 하는 과정\r\n    * Unrestricted: 자연어(사람 말)\r\n  * Context-sensitive부터 Regualr까지 오토마타(Automata)\r\n  \r\n  <br><br>\r\n  \r\n  ### `오토마타(Automata)`\r\n  \r\n  * 어떤 Language가 어떤 Grammar에 따르는지 그래서 Accept할지, Reject할지 Check하는 추상적인 기계(장치)\r\n* ![image-20200717161524521](/image-20200717161524521.png)\r\n  \r\n  * `Unrestricted(Natural Language)`<br>\r\n* Type-0 : Recognized by Turing Machine\r\n  * `Context-sensitive` \r\n    * Type-1 : Accepted by Linear Bound Automata\r\n  * `Context-free` \r\n    * Type-2 : Accepted by Push Down Automata (PDA)\r\n  * `Regular` \r\n    * Type-3 : Accepted by Finite State Automata (FSA)\r\n\r\n  <br>\r\n\r\n  <br>\r\n\r\n  ### Regular Grammar\r\n\r\n    * 결정적 유한 오토마타(Deterministic finite automaton, DFA)\r\n    * Regular 언어에서 오토마타는, 어떤 게 어디 속하는지에 관한 문제인 membership porblem 판별장치\r\n    * print(FSA('aabbb')):\r\n\r\n  | derivation                                                   | a*b+ | Automata | Grammar                                                      |\r\n  | ------------------------------------------------------------ | ---- | -------- | ------------------------------------------------------------ |\r\n  | a**s** -> <br />aa**s** -> <br />aaa**s** -> <br />aaaa**A** -> <br />aaaab**B** -> <br />aaaabb**B** -> <br />aaaabbb |      |          | S -> aS<br />S -> aA<br />A -> bB<br />B -> b<br /><br />-S -> as \\| aA<br />A -> bB \\| b |\r\n\r\n    >  Chomsky Hierarchy 中 **Regular** Grammar\r\n    >\r\n    > ![image-20200718020646135](/image-20200718020646135.png)\r\n\r\n  <br>\r\n\r\n\r\n    * 정규언어 (Regular language) 와 유한상태 인식기 (Accepted by Finite state acceptor : **FSA**)\r\n\r\n  ``` python\r\n  init_state = 0\r\n  final_state = [1]\r\n  trap_state = 2\r\n  delta = {0: {'a':0, 'b':1}, \r\n         1: {'a':2, 'b':1}}\r\n  \r\n  \"\"\"\r\n  {현재상태 0 {'a' 들어가면: 다음 상태는 0, 'b' 들어가면: 다음 상태는 1}}\r\n  {현재상태 1 {'a' 들어가면: 다음 상태는 2, 'b' 들어가면: 다음 상태는 1}}\r\n    \"\"\"\r\n  \r\n  def FSA(string):\r\n      state = init_state  # 초기상태 = 0\r\n      for s in string: \t# 'a' 들어가고 'a' 들어가고 'b' 들어가는 등 하나씩 for문에 입력됨! \r\n          state = delta[state][s]\r\n          if state == trap_state: # state가 2가 되면 멈춤. 즉, 1상태에서 'a'가 들어오면 멈춤\r\n              \t\t\t\t\t# 즉, 문자열을 읽어가다가 trap state에 빠지면 reject 됨 \r\n              break\r\n    \r\n      return state in final_state # state값이 final_state에 있으면 True, 없으면 False\r\n  \r\n  print(FSA('aabbb')) # True\r\n  print(FSA('aabba')) # False\r\n  print(FSA('aabbc')) # error\r\n  print(FSA('a'))     # False\r\n  ```\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n  ## Context-free Grammar\r\n\r\n  * Accepted by Push Down Automata, PDA\r\n  \r\n    * {a의 n승 b의 n승, n>=1}가 aaaabbbb라는 오토마타 형태(뭐다음 뭐 나와야 하고, 뭐 다음 뭐 나와야 하는 것)을\r\n    기계는 기억하지 못함.\r\n      ex: N의 n승 N의 n승 -> the cat(N) the dog(N) chased(V) run(V)\r\n\r\n  * 이때, 과거 데이터를 기억하는 오토마타의 장치: Stack\r\n  \r\n    \r\n    \r\n    > Chomsky Hierarchy 中 **Context-free** Grammar\r\n    >\r\n    > ![image-20200718021947962](/image-20200718021947962.png)\r\n\r\n\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n  ## Context-sensitive Grammar\r\n\r\n* 좌우 문맥에 따라 달라지는 경우\r\n  \r\n  * S -> NP VP\r\n  * aSb -> NP VP\r\n  * cSd -> NP PP\r\n  * aSb -> aS by\r\n  * bSa -> aA bb\r\n  \r\n* Accepted by Linear Bound Automata\r\n\r\n* '한글모아쓰기'에 활용되기도 함\r\n\r\n  \r\n\r\n  > Chomsky Hierarchy 中 **Context-sensitive** Grammar\r\n  >\r\n  > ![image-20200718022925812](/image-20200718022925812.png)\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n  ## Unrestricted Grammar (Natural Language)\r\n\r\n  * Recognized by Turing Machine\r\n  * 의미는 틀려도 되고, 아무 단어나 막 조합해도 되는 것\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n\r\n* 참고: \r\n\r\n  >* 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  >* 코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘","excerpt":"NLP 형식언어 이론 Context-free Grammar Context-sensitive Grammar Natural Language 문장 구조 분석 Word-salad…","fields":{"slug":"/NLP기초_4/"},"frontmatter":{"date":"Jul 17, 2020","title":"(NLP 기초) 문장 구조 분석","tags":["NLP","기초"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n# NLP\r\n\r\n* 품사 태깅 원리\r\n* HMM\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 품사 태깅\r\n\r\n* **`품사 태깅`**: 문장의 N, V, ad, av 판별\r\n  * 문장만 보고 품사를 붙여주는 기계:  **`pos tagger`**\r\n* 문맥 = '문장 내' 주변 단어 = **`Context`**\r\n  * 현재 NLP 상에선 문장 간, 절 간 Context는 불가\r\n* \"NLP 분석 시, 몇 개의 Context를 창조할 것인가?\"\r\n  * **`n-gram`**:\r\n    * 1개: **`unigram`**\r\n    * 2개: **`Bigram` **\r\n      * ex: (I love) , (love you)\r\n    * 3개: **`Trigram`**\r\n    * 4개: ...\r\n* 분석할 문장의 올바른 품사를 결정하기 위해선(올바른 tagger 기계를 만들기 위해선) 사전에 올바른 품사가 정의된 문서 코퍼스(말뭉치)가 있어야 한다.\r\n  * nltk: 영어용\r\n  * konlpy: 한글용 \r\n\r\n<br>\r\n\r\n## Tagging 거치는 원리\r\n\r\n1. 사람이 학습 문서에 품사를 태깅해 놓았음: Tagged Corpora  `trainX`\r\n2. 학습  `model.fit`\r\n3. 모델 파라미터  `machine`\r\n4. POS Tagger 완성 \r\n5. 추후 input text 입력 시  `test X`\r\n6. POS Tagger 거치면 `model.predict(testX)`\r\n7. Tagging 돼서 출력됨 \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## HMM\r\n\r\n- 히든 마코프 모델(HMM): sequence를 분석\r\n\r\n- 1차 Markov Chain:\r\n\r\n  : 현재 상태는 직전 상태에만 의존한다\r\n\r\n- 2차 Markov Chain:\r\n\r\n  : 현재 상태는 전전 상태에만 의존한다<br>\r\n\r\n- `Hidden Markov Model(HMM)`\r\n\r\n  - 관측데이터(주가, 수익률, 거래량 ,변동성, 등...)에 직접 나타나지 않는 히든 상태(Hidden State)가 있다\r\n  - 이때, **HMM은 관찰 데이터를 가지고 Hidden 상태를 추론하는 것**\r\n  - MLE 개념 사용\r\n  - 용어 정리: \r\n    - `초기상태` = `초기확률`\r\n    - Hidden State에서 행동 변화가 일어날 확률 `천이확률`\r\n    - 상태 변화가 일어나는 확률: `출력확률`\r\n  - 알고리즘 정리:\r\n    - `Forward 알고리즘`: X가 나올 확률 계산\r\n    - `Viterbi decoding 알고리즘`: Z 추정\r\n      * **`Forward 알고리즘`은 '확률' 계산이고, `Viterbi decoding 알고리즘`은 '시퀀스' 추정임**\r\n    - `Baum Welch 알고리즘`: Z 추정\r\n      - **`Viterbi 알고리즘` 과의 차이점: `Baum Welch 알고리즘`는 사전에 주어진 게 X 밖에 없음**\r\n\r\n<br>\r\n\r\n\r\n#### `Forward 알고리즘`\r\n\r\n- Evaluation Question 문제에서 활용\r\n\r\n  1. `초기 확률(초기 상태)`, \r\n  2. `Transition 확률(천이확률)`, \r\n  3. `Emission 확률(출력확률)`이 주어졌을 때, \r\n  4. 관측 데이터가 발생할 **확률**을 `Forward 알고리즘`으로 계산(추정)한다.\r\n     * **Forward알고리즘은 '확률' 계산이고, Viterbi decoding 알고리즘은 '시퀀스' 추정임**\t\r\n\r\n\r\n<br>\r\n\r\n```python\r\nimport numpy as np\r\nfrom hmmlearn import hmm\r\n```\r\n\r\n<br>\r\n\r\n- 히든 상태 정의\r\n\r\n```python\r\nstates = [\"Rainy\", \"Sunny\"]\r\nnState = len(states)\r\n```\r\n\r\n<br>\r\n\r\n- 관측 데이터 정의\r\n\r\n```python\r\nobservations = [\"Walk\", \"Shop\", \"Clean\"]\r\n# nObervation = len(observations)\r\n```\r\n\r\n<br>\r\n\r\n- HMM 모델 빌드\r\n\r\n```python\r\nmodel = hmm.MultinomialHMM(n_components=nState) # n_components = 2개 \r\nmodel.startprob_ = np.array([0.6, 0.4]) # 초기확률(상태)\r\nmodel.transmat_ = np.array([[0.7, 0.3], [0.4, 0.6]]) # 천이확률 Transition \r\nmodel.emissionprob_ = np.array([[0.1, 0.4, 0.5], [0.6, 0.3, 0.1]]) # 출력확률 Emission\r\n```\r\n\r\n>  Multinomial(다항분포): 여러 개의 값을 가질 수 있는 독립 확률변수들에 대한 확률분포\r\n\r\n<br>\r\n\r\n- `X`: 관측 데이터 시퀀스(Observations Sequence) \r\n  - ''이렇게 X가 나오도록 Z 값'' 계산하라 中 ''이렇게 X가 나오도록'' 담당 \r\n\r\n```python\r\nX = np.array([[0, 2, 1]]).T  # Walk(0) -> Clean(2) -> Shop(1)\r\n```\r\n\r\n<br>\r\n\r\n- `Forward 알고리즘`: `'.score()'`\r\n  - x가 관측될 likely probability(가능성, 확률) 계산\r\n\r\n```python\r\nlogL = model.score(X) # Forward 알고리즘. sequnce 값이 커지면 확률값이 굉장히 작아져 '0.00..' 등으로 나오니까 defaulf로 log 함수를 취해줌 \r\np = np.exp(logL) #log를 exp 씌워주면 일반 확률로 변환됨 \r\nprint(\"\\nProbability of [Walk, Clean, Shop] = %.4f%s\" % (p*100, '%'))\r\n```\r\n\r\n> Probability of [Walk, Clean, Shop] = 3.1038%\r\n\r\n<br>\r\n\r\n#### `Viterbi 알고리즘`\r\n\r\n- Decoding Question 에서 활용\r\n  1. `초기 확률(초기 상태)`, \r\n  2. `Transition 확률(천이확률)`, \r\n  3. `Emission 확률(출력확률)`,\r\n  4. `관측 데이터 시퀀스(X)`가 주어졌을 때, \r\n  5. **`히든 상태의 시퀀스(Z)`** 을    `Viterbi decoding 알고리즘`으로 계산(추정)한다.\r\n     * **Forward알고리즘은 '확률' 계산이고, Viterbi decoding 알고리즘은 '시퀀스' 추정임**\r\n\r\n<br>\r\n\r\n```python\r\nimport numpy as np\r\nfrom hmmlearn import hmm\r\n```\r\n\r\n<br>\r\n\r\n- 히든 상태 정의\r\n\r\n```python\r\nstates = [\"Rainy\", \"Sunny\"]\r\nnState = len(states)\r\n```\r\n\r\n<br>\r\n\r\n- 관측 데이터 정의\r\n\r\n```python\r\nobservations = [\"Walk\", \"Shop\", \"Clean\"]\r\n# nObervation = len(observations)\r\n```\r\n\r\n<br>\r\n\r\n- HMM 모델 빌드\r\n\r\n```python\r\nmodel = hmm.MultinomialHMM(n_components=nState) # n_components = 2개 \r\nmodel.startprob_ = np.array([0.6, 0.4]) # 초기확률(상태)\r\nmodel.transmat_ = np.array([[0.7, 0.3], [0.4, 0.6]]) # 천이확률 Transition \r\nmodel.emissionprob_ = np.array([[0.1, 0.4, 0.5], [0.6, 0.3, 0.1]]) # 출력확률 Emission\r\n```\r\n\r\n>  Multinomial(다항분포): 여러 개의 값을 가질 수 있는 독립 확률변수들에 대한 확률분포\r\n\r\n<br>\r\n\r\n- `X`: 관측 데이터 시퀀스(Observations Sequence) \r\n  - ''이렇게 X가 나오도록 Z 값'' 계산하라 中 `이렇게 X가 나오도록` 담당 \r\n\r\n```python\r\nX = np.array([[0, 2, 1, 0]]).T # walk -> clean -> shop -> walk\r\n```\r\n\r\n<br>\r\n\r\n- `Viterbi 알고리즘`: `'.decode( , algorithm=\"viterbi\")' `\r\n  - Z가 관측될 likely probability(가능성, 확률) 계산\r\n\r\n```python\r\nlogprob, Z = model.decode(X, algorithm=\"viterbi\") # 여기서 Z는 Z가 될 확률값\r\n```\r\n\r\n<br>\r\n\r\n- 결과 출력\r\n\r\n```python\r\nprint(\"\\n  Obervation Sequence :\", \", \".join(map(lambda x: observations[int(x)], X)))\r\nprint(\"Hidden State Sequence :\", \", \".join(map(lambda x: states[int(x)], Z)))\r\nprint(\"Probability = %.6f\" % np.exp(logprob))\r\n```\r\n\r\n> Obervation Sequence : Walk, Walk, Shop, Shop, Walk, Walk, Walk, Walk, Walk, Walk, Walk, Clean, Walk, ...\r\n>\r\n> Hidden State Sequence : Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Rainy, ...\r\n>\r\n> Probability = 0.000000\r\n\r\n<br>\r\n\r\n#### `Baum Welch 알고리즘`\r\n\r\n- X만 주어진 경우: `Learning Question ` 문제\r\n\r\n  1. `초기 확률(초기 상태)`, \r\n\r\n  2. `Transition 확률(천이확률)`, \r\n\r\n  3. `Emission 확률(출력확률)`을 추정,\r\n\r\n     1-3 까지 `Baum Welch 알고리즘`\r\n\r\n  4. `히든 데이터 시퀀스(Z)`까지 찾아낸다.\r\n\r\n     4는 `Viterbi 알고리즘`까지 쓴다면\r\n\r\n- 활용: 어떤 사람의 행위를 통해 초기 상태와 천이 확률, 그리고 출력 확률을 먼저 추정한 후 Z를 추정한다 \r\n\r\n  - 관찰만으로 전부 추정하는 알고리즘 \r\n  - 아래 code 내에선 정확도도 꽤 괜찮은 편\r\n\r\n<br>\r\n\r\n```python\r\nimport numpy as np\r\nfrom hmmlearn import hmm\r\nnp.set_printoptions(precision=2) # np.set_printoptions: numpy float 출력옵션 변경. 소수점 몇자리까지만 보고 싶은 경우\r\n```\r\n\r\n<br>\r\n\r\n- 나무랑 w(가중치) 세팅\r\n\r\n```python\r\nnState = 2\r\npStart = [0.6, 0.4]\r\npTran = [[0.7, 0.3], [0.2, 0.8]]\r\npEmit = [[0.1, 0.4, 0.5], [0.6, 0.3, 0.1]]\r\n```\r\n\r\n> 해당 code는 추후 `Baum Welch`을 통해 나온 결과값과의 정확도를 보기 위한 것으로, Data를 임의로 설정해주는 부분임에 유의\r\n\r\n> 걍 가짜로 X data, Z data 만들어내는 부분\r\n\r\n<br>\r\n\r\n- 주어진 확률 분포대로 관측 데이터 시퀀스를 생성한다. \r\n\r\n```python\r\n# 히든 상태 선택. 확률 = [0.6, 0.4]\r\ns = np.argmax(np.random.multinomial(1, pStart, size=1)) # {1, pStart=[0.6, 0.4]} 3개 중 가장 큰 수(np.argmax) 따라서 s = 1\r\nX = []      # Obervation 시퀀스\r\nZ = []      # 히든 상태 시퀀스\r\nfor i in range(5000):\r\n    # Walk, Shop, Clean ?\r\n    a = np.argmax(np.random.multinomial(1, pEmit[s], size=1)) # pEmit[s] = [0.6, 0.3, 0.1]\r\n    X.append(a)\r\n    Z.append(s)\r\n    \r\n    # 히든 상태 천이\r\n    s = np.argmax(np.random.multinomial(1, pTran[s], size=1))\r\n\r\nX = np.array(X)\r\nX = np.reshape(X, [len(X), 1])\r\nZ = np.array(Z)\r\n```\r\n\r\n> 따라서 현재는 X만 아는 상태 \r\n\r\n> Q. Z는 왜 만드는 것?? 바움 알고리즘은 X만 가지고 예측하는 건데??? \r\n> A: 지금 있는 기본 data x랑 나중에 model 만든 거를 합치면 predict z가 나오는데(yHat) 그거랑 찐 z랑 비교하려고\r\n\r\n<br>\r\n\r\n- `Forward 알고리즘` -> `Baum Welch 알고리즘` 사용\r\n\r\n  - Step 1) `Forward 알고리즘` 활용: Observation 시퀀스만을 이용하여, 초기 확률, Transition, Emmision 확률을 추정한다\r\n\r\n  ```python\r\n  zHat = np.zeros(len(Z))\r\n  minprob = 999999999 #3의 큰 수로 줘버림\r\n  for k in range(5):\r\n      model = hmm.MultinomialHMM(n_components=nState, tol=0.0001, n_iter=10000)\r\n      model = model.fit(X) # 가짜 data인 x로 학습(fit)\r\n      predZ = model.predict(X)\r\n      logprob = -model.score(X) # forword 알고리즘 # 원래 값이 음수가 나와서 앞에 '-' 붙여줌으로서 양수로 변환\r\n  ```\r\n\r\n  > logprob = -6349.458034174618\r\n  >\r\n  > **EM 알고리즘은 local optimum에 빠질 수 있으므로, 5번 반복하여 로그 우도값이 가장 작은 결과를 채택한다.\r\n  > (그게 가장 큰 결과가 되니까 작은 결과 채택).\r\n\r\n  <br>\r\n\r\n  * Step 2) `Baum Welch 알고리즘` 활용 : Z를 추정\r\n    * **`Viterbi 알고리즘` 과의 차이점: `Baum Welch 알고리즘`는 사전에 주어진 게 X 밖에 없음**\r\n\r\n  ```python\r\n      if logprob < minprob:\r\n          zHat = predZ\r\n          T = model.transmat_\r\n          E = model.emissionprob_\r\n          minprob = logprob\r\n      print(\"k = %d, logprob = %.2f\" % (k, logprob))\r\n  ```\r\n\r\n  > k = 4, logprob = -6349.46\r\n\r\n  <br>\r\n\r\n- `찐 Data 세팅 단계`에서 생성한 `Z`와 위 알고리즘들을 통해 추정한 `zHat`의 **정확도를 측정**한다.\r\n\r\n```python\r\naccuracy = (Z == zHat).sum() / len(Z)\r\n\r\nif accuracy < 0.5: # 정확도가 0.5보다 작다면 순서를 바꿔주는 부분 \r\n    T = np.fliplr(np.flipud(T)) # np.fliplr: 좌우 순서 변경\r\n    E = np.flipud(E) # np.flipud: 상하 순서 변경\r\n    zHat = 1 - zHat\r\n    print(\"flipped\")\r\n    \r\naccuracy = (Z == zHat).sum() / len(Z)\r\nprint(\"\\naccuracy = %.2f %s\" % (accuracy * 100, '%'))\r\n```\r\n\r\n> accuracy = 76.78 %\r\n\r\n<br>\r\n\r\n- 추정 결과를 출력한다\r\n\r\n```python\r\nprint(\"\\nlog prob = %.2f\" % minprob)\r\nprint(\"\\nstart prob :\\n\", model.startprob_)\r\nprint(\"\\ntrans prob :\\n\",T)\r\nprint(\"\\nemiss prob :\\n\", E)\r\nprint(\"\\niteration = \", model.monitor_.iter) \r\n```\r\n\r\n>- log prob = 5339.32\r\n>\r\n>- start prob :\r\n>   [6.93e-72 1.00e+00]\r\n>\r\n>- trans prob :\r\n>   [[0.74 0.26]\r\n>   [0.15 0.85]]\r\n>\r\n>- emiss prob :\r\n>   [[0.11 0.41 0.48]\r\n>   [0.58 0.3  0.12]]\r\n>\r\n>- iteration =  246\r\n\r\n> model.monitor_.iter: for문 몇 번 돌렸단 뜻. 여기서 위에 \"model = hmm.MultinomialHMM(n_components=nState, tol=0.0001, **n_iter=10000**)\" 라 설정했는데 model.monitor.iter가 10000이라 뜨면 값을 못 찾았다는 거라 20000정도로도 늘려보아야 함 \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## HMM 참고\r\n\r\n* Bigram POS tagging과 시험 데이터를 이용한 평가.\r\n  * `trade-off between accuracy and coverage`\r\n    * Bigram에서는 만약 NNS VBG 시퀀스가 학습 데이터에 없다면,\r\n    * P(VBG|NNS)=0, `*해석: VBG 안에 NNS가 없음 `\r\n    * sparse problem 이므로\r\n    * 그 이후의 모든 시퀀스에 악영향을 미쳐 평가 결과가 낮다.\r\n    * N-gram의 N이 클수록 accuracy는 낮지만 문맥의 coverage는 좋다.  따라서 학습용 데이터를 늘리면 약간 개선되기는 함.\r\n\r\n<br>\r\n\r\n* N-Gram tagging - Combining Tagger (Backoff Tagger)\r\n\r\n  - Bigram tagging을 시도하고 P(tag2 | tag1) = 0 (tag1 tag2 시퀀스가 없으면)이면, Unigram을 적용한다 P(tag2).\r\n  - 만약 이것도 없으면 default tag를 적용한다. \r\n\r\n  ```python\r\n  t0 = nltk.DefaultTagger('NN') \r\n  t1 = nltk.UnigramTagger(train_sents, backoff = t0) \r\n  t2 = nltk.BigramTagger(train_sents, backoff = t1) \r\n  t2.evaluate(test_sents)\r\n  ```\r\n\r\n  > 참고 : \r\n  >\r\n  > **`nltk.pos_tag()`**는 PerceptronTagger로 Penn Treebank (Wall Street Journal) **데이터를 사전에 학습**해 놓은 것을 사용한다. \r\n  >\r\n  > 반면에 UngramTagger나 BigramTagger는 사전에 학습해 놓은 것을 사용하는 것이 아니라 직접 학습해서 사용하는 것이다.\r\n\r\n<br>\r\n\r\n* 품사 태깅 : N-Gram tagging - Unknown word\r\n\r\n  * Tagger가 학습 데이터에서 경험하지 못한 단어를 보면 어떻게 태깅해야 하나?\r\n\r\n  ```python\r\n  text = \"I go to school in the klaldkf\" \r\n  token = text.split() \r\n  ```\r\n\r\n  ```python\r\n  print(unigram_tagger.tag(token))\r\n  ```\r\n\r\n  > [('I', 'PPSS'), ('go', 'VB'), ('to', 'TO'), ('school', 'NN'), ('in', 'IN'), ('the', 'AT'), ('klaldkf', None)]\r\n\r\n  ```python\r\n  print(bigram_tagger.tag(token)) \r\n  ```\r\n\r\n  > [('I', 'PPSS'), ('go', 'VB'), ('to', 'TO'), **('school', None), ('in', None), ('the', None), ('klaldkf', None)**]\r\n\r\n  ```python\r\n  print(nltk.pos_tag(token))\r\n  ```\r\n\r\n  > [('I', 'PRP'), ('go', 'VBP'), ('to', 'TO'), ('school', 'NN'), ('in', 'IN'), ('the', 'DT'), ('klaldkf', 'NN')]\r\n\r\n  <br>\r\n\r\n  * `Unigram Tagger`는 unknown word에만 영향을 미침. \r\n  * **`Bigram Tagger`**는 unknown word가 다른 단어에도 영향을 미침.\r\n  * `nltk.pos_tag()`는 unknown word를 명사로 태깅하고 있음.\r\n  * 단, `Unigram과 Bigram`은 충분한 데이터로 학습한 결과가 아니며, `nltk.pos_tag()`은 충분한 데이터로 사전에 학습된 것임.\r\n\r\n<br>\r\n\r\n* 시험 데이터로 태깅 성능을 측정할 때는 `nltk.ConfusionMatrix`를 이용한다.\r\n\r\n``` python\r\n# Confusion Matrix \r\ntest_tags = [tag for sent in brown.sents(categories='editorial') for (word, tag) in t2.tag(sent)] \r\ngold_tags = [tag for (word, tag) in brown.tagged_words(categories='editorial')] \r\ncm = nltk.ConfusionMatrix(gold_tags, test_tags) \r\ncm['NN', 'NN']\r\nprint(cm.pretty_format(truncate=10, sort_by_count=True))\r\n```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고: \r\n\r\n  >* 아마추어 퀀트, blog.naver.com/chunjein\r\n  >\r\n  >* 코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘","excerpt":"NLP 품사 태깅 원리 HMM 품사 태깅 : 문장의 N, V, ad, av 판별 문장만 보고 품사를 붙여주는 기계:   문맥 = '문장 내' 주변 단어 =  현재 NLP 상에선 문장 간, 절 간 Context는 불가 \"NLP…","fields":{"slug":"/NLP기초_2/"},"frontmatter":{"date":"Jul 16, 2020","title":"(NLP 기초) 품사 태깅","tags":["NLP","기초"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# 딥러닝 DL\r\n\r\n* RNN\r\n* CNN\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 순환 신경망(RNN)\r\n\r\n* hidden 층에서 서로 값을 기억해 순환한다.\r\n* 지금까진 FNN(feed forward neword) + 순서가 필요 없는 data를 써서 모델이 기억할 필요가 없었지만, 문장 같은 data를 쓸 땐 **순서가 중요한 data(Sequence Data)를 가지고 미래를 예측해야 한다.**\r\n* 학습(트레이닝) 방법: 순서가 있는 data를 모델이 ‘기억’하게 만드는 것\r\n* RNN 기본 입력은 3d 형태. D1=time, d2=feature, d0=data\r\n* RNN 문제점: 기울기 소실 문제(vanishing gradient)가 FFN보다 더 심해짐\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### LSTM\r\n\r\n* RNN의 vanishing gradient 해결을 위해 고안. C 추가<br>\r\n\r\n- f와 i의 가중평균 형태<br>\r\n\r\n  ```batch\r\n  f: forget date. 이전의 C를 얼마나 반영할 것인지 조절\r\n  i: input or ignore. 현재 입력값(x)과 이전의 출력값(h)를 얼마나 반영할 것인지 조절\r\n  \r\n  * h는 위, 왼쪽 / c는 왼쪽으로 전파. 둘다 처음엔 0으로 시작함\r\n  ```\r\n\r\n* GRU: LSTM 구조를 간결하게 만듦. 속도도 더 빠르지만 성능도 안 떨어짐 <br>\r\n\r\n* 학습 유형: 단방향(FNN,BFN) / 양방향(FNN+BFN) 모두 적용 가능.\r\n\r\n  ![image-20200816004535796](markdown-images/image-20200816004535796.png)\r\n\r\n  1. Many to one: 둘다 정보량이 TIME이 증가할수록 높아진다. 따라서 높은 정보량끼리 마지막에 합친다\r\n\r\n  2. Many to many\r\n\r\n     * FNN 정보량이 TIME이 증가할수록 높아진다. \r\n\r\n       BFN 정보량이 TIME이 증가할수록 낮아진다.\r\n\r\n       따라서 각 뉴런에서 latent layer로 이어지는 정보량(마지막에 FNN정보량+BFN정보량)은 같다\r\n\r\n  3. One to many\r\n\r\n  4. Many to many<br>\r\n\r\n* 단방향은 ‘이후’만 기억, 양방향은 ‘이전’+’이후’ 모두 기억\r\n  \r\n  * 어떻게? 단방향은 FBN만 사용, 양방향은 FBN+BFN 사용하기 떄문.<br>\r\n  \r\n* 양방향(FNN+BFN) 진행 순서: \r\n  1. 모델(code)에서(RNN층 내) FNN 진행 후 정보량 모아두고, \r\n  2. BFN 진행 후 정보량 모아두고,\r\n  3. CONCAT(합침)해서 \r\n  4. error를 역전파 시킴 <br>\r\n\r\n* FNN VS BFN:\r\n\r\n  * FNN : TIME이 낮->높\r\n  * BFN : TIME이 높->낮\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n## CNN\r\n\r\n* 사람의 시각인지 과정을 모방해서 피드포워드 신경망에 추가\r\n  * 이미지를 분류한다 치면, 이미지의 부분적 특성에 주목해 분류하여 FFN에 넣는 것 \r\n    \r\n  * 이미지 분석에 활용: 이미지를 대표할 수 있는 특성들을 도출해서 신경망에 넣어준다.\r\n    \r\n      <br>\r\n  \r\n* 순서 \r\n\r\n  특성 추출 → 클래스 분류 \r\n  → **컨볼루션** 또는 필터링 과정 \r\n  → **특성지도** 출력 \r\n  → 서브샘플링(subsampling) 또는 **풀링**(pooling) \r\n  → 다시 컨볼루션, 활성화, 서브샘플링을 수행 \r\n  → 최종 특성지도는 피드포워드 신경망에 입력되어 분류 작업을 시행<br>\r\n\r\n  ```batch\r\n  컨볼루션: \r\n  image data의 경우\r\n  → filter(kernel: image data와의 convolution(cross-correlation) 진행) \r\n  → feature map 생성(기호에 따라 zero padding, ReLU와 같은 활성함수 적용 가능)\r\n  → (max/mean) pooling \r\n  → feature map 생성(출력) \r\n  → flatten(: 1D구조로 만듦) \r\n  → FNN\r\n  ```\r\n\r\n<br>\r\n\r\n1. 입력된 이미지로부터 이미지의 고유한 특징을 부각시킨 특성지도(feature map)를 새로 만듦\r\n2. 그 이미지는 피드포워드 신경망에 입력되어 이미지가 어떤 클래스 라벨에 속하는지 분류\r\n3. 학습: (grid serch) 수평 엣지 필터, 수직 엣지 필터 컨볼루션\r\n4. ReLU와 같은 활성함수를 거쳐 특성지도 출력\r\n5. 서브샘플링(subsampling) 또는 풀링(pooling) 통해 활성화된 특성지도들의 크기를 줄임\r\n6. (저차원적인 특성부터 시작해서 고차원적인 특성을 도출)이 특성지도들에 다시 컨볼루션, 활성화, 서브샘플링을 수행하여 로컬한 특성지도로부터 글로벌한 특성지도를 만들어간다.\r\n7. 이 과정을 여러번 반복하여 얻어진 최종 특성지도는 fully-connected layer, 즉 피드포워드 신경망에 입력되어 분류 작업을 시행\r\n\r\n<br>\r\n\r\n* 용어\r\n  * `feature map`: 이미지의 부분적 특징을 모아놓은 것의 집합\r\n  * `padding`:\r\n  * `convolution layer`: convolution(cross-correlation) 진행되는 곳 \r\n  * `upsampling`: pooling layer와 달리 차원을 줄이는 게 아니라 차원을 늘림. Autoencoder의 decoder와 같은 곳에서 원래 데이터로 복원할 때 사용됨. Zero padding은 가생이를 0으로 채우는데 sampling은 무슨 계산을 해서 채우는 듯하다.  \r\n\r\n<br>\r\n\r\n### 코딩 용어 설명\r\n\r\n* 컨볼루션 레이어 단계\r\n  * `Filters`: 출력 모양의 깊이(depth) 를 결정<br>\r\n\r\n  * `kernel_size`: \r\n    1. w(연결선, 가중치)이자, filter의 size.\r\n    2. 연산을 수행할 때 윈도우의 크기\r\n       * 2D에서 kernel_size=(8,1)이면 8행+1열(이때 1열은 feature)\r\n       * 1D에서 kernel_sizw=8이면 자동 8행+전체열(1D에서 필터는 아래 방향으로 밖에 이동 못함)<br>\r\n    \r\n  * `strides`: 필터 적용 시 한 번에 얼마나 움직일지(이동 크기) 이동할 칸 수. 보통 1을 씀. <br>\r\n\r\n  * `padding`: \r\n\r\n    * 컨볼루션 레이어(합성곱) 혹은 풀링 연산을 수행하는 레이어에 파라미터로 설정\r\n      \r\n       convolution과 pooling 연산은 파라미터의 수를 줄여나가는 과정이다. 하지만 이러한 과정에서 지나치게 데이터가 축소되어 정보가 소실되는 것을 방지하기 위해 데이터에 0으로 이루어진 패딩을 주는 경우가 있다.\r\n      \r\n    * ‘원본’(사이즈)을 조정. filter를 거치면 이미지 사이즈가 원본과 달리 작아지는데, 이를 피하기 위해 작아지는 사이즈가 원본 사이즈만큼 되도록 원본 사이즈 크기를 늘림. 이때, Zero padding 기법을 사용. 수치(?)가 없는 부분 즉, 가생이(모서리)을 ‘0’으로 채움(가생이 아니고 중간 부분 채워도 zero-padding)<br>\r\n\r\n       1. `padding = 'same'`: 원본 사이즈 유지시킴(차원 유지)\r\n          * 원리: 필터의 사이즈가 k이면 사방으로 k/2 만큼의 패딩을 준다.\r\n\r\n       2. `padding = 'valid'`: 패딩 사용하지 않음 <br>\r\n\r\n  * `activation: ‘ReLu’`가 default. CNN에선 ReLu 사용을 권장한다고 함 \r\n\r\n     <br>\r\n\r\n* `pooling` 단계\r\n  * 원본이미지에서 특징 추출해서 feature map의 크기를 줄여주는 과정. \r\n  * (1) Max pooling, (2) mean pooling이 있음 \r\n  * pool_size: strides가 미리 설정되지 않을 경우 pool_size와 동일하게 설정된다. <br>\r\n    * strides\r\n  * padding<br>\r\n  \r\n* `Flatten` 단계\r\n  \r\n  * Flatten<br>\r\n  \r\n* `output` 단계\r\n  \r\n  * Dense(n, activation = )\r\n\r\n <br>\r\n\r\n <br>\r\n\r\n## 차원 참고\r\n\r\n* 1차원 벡터: shape(2,)\r\n* 2차원 Matrix : shape(행,열)\r\n* 3차원: shape(면, 행, 열) = D0, D1, D2\r\n* 4차원: shape (samples, rows, cols, channels) = D0, D1, D2 ,D3 \r\n\r\n <br>\r\n\r\n<br>\r\n\r\n <br>\r\n\r\n<br>\r\n\r\n> 참고: \r\n>\r\n> * 아마퀀트. 2019. 7. 19. \"Keras LSTM** 유형 정리 (2/5) – 단층-단방향 & many-to-many 유형\". http://blog.naver.com/chunjein/221589624838. 아마추어 퀀트 (Amateur Quant).\r\n> * chrisysl. 2018. 9. 10. \"3. Convolutional Networks / L2. Convolutional Neural Networks - Convolutional Layers in Keras\". https://kevinthegrey.tistory.com/141\r\n> * 심교훈. 2019. 3. 1. \"딥러닝 알고리즘의 대세, 컨볼루션 신경망(convolutional neural network, CNN)\". https://bskyvision.com/412?category=635506b. 스카이비전\r\n> * Seongyun Byeon. 2018.01.23. 딥러닝에서 사용되는 여러 유형의 Convolution 소개\". https://zzsza.github.io/data/2018/02/23/introduction-convolution/. 어쩐지 오늘은\r\n>\r\n> \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n ","excerpt":"딥러닝 DL RNN CNN 순환 신경망(RNN) hidden 층에서 서로 값을 기억해 순환한다. 지금까진 FNN(feed forward neword) + 순서가 필요 없는 data를 써서 모델이 기억할 필요가 없었지만, 문장 같은 data…","fields":{"slug":"/딥러닝_2/"},"frontmatter":{"date":"Jul 14, 2020","title":"딥러닝 LSTM&CNN","tags":["DL","LSTM","CNN"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# 딥러닝 DL\r\n\r\n* optimaizer\r\n* kerass\r\n\r\n  \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## optimizers\r\n\r\n* 이차방정식 계수 추정 방법들:\r\n  1. `SGD`: 움직임\r\n  2. `GD` : 미분해서 움직임\r\n  3. `momentum`: 지수이동평균법으로 움직임\r\n  4. `NAG`: 관성 방향으로 이동 후 그 지점에서 GD 방향으로 움직임 \r\n\r\n <br>\r\n\r\n* 가중치(알파 or lr) 조정 알고리즘\r\n  1. `Adagrad`: 업데이트 多~작은 알파 / 업데이트 小~큰 알파\r\n  2. `RMSprop`: Adagrad에서 반복할수록 과도하게 작아진다는 알파값 보완 \r\n  3. `Adadelta`: RMSprop와 같은데 알파값이 자동조절됨\r\n  4. `Adam`: RMSprop + momentum\r\n\r\n <br>\r\n\r\n<br>\r\n\r\n## Keras\r\n\r\n* Sequential 모델: \r\n\r\n  ```python\r\n  From tensorflow.keras.layes import Dense\r\n  From tensorflow.keras.models import Sequential\r\n  Model = Sequential() #그래프 생성(모델 생성)\r\n  Model.add(Dense(1, input_dim = 2)) #layer(dense), 노드 1개, 그 노드에 2개가 들어온다고 알려줌\r\n  Model.complile(loss=’mse’, optimizer=optimizers.Adam(lr=0.05))\r\n  Model.fit(dataX, y, epochs = 300) #학습\r\n  ```\r\n\r\n  <br>\r\n\r\n* 더 간단한 모델: \r\n\r\n  ```python\r\n  From tensorflow.keras.layes import Input, Dense\r\n  From tensorflow.keras.models import Model\r\n  xInput = Input(batch_shape=(None,2)) #그래프 생성(모델 생성)\r\n  yInput = Dense(1)(xInput)\r\n  model = Model(xInput, yOutput) #xinput 들어가서 yinput나오는 model\r\n  model.complie(loss=’mse’, optimizer=optimizers.Adam(lr=0.05))\r\n  model.fit(dataX,y,epochs=300) #학습\r\n  ```\r\n\r\n <br>\r\n\r\n* 잔차 계산 방법들:\r\n\r\n  1. Stochastic GD update: 그때그때 error 계산, a, b, c 업데이트\r\n  2. Batch update: 한꺼번에 error 계산하고 a, b , c 업뎃\r\n  3. Mini-batch update: 일부 error 계산하고 그때마다 a, b, c 를 업데이트. Stochastic GD update, Batch update의 중간 특성\r\n\r\n  <br>\r\n\r\n* Model 의 기본적인 code:\r\n  * `.fit` : train data를 만들어둔 model로 학습시킴\r\n  * `.predict`: test data를 만들어둔 model로 궁예해봄\r\n\r\n <br>\r\n\r\n <br>\r\n\r\n<br>\r\n\r\n<br>","excerpt":"딥러닝 DL optimaizer kerass optimizers 이차방정식 계수 추정 방법들: : 움직임  : 미분해서 움직임 : 지수이동평균법으로 움직임 : 관성 방향으로 이동 후 그 지점에서 GD 방향으로 움직임  가중치(알파 or lr…","fields":{"slug":"/딥러닝_1/"},"frontmatter":{"date":"Jul 03, 2020","title":"딥러닝 기초","tags":["DL"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n# 머신러닝(ML)\r\n\r\n- K-Means 클러스터링\r\n\r\n- H-clustering\r\n\r\n- DBSAN\r\n\r\n- 앙상블\r\n\r\n- 연관규칙 분석\r\n\r\n  <br>\r\n\r\n<br>\r\n\r\n\r\n\r\n\r\n\r\n## **k-means** 클러스터링\r\n\r\n```python\r\nGrid search: \r\n    Init = ‘k-means++’\r\n    n_init=3\r\n    max_iter=300\r\n    tol=le-04\r\n    random_state=0\r\n```\r\n\r\n<br>\r\n\r\n* 비지도학습\r\n  \r\n* 비계층적 군집분석\r\n  \r\n* k-means 클러스터링은 데이터를 k개의 클러스터(cluster, 무리)로 분류\r\n  \r\n  <br>\r\n  \r\n* `EM알고리즘`: 중점을 할당한 후, 각 중점까지의 거리의 합을 최소화하는 알고리즘\r\n\r\n* 알고리즘(작동 원리):\r\n  1. 사용자로부터 입력받은 k의 값에 따라, 임의로 클러스터 중심(centroid) k개를 설정해준다.\r\n  \r\n  2. k개의 클러스터 중심으로부터 모든 데이터가 얼마나 떨어져 있는지 계산한 후에, 가장 가까운 클러스터 중심을 각 데이터의 클러스터로 정해준다. \r\n  \r\n  3. 각 클러스터에 속하는 데이터들의 **평균**을 계산함으로 클러스터 중심을 **옮겨준다**. \r\n\r\n  4. 보정된 클러스터 중심을 기준으로 2, 3단계를 반복한다.\r\n  \r\n  5. 더이상 클러스터 중심이 이동하지 않으면 알고리즘을 종료한다. \r\n  \r\n     <br>\r\n  \r\n* new data 입력(발생) 시엔 각 중점과의 거리만 비교해서 가장 가까운 곳에 있는 군집에 속한다고 파악\r\n\r\n* 초기값에 따라 전역이 아닌 지역 최소 값을 찾을 수 있음\r\n\r\n* r에 따라 {0,1} 이면 명목형, 확률이면 연속형(GMM 모델)\r\n\r\n<br><br>\r\n\r\n* 적합한 k 개수를 찾고 검증하는 모델들\r\n\r\n### K-Means Elbow Method\r\n\r\n* “k는 얼마가 적합할까?” 적합한 k개수 찾는 성격인 듯하다.\r\n\r\n* Grid search: \r\n  1. n_clusters 조절\r\n  2. error: 군집 속 중점과의 거리의 합 <- 이라고 개념을 설정해두고(왜냐면 k-means는 비지도학습이라 정답이 없어서 label이나 target, class 등이 없어서 확인 못함) 군집화가 잘 된 경우라면 error가 작을 것.\r\n* 따라서 k가 증가할 때 줄어드는 ‘폭’이 작아지는 지점의 k값이 최적 군집 개수\r\n* 거리의 합 != 거리가 줄어드는 폭.\r\n* 엘보우는 거리가 줄어드는 폭을 봄\r\n\r\n <br><br>\r\n\r\n### 실루엣(Silhouette)\r\n\r\n* “군집화가 잘 됐나?” <- 약간 검증하는 성격인 듯하다.\r\n* 잘 된 군집화: \r\n  1. 군집 간 거리(b) > 군집 내 거리(a) \r\n  2. cohesion(응집도:군집 내) < separation(분리도:군집 간) \r\n\r\n* 실루엣 계수는 원형 군집이 아닌 경우 잘 맞지 않음\r\n\r\n* 0~1값을 가짐\r\n\r\n <br><br>\r\n\r\n## K-Means++군집(clustering)\r\n\r\n* local optimum 해결 위해 초기 중점을 좀 더 합리적으로 설정하는 방법\r\n\r\n <br>\r\n\r\n <br>\r\n\r\n------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## H-clustering\r\n\r\n* 계층적 군집분석\r\n\r\n* 덴드로그램\r\n\r\n* k-menas 와의 차이점:\r\n  * k-means는 **사전에 그룹수(k)** 결정, \r\n  * H-clutering은 한 개의 그룹이 남을 때까지 **그룹을 다 나눈 후** 몇 개 선택할지 두 개의 feature를 갖는 2차원의 덴드로그램으로 결정\r\n\r\n<br>\r\n\r\n <br>\r\n\r\n------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## DBSCAN\r\n\r\n```python\r\nGrid search:\r\n    eps = 0.2 # 앱실론: 특정 ‘반경’\r\n    min_samples=5 # 0.2 반경에 샘플 5개가 있어야 함\r\n    metric = ‘euclidean’\r\n```\r\n\r\n<br>\r\n\r\n* 계층적 군집분석\r\n* 밀집도 기반의 군집 알고리즘: core point(핵심 샘플), border point(경계 샘플), noise point(잡음 샘플)\r\n* noise point는 분류하지 않는다\r\n* K-means or 다른 군집분석과의 차이점: 모든 샘플을 클러스터에 할당하지 않고 잡음 샘플을 구분하는 능력이 있다\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 앙상블 기법\r\n\r\n* 다수의 결과를 예측하여 종합하고 분류함\r\n* 여러 알고리즘을 사용한 후 결과를 종합하여 정확도, 일반화 특성을 증가시킴\r\n* classification_report(~~)\r\n\r\n<br><br>\r\n\r\n### 배깅(Bagging or Bootstrap Aggregation)\r\n\r\n```python\r\nBaggingClassifier(~~)\r\n* Hyper parameter :\r\n    base_estimatior = m\r\n    n_estimators = 100\r\n    bootstrap = True\r\n* prob += bag.predict_proba(testX)\r\n* predY = np.argmax(prob, axis=1)  # axis=1 하는 이유: 안 하면 하나의 값인 int가 나와서 밑에 testY랑 mean하려면 array 형태로 나와야 함\r\n* accuracy = (testY == predY).mean()\r\n```\r\n\r\n<br>\r\n\r\n* BootStrap(단순복원 임의추출)을 통해 샘플 뽑아내 서브 데이터 만듦\r\n  * 각각의 서브 데이터 크기 = 원본 훈련 데이터 크기 \r\n  * why? 데이터 중복 허용해서 분산(변동)이 감소하고 overfitting 방지\r\n\r\n <br><br>\r\n\r\n### 부스팅(Boosting): 증폭, 가속. \r\n* 잘못 분류된 데이터에 가중치 두어 다시 뽑고 다시 분류하는 알고리즘\r\n\r\n  1. 서브 훈련 샘플 만듦\r\n\r\n  2. 처음 샘플링은 가중치를 두어 샘플링함 -> 분류 잘못된 데이터는 가중치 높이고 다시 샘플링. 이때 잘못 분류된 패턴이 선택될 확률이 높음. \r\n\r\n     → 분류가 어려운 패턴에 더욱 집중하여 정확도를 높이는 방법\r\n\r\n     <br><br>\r\n\r\n#### AdaBoost(Adaptive Boosting) \r\n\r\n* **약한 분류기** 사용. 잘못 분류한 데이터 샘플에 가중치를 두어 더 많이 샘플링하여 정확도 높임\r\n\r\n* 서브 데이터로만 만듦(잔차 등으로 만드는 거 아님)\r\n\r\n  ```python\r\n  AdaBoostClassifier(~~)\r\n  Hyper parameter:\r\n      base_estimator=svm\r\n      n_estimators=100 #100번 재조합한단 뜻(오분류한 거에 가중치둬서)\r\n  ```\r\n\r\n<br><br>\r\n\r\n#### Gradient Boosting(for regression)\r\n\r\n* target 데이터의 **잔차**를 줄이도록 학습. 학습할수록 residual(잔차)가 계속 작아짐. 잔차가 더 이상 줄어들지 않을 떄까지 tree 생성하며 학습+추정치 업데이트\r\n* residual 계산법 : 변수-(평균+학습률(알파. 0~1사이 값. 아무렇게나 줘도 됨. 보통 0.1)*tree의 leaf 평균\r\n* 선형회귀라 dataset도 연속형 변수인 boston 집값을 보도록 한다.\r\n\r\n* 선형회귀라 MSE 대신 r2 사용해도 OK\r\n* MSE: 선형, 로지스틱 회귀 둘다 쓰여도 OK. 다만 선형에선 R2를, 로지스틱에선 BCE(바이너리일 떄) 더 잘 쓰임..(?)\r\n\r\n```python\r\nGradientBoostingRegressor(~~)\r\nHyper parameter:\r\n    Loss = ‘ls’           \t# lest square = MSE 사용\r\n    Learning_rate = 0.1     # 알파. 가중치\r\n    n_estimators = 100      # 잔차(tree) 100개 만들라\r\n    max_depth=3 \t\t\t# 얕은 depth\r\n```\r\n\r\n<br><br>\r\n\r\n#### Gradient Boosting(for classification)\r\n\r\n* Regression과 동일하나, 추정치를 위해 odds, logs(odds), probability 개념 사용\r\n* binary cross entropy(BCE)를 loss함수로 사용\r\n\r\n```python\r\nGradientBoostingClassifier(~~)\r\nHyper parameter:\r\n    loss = ‘devianve’,      #로지스틱 함수 + CE 쓰라는 뜻\r\n    learning_rate = 0.1,     #학습률, 가중치, 알파값\r\n    n_estimators=100,      #잔차(tree) 수\r\n    max_depth=3 \r\n```\r\n\r\n<br><br>\r\n\r\n#### XGBoost(Extreme Gradient Boosting)(for regression)\r\n\r\n* 정규화와 가지치기를 통해 \r\n  1. overfitting을 줄이고 \r\n  2. 일반화 특성을 좋게 만듦\r\n  3. 특히 대용량 data의 경우에 속도도 SOSO\r\n* Similarity, output 값 사용: Similarity를 사용해서 잔차와 IG 계산하고 마지막에 output 계산해서 마지막 잔차 계산\r\n* 데이터 大 ~ similarity(유사도) 小 why? 상쇄되는 값이 많아서.\r\n\r\n```py\r\nXGBRegressor(~~)\r\nHyper parameter: \r\n\tObjective =’reg:squarederror’     #regression 사용하고 MSE 사용한단 뜻. regression이니 r2 사용\r\n```\r\n\r\n<br><br>\r\n\r\n#### **XGBoost(Extreme Gradient Boosting)(for classification)**\r\n\r\n* 잔차 계산 시, output value를 사용한다는 데서 Gradient Boost랑 차이가 있음\r\n\r\n```python\r\nHyper parameter:\r\n(chapter 1) XGBClassifier(~~)\r\n* Objective =’binary:logistic’        #바이너리 변수고 logistic함수(sigmoid) 사용\r\n    \r\n(chapter 2) XGBClassifier(~~)\r\n* Param – {‘eta’ : 0.3, \r\n  ‘max_depth’ : 3, \r\n  ‘objective’ : ‘multi:softprob’      #softmas 사용한단 뜻\r\n  ‘num_class’ : 3 }            \t\t  #클래스 개수\r\n```\r\n\r\n<br><br>\r\n\r\n### 랜덤포레스트(Random Forest)\r\n\r\n```python\r\nRandomForestClassifier(~~)\r\nHyper parameter:\r\n    max_depth=5\r\n    estimaors=100\r\n```\r\n\r\n<br>\r\n\r\n* DT(Decision Tree)를 앙상블함 \r\n  * 트리마다 서로 다른 feature 사용\r\n* 샘플링 함\r\n\r\n<br><br>\r\n\r\n### 다수결 알고리즘(Majority Voting)\r\n\r\n* 배깅/부스팅과의 차이점: 학습데이터를 서브data에 sampling 하느냐/안 하느냐\r\n  * 다수결 알고리즘은 배깅/부스팅처럼 서브데이터로 나눈 게 아니라 그 자체를 쓴다.\r\n\r\n<br><br>\r\n\r\n### Isolation Forest(iForest):\r\n\r\n```python\r\nModel = IsolationForest\r\nHyper parameter:\r\n    n_estimators = 100   #100개의 트리\r\n```\r\n\r\n<br>\r\n\r\n* 이상데이터 검출하는 알고리즘 (ex: 카드 불법 사용 색출에 활용)\r\n\r\n* Keyword: \r\n  * 이진검색트리\r\n  * Anomaly score(이상치 수치)\r\n  * recall, precison 사용\r\n    * 특히 recall 써서 실제 정상(T)인데 비정상(F)으로 예측했다던가, 실제 비정상(F)인데 정상(T)로 예측한 비율 찾아냄\r\n\r\n <br>\r\n\r\n <br>\r\n\r\n------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 연관규칙 분석\r\n\r\n* 장바구니 분석. 고객들의 구매 성향을 분석할 수 있음\r\n  1. 지지도: y가 독립변수인지 종속변수인지 불명확함\r\n  2. 신뢰도: y에 대한 영향을 무시한단 단점이 있음\r\n  3. 향상도: 1에 가까우면 X와 Y는 서로 독립적. 1보다 크면 양의 상관성, 1보다 작으면 음의 상관성. 리프트가 1보다 클수록 X→Y 규칙의 의미가 커짐\r\n* 지지도/신뢰도/향상도 특징:\r\n  1. 인과관계가 아닌 상관관계\r\n  2. 얼마나 빈번하게 나타나는지 측정\r\n* 이진행렬 구성\r\n* 지/신/향 모두 임계치 이상인 모든 규칙을 찾기엔 Brute Force 방식을 써서 조합이 너무 많아짐. 따라서 이 조합을 줄일 수 있는 알고리즘이 Apriori 알고리즘.\r\n* 항목을 줄이는 게 관건\r\n* 한 항목 집합이 반발하면, 그것의 모든 부분 집합이 반발한단 뜻에서 지지도 기반 가지치기\r\n* 연관성이 높다 = lift가 높다\r\n\r\n```python\r\nHyper parameter:\r\n    Frequent_itemsets = apriori(df, min_support = 0.6, use_columname==True) # Item sparse matrix생성\r\n    rules = association_rules(frequent_itemsets, metric=”lift”, min_threshold=0.7) # 모델 생성\r\n    Rules = association_rules(by=[‘lift]’, axis =0, ascendin=False) # Lift가 작은 것부터 sort\r\n```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n> 참고: 심교훈. 2019. 10. 9. “가장 간단한 군집 알고리즘, k-means 클러스터링\". https://bskyvision.com/564. b스카이비전\r\n\r\n ","excerpt":"머신러닝(ML) K-Means 클러스터링 H-clustering DBSAN 앙상블 연관규칙 분석 k-means 클러스터링 비지도학습 비계층적 군집분석 k-means 클러스터링은 데이터를 k개의 클러스터(cluster…","fields":{"slug":"/머신러닝_2/"},"frontmatter":{"date":"Jun 30, 2020","title":"머신러닝 분석 방법들, 두 번째","tags":["ML","XGBoost"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# 머신러닝(ML)\r\n\r\n- KNN\r\n- Decision Tree\r\n- SVM\r\n- 선형회귀분석\r\n- 로지스틱회귀분석\r\n- 나이브베이지안\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **`차원의 저주`**\r\n\r\n- 차원(feature)이 증가하면 성능이 저하된다\r\n\r\n  - 차원이 증가할수록 말 그대로 ‘근접 이웃’에 한정하기 어려워 멀리 떨어진 데이터를 참조한다\r\n\r\n    → 따라서 데이터 양에 비해 feature의 수가 많으면 차원의 저주 문제를 생각해봐야 한다.\r\n\r\n- 차원의 저주를 벗어날 수 있는 방법:\r\n\r\n  1. 차원 축소(feature 축소)\r\n  2. 데이터 양을 늘림\r\n\r\n- 차원의 저주를 벗어날 수 있는 모델\r\n  1. `중요도 분석`(의사결정나무 – 사전 가지치기)\r\n  2. PCA 주성분 분석\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **`kNN(k-Nearest Neighbor)`**\r\n\r\n```python\r\nModel = `KNeighborsClassifier(~~)`\r\nGrid search:\r\n    n_neighbors=5\r\n    p=2\r\n    meric = ‘minkowski’\r\n```\r\n\r\n- 지도학습\r\n- 테스트 데이터에서 k개의 가장 가까운 이웃을 찾고, 그 이웃들 중 다수가 속한 클래스가 테스트 데이터의 클래스가 되게 한다\r\n  - iris 패키지: “새로운 꽃이 발견됐을 때, 어느 종류(클래스)에 넣는 것이 좋을까?\r\n- `레이지 러닝(lazy learning)`: 미리 학습해 두는 방식이 아니라, test data 추정할 때마다 학습하기 때문에 시간이 오래 걸림\r\n\r\n ![image-20200721074726342](image-20200721074726342.png)\r\n\r\n> 그림 출처: [심교훈. \"유유상종의 진리를 이용한 분류 모델, kNN(k-Nearest Neighbor)\"](https://bskyvision.com/563)\r\n\r\n\r\n\r\n- K 가 작을수록 복잡도 높아짐\r\n\r\n  → 과잉적합\r\n\r\n- K가 증가할수록 정확도가 떨어진다\r\n\r\n- 거리 측정 방법:\r\n\r\n  1. 맨하튼 거리: 가장 심플\r\n  2. 유클리디안 거리: 최단 거리\r\n  3. 민코우스키 거리: 많이 떨어진 성분 부각\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **`결정 트리(Decision Tree)`**\r\n\r\n```python\r\nModel = DecisionTreeClassifier(~~)\r\n- grid search: \r\n    criterion=’gini’\r\n    알파(가중치)\r\n    max_depth=k\r\n    pd.Categorical(income[c]).codes\r\n    dt.feature_importances ← 중요도 분석\r\n    path = `DecisionTreeClassifier().cost_complexity_pruning_path(trainX, trainY)\r\n    ccp_alpha = ccp_alpha\r\n    * 이때 먼저, ccp_alpha = `ccp_alphas[np.where(ccp_alphas > 0.001)]`\r\n    clfs[-1].tree_.node_count / clfs[-1].tree_.max_depth\r\n```\r\n\r\n<br>\r\n\r\n- 지도학습, 비지도학습\r\n\r\n\r\n- 알파값(가중치 조정) 높이기 ~ 오분류율(불순도) 증가\r\n\r\n- 핵심: 변별력이 좋은 질문을 위에서부터 하나하나 세팅\r\n\r\n  <br>\r\n\r\n- Feature가 3개 이상이면 초평면으로 구분\r\n\r\n- Featrue(차원)이 많아져도 덜 중요한 feature는 분류 기준에서 제외되어 feature 선정에 크게 신경 쓸 필요 X\r\n\r\n- **중요한 Feature 확인 가능**\r\n  \r\n  - 중요도 분석<br>\r\n\r\n* Tree 과도하게 분할( = 과잉 적합 = 트리가 복잡) → 아래 노드에 데이터 小 → 데이터 단편화 → 유의미한 결정 내리기 어려움\r\n\r\n  * 즉, Depth 높 ~ 트리 길어짐 ~ 과도하게 분할 ~ overfitting ~ 정확도 낮음\r\n\r\n  * 해결 위해 정지기준 or 사전/사후 가지치기 사용\r\n    * `정지기준`: depth 지정 or 마지막 노드의 데이터 수가 임계치 이하로 떨어지지 않도록 지정\r\n\r\n      * 알파(가중치): depth 조정\r\n\r\n    * `가지치기`: 트리 단순화하여 일반화 특성 향상시키기.\r\n      1. `사전 가지치기`: depth, 마지막 노드의 최소 데이터 수, 불순척도(criterion)\r\n      \r\n      2. `사후 가지치기`: 오분류율, 패널티항, 알파(가중치)\r\n      \r\n         <br>\r\n\r\n* `ID3 알고리즘`: 정보량과 엔트로피 개념 활용\r\n  \r\n* 알고리즘 **순서**: \r\n\r\n  1. 엔트로피 계산량에 의해 엔트로피(E)가 낮고, \r\n  2. 정보획득량(IG)가 높은 선택지를 선택함\r\n\r\n     * A 속성은 마지막에도 결정 노드에 쓰이지 않았다. N개의 속성 중에 가장 변별력이 낮은 속성이었던 이유다.\r\n\r\n* 불순척도(지니지수, 엔트로피) 작아지도록 분할 기준 선택. 분할 전 부모노드 보다 분할 후 자식노드의 불순척도가 작아지는 게 좋음(IG)\r\n\r\n* `지니지수`: 0~0.5값\r\n  \r\n* **`정보량`**: 어떤 사건이 가지고 있는 정보의 양. 드물게 발생하는 일일수록 정보량이 크다.\r\n  \r\n* **`엔트로피`**(E): 0~1값 정보량의 기댓값(평균). 발생한 사건들의 정보량을 모두 구해서 (가중)평균\r\n  \r\n  * 엔트로피가 크다는 것은 평균정보량이 크다는 것\r\n  \r\n  * 대개 사건들이 일어날 확률이 비슷한 경우에 엔트로피가 크다.\r\n  \r\n  * 따라서 두 사건이 0.5, 0.5 확률로 일어날 때의 엔트로피가 가장 크다\r\n  \r\n    → 즉, **불확실성이** 클수록 엔트로피가 크다\r\n  \r\n    → 불확실성이 크면 클수록 분류하기는 어려워짐\r\n  \r\n    → 엔트로피가 가장 작은 것을 상위 의사결정 노드에 위치시켜야 함.\r\n  \r\n    → 이를 위해 **`정보획득량`**(IG)이란 개념이 필요\r\n  \r\n    \"어떤 속성을 가지고 분류했을 때 가장 엔트로피(불확실성)가 작은지, 정보획득량이 큰지\"\r\n  \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **`서포트 벡터 머신(SVM)`**\r\n\r\n```python\r\nModel = SVC(~~)\r\ngrid search : \r\n    kernel = ‘linear’\r\n    C\r\n    gamma\r\n    (비선형+multiclassification) kernel = `‘rbf’\r\n     * 파라미터 C는 이상치 또는 오류를 얼마나 허용하는 가(복잡도 조절)를 정해주고, gamma는 결정 경계의 곡률을 결정\r\n        * C: max margin + min 섞임 조절\r\n        * C: 大 ~ 패널티항 大 ~ 거리 짧음\r\n```\r\n\r\n</br>\r\n\r\n* 가장 많이 사용되는 SVM은 radial(방사형) basis function (RBF) 커널을 사용한 SVM\r\n\r\n* SVM은 일반화 특성이 우수\r\n\r\n* >  모델 생성시 특정 옵션을 주어야 `predict_proba`가 사용 가능\r\n  >\r\n  >  predict_proba 함수를 가지고 있지만, 모델 생성시 `probalility=True`를 설정하지 않으면 사용할 수 없다.\r\n  >\r\n  >  이때, 레이블이 3개 이상인 경우, LinearSVC보단 SVC를 사용하고, probability=True 옵션 주는 것을 추천한다. \r\n  >\r\n  >  출처: [mathcom. \"Scikit-learn에서 predict_proba 및 AUC 계산하기\"](https://m.blog.naver.com/cjh226/221358912619. )\r\n\r\n<br>\r\n\r\n### **선형 SVM**\r\n\r\n* 데이터를 선형으로 분리하는 최적의 선형 결정 경계를 찾는 알고리즘\r\n  \r\n  * 그 중 가장 간단한 것이 선형 SVM(linear SVM)\r\n  \r\n   </br>\r\n  \r\n* SVM 알고리즘의 목표: 클래스가 다른 데이터들을 가장 큰 마진(margin)으로 분리해내는 선 또는 면(결정 경계 또는 분리 초평면)을 찾아내는 것\r\n  * 마진: 두 데이터 군과 결정 경계와 떨어져있는 정도\r\n  * 서포트 벡터: 결정 경계와 가장 먼저 만나는 데이터\r\n  \r\n   </br>\r\n  \r\n* SVM의 기본 매개변수인 C\r\n\r\n* cost(C): C는 얼마나 많은 데이터 샘플이 다른 클래스에 놓이는 것을 허용하는지를 결정\r\n  > ex: 작을 수록 많이 허용, 클 수록 적게 허용\r\n  > ex: C값을 낮게 설정하면 이상치들이 있을 가능성을 크게 잡아 일반적인 결정 경계를 찾아내고, 높게 설정하면 반대로 이상치의 존재 가능성을 작게 봐서 좀 더 세심하게 결정 경계를 찾아낸다.\r\n  > ex: \"난 데이터 샘플하나도 잘못 분류할 수 없어!\" : C를 높여야\r\n  > ex: \"몇 개는 놓쳐도 괜찮아, 이상치들이 꽤 있을 수도 있으니까\" : C를 낮춰야\r\n  >\r\n  > 출처: [심교훈. \"서포트 벡터 머신(SVM)의 사용자로서 꼭 알아야할 것들 - 매개변수 C와 gamma\"](https://bskyvision.com/163. b스카이비전.)\r\n\r\n* C가 너무 낮으면 과소적합(underfitting)\r\n\r\n* C가 너무 높으면 과대적합(overfitting)\r\n  \r\n  → 적합한 C값을 찾아내는 것이 중요\r\n  \r\n* 하드마진(hard-margin) SVM\r\n\r\n* 소프트마진(soft-margin) SVM\r\n\r\n </br>\r\n\r\n### **RBF 커널 SVM**\r\n\r\n* 커널 기법은 주어진 데이터를 고차원 특징 공간으로 사상해주는 것이다.\r\n\r\n* 3차원 공간에서 분류된 것을 다시 2차원 공간으로 매핑해서 보면 결정 경계가 둥그렇게 보일 것\r\n\r\n* RBF 커널의 경우 gamma라는 매개변수를 사용자가 조정해야 한다.\r\n  * `gamma` : 하나의 데이터 샘플이 영향력을 행사하는 거리를 결정\r\n    * ex: gamma가 클수록 한 데이터 포인터들이 영향력을 행사하는 거리가 짧아지는 반면, 낮을수록 커진다\r\n    * ex: gamma는 가우시안 함수의 표준편차와 관련되어 있는데, 클수록 작은 표준편차를 의미\r\n      * '편차가 크다': 어떤 자료는 평균보다 엄청 크고 어떤 자료는 평균보다 엄청 작다\r\n  \r\n* gamma 매개변수는 결정 경계의 곡률을 조정한다고 말할 수도 있다.\r\n  \r\n  * gamma의 값이 높아짐에 따라 공간이 점점 작아지는데, 위에서 언급한 것과 같이 각각의 데이터 포인터가 영향력을 행사하는 거리가 짧아졌기 때문 <- 아마 정확도가 높아질 듯하다.\r\n  \r\n* 매개변수 C와 마찬가지로 너무 낮으면 과소적합될 가능성이 크고, 너무 높으면 과대적합의 위험이 있다.\r\n  \r\n  * 두 값 모두 커질수록 알고리즘의 복잡도는 증가하고, 작아질수록 복잡도는 낮아진다.\r\n  \r\n    <br>\r\n  \r\n\r\n<br>\r\n\r\n## **선형 회귀(linear regression)**\r\n\r\n```python\r\nModel = LinearRegression()\r\n```\r\n\r\n* 예측값(Y햇)이 실수(연속형)일 떈, ‘.mean’, ‘.score’ 말고 R2(*0~1값을 가짐) 사용(값의 범위가 MSE보다 작기 때문)\r\n\r\n* 선형회귀는 사용되는 '특성(feature)의 개수'에 따라 \r\n  1. 단순 선형 회귀(simple linear regression): 단 하나의 특징(feature)을 가지고 라벨값(label) 또는 타깃(target)을 예측하기 위한 회귀 모델을 찾는다.\r\n  2. 다중 선형 회귀(multiple linear regression): 하나의 특성이 아닌 여러 개의 특성을 활용해서 회귀모델을 만듦\r\n* **선형 회귀는 y와 y햇 사이의 평균제곱오차(mean squared error, MSE)를 최소화하는 파라미터(w, b)**를 찾는다. y와 y햇의 차이가 작으면 작을 수록 예측 성능이 좋기 때문\r\n* **라쏘(Lasso):** 선형 회귀의 단점을 극복하기 위해 개발된 방법\r\n* linear regression에선 predict_proba 함수를 제공하지 않는다\r\n* y햇 = w[0]+x[0]+b\r\n  * w: 가중치(weight), 계수(coefficient)\r\n  * b: 편항(offset)\r\n  * y햇: 예측값\r\n  * x[0]: 특징\r\n  * \"feature와 lable 사이의 관계를 잘 설명해낼 수 있는 최적(가장 적합한)의 w와 b를 찾는 것\"\r\n\r\n<br>\r\n\r\n### **`라쏘(L1)`**\r\n\r\n* 추가 제약조건이자 grid search\r\n* 선형 회귀에 **L1** 규제를 줘서 과대적합을 피하는 방법이다.\r\n* 상관성이 있을 수도 있는 feature의 영향력을 줄일 수 있음\r\n* 동작 원리:\r\n  * MSE가 최소가 되게 하는 w, b 찾기 + w의 모든 원소가 0이 되거나 0에 가깝게\r\n  * MSE와 penalty 항의 합이 최소가 되게 하는 w와 b를 찾는 것이 라쏘의 목적\r\n* L1-norm(벡터의 요소들의 절대값들의 합) 패널티를 조정하는 건 알파값(선형회귀 분석의 grid serch)\r\n  * **알파 너무 작으면 과대적합(복잡도 큼), 너무 크면 과소 적합(복잡도 넘 작음)**\r\n\r\n* 라쏘의 장점:\r\n  1. 제약 조건을 통해 일반화된 모형을 찾는다.\r\n  2. 모델 해석력이 good (모델에서 가장 중요한 특성이 무엇인지 아는)\r\n\r\n<br>\r\n\r\n### `릿지(L2)`\r\n\r\n* `L2-norm`\r\n* 릿지 원의 크기와 라쏘의 마름모 크기는 정규화 역할하는 람다 혹은 C로 조절\r\n* 특성이 다수일 경우에는 릿지 회귀가 좀 더 잘 작동. 선형 회귀와 달리 모델의 복잡도를 조정할 수 있기 때문. 복잡도를 조정할 수 있다는 말은 사용자가 설정 가능한 파라미터가 있다는 뜻\r\n* **알파값(가중치)**: (feature가 생각보다 덜 쓰였다던가의)과소적합: 1보다 작은 α 값(ex: 0.1, 0.01, 0.001)로 조정\r\n* 즉, alpha 값을 크게 설정 ~ 기울기가 줄어듦 ~ 특성들이 출력에 미치는 영향력이 줄어듦(현재 특성들에 덜 의존)\r\n  * alpha = 0 ← 선형회귀\r\n  * default : alpha = 1\r\n\r\n<br>\r\n\r\n* 정리\r\n  * 특성이 많은데 그중 **일부분만 중요하다면 라쏘**\r\n  * 특성의 중요도가 전체적으로 **비슷하다면 릿지**\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `로지스틱 회귀 분석`\r\n\r\n```python\r\nmodel = Logisticregression(~~)\r\ngrid search:\r\n    penaly = ‘l2’\r\n    C = c\r\n    max_iter = 500\r\n```\r\n\r\n<br>\r\n\r\n* 선형회귀분석에서 쓰던 MSE 말고 Cross Entropy(CE) 사용\r\n  \r\n* **오즈**(0.9가 나왔으면 1이라 보는 것)\r\n\r\n* 계산 시 유의 사항:\r\n\r\n  * 예측값(y햇)이 실제값(y)과에 가깝게 나오게 하기 위해 CE, MSE 최소화\r\n\r\n  * 출력에 1이 여러 개인(sigmoid 출력) 이진분류일 경우 **BCE**(바이너리 CE) 사용: 개별 출력이라 1이 여러 개\r\n\r\n  * 출력에 1이 한 개일 경우(one-shot 형태로 softmax가 출력) **CCE**(카테고리컬 CE) 사용: 그룹(?) 출력이라 1이 하나\r\n\r\n    → BCE, CCE는 결과가 다르고 정확도 측정도 달라지므로 주의해서 선택\r\n\r\n  <br>\r\n\r\n* sklearn 패키지에서는 sigmoid 안 거치고 바로 softmax로 감\r\n\r\n  <br>\r\n\r\n* 보통의 계산 순서: \r\n  1. sigmoid 함수로 계산\r\n  2. softmax함수로 계산(이때 CE 사용)\r\n\r\n <br>\r\n\r\n* 로지스틱함수의 yHat 계산법(step):\r\n  1. 시그모이드 계산\r\n     * 시그모이드(sigmoid) 함수: 가중치와 바이어스는 시그모이드의 비활성도를 조절해준다.\r\n  2. CE 계산\r\n\r\n<br>\r\n\r\n <br>\r\n\r\n## `나이브 베이지안`\r\n\r\n* model = GaussianNB()\r\n\r\n* **Feature들이 서로 독립이라 가정**하고 **조건부 확률 계산**해서 데이터 분류\r\n  \r\n* **명목형**(1, 0), **연속형**(정규분포 사용) 변수 모두 사용 가능\r\n  \r\n  <br>\r\n  \r\n* 계산 순서:\r\n\r\n  1. 결합 확률은 너무 복잡해서 두 feature를 독립이라 가정하여,\r\n\r\n  2. 베이지안 식에 의해 각각을 곱해 계산한 후,\r\n\r\n  3. 큰 확률의 값을 선택\r\n\r\n     Ex: yes 일 확률 : 1 , no일 확률: 0 => (계산 후) no로 분류\r\n     \r\n     <br>\r\n\r\n* `m 추정치(m-Estimates)`: 비교하려는 두 샘플의 data 중에 특정 데이터가 없을 땐 두 확률이 모두 0으로 나와서 분류할 수 없으므로, m-Estimates라는 m과 p를 사용해서 조건부 확률 계산식을 조정함. \r\n\r\n* 분모의 m은 임의의 확률, mp는 분자가 0 나오는 거 방지\r\n\r\n* 명목형, 연속형 모두 섞여 있는 data 일 땐,\r\n  1. 명목형, 연속형 각각 model 학습\r\n  2. 각각의 model 정확도 추정\r\n  3. '2'의 그 정확도(확률)을 곱함\r\n  4. '3'의 확률의 곱으로 정확도 측정\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n>  참고: \r\n>\r\n>  * 심교훈. 019. 10. 24. \"결정 트리(Decision Tree) 알고리즘, ID3 소개\". https://bskyvision.com/598. b스카이비전.\r\n>* 심교훈. 2020. 1. 20. \"[ubuntu+python] 선형 회귀의 업그레이드 버전1, 릿지 회귀\". https://bskyvision.com/687. b스카이비전\r\n>  * 심교훈. 2017. 10. 21. \"서포트 벡터 머신(SVM)의 사용자로서 꼭 알아야할 것들 - 매개변수 C와 gamma\". https://bskyvision.com/163. b스카이비전.\r\n>  * 머신러닝. 2020.01.14. \"서포트 벡터 머신(Support Vector Machine) 쉽게 이해하기\". http://hleecaster.com/ml-svm-concept/. 아무튼워라밸\r\n>  * mathcom. 2018. 09. 14. \"Scikit-learn에서 predict_proba 및 AUC 계산하기\". https://m.blog.naver.com/cjh226/221358912619. Notepad for mathcom\r\n\r\n\r\n\r\n","excerpt":"머신러닝(ML) KNN Decision Tree SVM 선형회귀분석 로지스틱회귀분석 나이브베이지안  차원(feature…","fields":{"slug":"/머신러닝_1/"},"frontmatter":{"date":"Jun 23, 2020","title":"머신러닝 분석 방법들, 첫 번째","tags":["ML"],"update":"Aug 16, 2020"}}}]}},"pageContext":{}},"staticQueryHashes":["3649515864","694178885"]}