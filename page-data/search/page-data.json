{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# GAN\r\n\r\n* 비지도학습(UL) 방식의 이미지, 문서, 음성 등의 데이터를 **생성(모방)하는 알고리즘**\r\n* **비모수적방법**으로도 비교적 정확한 **sampling이 가능**함 \r\n* 위조 데이터 생성 및 판별에 사용 \r\n  EX) 이미지 색깔(색칠) 해주는 프로그램, 딥페이크 영상\r\n\r\n\r\n\r\n![](image-20200728184326510.png)\r\n\r\n> 출처: https://www.naverlabs.com/storyDetail/44\r\n\r\n\r\n\r\n## 그림 보충 설명:\r\n\r\n1)  `Real`: 실제 데이터(이미지, 음성 등)\r\n\r\n2)  `Input`: 랜덤 데이터. **노이즈 섞인 것**. \t*But,* Generator 통과하면, Real data 같은 것으로 변환돼 나온다.\r\n\r\n3)  `Generator(network)`: 생성자. **진짜 같은 가짜(Fake) 생성**\r\n\r\n4)  `Discriminator(network)`: 판별자. **실제 데이터(Real)와 가짜 데이터(Fake)를 판별**함\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **즉, 총 2개의 네트워크 사용:**\r\n\r\n1)  `Discriminator`: real or fake 판별자\r\n\r\n2)  `Generator`: fake 생성자\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## Gan의 loss function:\r\n\r\n* minGmaxDV(D,G) = logD(x) + log(1-D(G(z)))``\r\n* 학습을 반복하여 (Pg = Pdata가 되어) Discriminator가 구별 불가능인 상태(‘D(x)=0.5’)로 수렴하도록 \r\n  → 마치 Generator가 x를 만들어낸 것처럼 됨 \r\n\r\n| Discriminator   | Generator       |\r\n| --------------- | --------------- |\r\n| 엔트로피 최대화 | 엔트로피 최소화 |\r\n\r\n> 엔트로피: 정보의 가치(정보량)과 ~\r\n\r\n**1)**  **`Discriminator`**(network): **`maxV(D, G)`**로 학습. D(x) = 1 and D(G(z)) = 0일 때 최대\r\n\r\n* *why?* D(G(z))가 1이 되고, D(x)가 1이 되니까\r\n\r\n2)  **`Generator`** network: **`minV(G)`**로 학습. D(G(z)) = 1 일 때 최소. 이때(D(x)는 상관 X)\r\n\r\n* *why?* D(G(z))가 0이 되니까\r\n\r\n<br>\r\n\r\n### 원리:\r\n\r\n![](image-20200728185621472.png)\r\n\r\n> 출처: Goodfellow 논문 공식\r\n\r\n<br>\r\n\r\n1. `Discriminator`를 k번 학습시키고, `Generator`를 1번 학습시킨다.\r\n\r\n   → D가 G보다 더 많이 학습된다.    * D: Discriminator / * G: Generator\r\n\r\n   <br>\r\n\r\n   *이에 따라* >\r\n\r\n   1) Real Data와 Fake Data를 구별해내는 `D loss`는 점점 더 작아져 영향력이 줄어들고,\r\n\r\n   2) `D`와 `G`는 점점 더 비슷해지며,\r\n\r\n   3) `KL`이 적어지고,   *****KL: G와 D의 정보량의 차이/분산의 차이\r\n\r\n   <br>\r\n\r\n   *이럴수록* >\r\n\r\n​\t3-1) G가 더 많은 영향력을 행사하고(역할을 하고),\r\n\r\n​\t3-2) `D loss`를 계산하는 공식 中 [-log4 + 2JSD(Pdata+||Pg)]에서 -log4의 값이 더욱더 1.38에 가까워진다. \r\n​    *[2JSD(Pdata+||Pg) ] : KL이라 보면 됨. (KL이 작아진다) = (D와 G의 분산이 적다) = (D loss가 1.38에 가깝다)\r\n\r\n   <br>\r\n\r\n   *따라서*  >\r\n\r\n   분별할 수 없이 실제와 가까운 Fake Data가 생성된다.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 위 원리에 따라,\r\n\r\n  *학습이 안 된 상태에선* >\r\n\r\n  G(z) ( = Fake Data. 이때 ‘z’는 input에서 들어온 random data임)의 분포가 오른쪽으로 치우친 상태로서 D(x)는 1에 가까운 값이 출력되고 D(G(z))는 0에 가까운 값이 출력된다.\r\n\r\n  [^'D(x)는 1에 가까운 값이 출력되고 D(G(z))는 0에 가까운 값이 출력된다']: 이때 D와 G는 아래 함수와 같은 상태임![image-20200728190633284](image-20200728190633284.png)![image-20200728190622855](image-20200728190622855.png)\r\n\r\n  즉, D는 진짜 (X)와 가짜 G(z)를 잘 구별하고, `G`는 진짜 같은 가짜를 잘 못 만든다\r\n\r\n  <br>\r\n\r\n  *학습이 진행되면* > \r\n\r\n  가짜 데이터 G(z)의 분포가 점점 Real Data( = X)의 분포와 유사해지고 D(G(z)) 값도 점차 커져서 D(x)값은 점차 작아진다 \r\n\r\n  <br>\r\n\r\n  *학습이 완료되면* > \r\n\r\n  Real data와 G(z)의 분포가 잘 일치하고 “D(x) = D(G(z)) = 0.5 “로 수렴한다.\r\n\r\n  즉, 임의의 random data를 G에 입력해 나온 Fake data는 Real data와 유사한 분포 특성을 갖는 데이터가 출력된다.\r\n\r\n![](image-20200728190502482.png)\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고:\r\n\r\n  >  http://blog.skby.net/gan-generative-adversarial-networks/\r\n\r\n","excerpt":"GAN 비지도학습(UL) 방식의 이미지, 문서, 음성 등의 데이터를 생성(모방)하는 알고리즘 비모수적방법으로도 비교적 정확한 sampling이 가능함  위조 데이터 생성 및 판별에 사용 \nEX…","fields":{"slug":"/GAN_1/"},"frontmatter":{"date":"Aug 08, 2020","title":"GAN 이론","tags":["DL","GAN"],"update":"Aug 08, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# GAN\r\n\r\n</br>\r\n\r\n* 1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다.</br>\r\n\r\n* fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등)</br>\r\n\r\n* Discrimi의 loss는 max[log(Dx) + log(1 - DGz)]이고, Generator의 loss는 min[log(Dx + log(1 - DGz))]이다. </br>\r\n\r\n  </br>\r\n\r\n* Tensorflow에서는 이 loss 함수를 이용하여 직접 GAN을 학습할 수 있지만, </br>\r\n\r\n  Keras에서는 model.fit(), model.train_on_batch() 함수에서 target 값을 지정해야 하기 때문에 이 loss로 GAN을 학습할 수 없다 **Keras는 기본적으로 Supervised learning 목적이다.**</br>\r\n\r\n  * Keras에서는 supervised learning 방식으로 바꿔 binary_crossentropy loss 함수를 써서 GAN을 학습하는 것이 보통이다.</br>\r\n\r\n    <br>\r\n\r\n* 이 코드는 아래 자료를 참조해서 응용했다.</br>\r\n\r\n  1. Rowel Atienza, 2018, Advanced Deep Learning with Keras. Chap 4. p.107 ~ p.113</br>\r\n  2. 아마추어 퀀트, blog.naver.com/chunjein,  2020.04.08</br>\r\n\r\n* 함수들의 기능을 파악하기 쉽도록 순서를 변경하였다.</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n## Basic CODE\r\n\r\n</br>\r\n\r\n* Keras를 이용하여 기본 GAN 모델을 연습한다.</br>\r\n* file: 딥러닝 8-2.GAN(Kears)</br>\r\n\r\n</br>\r\n\r\n#### step1. 정규분포로부터 데이터를 샘플링한다</br>\r\n\r\n```python\r\nrealData = np.random.normal(size=1000)\r\nrealData = realData.reshape(realData.shape[0], 1)\r\n```\r\n\r\n</br>\r\n\r\n#### step2. Network 빌드\r\n\r\n```python\r\nnDInput = realData.shape[1] # nDInput.shape[1] = 1\r\nnDHidden = 32\r\nnDOutput = 1\r\nnGInput = 16\r\nnGHidden = 32\r\nnGOutput = nDInput\r\n\r\n## nDInput와 nGOutput는 값이 같아야 함\r\n```\r\n\r\n</br>\r\n\r\n```python\r\ndef getNoise(m, n=nGInput):\r\n    z = np.random.uniform(-1., 1., size=[m, n])\r\n    return z\r\n```\r\n\r\n```python\r\ndef MyOptimizer(a = 0.001):\r\n    return RMSprop(lr = a)\r\n```\r\n\r\n</br>\r\n\r\n#### step3. 모델 그림\r\n\r\n```py\r\nGenerator --> Discriminator를 연결한 모델을 생성한다.\r\n아래 네트워크로 z가 들어가면 DGz = 1이 나오도록 G를 학습한다.\r\nD 네트워크는 업데이트하지 않고, G 네트워크만 업데이트한다.\r\n\r\n        +---+   Gz   +---+\r\n  z --->| G |------->| D |---> DGz\r\n        +---+        +---+\r\n      trainable   not trainable\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step4. (객체지향) 함수 정의\r\n\r\n**0. K.clear_session()</br>**\r\n\r\n#####   1. Discriminator = BuildDiscriminator()</br>\r\n\r\n#####   2. Generator = BuildGenerator()</br>\r\n\r\n#####   3. GAN = BuildGAN(Discriminator, Generator)</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step5. 학습 세팅\r\n\r\n```python\r\nnBatchCnt = 3       # Mini-batch를 위해 input 데이터를 n개 블록으로 나눈다. # 333개, 333개, 334개로 쪼개짐 \r\nnBatchSize = int(realData.shape[0] / nBatchCnt)  # 블록 당 Size # nBatchSize: 333개, 333개, 334개 순으로 들어감 \r\nfor epoch in range(1000):\r\n    # Mini-batch 방식으로 학습한다\r\n    for n in range(nBatchCnt):\r\n        # input 데이터를 Mini-batch 크기에 맞게 자른다\r\n        nFrom = n * nBatchSize #for문 다 돌면 nFrom= 666\r\n        nTo = n * nBatchSize + nBatchSize #for문 다 돌면 nTo=1000\r\n        \r\n        # 마지막 루프이면 nTo는 input 데이터의 끝까지. \r\n        ## 왜 써주냐면 , n=2(마지막)일때 nTo = n * nBatchSize + nBatchSize는 999로 1000이 안되기 땜에.\r\n        if n == nBatchCnt - 1:\r\n            nTo = realData.shape[0]\r\n```\r\n\r\n</br>\r\n\r\n``` python\r\n        # 학습 데이터를 준비한다\r\n        bx = realData[nFrom : nTo] #진짜 data 형성\r\n        bz = getNoise(m=bx.shape[0], n=nGInput) # bx.shape[0]=333->333->334, nGInput=16\r\n        Gz = Generator.predict(bz) #진짜 data shape 맞춰서 noise 써가지고 가짜 data 형성(fake data)\r\n```\r\n\r\n![image-20200715110832016](image-20200715110832016.png)\r\n\r\n</br>\r\n\r\n##### Discriminator = BuildDiscriminator()\r\n\r\n```python\r\n    \t### < Discriminator를 학습한다. > ###\r\n        # Real data가 들어가면 Discriminator의 출력이 '1'이 나오도록 학습하고,\r\n        # Fake data (Gz)가 들어가면 Discriminator의 출력이 '0'이 나오도록 학습한다.\r\n        \"\"\"target data 만들기\"\"\"\r\n        target = np.zeros(bx.shape[0] * 2)\r\n        target[ : bx.shape[0]] = 0.9     # '1' 대신 0.9로 함\r\n        target[bx.shape[0] : ] = 0.1     # '0' 대신 0.1로 함\r\n        \"\"\"target data 형성 완료\"\"\"\r\n        \r\n        bx_Gz = np.concatenate([bx, Gz]) # D 학습 \r\n        Dloss = Discriminator.train_on_batch(bx_Gz, target) \r\n        #real data & fake data 모두가 D를 거치게 한다. \r\n        ##참고: fit 함수보다 train_on_batch 쓰는 게 더 속도가 빨라서 이거 씀\r\n \r\n```\r\n\r\n\r\n\r\n![image-20200715110841184](image-20200715110841184.png)\r\n\r\n</br>\r\n\r\n###### \tdef BuildDiscriminator()\r\n\r\n```python\r\n# Discriminator를 G. D 각각 생성한다\r\ndef BuildDiscriminator():\r\n    x = Input(batch_shape = (None, nDInput))\r\n    h = Dense(nDHidden, activation = 'relu')(x)\r\n    Dx = Dense(nDOutput, activation = 'sigmoid')(h) #0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 \r\n    model = Model(x, Dx)\r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.001)) \r\n    #sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 \r\n    \r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n##### GAN = BuildGAN(Discriminator, Generator)\r\n\r\n```python\r\n### < Generator를 학습한다. > ###\r\n# Fake data (z --> Gz --> DGz)가 들어가도 Discriminator의 출력이 '1'이 나오도록 Generator를 학습한다.\r\n\"\"\"target data 만들기\"\"\"\r\ntarget = np.zeros(bx.shape[0])\r\ntarget[:] = 0.9\r\n\"\"\"target data 형성 완료\"\"\"\r\n        \r\nGloss = GAN.train_on_batch(bz, target) \r\n## GAN 함수 참고: D는 위에서 학습해서 여기선 학습 안 하고 G만 학습 \r\n# 어떤 학습? 가짜 data가 들어가면 target이 전부 1로 출력되도록(Discriminator가 전부 진짜로 판별하도록)! \r\n```\r\n\r\n\r\n\r\n![image-20200715110850214](image-20200715110850214.png)\r\n\r\n</br>\r\n\r\n###### \tdef BuildGAN(D, G)\r\n\r\n``` python\r\ndef BuildGAN(D, G): # 전체 NETWORK Build \r\n    D.trainable = False     # Discriminator는 업데이트하지 않는다= 학습하지 않는다. 왜냐면 자체적으로 위에서 학습했으니까. 따라서 G만 학습됨 \r\n    z = Input(batch_shape=(None, nGInput))\r\n    Gz = G(z)\r\n    DGz = D(Gz)\r\n    \r\n    model = Model(z, DGz) #z가 들어가면 최종적으로 DGz가 나온다. \r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.0005)) # binary_crossentropy: 출력값이 0 아니면 1 나오도록\r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef BuildDiscriminator() = Discriminator\r\n\r\n```python\r\n# Discriminator를 G. D 각각 생성한다\r\ndef BuildDiscriminator():\r\n    x = Input(batch_shape = (None, nDInput))\r\n    h = Dense(nDHidden, activation = 'relu')(x)\r\n    Dx = Dense(nDOutput, activation = 'sigmoid')(h) #0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 \r\n    model = Model(x, Dx)\r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.001)) \r\n    #sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 \r\n    \r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef BuildGenerator() = Generator\r\n\r\n```python\r\n# Generator를 생성한다 \r\n# G는 여기서 학습 안 하므로 '.complie' 안 함 \r\ndef BuildGenerator(): \r\n    z = Input(batch_shape = (None, nGInput))\r\n    h = Dense(nGHidden, activation = 'relu')(z)\r\n    Gz = Dense(nGOutput, activation='linear')(h)\r\n    return Model(z, Gz)\r\n```\r\n\r\n</br>\r\n\r\n##### kd = KL(ralData, fakeData)\r\n\r\n```python\r\n    if epoch % 10 == 0:\r\n        z = getNoise(m=realData.shape[0], n=nGInput)\r\n        fakeData = Generator.predict(z)  \r\n        # Generator = BuildGenerator()에서 만든 Model(z, Gz)를 활용하여, \r\n        # \"model.predict(z=노이즈 data)\" 하라는 뜻 \r\n        kd = KL(realData, fakeData)\r\n        print(\"epoch = %d, D-Loss = %.3f, G-Loss = %.3f, KL divergence = %.3f\" % (epoch, Dloss, Gloss, kd))\r\n        # Dloss: 0.6932636 , Gloss: 0.6933405 , kd: 0.2189525518812676 = 분산이 적다\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef KL\r\n\r\n```python\r\n# 두 분포 (P, Q)의 KL divergence를 계산한다.\r\ndef KL(P, Q):\r\n    # 두 데이터의 분포를 계산한다\r\n    histP, binsP = np.histogram(P, bins=100)\r\n    histQ, binsQ = np.histogram(Q, bins=binsP)\r\n    \r\n    # 두 분포를 pdf로 만들기 위해 normalization한다.\r\n    histP = histP / (np.sum(histP) + 1e-8)\r\n    histQ = histQ / (np.sum(histQ) + 1e-8)\r\n\r\n    # KL divergence를 계산한다\r\n    kld = np.sum(histP * (np.log(histP + 1e-8) - np.log(histQ + 1e-8)))\r\n    return kld\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### plt\r\n\r\n```python\r\n# real data 분포 (p)와 fake data 분포 (q)를 그려본다\r\nz = getNoise(m=realData.shape[0], n=nGInput)\r\nfakeData = Generator.predict(z)\r\n\r\nplt.figure(figsize=(8, 5))\r\nsns.set_style('whitegrid')\r\nsns.kdeplot(realData[:, 0], color='blue', bw=0.3, label='Real')\r\nsns.kdeplot(fakeData[:, 0], color='red', bw=0.3, label='Fake')\r\nplt.legend()\r\nplt.title('Distibution of real and fake data')\r\nplt.show()\r\n```\r\n\r\n\r\n\r\n![image-20200809130155797](markdown-images/image-20200809130155797.png)\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n------\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n## CNN GAN (DCGAN) CODE\r\n\r\n</br>\r\n\r\n* 사용한 함수 총 5개:</br>\r\n\r\n  1. def build_generator(inputs, image_size)</br>\r\n\r\n  2. def build_discriminator(inputs)</br>\r\n\r\n  3. def train(models, x_train, params)</br>\r\n\r\n  4. def build_and_train_models(load_W = False, train_steps = 100)</br>\r\n\r\n  5. def plot_images():</br>\r\n\r\n</br>\r\n\r\n![image-20200809130207635](markdown-images/image-20200809130207635.png)\r\n\r\n</br>\r\n\r\n#### Base\r\n\r\n```python\r\n# load MNIST dataset\r\n(x_train, _), (_, _) = mnist.load_data()\r\n\"\"\" 비지도 방법으로 사용 \"\"\"\r\n\r\n# reshape data for CNN as (28, 28, 1) and normalize \r\n\"\"\" 2D CNN \"\"\"\r\nimage_size = x_train.shape[1] # x_train.shape (60000, 28, 28)\r\nx_train = np.reshape(x_train, [-1, image_size, image_size, 1]) # x_train.shape = (60000, 28, 28, 1)\r\nx_train = x_train.astype('float32') / 255 # 표준화\r\n\r\n# the latent or z vector is 100-dim\r\nlatent_size = 100 #latent: KNN 가기 전 층들\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 1. build_generator\r\n\r\n```python\r\ndef build_generator(inputs, image_size): # latent 층에 씀 \r\n    image_resize = image_size // 4\r\n    \r\n    # network parameters \r\n    kernel_size = 5\r\n    layer_filters = [128, 64, 32, 1]\r\n\r\n    x = Dense(image_resize * image_resize * layer_filters[0])(inputs)\r\n    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\r\n\r\n    for filters in layer_filters: # hidden 층을 for문으로 써줌(쫙 쌓아주는 것)\r\n        # first two convolution layers use strides = 2\r\n        # the last two use strides = 1\r\n        if filters > layer_filters[-2]:\r\n            strides = 2 # 따라서 layer_filters의 뒤에서 2번째까진 strides = 2\r\n        else:\r\n            strides = 1\r\n        x = BatchNormalization()(x)\r\n        x = Activation('relu')(x)\r\n        x = Conv2DTranspose(filters=filters,\r\n                            kernel_size=kernel_size,\r\n                            strides=strides,\r\n                            padding='same')(x) # data 양 뿔려줌 \r\n\r\n    x = Activation('sigmoid')(x)\r\n    generator = Model(inputs, x, name='generator') # 모방 모델이므로 y 자리엔 x 학습 결과를 써줌 \r\n    return generator # 요렇게 fake data 만들어서 전에 모델처럼 Discriminator에 넣어줌 \r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 2. build_discriminator\r\n\r\n```python\r\ndef build_discriminator(inputs):\r\n    kernel_size = 5\r\n    layer_filters = [32, 64, 128, 256]\r\n\r\n    x = inputs\r\n    for filters in layer_filters:\r\n        # first 3 convolution layers use strides = 2\r\n        # last one uses strides = 1\r\n        # 따라서 Discriminator를 더 많이 학습하게 됨 \r\n        if filters == layer_filters[-1]:\r\n            strides = 1\r\n        else:\r\n            strides = 2\r\n        x = LeakyReLU(alpha=0.2)(x)\r\n        x = Conv2D(filters=filters,\r\n                   kernel_size=kernel_size,\r\n                   strides=strides,\r\n                   padding='same')(x)\r\n\r\n    x = Flatten()(x)\r\n    x = Dense(1)(x)\r\n    x = Activation('sigmoid')(x)\r\n    discriminator = Model(inputs, x, name='discriminator')\r\n    return discriminator\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 3. build_and_train_models\r\n\r\n```python\r\ndef build_and_train_models(load_W = False, train_steps = 100):\r\n    model_name = \"dcgan_mnist\"\r\n    \r\n    # network parameters\r\n    batch_size = 64\r\n    lr = 2e-4\r\n    decay = 6e-8\r\n    input_shape = (image_size, image_size, 1)\r\n\r\n    # build discriminator model\r\n    inputs = Input(shape=input_shape, name='discriminator_input')\r\n    discriminator = build_discriminator(inputs)\r\n    \r\n    # [1] or original paper uses Adam, \r\n    # but discriminator converges easily with RMSprop\r\n    optimizer = RMSprop(lr=lr, decay=decay)\r\n    discriminator.compile(loss='binary_crossentropy',\r\n                          optimizer=optimizer,\r\n                          metrics=['accuracy'])\r\n    discriminator.summary()\r\n    \r\n    # 저장된 discriminator 모델을 읽어온다.\r\n    if load_W:\r\n        discriminator.load_weights(\"dataset/dcgan_D.h5\")\r\n\r\n    # build generator model\r\n    input_shape = (latent_size, )\r\n    inputs = Input(shape=input_shape, name='z_input')\r\n    generator = build_generator(inputs, image_size)\r\n    generator.summary()\r\n\r\n    # 저장된 generator 모델을 읽어온다.\r\n    if load_W:\r\n        generator.load_weights(\"dataset/dcgan_G.h5\")\r\n        \r\n    # build adversarial model\r\n    optimizer = RMSprop(lr=lr * 0.5, decay=decay * 0.5)\r\n    \r\n    # freeze the weights of discriminator during adversarial training\r\n    discriminator.trainable = False\r\n    \r\n    # adversarial = generator + discriminator\r\n    adversarial = Model(inputs, \r\n                        discriminator(generator(inputs)),\r\n                        name=model_name)\r\n    adversarial.compile(loss='binary_crossentropy',\r\n                        optimizer=optimizer,\r\n                        metrics=['accuracy'])\r\n    adversarial.summary() #adversarial: 최종모델\r\n\r\n    # train discriminator and adversarial networks\r\n    models = (generator, discriminator, adversarial)\r\n    params = (batch_size, latent_size, train_steps, model_name)\r\n    train(models, x_train, params)\r\n    \r\n    # 모델을 저장해 둔다\r\n    discriminator.save_weights(\"dataset/dcgan_D.h5\")\r\n    generator.save_weights(\"dataset/dcgan_G.h5\")\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 4. train\r\n\r\n```python\r\ndef train(models, x_train, params):\r\n    # the GAN component models\r\n    generator, discriminator, adversarial = models \r\n    \r\n    \r\n    # network parameters\r\n    batch_size, latent_size, train_steps, model_name = params \r\n    \r\n    \r\n    # number of elements in train dataset\r\n    train_size = x_train.shape[0]\r\n    for i in range(train_steps):\r\n        # train the discriminator for 1 batch\r\n        # 1 batch of real (label=1.0) and fake images (label=0.0)\r\n        # randomly pick real images from dataset\r\n        rand_indexes = np.random.randint(0, train_size, size=batch_size)\r\n        real_images = x_train[rand_indexes]\r\n        \r\n        # generate fake images from noise using generator \r\n        # generate noise using uniform distribution(모든 확률변수에 대해 균일한 확률을 가짐)\r\n        noise = np.random.uniform(-1.0,\r\n                                  1.0,\r\n                                  size=[batch_size, latent_size])\r\n        # generate fake images\r\n        fake_images = generator.predict(noise)\r\n        \r\n        # real + fake images = 1 batch of train data\r\n        x = np.concatenate((real_images, fake_images))\r\n        \r\n        # label real and fake images\r\n        # real images label is 1.0\r\n        y = np.ones([2 * batch_size, 1])\r\n        \r\n        # fake images label is 0.0\r\n        y[batch_size:, :] = 0.0\r\n        \r\n        # train discriminator network, log the loss and accuracy\r\n        loss, acc = discriminator.train_on_batch(x, y) \r\n        \"\"\"Q. loss: 인덱스??? \"\"\"\r\n        log = \"%d: [D-loss: %.4f, acc: %.4f]\" % (i, loss, acc)\r\n\r\n        # train the adversarial network for 1 batch\r\n        # 1 batch of fake images with label=1.0\r\n        # since the discriminator weights \r\n        # are frozen in adversarial network(adversarial network: 적대적 신경망(경쟁 속 반대편에 놓인 신경망))\r\n        # only the generator is trained\r\n        # generate noise using uniform distribution\r\n        noise = np.random.uniform(-1.0,\r\n                                  1.0, \r\n                                  size=[batch_size, latent_size])\r\n        \r\n        # label fake images as real or 1.0\r\n        y = np.ones([batch_size, 1])\r\n        # train the adversarial network \r\n        # note that unlike in discriminator training, \r\n        # we do not save the fake images in a variable\r\n        # the fake images go to the discriminator input of the adversarial\r\n        # for classification\r\n        # log the loss and accuracy\r\n        loss, acc = adversarial.train_on_batch(noise, y) \r\n        \"\"\"Q. adversarial 뜻???\"\"\"\r\n        log = \"%s [G-loss: %.4f, acc: %.4f]\" % (log, loss, acc)\r\n        print(log)\r\n   \r\n    # save the model after training the generator\r\n    # the trained generator can be reloaded for \r\n    # future MNIST digit generation\r\n    generator.save(model_name + \".h5\")\r\n\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 5. fake data를 화면에 표시\r\n\r\n```python\r\n# Generator가 생성한 이미지(fake data)를 화면에 표시한다.\r\ndef plot_images():\r\n    inputs = Input(shape=(latent_size, ), name='z_input')\r\n    generator = build_generator(inputs, image_size)\r\n    generator.load_weights(\"dataset/dcgan_G.h5\")\r\n    \r\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\r\n    images = generator.predict(noise_input) # Generator 통해 나온 fake data\r\n    plt.figure(figsize=(6, 6))\r\n    num_images = images.shape[0]\r\n    \r\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\r\n    rows = int(np.sqrt(noise_input.shape[0]))\r\n    for i in range(num_images):\r\n        plt.subplot(rows, rows, i + 1)\r\n        image = np.reshape(images[i], [image _size, image_size]) \r\n        \"\"\"why 3차원 reshape???\"\"\"\r\n        plt.imshow(image, cmap='gray')\r\n        plt.axis('off')\r\n    plt.show()\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### Final\r\n\r\n```python\r\n# 이미 학습된 weights를 읽어오고, 추가로 학습한다.\r\nbuild_and_train_models(load_W = True, train_steps = 10) # train_steps 만큼 반복 학습\r\n\r\n# Generator가 생성한 이미지를 화면에 표시한다.\r\nplot_images()\r\n```\r\n\r\n</br>\r\n\r\n|                                                         |                                                         |\r\n| ------------------------------------------------------- | ------------------------------------------------------- |\r\n| ![image-20200714193936268](image-20200714193936268.png) | ![image-20200714193941200](image-20200714193941200.png) |\r\n\r\n","excerpt":"GAN 1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다. fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등) Discrimi의 loss는 maxlog(Dx) + log…","fields":{"slug":"/GAN_2/"},"frontmatter":{"date":"Aug 08, 2020","title":"GAN 실전 응용","tags":["DL","GAN"],"update":"Aug 08, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n<br>\r\n\r\n`JyneeEarth git blog`\r\n\r\n```batch\r\nML\r\nDL\r\nNLP\r\nContents\r\nJapanese\r\netc \r\n```\r\n\r\n<br>\r\n\r\n안녕하세요.\r\n\r\n이곳엔 다양한 포스팅이 올라옵니다.\r\n\r\n#태그로 동일 관심분야를 검색해주세요.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n> 안하면 모를테고, 하면 늘겠지\r\n\r\n싶은 마음으로 일단 파고들었던 모든 것들을 이곳에 올릴 예정입니다.\r\n\r\n<br>\r\n\r\n*이런 것까지...?* \r\n\r\n> \r\n\r\n이런 것까지... 올라올 거예요.\r\n\r\n<br>\r\n\r\n","excerpt":"안녕하세요. 이곳엔 다양한 포스팅이 올라옵니다. 태그로 동일 관심분야를 검색해주세요. 안하면 모를테고, 하면 늘겠지 싶은 마음으로 일단 파고들었던 모든 것들을 이곳에 올릴 예정입니다. 이런 것까지...?  이런 것까지... 올라올 거예요.","fields":{"slug":"/main/"},"frontmatter":{"date":"Aug 02, 2020","title":"처음 방문했다면 블로그 소개를","tags":["1st"],"update":"Aug 17, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n# pre-training & fine-tuning\r\n\r\n|              | 설명                                                         |\r\n| ------------ | ------------------------------------------------------------ |\r\n| pre-training | Weight와 Bias를 초기화 시키는 방법                           |\r\n| fine-tuning  | 기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적(나의 이미지 데이터에 맞게)변형하고 이미 학습된 모델 Weights로 부터 학습을 업데이트하는 방법 |\r\n\r\n> 출처: 꾸준희. 2017.08.17. \"[Deep Learning] pre-training 과 fine-tuning (파인튜닝)\". https://eehoeskrap.tistory.com/186. Enough is not enough\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# W(weights)\r\n\r\n* 네트워크 및 model build까지 완성해서 실행되어 역전파 되었을 때 형성된다.\r\n* `compile에서 w`: 네트워크 만들고 난 후 model build하는 과정. optimizer & loss 값을 정의해주는 부분임. w는 만들어져있지 않다.\r\n* `fit에서 w`: fit은 train data 사용. A 다음 B가 **나온다고 저장** \r\n* `predict에서 w`: predict(예측)는 test data 사용. 예측 모델 기준으로 A를 넣으면 B가 **나오게 하는** 어떤 것(Thing)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Hyper parameter\r\n\r\n* `weight decay`(annealing): epoch(alpha)를 처음에는 적당히 높게 했다가, 점차 줄여 나가는 방법\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Dense\r\n\r\n* `Dense`: fully connected\r\n\r\n* `ANN(FNN)`에서는 여러 `Dense`를 써도 되지만, `RNN(LSTM)`에선 마지막 층에서만 `Dense`를 써야함.\r\n  * `CNN`에서는 여러 `Dense` 써도 될까?\r\n  * => 일단... `lstm`에서 `lstm() → Dense → lstm()`은 `lstm 네트워크가 2개` 만들어진다고 보면 된다. `lstm() → Dense` 했을 때, `1개의 네트워크`가 형성된 것\r\n  * => 그리고 `CNN`은 일종의 잘 짜여진 레시피라서 `con1D → pooling → Dense → con1D → pooling`은 위 `lstm`처럼 좀 이상한 네트워크 구조가 되는 거라 생각함...\r\n\r\n* Dense(1, activation='sigmoid')\r\n\r\n* **LSTM에서 FNN으로 보내는 마지막 Dense에선 relu 쓰면 안됨**\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# FNN(순방향 신경망)\r\n\r\n* ↔ RNN\r\n\r\n* hidden 층에서\r\n\r\n  * Dense(4, `activation` = 'sigmoid', `kernel_regularizer`=regularizers.l2(0.0001), activation='relu')\r\n  * `Dropout`(rate=0.5)\r\n\r\n* `BatchNormalization`(momentum=0.9, epsilon=0.005, center=True, scale=True, moving_variance_initializer='ones')\r\n\r\n* `predict`까지 끝낸 **연속형** `yHat` 값을, `np.where` 써줘서 **바이너리 형태**로 변환 \r\n\r\n  ``` python\r\n  np.where(yHat > 0.5, 1, 0)\r\n  # 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기_커스텀loss.py\r\n  ```\r\n\r\n* `history` 활용\r\n\r\n  ```python\r\n  hist.history['loss']\r\n  hist.history['val_loss']\r\n  # 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기.py\r\n  ```\r\n\r\n* 학습/평가/예측용 model로 나누었을 때 **평가 데이터 활용**\r\n\r\n  ```python\r\n  model.fit(trainX, trainY, validation_data=(evlX, evlY), epochs=200, batch_size=50)\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# LSTM\r\n\r\n* long term(장기기억, 전체적 흐름), short term(단기기억, 최근의 흐름)\r\n\r\n* |                 | 설명                                                         |\r\n  | --------------- | ------------------------------------------------------------ |\r\n  | 2층             | `lstm()`을 2번 써준다                                        |\r\n  | 양방향          | `bidirectional` + `merge_mode = ‘concat’` <br />FNN, BFN 값을 merge_mode 형태로 합쳐서 list형으로 되돌려줌<br />단방향(FBN)은 ‘이후’만 기억, 양방향(FBN+BFN)은 ‘이전’+’이후’ 모두 기억 |\r\n  | many-to-many    | `return-sequences = True`<br />LSTM 뉴런 **각각의 중간 스텝에서 나오는 각각의 출력(h)**을 (바로 위 뉴런으로도) 사용(전파)한다는 뜻 |\r\n  | timedistributed | `timedistributed()`<br /> **FFN으로 가기 전** LSTM 마지막 층에서 각 뉴런의 각 지점에서 계산한 오류를 다음 층으로 전파 |\r\n\r\n* LSTM이 many-to-many 상태에서 FNN으로 가면 각각의 Output 값이 나온다\r\n\r\n  * NLP의 챗봇, 기계번역 등에서 사용함.\r\n    * Input > 안녕 만나서 반가워\r\n    * Output > 저도 반갑습니다\r\n    * 3개의 출력층. 비어 있는 1개는 padding \r\n    * Q. ... padding은 어디로?\r\n\r\n* LSTM에서 사용되는 h와 c\r\n\r\n  |      | 역할              | 특징                                                  |\r\n  | ---- | ----------------- | ----------------------------------------------------- |\r\n  | h    | **위, 왼쪽** 전파 | LSTM이 1층일 땐 c랑 똑같이 왼쪽으로 밖에 전파 못한다. |\r\n  | c    | **왼쪽** 전파     |                                                       |\r\n\r\n  > h와 c 둘다 처음엔 0으로 시작한다.\r\n\r\n  \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# CNN\r\n\r\n* 이미지를 대표할 수 있는 특성들을 도출해서 FNN에 넣어줌\r\n\r\n* | code                                                         | 설명                                                         |\r\n  | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n  | `Input`(batch_shape = (None, nStep, nFeature, nChannel))     |                                                              |\r\n  | `Conv2D`(filters=30, kernel_size=(8,3), strides=1, padding = 'same', activation='relu') |                                                              |\r\n  | `MaxPooling2D`(pool_size=(2,1), strides=1, padding='valid')  | - 경우에 따라 conv2D, pooling 더 써줄 수 있음<br />- `GlobalMaxPooling1D()`도 있음 |\r\n  | `Flatten()`                                                  | 2D는 4차원이라 shape 맞추려고 보통 flatten을 써줌<br />1d는 안 써도 되는 듯(?) |\r\n  | `Dense`(nOutput, activation='linear')                        |                                                              |\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## LSTM과 CNN의 차이\r\n\r\n* 둘다 (흐름을 보는)시계열 데이터에 사용할 수 있다.\r\n* LSTM과 CNN1D는 기능은 비슷하지만 CNN1D는 table 中 **(colum 전체+n row)아래 방향으로의 흐름**을 보는 거고, \r\n* LSTM은 bidirectional 을 사용해서 table 中 **위/아래로 흐름**을 이동시켜서 볼 수 있다.\r\n* CNN2D는 kernel_size, pooling 등을 통해 tabel 中 **(n colum(일부분) + n row(일부분) = 내가 focus를 맞춰 보고 싶은 부분)에 따라 그 흐름을 볼 수 있다는 데**서 차이가 있다.\r\n\r\n![image-20200805122723206](markdown-images/image-20200805122723206.png)\r\n\r\n\r\n\r\n\r\n\r\n# activation\r\n\r\n* | activation(비선형 함수) | loss                                                         |\r\n  | ----------------------- | ------------------------------------------------------------ |\r\n  | `softmax`               | `sparse_categorical_crossentropy`                            |\r\n  | `sigmoid`               | `binary_crossentropy`                                        |\r\n  | `linear`                | `mse`                                                        |\r\n  | `relu`                  | ← Hidden layer에 씀. 기울기가 0이기 때문에 뉴런이 죽을 수 있는 단점 有 |\r\n  |                         |                                                              |\r\n  | Leakly ReLU             | 뉴런이 죽을 수 있는 현상 해결                                |\r\n  | PReLU                   | x<0 에서 학습 가능                                           |\r\n  | granger causality       | 통제된 상황에서 인과관계가 가능하다고 말할 수 있음. 시계열 데이터에서 쓰일 수 있음 |\r\n\r\n  > * sparse_categorical_crossentropy\r\n  >\r\n  > ```python\r\n  > model = Model([encoderX, decoderX], outputY)\r\n  > model.compile(optimizer=optimizers.Adam(lr=0.001), loss='sparse_categorical_crossentropy')\r\n  > ```\r\n  >\r\n  > * sparse 안 쓸 거면 위에 'outputY'를 to_categorical()로 변형 후, loss 함수로 \"categorical_crossentropy\" 사용\r\n\r\n    > * target이 one-hot encoding되어 있으면 categorical_crossentropy,\r\n    >   target이 integer로 되어 있으면 sparse_categorical_crossentropy를 쓴다.\r\n    >   sparse_categorical_entropy는 integer인 target을 one-hot으로 바꾼 후에 categorical_entropy를 수행한다.\r\n\r\n* 딥러닝 네트워크(DN)의 노드는 입력값을 전부 더한 후, 활성화 함수(Activation function)를 통과시켜 다음 노드에 전달한다.\r\n\r\n  * 이때 사용하는 활성화 함수는 비선형 함수를 쓴다. \r\n\r\n\r\n\r\n\r\n\r\n## softmax - sigmoid\r\n\r\n| 구분           | 함수                           | code                                                         |\r\n| -------------- | ------------------------------ | ------------------------------------------------------------ |\r\n| 회귀           | 항등함수(출력값을 그대로 반환) |                                                              |\r\n| 분류(0/1)      | sigmoid                        | # 시험 데이터로 학습 성능을 평가한다<br/>predicted = model.predict(test_input)<br/>test_pred = np.where(predicted > 0.5, 1, 0)<br/>accuracy = (test_label == test_pred).mean() |\r\n| 분류(multiple) | softmax                        |                                                              |\r\n\r\n>  Cross-Entropy : 예측한 값과 실제값의 차를 계산. entropy 값이 감소하는 방향으로 진행하다 보면 최저 값을 찾을 수 있다. \r\n>\r\n>  * 출처: sshkim Sh.TK. 2017. 8. 23. \"[모두의딥러닝] Softmax Regression (Multinomial Logistic Regression)\". \"https://sshkim.tistory.com/146\"\r\n\r\n>  argmax 을 사용하면 2라는 값이 나온다. 가장 큰 값의 위치가 2번째에 있는 1이기 때문\r\n>\r\n>  * 출처: JINSOL KIM. 2017. 12. 24. \"Softmax vs Sigmoid\". https://blog.naver.com/infoefficien/221170205067\r\n\r\n\r\n\r\n\r\n\r\n## ReLu\r\n\r\n* 히든층에 자주 쓰임\r\n\r\n* 그냥 CNN이든 LSTM이든 출력층 Dense에 Relu 쓰지 말자\r\n\r\n  * LSTM에선 Relu 안 쓰는 게 좋음. 특히 출력층엔 쓰면 안 됨.\r\n\r\n  \r\n\r\n\r\n\r\n\r\n\r\n------------------\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# 학습(compile), 예측(predict)\r\n\r\n\r\n\r\n## optimizer\r\n\r\n* | 종류(빈도순)               |\r\n  | -------------------------- |\r\n  | `adam`                     |\r\n  | Adadelta, RMSprop, Adagrad |\r\n  | `momentum`                 |\r\n  | GD, NAG                    |\r\n\r\n* 최적화가 잘 안 되면 글로벌 minmun을 찾지 못하고 로컬 minimum에 빠진다. 이때 로컬 minimum을 **어떻게 빨리** 탈출할 수 있을지 U턴 메소드를 쓸지, 다른 1차 미분방법(GD)를 쓸 지 결정하게 된다. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## epoch\r\n\r\n* `epoch` 수치가 커지면 `optimizer`가 일을 해서 local이 아닌 global을 찾아간다.\r\n* 그런데 너무 크면 overfitting\r\n* 따라서 적당한 `epoch` 설정이 필요 \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## Batch_size\r\n\r\n* data가 크면 `batch_size`도 크게\r\n  * 25,000개의 raw data라면 `batch_size` = 20 보다 300 이 정도로 설정\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n-----------------------\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# NLP & DL\r\n\r\n\r\n\r\n## SGNS\r\n\r\n| 용어          | 설명                      | CODE                                | 참고                             |\r\n| ------------- | ------------------------- | ----------------------------------- | -------------------------------- |\r\n| pre-trained   | SGNS에서 학습한 We를 적용 | model.layers[1]**.set_weights**(We) | 해당 code 적용 후 model fit 진행 |\r\n| fine-training |                           |                                     |                                  |\r\n\r\n\r\n\r\n* SGNS에 모델 학습(fit) 시, 학습을 따로 시키는 이유?\r\n\r\n  ```python\r\n  # 학습\r\n  hist = model.fit([X[:, 0], X[:, 1]], X[:, 2], \r\n                   batch_size=BATCH_SIZE,\r\n                   epochs=NUM_EPOCHS)\r\n  ```\r\n\r\n  > *  각기 연결된 가중치 선이 구분되어 있기 때문에\r\n\r\n\r\n\r\n* SGNS 모델 만들 때 dot을 한다면, \r\n\r\n  1. **axis=2**    *@2*\r\n\r\n     → 후에\r\n\r\n  2. reshape**(())**    *@괄호 두 개*\r\n\r\n\r\n\r\n* SGNS로 만든 Embedding의 w(가중치)를 basic한 word data에 적용할 때, load_weights 사용하는 방법도 있다.\r\n\r\n  * 근데 이땐 shape을 맞춰줘야 한다.\r\n\r\n  ```python\r\n  w = encoder.load_weights('model_w.h5') # 가중치(w) 불러온 후,\r\n  emb = Embedding(max_features, embedding_dims, load_weights = w)(xInput) # embedding layer에 바로 적용\r\n  ```\r\n\r\n  * 보통 이런 느낌으로 씀\r\n\r\n    ```python\r\n    weights = load_weights()\r\n    embedding_layer = Embedding(input_dim=V,\r\n                                output_dim=embedding_dim,\r\n                                input_length=input_length,\r\n                                trainable=False,\r\n                                weights=weights,\r\n                                name='embedding')\r\n    ```\r\n\r\n    \r\n\r\n\r\n\r\n## Embedding & pad_sequences\r\n\r\n\r\n\r\n### word2vec 기준\r\n\r\n* | word2vec      | code                                                         | input                                      | output                                     |\r\n| ------------- | ------------------------------------------------------------ | ------------------------------------------ | ------------------------------------------ |\r\n| tokenizer     | tokenizer = Tokenizer()<br />tokenizer.fit_on_texts(clean_train_review)<br />train_sequences = tokenizer.texts_to_sequences(clean_train_review) | [안녕, 만나서, 반가워]                     | [13, 4, 3]                                 |\r\n| pad_sequences | train_inputs = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post') | [13, 4, 3]                                 | ([0,0...1,..],[0,0,0,1,0,...],[0,0,1,...]) |\r\n| Embedding     | embedding_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE) | ([0,0...1,..],[0,0,0,1,0,...],[0,0,1,...]) | [0,0...1,..] -> ANN layer                  |\r\n\r\n    > embedding_layer 는 결국 pad_sequence된 단어들끼리 모임. 즉, 1개 문장에 대한 임베딩 행렬이 됨 \r\n    >\r\n    > 1개 단어 = 1개 임베딩 레이어=벡터값\r\n\r\n\r\n\r\n\r\n\r\n### doc2vec 기준\r\n\r\n* | doc2vec        | code                                                         | input                                                        | output                                                       |\r\n| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| TaggedDocument | documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)] | [...,'laughabl', 'horror'], ...]                             | TaggedDocument(words=['move', 'last', ... 'horror'], tags=[999]) |\r\n| Embedding      | model = Doc2Vec(vector_size=300, alpha=0.025, min_alpha=0.00025, min_count=10, workers=4, dm =1) | TaggedDocument(words=['move', 'last', ... 'horror'], tags=[999]) | [벡터값]                                                     |\r\n\r\n    > tags=[999] : 999번 째 문장\r\n    >\r\n    > Embedding은 model.build_vocab, model.train 거치면 한 문장에 대한 하나의 벡터가 나온다.\r\n    >\r\n    > (word2vec의 경우 한 문장에 있는 각각의 단어 수만큼 벡터가 나온다.)\r\n    >\r\n    > 1개 문장 = 1개 임베딩 레이어 = 1개 벡터값\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n----------------------\r\n\r\n\r\n\r\n\r\n\r\n# ChatBot\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## Sequence to Sequence\r\n\r\n| encoder | decoder | 가능/불가능 |\r\n| ------- | ------- | ----------- |\r\n| 1층     | 2층     | *불가능*    |\r\n| 1층     | 1층     | 가능        |\r\n| 2층     | 1층     | 가능        |\r\n| 2층     | 2층     | 가능        |\r\n\r\n> \"굳이 2층으로 할 필요가 있는가?\"\r\n>\r\n> → 1층으로 하는 건 선형의 개념. 2층은 비선형의 개념이다.\r\n>\r\n> 비선형이 분류를 더 잘해낼 수도 있지만, overfitting의 위험이 있다. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n-----------\r\n\r\n\r\n\r\n\r\n\r\n# 기타\r\n\r\n\r\n\r\n## 유클리디안 거리\r\n\r\n* 거리 계산할 때, 비교하고 싶은 건 `[]`를 쳐서 넣어주기  \r\n\r\n  ```python\r\n  euclidean_distances([father, mother])\r\n  ```\r\n\r\n\r\n\r\n## 가중치 저장(Save)\r\n\r\n* Embedding (left side) layer의 W를 저장할 때, [2]를 저장한단 사실 알아두기\r\n\r\n  ```python\r\n  with open('data/embedding_W.pickle', 'wb') as f:\r\n      pickle.dump(model.layers[2].get_weights(), f, pickle.HIGHEST_PROTOCOL)\r\n  ```\r\n\r\n\r\n\r\n## 영역별 code & 논문 참고하기 좋은 site\r\n\r\n* SOTA site\r\n\r\n  https://paperswithcode.com/sota","excerpt":"pre-training & fine-tuning  설명 pre-training Weight와 Bias를 초기화 시키는 방법 fine-tuning…","fields":{"slug":"/TQT(The question I asked the teacher today.)/"},"frontmatter":{"date":"Aug 01, 2020","title":"TQT(The question I asked the teacher today)","tags":["TQT"],"update":"Aug 06, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# 딥러닝 DL\r\n\r\n* RNN\r\n* CNN\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 순환 신경망(RNN)\r\n\r\n* hidden 층에서 서로 값을 기억해 순환한다.\r\n* 지금까진 FNN(feed forward neword) + 순서가 필요 없는 data를 써서 모델이 기억할 필요가 없었지만, 문장 같은 data를 쓸 땐 **순서가 중요한 data(Sequence Data)를 가지고 미래를 예측해야 한다.**\r\n* 학습(트레이닝) 방법: 순서가 있는 data를 모델이 ‘기억’하게 만드는 것\r\n* RNN 기본 입력은 3d 형태. D1=time, d2=feature, d0=data\r\n* RNN 문제점: 기울기 소실 문제(vanishing gradient)가 FFN보다 더 심해짐\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n### LSTM\r\n\r\n* RNN의 vanishing gradient 해결을 위해 고안. C 추가\r\n\r\n- f와 i의 가중평균 형태\r\n\r\n  ```batch\r\n  f: forget date. 이전의 C를 얼마나 반영할 것인지 조절\r\n  i: input or ignore. 현재 입력값(x)과 이전의 출력값(h)를 얼마나 반영할 것인지 조절\r\n  \r\n  * h는 위, 왼쪽 / c는 왼쪽으로 전파. 둘다 처음엔 0으로 시작함\r\n  ```\r\n\r\n* GRU: LSTM 구조를 간결하게 만듦. 속도도 더 빠르지만 성능도 안 떨어짐 \r\n\r\n* 학습 유형: 단방향(FNN,BFN) / 양방향(FNN+BFN) 모두 적용 가능.\r\n\r\n  ![image-20200816004535796](markdown-images/image-20200816004535796.png)\r\n\r\n  1. Many to one: 둘다 정보량이 TIME이 증가할수록 높아진다. 따라서 높은 정보량끼리 마지막에 합친다\r\n\r\n  2. Many to many\r\n\r\n     * FNN 정보량이 TIME이 증가할수록 높아진다. \r\n\r\n       BFN 정보량이 TIME이 증가할수록 낮아진다.\r\n\r\n       따라서 각 뉴런에서 latent layer로 이어지는 정보량(마지막에 FNN정보량+BFN정보량)은 같다\r\n\r\n  3. One to many\r\n\r\n  4. Many to many\r\n\r\n* 단방향은 ‘이후’만 기억, 양방향은 ‘이전’+’이후’ 모두 기억\r\n  \r\n  * 어떻게? 단방향은 FBN만 사용, 양방향은 FBN+BFN 사용하기 떄문.\r\n  \r\n* 양방향(FNN+BFN) 진행 순서: \r\n  1. 모델(code)에서(RNN층 내) FNN 진행 후 정보량 모아두고, \r\n  2. BFN 진행 후 정보량 모아두고,\r\n  3. CONCAT(합침)해서 \r\n  4. error를 역전파 시킴 \r\n\r\n* FNN VS BFN:\r\n\r\n  * FNN : TIME이 낮->높\r\n  * BFN : TIME이 높->낮\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n\r\n## CNN\r\n\r\n* 사람의 시각인지 과정을 모방해서 피드포워드 신경망에 추가\r\n  * 이미지를 분류한다 치면, 이미지의 부분적 특성에 주목해 분류하여 FFN에 넣는 것 \r\n    \r\n  * 이미지 분석에 활용: 이미지를 대표할 수 있는 특성들을 도출해서 신경망에 넣어준다.\r\n    \r\n      <br>\r\n  \r\n* 순서 \r\n\r\n  특성 추출 → 클래스 분류 \r\n  → **컨볼루션** 또는 필터링 과정 \r\n  → **특성지도** 출력 \r\n  → 서브샘플링(subsampling) 또는 **풀링**(pooling) \r\n  → 다시 컨볼루션, 활성화, 서브샘플링을 수행 \r\n  → 최종 특성지도는 피드포워드 신경망에 입력되어 분류 작업을 시행\r\n\r\n  ```batch\r\n  컨볼루션: \r\n  image data의 경우\r\n  → filter(kernel: image data와의 convolution(cross-correlation) 진행) \r\n  → feature map 생성(기호에 따라 zero padding, ReLU와 같은 활성함수 적용 가능)\r\n  → (max/mean) pooling \r\n  → feature map 생성(출력) \r\n  → flatten(: 1D구조로 만듦) \r\n  → FNN\r\n  ```\r\n\r\n<br>\r\n\r\n1. 입력된 이미지로부터 이미지의 고유한 특징을 부각시킨 특성지도(feature map)를 새로 만듦\r\n2. 그 이미지는 피드포워드 신경망에 입력되어 이미지가 어떤 클래스 라벨에 속하는지 분류\r\n3. 학습: (grid serch) 수평 엣지 필터, 수직 엣지 필터 컨볼루션\r\n4. ReLU와 같은 활성함수를 거쳐 특성지도 출력\r\n5. 서브샘플링(subsampling) 또는 풀링(pooling) 통해 활성화된 특성지도들의 크기를 줄임\r\n6. (저차원적인 특성부터 시작해서 고차원적인 특성을 도출)이 특성지도들에 다시 컨볼루션, 활성화, 서브샘플링을 수행하여 로컬한 특성지도로부터 글로벌한 특성지도를 만들어간다.\r\n7. 이 과정을 여러번 반복하여 얻어진 최종 특성지도는 fully-connected layer, 즉 피드포워드 신경망에 입력되어 분류 작업을 시행\r\n\r\n<br>\r\n\r\n* 용어\r\n  * `feature map`: 이미지의 부분적 특징을 모아놓은 것의 집합\r\n  * `padding`:\r\n  * `convolution layer`: convolution(cross-correlation) 진행되는 곳 \r\n  * `upsampling`: pooling layer와 달리 차원을 줄이는 게 아니라 차원을 늘림. Autoencoder의 decoder와 같은 곳에서 원래 데이터로 복원할 때 사용됨. Zero padding은 가생이를 0으로 채우는데 sampling은 무슨 계산을 해서 채우는 듯하다.  \r\n\r\n<br>\r\n\r\n### 코딩 용어 설명\r\n\r\n* 컨볼루션 레이어 단계\r\n  * `Filters`: 출력 모양의 깊이(depth) 를 결정\r\n  \r\n  * `kernel_size`: \r\n    1. w(연결선, 가중치)이자, filter의 size.\r\n    2. 연산을 수행할 때 윈도우의 크기\r\n       * 2D에서 kernel_size=(8,1)이면 8행+1열(이때 1열은 feature)\r\n       * 1D에서 kernel_sizw=8이면 자동 8행+전체열(1D에서 필터는 아래 방향으로 밖에 이동 못함)\r\n    \r\n  * `strides`: 필터 적용 시 한 번에 얼마나 움직일지(이동 크기) 이동할 칸 수. 보통 1을 씀. \r\n  \r\n  * `padding`: \r\n     컨볼루션 레이어(합성곱) 혹은 풀링 연산을 수행하는 레이어에 파라미터로 설정\r\n     convolution과 pooling 연산은 파라미터의 수를 줄여나가는 과정이다. 하지만 이러한 과정에서 지나치게 데이터가 축소되어 정보가 소실되는 것을 방지하기 위해 데이터에 0으로 이루어진 패딩을 주는 경우가 있다.\r\n    1. `padding = 'same'`: 원본 사이즈 유지시킴(차원 유지)\r\n      * 원리: 필터의 사이즈가 k이면 사방으로 k/2 만큼의 패딩을 준다.\r\n    2. `padding = 'valid'`: 패딩 사용하지 않음 \r\n    \r\n  * `activation: ‘ReLu’`가 default. CNN에선 ReLu 사용을 권장한다고 함 \r\n  \r\n     <br>\r\n  \r\n* `pooling` 단계\r\n  * 원본이미지에서 특징 추출해서 feature map의 크기를 줄여주는 과정. \r\n  * (1) Max pooling, (2) mean pooling이 있음 \r\n  * pool_size: strides가 미리 설정되지 않을 경우 pool_size와 동일하게 설정된다. \r\n* strides\r\n  * padding:  ‘원본’(사이즈)을 조정. filter를 거치면 이미지 사이즈가 원본과 달리 작아지는데, 이를 피하기 위해 작아지는 사이즈가 원본 사이즈만큼 되도록 원본 사이즈 크기를 늘림. 이때, Zero padding 기법을 사용. 수치(?)가 없는 부분 즉, 가생이(모서리)을 ‘0’으로 채움(가생이 아니고 중간 부분 채워도 zero-padding)\r\n  \r\n* `fatten` 단계\r\n  \r\n* Flatten\r\n  \r\n* `output` 단계\r\n  \r\n  * Dense(n, activation = )\r\n\r\n <br>\r\n\r\n <br>\r\n\r\n## 차원 참고\r\n\r\n* 1차원 벡터: shape(2,)\r\n* 2차원 Matrix : shape(행,열)\r\n* 3차원: shape(면, 행, 열) = D0, D1, D2\r\n* 4차원: shape (samples, rows, cols, channels) = D0, D1, D2 ,D3 \r\n\r\n <br>\r\n\r\n<br>\r\n\r\n <br>\r\n\r\n> 참고: \r\n>\r\n> * 아마퀀트. 2019. 7. 19. \"Keras LSTM** 유형 정리 (2/5) – 단층-단방향 & many-to-many 유형\". http://blog.naver.com/chunjein/221589624838. 아마추어 퀀트 (Amateur Quant).\r\n> * chrisysl. 2018. 9. 10. \"3. Convolutional Networks / L2. Convolutional Neural Networks - Convolutional Layers in Keras\". https://kevinthegrey.tistory.com/141\r\n> * 심교훈. 2019. 3. 1. \"딥러닝 알고리즘의 대세, 컨볼루션 신경망(convolutional neural network, CNN)\". https://bskyvision.com/412?category=635506b. 스카이비전\r\n> * Seongyun Byeon. 2018.01.23. 딥러닝에서 사용되는 여러 유형의 Convolution 소개\". https://zzsza.github.io/data/2018/02/23/introduction-convolution/. 어쩐지 오늘은\r\n>\r\n> \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n ","excerpt":"딥러닝 DL RNN CNN 순환 신경망(RNN) hidden 층에서 서로 값을 기억해 순환한다. 지금까진 FNN(feed forward neword) + 순서가 필요 없는 data를 써서 모델이 기억할 필요가 없었지만, 문장 같은 data…","fields":{"slug":"/딥러닝_2/"},"frontmatter":{"date":"Jul 14, 2020","title":"딥러닝 LSTM&CNN","tags":["ML","LSTM","CNN"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n\r\n\r\n# 딥러닝 DL\r\n\r\n* optimaizer\r\n* kerass\r\n\r\n  \r\n\r\n\r\n\r\n\r\n\r\n## optimizers\r\n\r\n* 이차방정식 계수 추정 방법들:\r\n  1. `SGD`: 움직임\r\n  2. `GD` : 미분해서 움직임\r\n  3. `momentum`: 지수이동평균법으로 움직임\r\n  4. `NAG`: 관성 방향으로 이동 후 그 지점에서 GD 방향으로 움직임 \r\n\r\n \r\n\r\n* 가중치(알파 or lr) 조정 알고리즘\r\n  1. `Adagrad`: 업데이트 多~작은 알파 / 업데이트 小~큰 알파\r\n  2. `RMSprop`: Adagrad에서 반복할수록 과도하게 작아진다는 알파값 보완 \r\n  3. `Adadelta`: RMSprop와 같은데 알파값이 자동조절됨\r\n  4. `Adam`: RMSprop + momentum\r\n\r\n \r\n\r\n\r\n\r\n## Keras\r\n\r\n* Sequential 모델: \r\n\r\n  ```python\r\n  From tensorflow.keras.layes import Dense\r\n  From tensorflow.keras.models import Sequential\r\n  Model = Sequential() #그래프 생성(모델 생성)\r\n  Model.add(Dense(1, input_dim = 2)) #layer(dense), 노드 1개, 그 노드에 2개가 들어온다고 알려줌\r\n  Model.complile(loss=’mse’, optimizer=optimizers.Adam(lr=0.05))\r\n  Model.fit(dataX, y, epochs = 300) #학습\r\n  ```\r\n\r\n  \r\n\r\n* 더 간단한 모델: \r\n\r\n  ```python\r\n  From tensorflow.keras.layes import Input, Dense\r\n  From tensorflow.keras.models import Model\r\n  xInput = Input(batch_shape=(None,2)) #그래프 생성(모델 생성)\r\n  yInput = Dense(1)(xInput)\r\n  model = Model(xInput, yOutput) #xinput 들어가서 yinput나오는 model\r\n  model.complie(loss=’mse’, optimizer=optimizers.Adam(lr=0.05))\r\n  model.fit(dataX,y,epochs=300) #학습\r\n  ```\r\n\r\n \r\n\r\n* 잔차 계산 방법들:\r\n\r\n  1. Stochastic GD update: 그때그때 error 계산, a, b, c 업데이트\r\n  2. Batch update: 한꺼번에 error 계산하고 a, b , c 업뎃\r\n  3. Mini-batch update: 일부 error 계산하고 그때마다 a, b, c 를 업데이트. Stochastic GD update, Batch update의 중간 특성\r\n\r\n  \r\n\r\n* Model 의 기본적인 code:\r\n  * `.fit` : train data를 만들어둔 model로 학습시킴\r\n  * `.predict`: test data를 만들어둔 model로 궁예해봄\r\n\r\n \r\n\r\n \r\n\r\n ","excerpt":"딥러닝 DL optimaizer kerass optimizers 이차방정식 계수 추정 방법들: : 움직임  : 미분해서 움직임 : 지수이동평균법으로 움직임 : 관성 방향으로 이동 후 그 지점에서 GD 방향으로 움직임  가중치(알파 or lr…","fields":{"slug":"/딥러닝_1/"},"frontmatter":{"date":"Jul 03, 2020","title":"딥러닝 기초","tags":["DL"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n\r\n# 머신러닝(ML)\r\n\r\n- K-Means 클러스터링\r\n\r\n- H-clustering\r\n\r\n- DBSAN\r\n\r\n- 앙상블\r\n\r\n- 연관규칙 분석\r\n\r\n  <br>\r\n\r\n<br>\r\n\r\n\r\n\r\n\r\n\r\n## **k-means** 클러스터링\r\n\r\n```python\r\nGrid search: \r\n    Init = ‘k-means++’\r\n    n_init=3\r\n    max_iter=300\r\n    tol=le-04\r\n    random_state=0\r\n```\r\n\r\n<br>\r\n\r\n* 비지도학습\r\n  \r\n* 비계층적 군집분석\r\n  \r\n* k-means 클러스터링은 데이터를 k개의 클러스터(cluster, 무리)로 분류\r\n  \r\n  <br>\r\n  \r\n* `EM알고리즘`: 중점을 할당한 후, 각 중점까지의 거리의 합을 최소화하는 알고리즘\r\n\r\n* 알고리즘(작동 원리):\r\n  1. 사용자로부터 입력받은 k의 값에 따라, 임의로 클러스터 중심(centroid) k개를 설정해준다.\r\n  \r\n  2. k개의 클러스터 중심으로부터 모든 데이터가 얼마나 떨어져 있는지 계산한 후에, 가장 가까운 클러스터 중심을 각 데이터의 클러스터로 정해준다. \r\n  \r\n  3. 각 클러스터에 속하는 데이터들의 **평균**을 계산함으로 클러스터 중심을 **옮겨준다**. \r\n\r\n  4. 보정된 클러스터 중심을 기준으로 2, 3단계를 반복한다.\r\n  \r\n  5. 더이상 클러스터 중심이 이동하지 않으면 알고리즘을 종료한다. \r\n  \r\n     <br>\r\n  \r\n* new data 입력(발생) 시엔 각 중점과의 거리만 비교해서 가장 가까운 곳에 있는 군집에 속한다고 파악\r\n\r\n* 초기값에 따라 전역이 아닌 지역 최소 값을 찾을 수 있음\r\n\r\n* r에 따라 {0,1} 이면 명목형, 확률이면 연속형(GMM 모델)\r\n\r\n\r\n<br>\r\n\r\n* 적합한 k 개수를 찾고 검증하는 모델들\r\n\r\n### K-Means Elbow Method\r\n\r\n* “k는 얼마가 적합할까?” 적합한 k개수 찾는 성격인 듯하다.\r\n\r\n* Grid search: \r\n  1. n_clusters 조절\r\n  2. error: 군집 속 중점과의 거리의 합 <- 이라고 개념을 설정해두고(왜냐면 k-means는 비지도학습이라 정답이 없어서 label이나 target, class 등이 없어서 확인 못함) 군집화가 잘 된 경우라면 error가 작을 것.\r\n* 따라서 k가 증가할 때 줄어드는 ‘폭’이 작아지는 지점의 k값이 최적 군집 개수\r\n* 거리의 합 != 거리가 줄어드는 폭.\r\n* 엘보우는 거리가 줄어드는 폭을 봄\r\n\r\n <br>\r\n\r\n### 실루엣(Silhouette)\r\n\r\n* “군집화가 잘 됐나?” <- 약간 검증하는 성격인 듯하다.\r\n* 잘 된 군집화: \r\n  1. 군집 간 거리(b) > 군집 내 거리(a) \r\n  2. cohesion(응집도:군집 내) < separation(분리도:군집 간) \r\n\r\n* 실루엣 계수는 원형 군집이 아닌 경우 잘 맞지 않음\r\n\r\n* 0~1값을 가짐\r\n\r\n <br>\r\n\r\n## K-Means++군집(clustering)\r\n\r\n* local optimum 해결 위해 초기 중점을 좀 더 합리적으로 설정하는 방법\r\n\r\n <br>\r\n\r\n <br>\r\n\r\n------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## H-clustering\r\n\r\n* 계층적 군집분석\r\n\r\n* 덴드로그램\r\n\r\n* k-menas 와의 차이점:\r\n  * k-means는 **사전에 그룹수(k)** 결정, \r\n  * H-clutering은 한 개의 그룹이 남을 때까지 **그룹을 다 나눈 후** 몇 개 선택할지 두 개의 feature를 갖는 2차원의 덴드로그램으로 결정\r\n\r\n<br>\r\n\r\n <br>\r\n\r\n------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## DBSCAN\r\n\r\n```python\r\nGrid search:\r\n    eps = 0.2 # 앱실론: 특정 ‘반경’\r\n    min_samples=5 # 0.2 반경에 샘플 5개가 있어야 함\r\n    metric = ‘euclidean’\r\n```\r\n\r\n<br>\r\n\r\n* 계층적 군집분석\r\n* 밀집도 기반의 군집 알고리즘: core point(핵심 샘플), border point(경계 샘플), noise point(잡음 샘플)\r\n* noise point는 분류하지 않는다\r\n* K-means or 다른 군집분석과의 차이점: 모든 샘플을 클러스터에 할당하지 않고 잡음 샘플을 구분하는 능력이 있다\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 앙상블 기법\r\n\r\n* 다수의 결과를 예측하여 종합하고 분류함\r\n* 여러 알고리즘을 사용한 후 결과를 종합하여 정확도, 일반화 특성을 증가시킴\r\n* classification_report(~~)\r\n\r\n<br>\r\n\r\n### 배깅(Bagging or Bootstrap Aggregation)\r\n\r\n```python\r\nBaggingClassifier(~~)\r\n* Hyper parameter :\r\n    base_estimatior = m\r\n    n_estimators = 100\r\n    bootstrap = True\r\n* prob += bag.predict_proba(testX)\r\n* predY = np.argmax(prob, axis=1)  # axis=1 하는 이유: 안 하면 하나의 값인 int가 나와서 밑에 testY랑 mean하려면 array 형태로 나와야 함\r\n* accuracy = (testY == predY).mean()\r\n```\r\n\r\n<br>\r\n\r\n* BootStrap(단순복원 임의추출)을 통해 샘플 뽑아내 서브 데이터 만듦\r\n  * 각각의 서브 데이터 크기 = 원본 훈련 데이터 크기 \r\n  * why? 데이터 중복 허용해서 분산(변동)이 감소하고 overfitting 방지\r\n\r\n <br>\r\n\r\n### 부스팅(Boosting): 증폭, 가속. \r\n* 잘못 분류된 데이터에 가중치 두어 다시 뽑고 다시 분류하는 알고리즘\r\n\r\n  1. 서브 훈련 샘플 만듦\r\n\r\n  2. 처음 샘플링은 가중치를 두어 샘플링함 -> 분류 잘못된 데이터는 가중치 높이고 다시 샘플링. 이때 잘못 분류된 패턴이 선택될 확률이 높음. \r\n\r\n     → 분류가 어려운 패턴에 더욱 집중하여 정확도를 높이는 방법\r\n\r\n     <br>\r\n\r\n#### AdaBoost(Adaptive Boosting) \r\n\r\n* **약한 분류기** 사용. 잘못 분류한 데이터 샘플에 가중치를 두어 더 많이 샘플링하여 정확도 높임\r\n\r\n* 서브 데이터로만 만듦(잔차 등으로 만드는 거 아님)\r\n\r\n  ```python\r\n  AdaBoostClassifier(~~)\r\n  Hyper parameter:\r\n      base_estimator=svm\r\n      n_estimators=100 #100번 재조합한단 뜻(오분류한 거에 가중치둬서)\r\n  ```\r\n\r\n<br>\r\n\r\n#### Gradient Boosting(for regression)\r\n\r\n* target 데이터의 **잔차**를 줄이도록 학습. 학습할수록 residual(잔차)가 계속 작아짐. 잔차가 더 이상 줄어들지 않을 떄까지 tree 생성하며 학습+추정치 업데이트\r\n* residual 계산법 : 변수-(평균+학습률(알파. 0~1사이 값. 아무렇게나 줘도 됨. 보통 0.1)*tree의 leaf 평균\r\n* 선형회귀라 dataset도 연속형 변수인 boston 집값을 보도록 한다.\r\n\r\n* 선형회귀라 MSE 대신 r2 사용해도 OK\r\n* MSE: 선형, 로지스틱 회귀 둘다 쓰여도 OK. 다만 선형에선 R2를, 로지스틱에선 BCE(바이너리일 떄) 더 잘 쓰임..(?)\r\n\r\n```python\r\nGradientBoostingRegressor(~~)\r\nHyper parameter:\r\n    Loss = ‘ls’           \t# lest square = MSE 사용\r\n    Learning_rate = 0.1     # 알파. 가중치\r\n    n_estimators = 100      # 잔차(tree) 100개 만들라\r\n    max_depth=3 \t\t\t# 얕은 depth\r\n```\r\n\r\n<br>\r\n\r\n#### Gradient Boosting(for classification)\r\n\r\n* Regression과 동일하나, 추정치를 위해 odds, logs(odds), probability 개념 사용\r\n* binary cross entropy(BCE)를 loss함수로 사용\r\n\r\n```python\r\nGradientBoostingClassifier(~~)\r\nHyper parameter:\r\n    loss = ‘devianve’,      #로지스틱 함수 + CE 쓰라는 뜻\r\n    learning_rate = 0.1,     #학습률, 가중치, 알파값\r\n    n_estimators=100,      #잔차(tree) 수\r\n    max_depth=3 \r\n```\r\n\r\n<br>\r\n\r\n#### XGBoost(Extreme Gradient Boosting)(for regression)\r\n\r\n* 정규화와 가지치기를 통해 \r\n  1. overfitting을 줄이고 \r\n  2. 일반화 특성을 좋게 만듦\r\n  3. 특히 대용량 data의 경우에 속도도 SOSO\r\n* Similarity, output 값 사용: Similarity를 사용해서 잔차와 IG 계산하고 마지막에 output 계산해서 마지막 잔차 계산\r\n* 데이터 大 ~ similarity(유사도) 小 why? 상쇄되는 값이 많아서.\r\n\r\n```py\r\nXGBRegressor(~~)\r\nHyper parameter: \r\n\tObjective =’reg:squarederror’     #regression 사용하고 MSE 사용한단 뜻. regression이니 r2 사용\r\n```\r\n\r\n<br>\r\n\r\n#### **XGBoost(Extreme Gradient Boosting)(for classification)**\r\n\r\n* 잔차 계산 시, output value를 사용한다는 데서 Gradient Boost랑 차이가 있음\r\n\r\n```python\r\nHyper parameter:\r\n(chapter 1) XGBClassifier(~~)\r\n* Objective =’binary:logistic’        #바이너리 변수고 logistic함수(sigmoid) 사용\r\n    \r\n(chapter 2) XGBClassifier(~~)\r\n* Param – {‘eta’ : 0.3, \r\n  ‘max_depth’ : 3, \r\n  ‘objective’ : ‘multi:softprob’      #softmas 사용한단 뜻\r\n  ‘num_class’ : 3 }            \t\t  #클래스 개수\r\n```\r\n\r\n<br>\r\n\r\n### 랜덤포레스트(Random Forest)\r\n\r\n```python\r\nRandomForestClassifier(~~)\r\nHyper parameter:\r\n    max_depth=5\r\n    estimaors=100\r\n```\r\n\r\n<br>\r\n\r\n* DT(Decision Tree)를 앙상블함 \r\n  * 트리마다 서로 다른 feature 사용\r\n* 샘플링 함\r\n\r\n<br>\r\n\r\n### 다수결 알고리즘(Majority Voting)\r\n\r\n* 배깅/부스팅과의 차이점: 학습데이터를 서브data에 sampling 하느냐/안 하느냐\r\n  * 다수결 알고리즘은 배깅/부스팅처럼 서브데이터로 나눈 게 아니라 그 자체를 쓴다.\r\n\r\n<br>\r\n\r\n### Isolation Forest(iForest):\r\n\r\n```python\r\nModel = IsolationForest\r\nHyper parameter:\r\n    n_estimators = 100   #100개의 트리\r\n```\r\n\r\n<br>\r\n\r\n* 이상데이터 검출하는 알고리즘 (ex: 카드 불법 사용에 사용)\r\n\r\n* Keyword: \r\n  * 이진검색트리\r\n  * Anomaly score(이상치 수치)\r\n  * recall, precison 사용\r\n    * 특히 recall 써서 실제 정상(T)인데 비정상(F)으로 예측했다던가, 실제 비정상(F)인데 정상(T)로 예측한 비율 찾아냄\r\n\r\n <br>\r\n\r\n <br>\r\n\r\n------------------\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## 연관규칙 분석\r\n\r\n* 장바구니 분석. 고객들의 구매 성향을 분석할 수 있음\r\n  1. 지지도: y가 독립변수인지 종속변수인지 불명확함\r\n  2. 신뢰도: y에 대한 영향을 무시한단 단점이 있음\r\n  3. 향상도: 1에 가까우면 X와 Y는 서로 독립적. 1보다 크면 양의 상관성, 1보다 작으면 음의 상관성. 리프트가 1보다 클수록 X→Y 규칙의 의미가 커짐\r\n* 지지도/신뢰도/향상도 특징:\r\n  1. 인과관계가 아닌 상관관계\r\n  2. 얼마나 빈번하게 나타나는지 측정\r\n* 이진행렬 구성\r\n* 지/신/향 모두 임계치 이상인 모든 규칙을 찾기엔 Brute Force 방식을 써서 조합이 너무 많아짐. 따라서 이 조합을 줄일 수 있는 알고리즘이 Apriori 알고리즘.\r\n* 항목을 줄이는 게 관건\r\n* 한 항목 집합이 반발하면, 그것의 모든 부분 집합이 반발한단 뜻에서 지지도 기반 가지치기\r\n* 연관성이 높다 = lift가 높다\r\n\r\n```python\r\nHyper parameter:\r\n    Frequent_itemsets = apriori(df, min_support = 0.6, use_columname==True) # Item sparse matrix생성\r\n    rules = association_rules(frequent_itemsets, metric=”lift”, min_threshold=0.7) # 모델 생성\r\n    Rules = association_rules(by=[‘lift]’, axis =0, ascendin=False) # Lift가 작은 것부터 sort\r\n```\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n> 참고: 심교훈. 2019. 10. 9. “가장 간단한 군집 알고리즘, k-means 클러스터링\". https://bskyvision.com/564. b스카이비전\r\n\r\n ","excerpt":"머신러닝(ML) K-Means 클러스터링 H-clustering DBSAN 앙상블 연관규칙 분석 k-means 클러스터링 비지도학습 비계층적 군집분석 k-means 클러스터링은 데이터를 k개의 클러스터(cluster…","fields":{"slug":"/머신러닝_2/"},"frontmatter":{"date":"Jun 30, 2020","title":"머신러닝 분석 방법들, 두 번째","tags":["ML","XGBoost"],"update":"Aug 16, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# 머신러닝(ML)\r\n\r\n- KNN\r\n- Decision Tree\r\n- SVM\r\n- 선형회귀분석\r\n- 로지스틱회귀분석\r\n- 나이브베이지안\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **`차원의 저주`**\r\n\r\n- 차원(feature)이 증가하면 성능이 저하된다\r\n\r\n  - 차원이 증가할수록 말 그대로 ‘근접 이웃’에 한정하기 어려워 멀리 떨어진 데이터를 참조한다\r\n\r\n    → 따라서 데이터 양에 비해 feature의 수가 많으면 차원의 저주 문제를 생각해봐야 한다.\r\n\r\n- 차원의 저주를 벗어날 수 있는 방법:\r\n\r\n  1. 차원 축소(feature 축소)\r\n  2. 데이터 양을 늘림\r\n\r\n- 차원의 저주를 벗어날 수 있는 모델\r\n  1. `중요도 분석`(의사결정나무 – 사전 가지치기)\r\n  2. PCA 주성분 분석\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **`kNN(k-Nearest Neighbor)`**\r\n\r\n```python\r\nModel = `KNeighborsClassifier(~~)`\r\nGrid search:\r\n    n_neighbors=5\r\n    p=2\r\n    meric = ‘minkowski’\r\n```\r\n\r\n- 지도학습\r\n- 테스트 데이터에서 k개의 가장 가까운 이웃을 찾고, 그 이웃들 중 다수가 속한 클래스가 테스트 데이터의 클래스가 되게 한다\r\n  - iris 패키지: “새로운 꽃이 발견됐을 때, 어느 종류(클래스)에 넣는 것이 좋을까?\r\n- `레이지 러닝(lazy learning)`: 미리 학습해 두는 방식이 아니라, test data 추정할 때마다 학습하기 때문에 시간이 오래 걸림\r\n\r\n ![image-20200721074726342](image-20200721074726342.png)\r\n\r\n> 그림 출처: 심교훈. 2019. 10. 8. \"유유상종의 진리를 이용한 분류 모델, kNN(k-Nearest Neighbor)\". https://bskyvision.com/563. b스카이비전\r\n\r\n\r\n\r\n- K 가 작을수록 복잡도 높아짐\r\n\r\n  → 과잉적합\r\n\r\n- K가 증가할수록 정확도가 떨어진다\r\n\r\n- 거리 측정 방법:\r\n\r\n  1. 맨하튼 거리: 가장 심플\r\n  2. 유클리디안 거리: 최단 거리\r\n  3. 민코우스키 거리: 많이 떨어진 성분 부각\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **`결정 트리(Decision Tree)`**\r\n\r\n```python\r\nModel = DecisionTreeClassifier(~~)\r\n- grid search: \r\n    criterion=’gini’\r\n    알파(가중치)\r\n    max_depth=k\r\n    pd.Categorical(income[c]).codes\r\n    dt.feature_importances ← 중요도 분석\r\n    path = `DecisionTreeClassifier().cost_complexity_pruning_path(trainX, trainY)\r\n    ccp_alpha = ccp_alpha\r\n    * 이때 먼저, ccp_alpha = `ccp_alphas[np.where(ccp_alphas > 0.001)]`\r\n    clfs[-1].tree_.node_count / clfs[-1].tree_.max_depth\r\n```\r\n\r\n<br>\r\n\r\n- 지도학습, 비지도학습\r\n\r\n\r\n- 알파값(가중치 조정) 높이기 ~ 오분류율(불순도) 증가\r\n\r\n- 핵심: 변별력이 좋은 질문을 위에서부터 하나하나 세팅\r\n\r\n  <br>\r\n\r\n- Feature가 3개 이상이면 초평면으로 구분\r\n\r\n- Featrue(차원)이 많아져도 덜 중요한 feature는 분류 기준에서 제외되어 feature 선정에 크게 신경 쓸 필요 X\r\n\r\n- **중요한 Feature 확인 가능**\r\n  \r\n  - 중요도 분석\r\n\r\n* Tree 과도하게 분할( = 과잉 적합 = 트리가 복잡) → 아래 노드에 데이터 小 → 데이터 단편화 → 유의미한 결정 내리기 어려움\r\n\r\n  * 즉, Depth 높 ~ 트리 길어짐 ~ 과도하게 분할 ~ overfitting ~ 정확도 낮음\r\n\r\n  * 해결 위해 정지기준 or 사전/사후 가지치기 사용\r\n    * `정지기준`: depth 지정 or 마지막 노드의 데이터 수가 임계치 이하로 떨어지지 않도록 지정\r\n\r\n      * 알파(가중치): depth 조정\r\n\r\n    * `가지치기`: 트리 단순화하여 일반화 특성 향상시키기.\r\n      1. `사전 가지치기`: depth, 마지막 노드의 최소 데이터 수, 불순척도(criterion)\r\n      \r\n      2. `사후 가지치기`: 오분류율, 패널티항, 알파(가중치)\r\n      \r\n         <br>\r\n\r\n* `ID3 알고리즘`: 정보량과 엔트로피 개념 활용\r\n  \r\n* 알고리즘 **순서**: \r\n\r\n  1. 엔트로피 계산량에 의해 엔트로피(E)가 낮고, \r\n  2. 정보획득량(IG)가 높은 선택지를 선택함\r\n\r\n     * 온도 속성은 끝내 결정 노드에 쓰이지 않았다. 4개의 속성 중에 가장 변별력이 낮은 속성이었던 것이다.\r\n\r\n* 불순척도(지니지수, 엔트로피) 작아지도록 분할 기준 선택. 분할 전 부모노드 보다 분할 후 자식노드의 불순척도가 작아지는 게 좋음(IG)\r\n\r\n* `지니지수`: 0~0.5값\r\n  \r\n* **`정보량`**: 어떤 사건이 가지고 있는 정보의 양. 드물게 발생하는 일일수록 정보량이 크다.\r\n  \r\n* **`엔트로피`**(E): 0~1값 정보량의 기댓값(평균). 발생한 사건들의 정보량을 모두 구해서 (가중)평균\r\n  \r\n  * 엔트로피가 크다는 것은 평균정보량이 크다는 것\r\n  \r\n  * 대개 사건들이 일어날 확률이 비슷한 경우에 엔트로피가 크다.\r\n  \r\n  * 따라서 두 사건이 0.5, 0.5 확률로 일어날 때의 엔트로피가 가장 크다\r\n  \r\n    → 즉, **불확실성이** 클수록 엔트로피가 크다\r\n  \r\n    → 불확실성이 크면 클수록 분류하기는 어려워짐\r\n  \r\n    → 엔트로피가 가장 작은 것을 상위 의사결정 노드에 위치시켜야 함.\r\n  \r\n    → 이를 위해 **`정보획득량`**(IG)이란 개념이 필요\r\n  \r\n    \"어떤 속성을 가지고 분류했을 때 가장 엔트로피(불확실성)가 작은지, 정보획득량이 큰지\"\r\n  \r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **`서포트 벡터 머신(SVM)`**\r\n\r\n```python\r\nModel = SVC(~~)\r\ngrid search : \r\n    kernel = ‘linear’\r\n    C\r\n    gamma\r\n    (비선형+multiclassification) kernel = `‘rbf’\r\n     * 파라미터 C는 이상치 또는 오류를 얼마나 허용하는 가(복잡도 조절)를 정해주고, gamma는 결정 경계의 곡률을 결정\r\n        * C: max margin + min 섞임 조절\r\n        * C: 大 ~ 패널티항 大 ~ 거리 짧음\r\n```\r\n\r\n</br>\r\n\r\n* 가장 많이 사용되는 SVM은 radial(방사형) basis function (RBF) 커널을 사용한 SVM\r\n\r\n* SVM은 일반화 특성이 우수\r\n\r\n* >  모델 생성시 특정 옵션을 주어야 `predict_proba`가 사용 가능\r\n  >\r\n  > predict_proba 함수를 가지고 있지만, 모델 생성시 `probalility=True`를 설정하지 않으면 사용할 수 없다.\r\n>\r\n  > 이때, 레이블이 3개 이상인 경우, LinearSVC보단 SVC를 사용하고, probability=True 옵션 주는 것을 추천한다. \r\n  >\r\n  > 출처: https://m.blog.naver.com/cjh226/221358912619)\r\n\r\n<br>\r\n\r\n### **선형 SVM**\r\n\r\n* 데이터를 선형으로 분리하는 최적의 선형 결정 경계를 찾는 알고리즘\r\n  \r\n  * 그 중 가장 간단한 것이 선형 SVM(linear SVM)\r\n  \r\n* SVM 알고리즘의 목표: 클래스가 다른 데이터들을 가장 큰 마진(margin)으로 분리해내는 선 또는 면(결정 경계 또는 분리 초평면)을 찾아내는 것\r\n  * 마진: 두 데이터 군과 결정 경계와 떨어져있는 정도\r\n  * 서포트 벡터: 결정 경계와 가장 먼저 만나는 데이터\r\n  \r\n* SVM의 기본 매개변수인 C\r\n\r\n* cost(C): C는 얼마나 많은 데이터 샘플이 다른 클래스에 놓이는 것을 허용하는지를 결정\r\n  * ex: 작을 수록 많이 허용, 클 수록 적게 허용\r\n  * ex: C값을 낮게 설정하면 이상치들이 있을 가능성을 크게 잡아 일반적인 결정 경계를 찾아내고, 높게 설정하면 반대로 이상치의 존재 가능성을 작게 봐서 좀 더 세심하게 결정 경계를 찾아낸다.\r\n  * ex: \"난 데이터 샘플하나도 잘못 분류할 수 없어!\" : C를 높여야\r\n  * ex: \"몇 개는 놓쳐도 괜찮아, 이상치들이 꽤 있을 수도 있으니까\" : C를 낮춰야\r\n  \r\n* C가 너무 낮으면 과소적합(underfitting)\r\n\r\n* C가 너무 높으면 과대적합(overfitting)\r\n  \r\n  → 적합한 C값을 찾아내는 것이 중요\r\n  \r\n* 하드마진(hard-margin) SVM\r\n\r\n* 소프트마진(soft-margin) SVM\r\n\r\n </br>\r\n\r\n### **RBF 커널 SVM**\r\n\r\n* 커널 기법은 주어진 데이터를 고차원 특징 공간으로 사상해주는 것이다.\r\n\r\n* 3차원 공간에서 분류된 것을 다시 2차원 공간으로 매핑해서 보면 결정 경계가 둥그렇게 보일 것\r\n\r\n* RBF 커널의 경우 gamma라는 매개변수를 사용자가 조정해야 한다.\r\n  * `gamma` : 하나의 데이터 샘플이 영향력을 행사하는 거리를 결정\r\n    * ex: gamma가 클수록 한 데이터 포인터들이 영향력을 행사하는 거리가 짧아지는 반면, 낮을수록 커진다\r\n    * ex: gamma는 가우시안 함수의 표준편차와 관련되어 있는데, 클수록 작은 표준편차를 의미\r\n      * '편차가 크다': 어떤 자료는 평균보다 엄청 크고 어떤 자료는 평균보다 엄청 작다\r\n  \r\n* gamma 매개변수는 결정 경계의 곡률을 조정한다고 말할 수도 있다.\r\n  \r\n  * gamma의 값이 높아짐에 따라 공간이 점점 작아지는데, 위에서 언급한 것과 같이 각각의 데이터 포인터가 영향력을 행사하는 거리가 짧아졌기 때문 <- 아마 정확도가 높아질 듯하다.\r\n  \r\n* 매개변수 C와 마찬가지로 너무 낮으면 과소적합될 가능성이 크고, 너무 높으면 과대적합의 위험이 있다.\r\n  \r\n  * 두 값 모두 커질수록 알고리즘의 복잡도는 증가하고, 작아질수록 복잡도는 낮아진다.\r\n  \r\n    <br>\r\n  \r\n\r\n<br>\r\n\r\n## **선형 회귀(linear regression)**\r\n\r\n```python\r\nModel = LinearRegression()\r\n```\r\n\r\n* 예측값(Y햇)이 실수(연속형)일 떈, ‘.mean’, ‘.score’ 말고 R2(*0~1값을 가짐) 사용(값의 범위가 MSE보다 작기 때문)\r\n\r\n* 선형회귀는 사용되는 '특성(feature)의 개수'에 따라 \r\n  1. 단순 선형 회귀(simple linear regression): 단 하나의 특징(feature)을 가지고 라벨값(label) 또는 타깃(target)을 예측하기 위한 회귀 모델을 찾는다.\r\n  2. 다중 선형 회귀(multiple linear regression): 하나의 특성이 아닌 여러 개의 특성을 활용해서 회귀모델을 만듦\r\n* **선형 회귀는 y와 y햇 사이의 평균제곱오차(mean squared error, MSE)를 최소화하는 파라미터(w, b)**를 찾는다. y와 y햇의 차이가 작으면 작을 수록 예측 성능이 좋기 때문\r\n* **라쏘(Lasso):** 선형 회귀의 단점을 극복하기 위해 개발된 방법\r\n* linear regression에선 predict_proba 함수를 제공하지 않는다\r\n* y햇 = w[0]+x[0]+b\r\n  * w: 가중치(weight), 계수(coefficient)\r\n  * b: 편항(offset)\r\n  * y햇: 예측값\r\n  * x[0]: 특징\r\n  * \"feature와 lable 사이의 관계를 잘 설명해낼 수 있는 최적(가장 적합한)의 w와 b를 찾는 것\"\r\n\r\n<br>\r\n\r\n### **`라쏘(L1)`**\r\n\r\n* 추가 제약조건이자 grid search\r\n* 선형 회귀에 **L1** 규제를 줘서 과대적합을 피하는 방법이다.\r\n* 상관성이 있을 수도 있는 feature의 영향력을 줄일 수 있음\r\n* 동작 원리:\r\n  * MSE가 최소가 되게 하는 w, b 찾기 + w의 모든 원소가 0이 되거나 0에 가깝게\r\n  * MSE와 penalty 항의 합이 최소가 되게 하는 w와 b를 찾는 것이 라쏘의 목적\r\n* L1-norm(벡터의 요소들의 절대값들의 합) 패널티를 조정하는 건 알파값(선형회귀 분석의 grid serch)\r\n  * **알파 너무 작으면 과대적합(복잡도 큼), 너무 크면 과소 적합(복잡도 넘 작음)**\r\n\r\n* 라쏘의 장점:\r\n  1. 제약 조건을 통해 일반화된 모형을 찾는다.\r\n  2. 모델 해석력이 good (모델에서 가장 중요한 특성이 무엇인지 아는)\r\n\r\n> 총 105개의 특성을 라쏘 회귀 모델을 만들기 위해 사용했다. ![image-20200721081736446](image-20200721081736446.png)로 설정했더니 105개의 가중치 중에서 101개가 0이 되면서 특성은 단 4개만 사용되었다. 훈련셋에서의 점수와 테스트셋에서의 점수를 보니 과소적합이었다. 따라서 복잡도를 높이기 위해서 ![image-20200721081835369](image-20200721081835369.png)로 설정했더니 가중치 중에서 7개만 0이 되면서 94개의 특성이 사용되었다. 훈련셋과 테스트셋에서의 점수를 보니 훈련셋에서는 좋은데 테스트셋에서는 많이 떨어졌다. 즉, 과대적합이었다. 따라서 다시 복잡도를 낮추기 위해 ![img](https://t1.daumcdn.net/cfile/tistory/99E9B0335A0547A912)을 사용했다. 105개의 가중치 중에서 72개가 0이 되면서 33개의 특성이 사용되었다. 훈련셋에서의 점수와 테스트셋에서의 점수가 모두 괜찮았다. \r\n\r\n<br>\r\n\r\n### `릿지(L2)`\r\n\r\n* `L2-norm`\r\n* 릿지 원의 크기와 라쏘의 마름모 크기는 정규화 역할하는 람다 혹은 C로 조절\r\n* 특성이 다수일 경우에는 릿지 회귀가 좀 더 잘 작동. 선형 회귀와 달리 모델의 복잡도를 조정할 수 있기 때문. 복잡도를 조정할 수 있다는 말은 사용자가 설정 가능한 파라미터가 있다는 뜻\r\n* **알파값(가중치)**: (feature가 생각보다 덜 쓰였다던가의)과소적합: 1보다 작은 α 값(ex: 0.1, 0.01, 0.001)로 조정\r\n* 즉, alpha 값을 크게 설정 ~ 기울기가 줄어듦 ~ 특성들이 출력에 미치는 영향력이 줄어듦(현재 특성들에 덜 의존)\r\n  * alpha = 0 ← 선형회귀\r\n  * default : alpha = 1\r\n\r\n<br>\r\n\r\n* 정리\r\n  * 특성이 많은데 그중 **일부분만 중요하다면 라쏘**\r\n  * 특성의 중요도가 전체적으로 **비슷하다면 릿지**\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## `로지스틱 회귀 분석`\r\n\r\n```python\r\nmodel = Logisticregression(~~)\r\ngrid search:\r\n    penaly = ‘l2’\r\n    C = c\r\n    max_iter = 500\r\n```\r\n\r\n<br>\r\n\r\n* 선형회귀분석에서 쓰던 MSE 말고 Cross Entropy(CE) 사용\r\n  \r\n* **오즈**(0.9가 나왔으면 1이라 보는 것)\r\n\r\n* 계산 시 유의 사항:\r\n\r\n  * 예측값(y햇)이 실제값(y)과에 가깝게 나오게 하기 위해 CE, MSE 최소화\r\n\r\n  * 출력에 1이 여러 개인(sigmoid 출력) 이진분류일 경우 **BCE**(바이너리 CE) 사용: 개별 출력이라 1이 여러 개\r\n\r\n  * 출력에 1이 한 개일 경우(one-shot 형태로 softmax가 출력) **CCE**(카테고리컬 CE) 사용: 그룹(?) 출력이라 1이 하나\r\n\r\n    → BCE, CCE는 결과가 다르고 정확도 측정도 달라지므로 주의해서 선택\r\n\r\n  <br>\r\n\r\n* sklearn 패키지에서는 sigmoid 안 거치고 바로 softmax로 감\r\n\r\n  <br>\r\n\r\n* 보통의 계산 순서: \r\n  1. sigmoid 함수로 계산\r\n  2. softmax함수로 계산(이때 CE 사용)\r\n\r\n <br>\r\n\r\n* 로지스틱함수의 yHat 계산법(step):\r\n  1. 시그모이드 계산\r\n     * 시그모이드(sigmoid) 함수: 가중치와 바이어스는 시그모이드의 비활성도를 조절해준다.\r\n  2. CE 계산\r\n\r\n<br>\r\n\r\n <br>\r\n\r\n## `나이브 베이지안`\r\n\r\n* model = GaussianNB()\r\n\r\n* **Feature들이 서로 독립이라 가정**하고 **조건부 확률 계산**해서 데이터 분류\r\n  \r\n* **명목형**(1, 0), **연속형**(정규분포 사용) 변수 모두 사용 가능\r\n  \r\n  <br>\r\n  \r\n* 계산 순서:\r\n\r\n  1. 결합 확률은 너무 복잡해서 두 feature를 독립이라 가정하여,\r\n\r\n  2. 베이지안 식에 의해 각각을 곱해 계산한 후,\r\n\r\n  3. 큰 확률의 값을 선택\r\n\r\n     Ex: yes 일 확률 : 1 , no일 확률: 0 => (계산 후) no로 분류\r\n     \r\n     <br>\r\n\r\n* `m 추정치(m-Estimates)`: 비교하려는 두 샘플의 data 중에 특정 데이터가 없을 땐 두 확률이 모두 0으로 나와서 분류할 수 없으므로, m-Estimates라는 m과 p를 사용해서 조건부 확률 계산식을 조정함. \r\n\r\n* 분모의 m은 임의의 확률, mp는 분자가 0 나오는 거 방지\r\n\r\n* 명목형, 연속형 모두 섞여 있는 data 일 땐,\r\n  1. 명목형, 연속형 각각 model 학습\r\n  2. 각각의 model 정확도 추정\r\n  3. '2'의 그 정확도(확률)을 곱함\r\n  4. '3'의 확률의 곱으로 정확도 측정\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n>  참고: \r\n>\r\n>  * 심교훈. 019. 10. 24. \"결정 트리(Decision Tree) 알고리즘, ID3 소개\". https://bskyvision.com/598. b스카이비전.\r\n>\r\n>  * 심교훈. 2020. 1. 20. \"[ubuntu+python] 선형 회귀의 업그레이드 버전1, 릿지 회귀\". https://bskyvision.com/687. b스카이비전\r\n>  * 심교훈. 2017. 10. 21. \"서포트 벡터 머신(SVM)의 사용자로서 꼭 알아야할 것들 - 매개변수 C와 gamma\". https://bskyvision.com/163. b스카이비전.\r\n>  * 머신러닝. 2020.01.14. \"서포트 벡터 머신(Support Vector Machine) 쉽게 이해하기\". http://hleecaster.com/ml-svm-concept/. 아무튼워라밸\r\n\r\n\r\n\r\n","excerpt":"머신러닝(ML) KNN Decision Tree SVM 선형회귀분석 로지스틱회귀분석 나이브베이지안  차원(feature…","fields":{"slug":"/머신러닝_1/"},"frontmatter":{"date":"Jun 23, 2020","title":"머신러닝 분석 방법들, 첫 번째","tags":["ML"],"update":"Aug 16, 2020"}}}]}},"pageContext":{}},"staticQueryHashes":["3649515864","694178885"]}