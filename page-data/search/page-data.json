{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\r\n\r\n\r\n**TQT(The question I asked the teacher today.)**\r\n\r\n\r\n# Dense\r\n\r\n* `Dense`: fully connected\r\n* `ANN(FNN)`에서는 여러 `Dense`를 써도 되지만, `RNN(LSTM)`에선 마지막 층에서만 `Dense`를 써야함.\r\n  * `CNN`에서는 여러 `Dense` 써도 됨  ##?#?#??#?#???\r\n  * => 일단... `lstm`에서 `lstm() → Dense → lstm()`은 `lstm 네트워크가 2개` 만들어진다고 보면 됨. `lstm() → Dense` 했을 때, `1개의 네트워크`가 형성된 것\r\n  * => 그리고 `CNN`은 일종의 잘 짜여진 레시피라서 `con1D → pooling → Dense → con1D → pooling`은 위 `lstm`처럼 좀 이상한 네트워크 구조가 되는 거라 생각함...\r\n* Dense(1, activation='sigmoid')\r\n* ==LSTM에서 FNN으로 보내는 마지막 Dense에선 relu 쓰면 안됨==\r\n\r\n\r\n\r\n# FNN(순방향 신경망)\r\n* ↔ RNN\r\n* hidden 층에서\r\n  * Dense(4, `activation` = 'sigmoid', `kernel_regularizer`=regularizers.l2(0.0001), activation='relu')\r\n  * `Dropout`(rate=0.5)\r\n* `BatchNormalization`(momentum=0.9, epsilon=0.005, center=True, scale=True, moving_variance_initializer='ones')\r\n* `predict`까지 끝낸 **연속형** `yHat` 값을, `np.where` 써줘서 **바이너리 형태**로 변환 \r\n\r\n  ``` python\r\n  np.where(yHat > 0.5, 1, 0)\r\n  # 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기_커스텀loss.py\r\n  ```\r\n\r\n* `history` 활용\r\n  ```python\r\n  hist.history['loss']\r\n  hist.history['val_loss']\r\n  # 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기.py\r\n  ```\r\n* 학습/평가/예측용 model로 나누었을 때 **평가 데이터 활용**\r\n  ```python\r\n  model.fit(trainX, trainY, validation_data=(evlX, evlY), epochs=200, batch_size=50)\r\n  ```\r\n\r\n\r\n\r\n# LSTM\r\n\r\n* |              | 설명                                                         |\r\n  | ------------ | ------------------------------------------------------------ |\r\n  | 2층          | `lstm()`을 2번 써준다                                        |\r\n  | 양방향       | `bidirectional` + `merge_mode = ‘concat’` <br />FNN, BFN 값을 merge_mode 형태로 합쳐서 list형으로 되돌려줌 |\r\n  | many-to-many | `return-sequences = True`<br />LSTM의 중간 스텝의 출력을 모두 사용 |\r\n  |              | `timedistributed`<br /> FFN으로 가기 전 LSTM 마지막 층에서 각 뉴런의 각 지점에서 계산한 오류를 다음 층으로 전파 |\r\n\r\n\r\n\r\n\r\n# CNN\r\n\r\n* 이미지를 대표할 수 있는 특성들을 도출해서 FNN에 넣어줌\r\n\r\n* | code                                                         | 설명                                                         |\r\n  | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n  | `Input`(batch_shape = (None, nStep, nFeature, nChannel))     |                                                              |\r\n  | `Conv2D`(filters=30, kernel_size=(8,3), strides=1, padding = 'same', activation='relu') |                                                              |\r\n  | `MaxPooling2D`(pool_size=(2,1), strides=1, padding='valid')  | - 경우에 따라 conv2D, pooling 더 써줄 수 있음<br />- `GlobalMaxPooling1D()`도 있음 |\r\n  | `Flatten()`                                                  | 2D는 4차원이라 shape 맞추려고 보통 flatten을 써줌<br />1d는 안 써도 되는 듯(?) |\r\n  | `Dense`(nOutput, activation='linear')                        |                                                              |\r\n\r\n  \r\n\r\n# activation\r\n\r\n* | activation(비선형 함수) | loss                                                         |\r\n  | ----------------------- | ------------------------------------------------------------ |\r\n  | `softmax`               | `sparse_categorical_crossentropy`                            |\r\n  | `sigmoid`               | `binary_crossentropy`                                        |\r\n  | `linear`                | `mse`                                                        |\r\n| `relu`                  | ← Hidden layer에 씀. 기울기가 0이기 때문에 뉴런이 죽을 수 있는 단점 有 |\r\n  |                         |                                                              |\r\n  | Leakly ReLU             | 뉴런이 죽을 수 있는 현상 해결                                |\r\n  | PReLU                   | x<0 에서 학습 가능                                           |\r\n  | granger causality       | 통제된 상황에서 인과관계가 가능하다고 말할 수 있음. 시계열 데이터에서 쓰일 수 있음 |\r\n\r\n* 딥러닝 네트워크(DN)의 노드는 입력값을 전부 더한 후, 활성화 함수(Activation function)를 통과시켜 다음 노드에 전달한다.\r\n  \r\n  * 이때 사용하는 활성화 함수는 비선형 함수를 쓴다. \r\n\r\n\r\n\r\n\r\n\r\n## ReLu\r\n\r\n* 히든층에 자주 쓰임\r\n\r\n* 그냥 CNN이든 LSTM이든 출력층 Dense에 Relu 쓰지 말자\r\n\r\n  * LSTM에선 Relu 안 쓰는 게 좋음. 특히 출력층엔 쓰면 안 됨.\r\n\r\n  \r\n\r\n\r\n\r\n\r\n\r\n# 학습(compile), 예측(predict)\r\n\r\n## optimizer\r\n\r\n* | 종류(빈도순)               |\r\n  | -------------------------- |\r\n  | `adam`                     |\r\n  | Adadelta, RMSprop, Adagrad |\r\n  | `momentum`                 |\r\n  | GD, NAG                    |\r\n\r\n* 최적화가 잘 안 되면 글로벌 minmun을 찾지 못하고 로컬 minimum에 빠진다. 이때 로컬 minimum을 **어떻게 빨리** 탈출할 수 있을지 U턴 메소드를 쓸지, 다른 1차 미분방법(GD)를 쓸 지 결정하게 된다. \r\n\r\n\r\n\r\n## epoch\r\n\r\n* `epoch` 수치가 커지면 `optimizer`가 일을 해서 local이 아닌 global을 찾아간다.\r\n* 그런데 너무 크면 overfitting\r\n* 따라서 적당한 `epoch` 설정이 필요 \r\n\r\n\r\n\r\n## Batch_size\r\n\r\n* data가 크면 `batch_size`도 크게\r\n  * 25,000개의 raw data라면 `batch_size` = 20 보다 300 이 정도로 설정\r\n\r\n\r\n\r\n\r\n\r\n# NLP & DL\r\n\r\n* SGNS\r\n\r\n| 용어          | 설명                      | CODE                                | 참고                             |\r\n| ------------- | ------------------------- | ----------------------------------- | -------------------------------- |\r\n| pre-trained   | SKNS에서 학습한 We를 적용 | model.layers[1]**.set_weights**(We) | 해당 code 적용 후 model fit 진행 |\r\n|               |                           |                                     |                                  |\r\n| fine-training |                           |                                     |                                  |\r\n\r\n\r\n\r\n* SGNS에 모델 학습(fit) 시, 학습을 따로 시키는 이유?\r\n\r\n  ```python\r\n  # 학습\r\n  hist = model.fit([X[:, 0], X[:, 1]], X[:, 2], \r\n                   batch_size=BATCH_SIZE,\r\n                   epochs=NUM_EPOCHS)\r\n  ```\r\n\r\n  > *  각기 연결된 가중치 선이 구분되어 있기 때문에\r\n\r\n\r\n\r\n* SGNS 모델 만들 때 dot을 한다면, \r\n\r\n  1. **axis=2**    *@2*\r\n\r\n     → 후에\r\n\r\n  2. reshape**(())**    *@괄호 두 개*\r\n\r\n\r\n\r\n* SGNS로 만든 Embedding의 w(가중치)를 basic한 word data에 적용할 때, load_weights 사용하는 방법도 있다.\r\n\r\n  * 근데 이땐 shape을 맞춰줘야 한다.\r\n\r\n  ```python\r\n  w = encoder.load_weights('model_w.h5') # 가중치(w) 불러온 후,\r\n  emb = Embedding(max_features, embedding_dims, load_weights = w)(xInput) # embedding layer에 바로 적용\r\n  ```\r\n\r\n  * 보통 이런 느낌으로 씀\r\n\r\n    ```python\r\n    weights = load_weights()\r\n    embedding_layer = Embedding(input_dim=V,\r\n                                output_dim=embedding_dim,\r\n                                input_length=input_length,\r\n                                trainable=False,\r\n                                weights=weights,\r\n                                name='embedding')\r\n    ```\r\n\r\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# 기타\r\n\r\n## 유클리디안 거리\r\n\r\n* 거리 계산할 때, 비교하고 싶은 건 `[]`를 쳐서 넣어주기  \r\n\r\n  ```python\r\n  euclidean_distances([father, mother])\r\n  ```\r\n\r\n\r\n## 가중치 저장(Save)\r\n\r\n* Embedding (left side) layer의 W를 저장할 때, [2]를 저장한단 사실 알아두기\r\n\r\n  ```python\r\n  with open('data/embedding_W.pickle', 'wb') as f:\r\n      pickle.dump(model.layers[2].get_weights(), f, pickle.HIGHEST_PROTOCOL)\r\n  ```\r\n\r\n\r\n","excerpt":"TQT(The question I asked the teacher today.) Dense : fully connected…","fields":{"slug":"/TQT/"},"frontmatter":{"date":"Aug 01, 2020","title":"TQT","tags":["TQT"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n게시물에 태그를 지정할 수 있습니다.\r\n\r\n해당 게시물의 Markdown YAML Front matter은 아래와 같습니다.\r\n\r\n```\r\n---\r\ntitle: Tag, 태그 게시물 예제\r\ndate: 2019-07-30\r\ntags:\r\n  - tag\r\n  - 태그\r\n---\r\n```\r\n\r\n가이드의 Markdown YAML Front matter를 참고하세요.\r\n\r\n자세한 가이드는 [Documents](<https://github.com/junhobaik/junhobaik.github.io/wiki/Document-(Borderless)>)를 확인해주세요.\r\n","excerpt":"게시물에 태그를 지정할 수 있습니다. 해당 게시물의 Markdown YAML Front matter은 아래와 같습니다. 가이드의 Markdown YAML Front matter를 참고하세요. 자세한 가이드는 Documents를 확인해주세요.","fields":{"slug":"/tag-post-example/"},"frontmatter":{"date":"Mar 24, 1991","title":"Tag, 태그 게시물 예제","tags":["tag","태그"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n![](screenshot.png)\r\n\r\n이미지 파일이 첨부된 게시물의 예제입니다.\r\n\r\n폴더를 만들고 폴더의 제목이 해당 게시물의 주소가 됩니다.\r\n\r\n게시물 파일명은 index.md 로 합니다.\r\n\r\n이미지 파일은 폴더 내에 위치시킵니다.\r\n\r\n자세한 가이드는 [Documents](<https://github.com/junhobaik/junhobaik.github.io/wiki/Document-(Borderless)>)를 확인해주세요.\r\n","excerpt":"이미지 파일이 첨부된 게시물의 예제입니다. 폴더를 만들고 폴더의 제목이 해당 게시물의 주소가 됩니다. 게시물 파일명은 index.md 로 합니다. 이미지 파일은 폴더 내에 위치시킵니다. 자세한 가이드는 Documents를 확인해주세요.","fields":{"slug":"/image-post-example.md/"},"frontmatter":{"date":"Mar 24, 1991","title":"Image, 이미지 게시물 예제","tags":["undefined"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n블로그를 본인에 맞춰 커스터마이징하려면 우선 config.js의 수정이 필요합니다.\r\n\r\n[Documents](<https://github.com/junhobaik/junhobaik.github.io/wiki/Document-(Borderless)>)를 확인해주세요.\r\n","excerpt":"블로그를 본인에 맞춰 커스터마이징하려면 우선 config.js의 수정이 필요합니다. Documents를 확인해주세요.","fields":{"slug":"/first-post/"},"frontmatter":{"date":"Mar 23, 1991","title":"Borderless Documents","tags":["undefined"],"update":"Mar 08, 2020"}}}]}},"pageContext":{}},"staticQueryHashes":["3649515864","694178885"]}