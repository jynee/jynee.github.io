{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# GAN\r\n\r\n* 비지도학습(UL) 방식의 이미지, 문서, 음성 등의 데이터를 **생성(모방)하는 알고리즘**\r\n* **비모수적방법**으로도 비교적 정확한 **sampling이 가능**함 \r\n* 위조 데이터 생성 및 판별에 사용 \r\n  EX) 이미지 색깔(색칠) 해주는 프로그램, 딥페이크 영상\r\n\r\n\r\n\r\n![](image-20200728184326510.png)\r\n\r\n> 출처: https://www.naverlabs.com/storyDetail/44\r\n\r\n\r\n\r\n## 그림 보충 설명:\r\n\r\n1)  `Real`: 실제 데이터(이미지, 음성 등)\r\n\r\n2)  `Input`: 랜덤 데이터. **노이즈 섞인 것**. \t*But,* Generator 통과하면, Real data 같은 것으로 변환돼 나온다.\r\n\r\n3)  `Generator(network)`: `생성자`. **진짜 같은 가짜(Fake) 생성**\r\n\r\n4)  `Discriminator(network)`: `판별자`. **실제 데이터(Real)와 가짜 데이터(Fake)를 판별**함\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## **즉, 총 2개의 네트워크 사용:**\r\n\r\n1)  `Discriminator`: real or fake 판별자\r\n\r\n2)  `Generator`: fake 생성자\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n## Gan의 loss function:\r\n\r\n* `minGmaxDV(D,G) = logD(x) + log(1-D(G(z)))`\r\n* 학습을 반복하여 (Pg = Pdata가 되어) Discriminator가 구별 불가능인 상태(‘D(x)=0.5’)로 수렴하도록 \r\n  → 마치 Generator가 x를 만들어낸 것처럼 됨 \r\n\r\n| Discriminator   | Generator       |\r\n| --------------- | --------------- |\r\n| 엔트로피 최대화 | 엔트로피 최소화 |\r\n\r\n> 엔트로피: 정보의 가치(정보량)과 ~\r\n\r\n**1)**  **`Discriminator`**(network): **`maxV(D, G)`**로 학습. D(x) = 1 and D(G(z)) = 0일 때 최대\r\n\r\n* *why?* D(G(z))가 1이 되고, D(x)가 1이 되니까\r\n\r\n2)  **`Generator`** network: **`minV(G)`**로 학습. D(G(z)) = 1 일 때 최소. 이때(D(x)는 상관 X)\r\n\r\n* *why?* D(G(z))가 0이 되니까\r\n\r\n<br>\r\n\r\n### 원리:\r\n\r\n![](image-20200728185621472.png)\r\n\r\n> 출처: Goodfellow 논문 공식\r\n\r\n<br>\r\n\r\n1. `Discriminator`를 k번 학습시키고, `Generator`를 1번 학습시킨다.\r\n\r\n   → `D`가 `G`보다 더 많이 학습된다.    *****`D`: `Discriminator` / `G`: `Generator`\r\n\r\n   <br>\r\n\r\n   *이에 따라* >\r\n\r\n   1) Real Data와 Fake Data를 구별해내는 `D loss`는 점점 더 작아져 영향력이 줄어들고,\r\n\r\n   2) `D`와 `G`는 점점 더 비슷해지며,\r\n\r\n   3) `KL`이 적어지고,   *****`KL: G와 D의 정보량의 차이/분산의 차이`\r\n\r\n   <br>\r\n\r\n   *이럴수록* >\r\n\r\n​\t3-1) `G`가 더 많은 영향력을 행사하고(역할을 하고),\r\n\r\n​\t3-2) `D loss`를 계산하는 공식 中 [-log4 + 2JSD(Pdata+||Pg)]에서 -log4의 값이 더욱더 `1.38`에 가까워진다. \r\n​    *`[2JSD(Pdata+||Pg) ]` : `KL`이라 보면 됨. `(KL이 작아진다) = (D와 G의 분산이 적다) = (D loss가 1.38에 가깝다)`\r\n\r\n   <br>\r\n\r\n   *따라서*  >\r\n\r\n   분별할 수 없이 실제와 가까운 Fake Data가 생성된다.\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 위 원리에 따라,\r\n\r\n  *학습이 안 된 상태에선* >\r\n\r\n  `G(z)` `( = Fake Data. 이때 ‘z’는 input에서 들어온 random data임)`의 분포가 오른쪽으로 치우친 상태로서 `D(x)`는 1에 가까운 값이 출력되고 `D(G(z))`는 0에 가까운 값이 출력된다.\r\n\r\n  [^'D(x)는 1에 가까운 값이 출력되고 D(G(z))는 0에 가까운 값이 출력된다']: 이때 D와 G는 아래 함수와 같은 상태임![image-20200728190633284](image-20200728190633284.png)![image-20200728190622855](image-20200728190622855.png)\r\n\r\n  즉, `D`는 `진짜 (X)`와 `가짜 G(z)`를 잘 구별하고, `G`는 진짜 같은 가짜를 잘 못 만든다\r\n\r\n  <br>\r\n\r\n  *학습이 진행되면* > \r\n\r\n  가짜 데이터 `G(z)`의 분포가 점점 `Real Data( = X)`의 분포와 유사해지고 `D(G(z))` 값도 점차 커져서 `D(x)`값은 점차 작아진다 \r\n\r\n  <br>\r\n\r\n  *학습이 완료되면* > \r\n\r\n  Real data와 `G(z)`의 분포가 잘 일치하고 “`D(x) = D(G(z)) = 0.5` “로 수렴한다.\r\n\r\n  즉, 임의의 random data를 `G`에 입력해 나온 Fake data는 Real data와 유사한 분포 특성을 갖는 데이터가 출력된다.\r\n\r\n![](image-20200728190502482.png)\r\n\r\n\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n<br>\r\n\r\n* 참고:\r\n\r\n  >  http://blog.skby.net/gan-generative-adversarial-networks/\r\n\r\n","excerpt":"GAN 비지도학습(UL) 방식의 이미지, 문서, 음성 등의 데이터를 생성(모방)하는 알고리즘 비모수적방법으로도 비교적 정확한 sampling이 가능함  위조 데이터 생성 및 판별에 사용 \nEX…","fields":{"slug":"/GAN-v1_1/"},"frontmatter":{"date":"Aug 08, 2020","title":"GAN 이론","tags":["DL","GAN"],"update":"Aug 08, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n# GAN\r\n\r\n</br>\r\n\r\n* 1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다.</br>\r\n\r\n* fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등)</br>\r\n\r\n* Discrimi의 loss는 max[log(Dx) + log(1 - DGz)]이고, Generator의 loss는 min[log(Dx + log(1 - DGz))]이다. </br>\r\n\r\n  </br>\r\n\r\n* Tensorflow에서는 이 loss 함수를 이용하여 직접 GAN을 학습할 수 있지만, </br>\r\n\r\n  Keras에서는 model.fit(), model.train_on_batch() 함수에서 target 값을 지정해야 하기 때문에 이 loss로 GAN을 학습할 수 없다 **Keras는 기본적으로 Supervised learning 목적이다.**</br>\r\n\r\n  * Keras에서는 supervised learning 방식으로 바꿔 binary_crossentropy loss 함수를 써서 GAN을 학습하는 것이 보통이다.</br>\r\n\r\n    <br>\r\n\r\n* 이 코드는 아래 자료를 참조해서 응용했다.</br>\r\n\r\n  1. Rowel Atienza, 2018, Advanced Deep Learning with Keras. Chap 4. p.107 ~ p.113</br>\r\n  2. 아마추어 퀀트, blog.naver.com/chunjein,  2020.04.08</br>\r\n\r\n* 함수들의 기능을 파악하기 쉽도록 순서를 변경하였다.</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n## Basic CODE\r\n\r\n</br>\r\n\r\n* Keras를 이용하여 기본 GAN 모델을 연습한다.</br>\r\n* file: 딥러닝 8-2.GAN(Kears)</br>\r\n\r\n</br>\r\n\r\n#### step1. 정규분포로부터 데이터를 샘플링한다</br>\r\n\r\n```python\r\nrealData = np.random.normal(size=1000)\r\nrealData = realData.reshape(realData.shape[0], 1)\r\n```\r\n\r\n</br>\r\n\r\n#### step2. Network 빌드\r\n\r\n```python\r\nnDInput = realData.shape[1] # nDInput.shape[1] = 1\r\nnDHidden = 32\r\nnDOutput = 1\r\nnGInput = 16\r\nnGHidden = 32\r\nnGOutput = nDInput\r\n\r\n## nDInput와 nGOutput는 값이 같아야 함\r\n```\r\n\r\n</br>\r\n\r\n```python\r\ndef getNoise(m, n=nGInput):\r\n    z = np.random.uniform(-1., 1., size=[m, n])\r\n    return z\r\n```\r\n\r\n```python\r\ndef MyOptimizer(a = 0.001):\r\n    return RMSprop(lr = a)\r\n```\r\n\r\n</br>\r\n\r\n#### step3. 모델 그림\r\n\r\n```py\r\nGenerator --> Discriminator를 연결한 모델을 생성한다.\r\n아래 네트워크로 z가 들어가면 DGz = 1이 나오도록 G를 학습한다.\r\nD 네트워크는 업데이트하지 않고, G 네트워크만 업데이트한다.\r\n\r\n        +---+   Gz   +---+\r\n  z --->| G |------->| D |---> DGz\r\n        +---+        +---+\r\n      trainable   not trainable\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step4. (객체지향) 함수 정의\r\n\r\n**0. K.clear_session()</br>**\r\n\r\n#####   1. Discriminator = BuildDiscriminator()</br>\r\n\r\n#####   2. Generator = BuildGenerator()</br>\r\n\r\n#####   3. GAN = BuildGAN(Discriminator, Generator)</br>\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step5. 학습 세팅\r\n\r\n```python\r\nnBatchCnt = 3       # Mini-batch를 위해 input 데이터를 n개 블록으로 나눈다. # 333개, 333개, 334개로 쪼개짐 \r\nnBatchSize = int(realData.shape[0] / nBatchCnt)  # 블록 당 Size # nBatchSize: 333개, 333개, 334개 순으로 들어감 \r\nfor epoch in range(1000):\r\n    # Mini-batch 방식으로 학습한다\r\n    for n in range(nBatchCnt):\r\n        # input 데이터를 Mini-batch 크기에 맞게 자른다\r\n        nFrom = n * nBatchSize #for문 다 돌면 nFrom= 666\r\n        nTo = n * nBatchSize + nBatchSize #for문 다 돌면 nTo=1000\r\n        \r\n        # 마지막 루프이면 nTo는 input 데이터의 끝까지. \r\n        ## 왜 써주냐면 , n=2(마지막)일때 nTo = n * nBatchSize + nBatchSize는 999로 1000이 안되기 땜에.\r\n        if n == nBatchCnt - 1:\r\n            nTo = realData.shape[0]\r\n```\r\n\r\n</br>\r\n\r\n``` python\r\n        # 학습 데이터를 준비한다\r\n        bx = realData[nFrom : nTo] #진짜 data 형성\r\n        bz = getNoise(m=bx.shape[0], n=nGInput) # bx.shape[0]=333->333->334, nGInput=16\r\n        Gz = Generator.predict(bz) #진짜 data shape 맞춰서 noise 써가지고 가짜 data 형성(fake data)\r\n```\r\n\r\n![image-20200715110832016](image-20200715110832016.png)\r\n\r\n</br>\r\n\r\n##### Discriminator = BuildDiscriminator()\r\n\r\n```python\r\n    \t### < Discriminator를 학습한다. > ###\r\n        # Real data가 들어가면 Discriminator의 출력이 '1'이 나오도록 학습하고,\r\n        # Fake data (Gz)가 들어가면 Discriminator의 출력이 '0'이 나오도록 학습한다.\r\n        \"\"\"target data 만들기\"\"\"\r\n        target = np.zeros(bx.shape[0] * 2)\r\n        target[ : bx.shape[0]] = 0.9     # '1' 대신 0.9로 함\r\n        target[bx.shape[0] : ] = 0.1     # '0' 대신 0.1로 함\r\n        \"\"\"target data 형성 완료\"\"\"\r\n        \r\n        bx_Gz = np.concatenate([bx, Gz]) # D 학습 \r\n        Dloss = Discriminator.train_on_batch(bx_Gz, target) \r\n        #real data & fake data 모두가 D를 거치게 한다. \r\n        ##참고: fit 함수보다 train_on_batch 쓰는 게 더 속도가 빨라서 이거 씀\r\n \r\n```\r\n\r\n\r\n\r\n![image-20200715110841184](image-20200715110841184.png)\r\n\r\n</br>\r\n\r\n###### \tdef BuildDiscriminator()\r\n\r\n```python\r\n# Discriminator를 G. D 각각 생성한다\r\ndef BuildDiscriminator():\r\n    x = Input(batch_shape = (None, nDInput))\r\n    h = Dense(nDHidden, activation = 'relu')(x)\r\n    Dx = Dense(nDOutput, activation = 'sigmoid')(h) #0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 \r\n    model = Model(x, Dx)\r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.001)) \r\n    #sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 \r\n    \r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n##### GAN = BuildGAN(Discriminator, Generator)\r\n\r\n```python\r\n### < Generator를 학습한다. > ###\r\n# Fake data (z --> Gz --> DGz)가 들어가도 Discriminator의 출력이 '1'이 나오도록 Generator를 학습한다.\r\n\"\"\"target data 만들기\"\"\"\r\ntarget = np.zeros(bx.shape[0])\r\ntarget[:] = 0.9\r\n\"\"\"target data 형성 완료\"\"\"\r\n        \r\nGloss = GAN.train_on_batch(bz, target) \r\n## GAN 함수 참고: D는 위에서 학습해서 여기선 학습 안 하고 G만 학습 \r\n# 어떤 학습? 가짜 data가 들어가면 target이 전부 1로 출력되도록(Discriminator가 전부 진짜로 판별하도록)! \r\n```\r\n\r\n\r\n\r\n![image-20200715110850214](image-20200715110850214.png)\r\n\r\n</br>\r\n\r\n###### \tdef BuildGAN(D, G)\r\n\r\n``` python\r\ndef BuildGAN(D, G): # 전체 NETWORK Build \r\n    D.trainable = False     # Discriminator는 업데이트하지 않는다= 학습하지 않는다. 왜냐면 자체적으로 위에서 학습했으니까. 따라서 G만 학습됨 \r\n    z = Input(batch_shape=(None, nGInput))\r\n    Gz = G(z)\r\n    DGz = D(Gz)\r\n    \r\n    model = Model(z, DGz) #z가 들어가면 최종적으로 DGz가 나온다. \r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.0005)) # binary_crossentropy: 출력값이 0 아니면 1 나오도록\r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef BuildDiscriminator() = Discriminator\r\n\r\n```python\r\n# Discriminator를 G. D 각각 생성한다\r\ndef BuildDiscriminator():\r\n    x = Input(batch_shape = (None, nDInput))\r\n    h = Dense(nDHidden, activation = 'relu')(x)\r\n    Dx = Dense(nDOutput, activation = 'sigmoid')(h) #0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 \r\n    model = Model(x, Dx)\r\n    model.compile(loss = 'binary_crossentropy', optimizer = MyOptimizer(0.001)) \r\n    #sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 \r\n    \r\n    return model\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef BuildGenerator() = Generator\r\n\r\n```python\r\n# Generator를 생성한다 \r\n# G는 여기서 학습 안 하므로 '.complie' 안 함 \r\ndef BuildGenerator(): \r\n    z = Input(batch_shape = (None, nGInput))\r\n    h = Dense(nGHidden, activation = 'relu')(z)\r\n    Gz = Dense(nGOutput, activation='linear')(h)\r\n    return Model(z, Gz)\r\n```\r\n\r\n</br>\r\n\r\n##### kd = KL(ralData, fakeData)\r\n\r\n```python\r\n    if epoch % 10 == 0:\r\n        z = getNoise(m=realData.shape[0], n=nGInput)\r\n        fakeData = Generator.predict(z)  \r\n        # Generator = BuildGenerator()에서 만든 Model(z, Gz)를 활용하여, \r\n        # \"model.predict(z=노이즈 data)\" 하라는 뜻 \r\n        kd = KL(realData, fakeData)\r\n        print(\"epoch = %d, D-Loss = %.3f, G-Loss = %.3f, KL divergence = %.3f\" % (epoch, Dloss, Gloss, kd))\r\n        # Dloss: 0.6932636 , Gloss: 0.6933405 , kd: 0.2189525518812676 = 분산이 적다\r\n```\r\n\r\n</br>\r\n\r\n###### \tdef KL\r\n\r\n```python\r\n# 두 분포 (P, Q)의 KL divergence를 계산한다.\r\ndef KL(P, Q):\r\n    # 두 데이터의 분포를 계산한다\r\n    histP, binsP = np.histogram(P, bins=100)\r\n    histQ, binsQ = np.histogram(Q, bins=binsP)\r\n    \r\n    # 두 분포를 pdf로 만들기 위해 normalization한다.\r\n    histP = histP / (np.sum(histP) + 1e-8)\r\n    histQ = histQ / (np.sum(histQ) + 1e-8)\r\n\r\n    # KL divergence를 계산한다\r\n    kld = np.sum(histP * (np.log(histP + 1e-8) - np.log(histQ + 1e-8)))\r\n    return kld\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### plt\r\n\r\n```python\r\n# real data 분포 (p)와 fake data 분포 (q)를 그려본다\r\nz = getNoise(m=realData.shape[0], n=nGInput)\r\nfakeData = Generator.predict(z)\r\n\r\nplt.figure(figsize=(8, 5))\r\nsns.set_style('whitegrid')\r\nsns.kdeplot(realData[:, 0], color='blue', bw=0.3, label='Real')\r\nsns.kdeplot(fakeData[:, 0], color='red', bw=0.3, label='Fake')\r\nplt.legend()\r\nplt.title('Distibution of real and fake data')\r\nplt.show()\r\n```\r\n\r\n\r\n\r\n![image-20200809130155797](markdown-images/image-20200809130155797.png)\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n------\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n## CNN GAN (DCGAN) CODE\r\n\r\n</br>\r\n\r\n* 사용한 함수 총 5개:</br>\r\n\r\n  1. def build_generator(inputs, image_size)</br>\r\n\r\n  2. def build_discriminator(inputs)</br>\r\n\r\n  3. def train(models, x_train, params)</br>\r\n\r\n  4. def build_and_train_models(load_W = False, train_steps = 100)</br>\r\n\r\n  5. def plot_images():</br>\r\n\r\n</br>\r\n\r\n![image-20200809130207635](markdown-images/image-20200809130207635.png)\r\n\r\n</br>\r\n\r\n#### Base\r\n\r\n```python\r\n# load MNIST dataset\r\n(x_train, _), (_, _) = mnist.load_data()\r\n\"\"\" 비지도 방법으로 사용 \"\"\"\r\n\r\n# reshape data for CNN as (28, 28, 1) and normalize \r\n\"\"\" 2D CNN \"\"\"\r\nimage_size = x_train.shape[1] # x_train.shape (60000, 28, 28)\r\nx_train = np.reshape(x_train, [-1, image_size, image_size, 1]) # x_train.shape = (60000, 28, 28, 1)\r\nx_train = x_train.astype('float32') / 255 # 표준화\r\n\r\n# the latent or z vector is 100-dim\r\nlatent_size = 100 #latent: KNN 가기 전 층들\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 1. build_generator\r\n\r\n```python\r\ndef build_generator(inputs, image_size): # latent 층에 씀 \r\n    image_resize = image_size // 4\r\n    \r\n    # network parameters \r\n    kernel_size = 5\r\n    layer_filters = [128, 64, 32, 1]\r\n\r\n    x = Dense(image_resize * image_resize * layer_filters[0])(inputs)\r\n    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\r\n\r\n    for filters in layer_filters: # hidden 층을 for문으로 써줌(쫙 쌓아주는 것)\r\n        # first two convolution layers use strides = 2\r\n        # the last two use strides = 1\r\n        if filters > layer_filters[-2]:\r\n            strides = 2 # 따라서 layer_filters의 뒤에서 2번째까진 strides = 2\r\n        else:\r\n            strides = 1\r\n        x = BatchNormalization()(x)\r\n        x = Activation('relu')(x)\r\n        x = Conv2DTranspose(filters=filters,\r\n                            kernel_size=kernel_size,\r\n                            strides=strides,\r\n                            padding='same')(x) # data 양 뿔려줌 \r\n\r\n    x = Activation('sigmoid')(x)\r\n    generator = Model(inputs, x, name='generator') # 모방 모델이므로 y 자리엔 x 학습 결과를 써줌 \r\n    return generator # 요렇게 fake data 만들어서 전에 모델처럼 Discriminator에 넣어줌 \r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 2. build_discriminator\r\n\r\n```python\r\ndef build_discriminator(inputs):\r\n    kernel_size = 5\r\n    layer_filters = [32, 64, 128, 256]\r\n\r\n    x = inputs\r\n    for filters in layer_filters:\r\n        # first 3 convolution layers use strides = 2\r\n        # last one uses strides = 1\r\n        # 따라서 Discriminator를 더 많이 학습하게 됨 \r\n        if filters == layer_filters[-1]:\r\n            strides = 1\r\n        else:\r\n            strides = 2\r\n        x = LeakyReLU(alpha=0.2)(x)\r\n        x = Conv2D(filters=filters,\r\n                   kernel_size=kernel_size,\r\n                   strides=strides,\r\n                   padding='same')(x)\r\n\r\n    x = Flatten()(x)\r\n    x = Dense(1)(x)\r\n    x = Activation('sigmoid')(x)\r\n    discriminator = Model(inputs, x, name='discriminator')\r\n    return discriminator\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 3. build_and_train_models\r\n\r\n```python\r\ndef build_and_train_models(load_W = False, train_steps = 100):\r\n    model_name = \"dcgan_mnist\"\r\n    \r\n    # network parameters\r\n    batch_size = 64\r\n    lr = 2e-4\r\n    decay = 6e-8\r\n    input_shape = (image_size, image_size, 1)\r\n\r\n    # build discriminator model\r\n    inputs = Input(shape=input_shape, name='discriminator_input')\r\n    discriminator = build_discriminator(inputs)\r\n    \r\n    # [1] or original paper uses Adam, \r\n    # but discriminator converges easily with RMSprop\r\n    optimizer = RMSprop(lr=lr, decay=decay)\r\n    discriminator.compile(loss='binary_crossentropy',\r\n                          optimizer=optimizer,\r\n                          metrics=['accuracy'])\r\n    discriminator.summary()\r\n    \r\n    # 저장된 discriminator 모델을 읽어온다.\r\n    if load_W:\r\n        discriminator.load_weights(\"dataset/dcgan_D.h5\")\r\n\r\n    # build generator model\r\n    input_shape = (latent_size, )\r\n    inputs = Input(shape=input_shape, name='z_input')\r\n    generator = build_generator(inputs, image_size)\r\n    generator.summary()\r\n\r\n    # 저장된 generator 모델을 읽어온다.\r\n    if load_W:\r\n        generator.load_weights(\"dataset/dcgan_G.h5\")\r\n        \r\n    # build adversarial model\r\n    optimizer = RMSprop(lr=lr * 0.5, decay=decay * 0.5)\r\n    \r\n    # freeze the weights of discriminator during adversarial training\r\n    discriminator.trainable = False\r\n    \r\n    # adversarial = generator + discriminator\r\n    adversarial = Model(inputs, \r\n                        discriminator(generator(inputs)),\r\n                        name=model_name)\r\n    adversarial.compile(loss='binary_crossentropy',\r\n                        optimizer=optimizer,\r\n                        metrics=['accuracy'])\r\n    adversarial.summary() #adversarial: 최종모델\r\n\r\n    # train discriminator and adversarial networks\r\n    models = (generator, discriminator, adversarial)\r\n    params = (batch_size, latent_size, train_steps, model_name)\r\n    train(models, x_train, params)\r\n    \r\n    # 모델을 저장해 둔다\r\n    discriminator.save_weights(\"dataset/dcgan_D.h5\")\r\n    generator.save_weights(\"dataset/dcgan_G.h5\")\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 4. train\r\n\r\n```python\r\ndef train(models, x_train, params):\r\n    # the GAN component models\r\n    generator, discriminator, adversarial = models \r\n    \r\n    \r\n    # network parameters\r\n    batch_size, latent_size, train_steps, model_name = params \r\n    \r\n    \r\n    # number of elements in train dataset\r\n    train_size = x_train.shape[0]\r\n    for i in range(train_steps):\r\n        # train the discriminator for 1 batch\r\n        # 1 batch of real (label=1.0) and fake images (label=0.0)\r\n        # randomly pick real images from dataset\r\n        rand_indexes = np.random.randint(0, train_size, size=batch_size)\r\n        real_images = x_train[rand_indexes]\r\n        \r\n        # generate fake images from noise using generator \r\n        # generate noise using uniform distribution(모든 확률변수에 대해 균일한 확률을 가짐)\r\n        noise = np.random.uniform(-1.0,\r\n                                  1.0,\r\n                                  size=[batch_size, latent_size])\r\n        # generate fake images\r\n        fake_images = generator.predict(noise)\r\n        \r\n        # real + fake images = 1 batch of train data\r\n        x = np.concatenate((real_images, fake_images))\r\n        \r\n        # label real and fake images\r\n        # real images label is 1.0\r\n        y = np.ones([2 * batch_size, 1])\r\n        \r\n        # fake images label is 0.0\r\n        y[batch_size:, :] = 0.0\r\n        \r\n        # train discriminator network, log the loss and accuracy\r\n        loss, acc = discriminator.train_on_batch(x, y) \r\n        \"\"\"Q. loss: 인덱스??? \"\"\"\r\n        log = \"%d: [D-loss: %.4f, acc: %.4f]\" % (i, loss, acc)\r\n\r\n        # train the adversarial network for 1 batch\r\n        # 1 batch of fake images with label=1.0\r\n        # since the discriminator weights \r\n        # are frozen in adversarial network(adversarial network: 적대적 신경망(경쟁 속 반대편에 놓인 신경망))\r\n        # only the generator is trained\r\n        # generate noise using uniform distribution\r\n        noise = np.random.uniform(-1.0,\r\n                                  1.0, \r\n                                  size=[batch_size, latent_size])\r\n        \r\n        # label fake images as real or 1.0\r\n        y = np.ones([batch_size, 1])\r\n        # train the adversarial network \r\n        # note that unlike in discriminator training, \r\n        # we do not save the fake images in a variable\r\n        # the fake images go to the discriminator input of the adversarial\r\n        # for classification\r\n        # log the loss and accuracy\r\n        loss, acc = adversarial.train_on_batch(noise, y) \r\n        \"\"\"Q. adversarial 뜻???\"\"\"\r\n        log = \"%s [G-loss: %.4f, acc: %.4f]\" % (log, loss, acc)\r\n        print(log)\r\n   \r\n    # save the model after training the generator\r\n    # the trained generator can be reloaded for \r\n    # future MNIST digit generation\r\n    generator.save(model_name + \".h5\")\r\n\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### step 5. fake data를 화면에 표시\r\n\r\n```python\r\n# Generator가 생성한 이미지(fake data)를 화면에 표시한다.\r\ndef plot_images():\r\n    inputs = Input(shape=(latent_size, ), name='z_input')\r\n    generator = build_generator(inputs, image_size)\r\n    generator.load_weights(\"dataset/dcgan_G.h5\")\r\n    \r\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\r\n    images = generator.predict(noise_input) # Generator 통해 나온 fake data\r\n    plt.figure(figsize=(6, 6))\r\n    num_images = images.shape[0]\r\n    \r\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\r\n    rows = int(np.sqrt(noise_input.shape[0]))\r\n    for i in range(num_images):\r\n        plt.subplot(rows, rows, i + 1)\r\n        image = np.reshape(images[i], [image _size, image_size]) \r\n        \"\"\"why 3차원 reshape???\"\"\"\r\n        plt.imshow(image, cmap='gray')\r\n        plt.axis('off')\r\n    plt.show()\r\n```\r\n\r\n</br>\r\n\r\n</br>\r\n\r\n#### Final\r\n\r\n```python\r\n# 이미 학습된 weights를 읽어오고, 추가로 학습한다.\r\nbuild_and_train_models(load_W = True, train_steps = 10) # train_steps 만큼 반복 학습\r\n\r\n# Generator가 생성한 이미지를 화면에 표시한다.\r\nplot_images()\r\n```\r\n\r\n</br>\r\n\r\n|                                                         |                                                         |\r\n| ------------------------------------------------------- | ------------------------------------------------------- |\r\n| ![image-20200714193936268](image-20200714193936268.png) | ![image-20200714193941200](image-20200714193941200.png) |\r\n\r\n","excerpt":"GAN 1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다. fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등) Discrimi의 loss는 maxlog(Dx) + log…","fields":{"slug":"/GAN-v1_2/"},"frontmatter":{"date":"Aug 08, 2020","title":"GAN 실전 응용","tags":["DL","GAN"],"update":"Aug 08, 2020"}}},{"node":{"rawMarkdownBody":"\r\n\r\n\r\n\r\n# W(weights)\r\n\r\n* 네트워크 및 model build까지 완성해서 실행되어 역전파 되었을 때 형성된다.\r\n* `compile에서 w`: 네트워크 만들고 난 후 model build하는 과정. optimizer & loss 값을 정의해주는 부분임. w는 만들어져있지 않다.\r\n* `fit에서 w`: fit은 train data 사용. A 다음 B가 **나온다고 저장** \r\n* `predict에서 w`: predict(예측)는 test data 사용. 예측 모델 기준으로 A를 넣으면 B가 **나오게 하는** 어떤 것(Thing)\r\n\r\n\r\n\r\n\r\n\r\n# Hyper parameter\r\n\r\n* `weight decay`(annealing): epoch(alpha)를 처음에는 적당히 높게 했다가, 점차 줄여 나가는 방법\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Dense\r\n\r\n* `Dense`: fully connected\r\n\r\n* `ANN(FNN)`에서는 여러 `Dense`를 써도 되지만, `RNN(LSTM)`에선 마지막 층에서만 `Dense`를 써야함.\r\n  * `CNN`에서는 여러 `Dense` 써도 될까?\r\n  * => 일단... `lstm`에서 `lstm() → Dense → lstm()`은 `lstm 네트워크가 2개` 만들어진다고 보면 된다. `lstm() → Dense` 했을 때, `1개의 네트워크`가 형성된 것\r\n  * => 그리고 `CNN`은 일종의 잘 짜여진 레시피라서 `con1D → pooling → Dense → con1D → pooling`은 위 `lstm`처럼 좀 이상한 네트워크 구조가 되는 거라 생각함...\r\n\r\n* Dense(1, activation='sigmoid')\r\n\r\n* **LSTM에서 FNN으로 보내는 마지막 Dense에선 relu 쓰면 안됨**\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# FNN(순방향 신경망)\r\n\r\n* ↔ RNN\r\n  \r\n* hidden 층에서\r\n  \r\n  * Dense(4, `activation` = 'sigmoid', `kernel_regularizer`=regularizers.l2(0.0001), activation='relu')\r\n  * `Dropout`(rate=0.5)\r\n* `BatchNormalization`(momentum=0.9, epsilon=0.005, center=True, scale=True, moving_variance_initializer='ones')\r\n  \r\n* `predict`까지 끝낸 **연속형** `yHat` 값을, `np.where` 써줘서 **바이너리 형태**로 변환 \r\n\r\n  ``` python\r\n  np.where(yHat > 0.5, 1, 0)\r\n  # 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기_커스텀loss.py\r\n  ```\r\n\r\n* `history` 활용\r\n\r\n  ```python\r\n  hist.history['loss']\r\n  hist.history['val_loss']\r\n  # 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기.py\r\n  ```\r\n\r\n* 학습/평가/예측용 model로 나누었을 때 **평가 데이터 활용**\r\n\r\n  ```python\r\n  model.fit(trainX, trainY, validation_data=(evlX, evlY), epochs=200, batch_size=50)\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# LSTM\r\n\r\n* long term(장기기억, 전체적 흐름), short term(단기기억, 최근의 흐름)\r\n*  |                 | 설명                                                         |\r\n  | --------------- | ------------------------------------------------------------ |\r\n  | 2층             | `lstm()`을 2번 써준다                                        |\r\n  | 양방향          | `bidirectional` + `merge_mode = ‘concat’` <br />FNN, BFN 값을 merge_mode 형태로 합쳐서 list형으로 되돌려줌<br />단방향(FBN)은 ‘이후’만 기억, 양방향(FBN+BFN)은 ‘이전’+’이후’ 모두 기억 |\r\n  | many-to-many    | `return-sequences = True`<br />LSTM 뉴런 **각각의 중간 스텝에서 나오는 각각의 출력(h)**을 (바로 위 뉴런으로도) 사용(전파)한다는 뜻 |\r\n  | timedistributed | `timedistributed()`<br /> **FFN으로 가기 전** LSTM 마지막 층에서 각 뉴런의 각 지점에서 계산한 오류를 다음 층으로 전파 |\r\n\r\n* LSTM이 many-to-many 상태에서 FNN으로 가면 각각의 Output 값이 나온다\r\n\r\n  * NLP의 챗봇, 기계번역 등에서 사용함.\r\n    * Input > 안녕 만나서 반가워\r\n    * Output > 저도 반갑습니다\r\n    * 3개의 출력층. 비어 있는 1개는 padding \r\n    * Q. ... padding은 어디로?\r\n\r\n* LSTM에서 사용되는 h와 c\r\n\r\n  |      | 역할              | 특징                                                  |\r\n  | ---- | ----------------- | ----------------------------------------------------- |\r\n  | h    | **위, 왼쪽** 전파 | LSTM이 1층일 땐 c랑 똑같이 왼쪽으로 밖에 전파 못한다. |\r\n  | c    | **왼쪽** 전파     |                                                       |\r\n\r\n  > h와 c 둘다 처음엔 0으로 시작한다.\r\n\r\n  \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# CNN\r\n\r\n* 이미지를 대표할 수 있는 특성들을 도출해서 FNN에 넣어줌\r\n\r\n* | code                                                         | 설명                                                         |\r\n  | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n  | `Input`(batch_shape = (None, nStep, nFeature, nChannel))     |                                                              |\r\n  | `Conv2D`(filters=30, kernel_size=(8,3), strides=1, padding = 'same', activation='relu') |                                                              |\r\n  | `MaxPooling2D`(pool_size=(2,1), strides=1, padding='valid')  | - 경우에 따라 conv2D, pooling 더 써줄 수 있음<br />- `GlobalMaxPooling1D()`도 있음 |\r\n  | `Flatten()`                                                  | 2D는 4차원이라 shape 맞추려고 보통 flatten을 써줌<br />1d는 안 써도 되는 듯(?) |\r\n  | `Dense`(nOutput, activation='linear')                        |                                                              |\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## LSTM과 CNN의 차이\r\n\r\n* 둘다 (흐름을 보는)시계열 데이터에 사용할 수 있다.\r\n* LSTM과 CNN1D는 기능은 비슷하지만 CNN1D는 table 中 **(colum 전체+n row)아래 방향으로의 흐름**을 보는 거고, \r\n* LSTM은 bidirectional 을 사용해서 table 中 **위/아래로 흐름**을 이동시켜서 볼 수 있다.\r\n* CNN2D는 kernel_size, pooling 등을 통해 tabel 中 **(n colum(일부분) + n row(일부분) = 내가 focus를 맞춰 보고 싶은 부분)에 따라 그 흐름을 볼 수 있다는 데**서 차이가 있다.\r\n\r\n![image-20200805122723206](markdown-images/image-20200805122723206.png)\r\n\r\n\r\n\r\n\r\n\r\n# activation\r\n\r\n* | activation(비선형 함수) | loss                                                         |\r\n  | ----------------------- | ------------------------------------------------------------ |\r\n  | `softmax`               | `sparse_categorical_crossentropy`                            |\r\n  | `sigmoid`               | `binary_crossentropy`                                        |\r\n  | `linear`                | `mse`                                                        |\r\n  | `relu`                  | ← Hidden layer에 씀. 기울기가 0이기 때문에 뉴런이 죽을 수 있는 단점 有 |\r\n  |                         |                                                              |\r\n  | Leakly ReLU             | 뉴런이 죽을 수 있는 현상 해결                                |\r\n  | PReLU                   | x<0 에서 학습 가능                                           |\r\n  | granger causality       | 통제된 상황에서 인과관계가 가능하다고 말할 수 있음. 시계열 데이터에서 쓰일 수 있음 |\r\n\r\n  > * sparse_categorical_crossentropy\r\n  >\r\n  > ```python\r\n  > model = Model([encoderX, decoderX], outputY)\r\n  > model.compile(optimizer=optimizers.Adam(lr=0.001), loss='sparse_categorical_crossentropy')\r\n  > ```\r\n  >\r\n  > * sparse 안 쓸 거면 위에 'outputY'를 to_categorical()로 변형 후, loss 함수로 \"categorical_crossentropy\" 사용\r\n> * target이 one-hot encoding되어 있으면 categorical_crossentropy,\r\n  >   target이 integer로 되어 있으면 sparse_categorical_crossentropy를 쓴다.\r\n  >   sparse_categorical_entropy는 integer인 target을 one-hot으로 바꾼 후에 categorical_entropy를 수행한다.\r\n\r\n* 딥러닝 네트워크(DN)의 노드는 입력값을 전부 더한 후, 활성화 함수(Activation function)를 통과시켜 다음 노드에 전달한다.\r\n  \r\n  * 이때 사용하는 활성화 함수는 비선형 함수를 쓴다. \r\n\r\n\r\n\r\n\r\n\r\n## softmax - sigmoid\r\n\r\n| 구분           | 함수                           | code                                                         |\r\n| -------------- | ------------------------------ | ------------------------------------------------------------ |\r\n| 회귀           | 항등함수(출력값을 그대로 반환) |                                                              |\r\n| 분류(0/1)      | sigmoid                        | # 시험 데이터로 학습 성능을 평가한다<br/>predicted = model.predict(test_input)<br/>test_pred = np.where(predicted > 0.5, 1, 0)<br/>accuracy = (test_label == test_pred).mean() |\r\n| 분류(multiple) | softmax                        |                                                              |\r\n\r\n>  Cross-Entropy : 예측한 값과 실제값의 차를 계산. entropy 값이 감소하는 방향으로 진행하다 보면 최저 값을 찾을 수 있다. \r\n>\r\n> * sshkim Sh.TK. 2017. 8. 23. \"[모두의딥러닝] Softmax Regression (Multinomial Logistic Regression)\". \"https://sshkim.tistory.com/146\"\r\n\r\n>  argmax 을 사용하면 2라는 값이 나온다. 가장 큰 값의 위치가 2번째에 있는 1이기 때문\r\n>\r\n> * JINSOL KIM. 2017. 12. 24. \"Softmax vs Sigmoid\". https://blog.naver.com/infoefficien/221170205067\r\n\r\n\r\n\r\n\r\n\r\n## ReLu\r\n\r\n* 히든층에 자주 쓰임\r\n\r\n* 그냥 CNN이든 LSTM이든 출력층 Dense에 Relu 쓰지 말자\r\n\r\n  * LSTM에선 Relu 안 쓰는 게 좋음. 특히 출력층엔 쓰면 안 됨.\r\n\r\n  \r\n\r\n\r\n\r\n\r\n\r\n------------------\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# 학습(compile), 예측(predict)\r\n\r\n\r\n\r\n## optimizer\r\n\r\n* | 종류(빈도순)               |\r\n  | -------------------------- |\r\n  | `adam`                     |\r\n  | Adadelta, RMSprop, Adagrad |\r\n  | `momentum`                 |\r\n  | GD, NAG                    |\r\n\r\n* 최적화가 잘 안 되면 글로벌 minmun을 찾지 못하고 로컬 minimum에 빠진다. 이때 로컬 minimum을 **어떻게 빨리** 탈출할 수 있을지 U턴 메소드를 쓸지, 다른 1차 미분방법(GD)를 쓸 지 결정하게 된다. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## epoch\r\n\r\n* `epoch` 수치가 커지면 `optimizer`가 일을 해서 local이 아닌 global을 찾아간다.\r\n* 그런데 너무 크면 overfitting\r\n* 따라서 적당한 `epoch` 설정이 필요 \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## Batch_size\r\n\r\n* data가 크면 `batch_size`도 크게\r\n  * 25,000개의 raw data라면 `batch_size` = 20 보다 300 이 정도로 설정\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n-----------------------\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# NLP & DL\r\n\r\n\r\n\r\n## SGNS\r\n\r\n| 용어          | 설명                      | CODE                                | 참고                             |\r\n| ------------- | ------------------------- | ----------------------------------- | -------------------------------- |\r\n| pre-trained   | SGNS에서 학습한 We를 적용 | model.layers[1]**.set_weights**(We) | 해당 code 적용 후 model fit 진행 |\r\n| fine-training |                           |                                     |                                  |\r\n\r\n\r\n\r\n* SGNS에 모델 학습(fit) 시, 학습을 따로 시키는 이유?\r\n\r\n  ```python\r\n  # 학습\r\n  hist = model.fit([X[:, 0], X[:, 1]], X[:, 2], \r\n                   batch_size=BATCH_SIZE,\r\n                   epochs=NUM_EPOCHS)\r\n  ```\r\n\r\n  > *  각기 연결된 가중치 선이 구분되어 있기 때문에\r\n\r\n\r\n\r\n* SGNS 모델 만들 때 dot을 한다면, \r\n\r\n  1. **axis=2**    *@2*\r\n\r\n     → 후에\r\n\r\n  2. reshape**(())**    *@괄호 두 개*\r\n\r\n\r\n\r\n* SGNS로 만든 Embedding의 w(가중치)를 basic한 word data에 적용할 때, load_weights 사용하는 방법도 있다.\r\n\r\n  * 근데 이땐 shape을 맞춰줘야 한다.\r\n\r\n  ```python\r\n  w = encoder.load_weights('model_w.h5') # 가중치(w) 불러온 후,\r\n  emb = Embedding(max_features, embedding_dims, load_weights = w)(xInput) # embedding layer에 바로 적용\r\n  ```\r\n\r\n  * 보통 이런 느낌으로 씀\r\n\r\n    ```python\r\n    weights = load_weights()\r\n    embedding_layer = Embedding(input_dim=V,\r\n                                output_dim=embedding_dim,\r\n                                input_length=input_length,\r\n                                trainable=False,\r\n                                weights=weights,\r\n                                name='embedding')\r\n    ```\r\n\r\n    \r\n\r\n\r\n\r\n## Embedding & pad_sequences\r\n\r\n\r\n\r\n### word2vec 기준\r\n\r\n| word2vec      | code                                                         | input                                                  | output                                                 |\r\n| ------------- | ------------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ |\r\n| tokenizer     | tokenizer = Tokenizer()<br />tokenizer.fit_on_texts(clean_train_review)<br />train_sequences = tokenizer.texts_to_sequences(clean_train_review) | [안녕, 만나서, 반가워]                                 | [13, 4, 3]                                             |\r\n| pad_sequences | train_inputs = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post') | [13, 4, 3]                                             | ([0,0...1,..],<br />[0,0,0,1,0,...],<br />[0,0,1,...]) |\r\n| Embedding     | embedding_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE) | ([0,0...1,..],<br />[0,0,0,1,0,...],<br />[0,0,1,...]) | [0,0...1,..] -> ANN layer                              |\r\n\r\n> embedding_layer 는 결국 pad_sequence된 단어들끼리 모임. 즉, 1개 문장에 대한 임베딩 행렬이 됨 \r\n>\r\n> 1개 단어 = 1개 임베딩 레이어=벡터값\r\n\r\n\r\n\r\n\r\n\r\n### doc2vec 기준\r\n\r\n| doc2vec        | code                                                         | input                                                        | output                                                       |\r\n| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| TaggedDocument | documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)] | [...,'laughabl',<br/>  'horror'],<br/> ...]                  | TaggedDocument(words=['move', 'last', ... 'horror'], tags=[999]) |\r\n| Embedding      | model = Doc2Vec(vector_size=300, alpha=0.025, min_alpha=0.00025, min_count=10, workers=4, dm =1) | TaggedDocument(words=['move', 'last', ... 'horror'], tags=[999]) | [벡터값]                                                     |\r\n\r\n> tags=[999] : 999번 째 문장\r\n>\r\n> Embedding은 model.build_vocab, model.train 거치면 한 문장에 대한 하나의 벡터가 나온다.\r\n>\r\n> (word2vec의 경우 한 문장에 있는 각각의 단어 수만큼 벡터가 나온다.)\r\n>\r\n> 1개 문장 = 1개 임베딩 레이어 = 1개 벡터값\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n----------------------\r\n\r\n\r\n\r\n\r\n\r\n# ChatBot\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## Sequence to Sequence\r\n\r\n| encoder | decoder | 가능/불가능 |\r\n| ------- | ------- | ----------- |\r\n| 1층     | 2층     | *불가능*    |\r\n| 1층     | 1층     | 가능        |\r\n| 2층     | 1층     | 가능        |\r\n| 2층     | 2층     | 가능        |\r\n\r\n> \"굳이 2층으로 할 필요가 있는가?\"\r\n>\r\n> → 1층으로 하는 건 선형의 개념. 2층은 비선형의 개념이다.\r\n>\r\n> 비선형이 분류를 더 잘해낼 수도 있지만, overfitting의 위험이 있다. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n-----------\r\n\r\n\r\n\r\n\r\n\r\n# 기타\r\n\r\n\r\n\r\n## 유클리디안 거리\r\n\r\n* 거리 계산할 때, 비교하고 싶은 건 `[]`를 쳐서 넣어주기  \r\n\r\n  ```python\r\n  euclidean_distances([father, mother])\r\n  ```\r\n\r\n\r\n\r\n## 가중치 저장(Save)\r\n\r\n* Embedding (left side) layer의 W를 저장할 때, [2]를 저장한단 사실 알아두기\r\n\r\n  ```python\r\n  with open('data/embedding_W.pickle', 'wb') as f:\r\n      pickle.dump(model.layers[2].get_weights(), f, pickle.HIGHEST_PROTOCOL)\r\n  ```\r\n\r\n\r\n\r\n","excerpt":"W(weights) 네트워크 및 model build까지 완성해서 실행되어 역전파 되었을 때 형성된다. : 네트워크 만들고 난 후 model build하는 과정. optimizer & loss 값을 정의해주는 부분임. w…","fields":{"slug":"/TQT(The question I asked the teacher today.)/"},"frontmatter":{"date":"Aug 01, 2020","title":"TQT(The question I asked the teacher today)","tags":["TQT"],"update":"Aug 06, 2020"}}}]}},"pageContext":{}},"staticQueryHashes":["3649515864","694178885"]}