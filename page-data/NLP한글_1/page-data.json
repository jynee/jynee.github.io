{"componentChunkName":"component---src-templates-post-tsx","path":"/NLP한글_1/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"one-hot-인코딩\" style=\"position:relative;\"><a href=\"#one-hot-%EC%9D%B8%EC%BD%94%EB%94%A9\" aria-label=\"one hot 인코딩 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>one-hot 인코딩</h1>\n<ul>\n<li>categorical 변환 방법</li>\n</ul>\n<br>\n<br>\n<h2 id=\"code-classlanguage-textkerascode\" style=\"position:relative;\"><a href=\"#code-classlanguage-textkerascode\" aria-label=\"code classlanguage textkerascode permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">keras</code></h2>\n<ul>\n<li>\n<p>Keras를 이용한 one-hot encoding</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'남자'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'여자'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'아빠'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'엄마'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'삼촌'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'이모'</span><span class=\"token punctuation\">]</span>\nvalues <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>values<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">sorted</span><span class=\"token punctuation\">(</span>values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>['남자' '여자' '아빠' '엄마' '삼촌' '이모']\n['남자', '삼촌', '아빠', '엄마', '여자', '이모']</p>\n</blockquote>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils <span class=\"token keyword\">import</span> to_categorical\nencoded <span class=\"token operator\">=</span> to_categorical<span class=\"token punctuation\">(</span>integer_encoded<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>encoded<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[1. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 1. 0.]\n[0. 0. 1. 0. 0. 0.]\n[0. 0. 0. 1. 0. 0.]\n[0. 1. 0. 0. 0. 0.]\n[0. 0. 0. 0. 0. 1.]]</p>\n</blockquote>\n</li>\n</ul>\n<br>\n<h2 id=\"code-classlanguage-textsklearncode\" style=\"position:relative;\"><a href=\"#code-classlanguage-textsklearncode\" aria-label=\"code classlanguage textsklearncode permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">sklearn</code></h2>\n<ul>\n<li>\n<p>sklearn의 preprocessing을 이용한 one-hot encoding 방법</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'남자'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'여자'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'아빠'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'엄마'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'삼촌'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'이모'</span><span class=\"token punctuation\">]</span>\nvalues <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>values<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">sorted</span><span class=\"token punctuation\">(</span>values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>['남자' '여자' '아빠' '엄마' '삼촌' '이모']\n['남자', '삼촌', '아빠', '엄마', '여자', '이모']</p>\n</blockquote>\n<br>\n<ul>\n<li>label 인코딩 필요</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">as</span> sk\n\nlabel_encoder <span class=\"token operator\">=</span> sk<span class=\"token punctuation\">.</span>LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ninteger_encoded <span class=\"token operator\">=</span> label_encoder<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>values<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>integer_encoded<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[0]\n[4]\n[2]\n[3]\n[1]\n[5]]</p>\n</blockquote>\n<br>\n<ul>\n<li>OneHotEncoding</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># integer encoding</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>integer_encoded<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># binary encoding</span>\ninteger_encoded <span class=\"token operator\">=</span> integer_encoded<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>integer_encoded<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nonehot_encoder <span class=\"token operator\">=</span> sk<span class=\"token punctuation\">.</span>OneHotEncoder<span class=\"token punctuation\">(</span>sparse<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> categories<span class=\"token operator\">=</span><span class=\"token string\">'auto'</span><span class=\"token punctuation\">)</span>\nonehot_encoded <span class=\"token operator\">=</span> onehot_encoder<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>integer_encoded<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>onehot_encoded<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[1. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 1. 0.]\n[0. 0. 1. 0. 0. 0.]\n[0. 0. 0. 1. 0. 0.]\n[0. 1. 0. 0. 0. 0.]\n[0. 0. 0. 0. 0. 1.]]</p>\n</blockquote>\n<br>\n</li>\n<li>\n<p>단점: OOV 문제</p>\n<ul>\n<li>해결을 위한 노력: 페이스북의 FastText</li>\n</ul>\n</li>\n</ul>\n<br>\n<br>\n<hr>\n<br>\n<br>\n<h1 id=\"code-classlanguage-texthashcode\" style=\"position:relative;\"><a href=\"#code-classlanguage-texthashcode\" aria-label=\"code classlanguage texthashcode permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">Hash</code></h1>\n<br>\n<h2 id=\"indexing\" style=\"position:relative;\"><a href=\"#indexing\" aria-label=\"indexing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Indexing</h2>\n<ul>\n<li>예) 견출지</li>\n<li>SQL의 내부 알고리즘</li>\n<li>\n<p>단점: 견출지 붙일 때, 몇 장마다 붙일지 미리 정해야 됨</p>\n<ul>\n<li>Key의 범위가 넓다면 Memory 비효율성</li>\n</ul>\n</li>\n<li>장점: 나중에 찾을 때, 빠르다</li>\n<li>\n<p>검색 속도는 빠르다</p>\n<br>\n</li>\n</ul>\n<h2 id=\"hashing\" style=\"position:relative;\"><a href=\"#hashing\" aria-label=\"hashing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hashing</h2>\n<ul>\n<li>예) apple이란 단어를 수치변환하여 84 page의 36번째 line에 기록한다</li>\n<li>다른 단어를 입력할 때, apple에 적용했던 방법을 답습하여 손쉽게 기록할 수 있다</li>\n<li>\n<p>단점: collision 발생</p>\n<ul>\n<li>apple과 tiger 단어가 우연히 같은 line에 기록될 수 있다. </li>\n<li>단점 해결: overflow 처리</li>\n</ul>\n</li>\n<li>\n<p>장점: 메모리 효율성</p>\n<ul>\n<li>특히 넓은 key 영역에서 효율적이다.</li>\n</ul>\n</li>\n</ul>\n<br>\n<h2 id=\"hashing을-단어-표현에-적용\" style=\"position:relative;\"><a href=\"#hashing%EC%9D%84-%EB%8B%A8%EC%96%B4-%ED%91%9C%ED%98%84%EC%97%90-%EC%A0%81%EC%9A%A9\" aria-label=\"hashing을 단어 표현에 적용 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hashing을 단어 표현에 적용</h2>\n<ul>\n<li>\n<p>Hashing trick을 위한 word emgedding 방법</p>\n<ul>\n<li>vocabulary 크기를 미리 지정(hash table)하고, 단어들을 hash table에 대응 시키는 방식</li>\n</ul>\n</li>\n<li>\n<p>hash('apple') or md5('apple') % 8 = 1</p>\n<ul>\n<li>'% 8' : 모듈러 연산을 취해준다</li>\n<li>'1' : vetor화 시킨 것 => 1번째 line에 있다</li>\n</ul>\n</li>\n<li>현업에선 \"collision 발생 확률을 몇 프로로 줄이기 위해 hash table의 크기를 몇으로 둘 것인가?\" 에 관해 논의 후 설계하기도 함</li>\n<li>code: 3-2. hashing_trick.py</li>\n</ul>\n<br>\n<br>\n<hr>\n<br>\n<br>\n<h1 id=\"카운트-기반-방법code-classlanguage-textco-occurrence-matrixcode\" style=\"position:relative;\"><a href=\"#%EC%B9%B4%EC%9A%B4%ED%8A%B8-%EA%B8%B0%EB%B0%98-%EB%B0%A9%EB%B2%95code-classlanguage-textco-occurrence-matrixcode\" aria-label=\"카운트 기반 방법code classlanguage textco occurrence matrixcode permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>카운트 기반 방법(<code class=\"language-text\">Co-occurrence matrix</code>)</h1>\n<ul>\n<li>Co-occurrence matrix: 동시 발생(출현) 행렬</li>\n<li>같이 쓰인 횟수(인접 사용한 횟수)를 matrix에 기록하는 것 </li>\n<li>학습 기반이 아닌 <strong>빈도 기반</strong>의 단어들 간의 관계 정보(단어 간 유사도)를 내포하고 있다.</li>\n<li>모든 단어를 vocabulary라고 할 때, one-hot의 size(개수) = vocabulary의 size(개수) = 단어 벡터</li>\n<li>\n<p>one-hot 인코딩이 아니다.</p>\n<ul>\n<li>예) 0 0 0  2 1 0 0 0 </li>\n</ul>\n</li>\n<li>대칭 행렬, 희소 행렬('0'이 많음)</li>\n<li>\n<p>긴 단어일수록 차원이 크다</p>\n<ul>\n<li>SVD(특이값 분해)를 사용해 단어 벡터의 차원을 줄일 수 있다.</li>\n<li>약 25% 정도 줄일 수 있다.</li>\n<li>vocab 사이즈를 줄이고 embedding layer에 쓴 것처럼.<br></li>\n</ul>\n</li>\n<li>\n<p>(Documnet Term Freq 2개) Xt와 X의 곱행렬을 하면, 일일이 빈도를 구하지 않아도 문장 간 공통된 단어가 쓰인 횟수를 행렬로 만들 수 있다.</p>\n<ul>\n<li>그렇게 만들어진 행렬이 Co-occurrence matrix<br></li>\n</ul>\n</li>\n<li>\n<p>Unigram(1단어), Bigram(2단어)까지 vocab을 만들 수 있다.</p>\n<ul>\n<li>조합이 더 많아진다.<br></li>\n</ul>\n</li>\n<li>\n<p>Glove: </p>\n<ul>\n<li>아래 2개의 단점을 고려해 장점을 합친 것 </li>\n<li>Co-occurrence matrix: (빈도 기반) 전체 단어를 고려했다.</li>\n<li>Skip-gram: (학습 기반)주변 단어에 한정했다.</li>\n<li>두 단어를 Embedding layer에 통과시키고(학습기반) 각 vector의 내적의 합(빈도기반)을 구해 거리를 구한다.</li>\n<li>log(P(도서관, 갔다)) = 0.33 </li>\n<li>기계 : 도서관은... 가는 곳이다.... 라고 기계가 인식함 <br></li>\n</ul>\n</li>\n<li>단점: 계산량이 많다</li>\n</ul>\n<br>\n<br>\n<h2 id=\"code-classlanguage-text특이값-분해svd-차원축소code-code\" style=\"position:relative;\"><a href=\"#code-classlanguage-text%ED%8A%B9%EC%9D%B4%EA%B0%92-%EB%B6%84%ED%95%B4svd-%EC%B0%A8%EC%9B%90%EC%B6%95%EC%86%8Ccode-code\" aria-label=\"code classlanguage text특이값 분해svd 차원축소code code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">특이값 분해(SVD: 차원축소)</code> code</h2>\n<blockquote>\n<ul>\n<li>\n<p>LSA : 잠재 의미 분석 </p>\n<ul>\n<li>U, S, VT 행렬의 의미 --> Latent Semantic Analysis (LSA)</li>\n<li>U 행렬 ~ 차원 = (문서 개수 X topic 개수) : 문서당 topic 분포</li>\n<li>S 행렬 ~ 차원 = (topic 개수 X topic 개수) : 대각성분. 나중에 행렬에 넣을 땐 대각성분만 빼면 0</li>\n<li>VT 행렬. 차원 = (topic 개수 X 단어 개수) : topic 당 단어 빈도의 분포</li>\n</ul>\n</li>\n</ul>\n<p>=> 이를 여기선 <strong>문장과 단어 사이의 관계로 해석</strong></p>\n</blockquote>\n<br>\n<ul>\n<li>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b9872c633b3e4a7f22f8c0e9e281b945/78958/image-20200722094819751.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.70270270270271%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABl0lEQVQoz2WT6XLCMAyE/f5v2B8tpSFNgNzORRJQ93Njhk6Z0TiWVseujLtcLna9Xq0oCquqyuq6DmdZluGbs21bezweFn+v39M0Wdd11ve9zfNsDscwDP+A/O73+/PEiEfMtm22LMsfLDF3u90Mo/o4jgFEk+jHon9d1zA9rLDz+RzYcXIH47gAgjIOkqEIXSb33gdKNKQ4sSzLLEkSS9PUTqeTHY9Hy/M8TPmckGI4oMIk0cc9+jCmb5rGovZhQhVDa3COKVoBvO9CsFKAhFmJJDMp0zMZ/kHiv2pKk3mXLBRkklXB27KFouMoass+jUA0pDDJJLyubdU96K8mozCLctxZGlTHL+ta/7vpdbMqkU86+V1ouseNbmgqfyPt889Pq4WbxADfJDauVKBRwIvOvv8AmHQnaVYhlsKy7lAU9fzjw7Ld0vd3yw4HS97erJdkbpJmo0Bss+Axy3ptvd/PQV294hQMDGS9sFeejhqyEE42jzyu5onIWEj6/W0XWSkZCkxPI5gSaFbuxpI44z+q3J8di/sBVyJODi8AubUAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20200722094819751\"\n        title=\"image-20200722094819751\"\n        src=\"/static/b9872c633b3e4a7f22f8c0e9e281b945/fcda8/image-20200722094819751.png\"\n        srcset=\"/static/b9872c633b3e4a7f22f8c0e9e281b945/12f09/image-20200722094819751.png 148w,\n/static/b9872c633b3e4a7f22f8c0e9e281b945/e4a3f/image-20200722094819751.png 295w,\n/static/b9872c633b3e4a7f22f8c0e9e281b945/fcda8/image-20200722094819751.png 590w,\n/static/b9872c633b3e4a7f22f8c0e9e281b945/efc66/image-20200722094819751.png 885w,\n/static/b9872c633b3e4a7f22f8c0e9e281b945/c83ae/image-20200722094819751.png 1180w,\n/static/b9872c633b3e4a7f22f8c0e9e281b945/78958/image-20200722094819751.png 1320w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<br>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>feature_extraction<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> CountVectorizer</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">docs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'성진과 창욱은 야구장에 갔다'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'성진과 태균은 도서관에 갔다'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'성진과 창욱은 공부를 좋아한다'</span><span class=\"token punctuation\">]</span></code></pre></div>\n<br>\n<ul>\n<li>Vocab 만들기 </li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">count_model <span class=\"token operator\">=</span> CountVectorizer<span class=\"token punctuation\">(</span>ngram_range<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># gram_range=(1,1): Unigram 단어 1개씩 동시 발생. # CountVectorizer: 문장의 단어를 단어 하나씩 자른단 뜻 </span>\nx <span class=\"token operator\">=</span> count_model<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>docs<span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<ul>\n<li>문서에 사용된 사전을 조회한다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>count_model<span class=\"token punctuation\">.</span>vocabulary_<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>{'성진과': 3, '창욱은': 6, '야구장에': 4, '갔다': 0, '태균은': 7, '도서관에': 2, '공부를': 1, '좋아한다': 5}</p>\n</blockquote>\n<br>\n<ul>\n<li>Compact Sparse Row(CSR) format: 단어별 빈도를 표현한다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># (row, col) value</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>  (0, 3)\t1\n(0, 6)\t1\n(0, 4)\t1\n(0, 0)\t1\n(1, 3)\t1\n(1, 0)\t1\n(1, 7)\t1\n(1, 2)\t1\n(2, 3)\t1\n(2, 6)\t1\n(2, 1)\t1\n(2, 5)\t1</p>\n</blockquote>\n<br>\n<ul>\n<li>행렬 형태로 표시한다. (Document-Term Freq)</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p><em>print(x.toarray())</em> ></p>\n<p>[[1 0 0 1 1 0 1 0]\n[1 0 1 1 0 0 0 1]\n[0 1 0 1 0 1 1 0]]</p>\n</blockquote>\n<blockquote>\n<p><em>print(x.T.toarray())</em> ></p>\n<p>[[1 1 0]\n[0 0 1]\n[0 1 0]\n[1 1 1]\n[1 0 0]\n[0 0 1]\n[1 0 1]\n[0 1 0]]</p>\n<ul>\n<li>x.T의 의미 >\n1 2 3  - 문장\n갔다    [[1 1 0] - '갔다'라는 단어는 문장-1과 문장-2에 쓰였음.\n공부를   [0 0 1] - '공부를'은 문장-3에만 쓰였음.\n도서관에 [0 1 0]\n성진과   [1 1 1]\n야구장에 [1 0 0]\n좋아한다 [0 0 1]\n창욱은   [1 0 1]\n태균은   [0 1 0]]</li>\n</ul>\n</blockquote>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">xc <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>T <span class=\"token operator\">*</span> x <span class=\"token comment\"># this is co-occurrence matrix in sparse csr format</span>\nxc<span class=\"token punctuation\">.</span>setdiag<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># sometimes you want to fill same word cooccurence to 0</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>xc<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>0<br />갔다</th>\n<th>1<br />공부를</th>\n<th>2<br />도서관에</th>\n<th>3<br />성진과</th>\n<th>4<br />야구장에</th>\n<th>5<br />좋아한다</th>\n<th>6<br />창욱은</th>\n<th>7<br />태균은</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0 갔다</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>2</td>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n</tr>\n<tr>\n<td>1 공부를</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n<td>0</td>\n</tr>\n<tr>\n<td>2 도서관에</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>3 성진과</td>\n<td>2</td>\n<td>1</td>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n<td>2</td>\n<td>1</td>\n</tr>\n<tr>\n<td>4 야구장에</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n</tr>\n<tr>\n<td>5 좋아한다</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n</tr>\n<tr>\n<td>6 창욱은</td>\n<td>1</td>\n<td>1</td>\n<td>0</td>\n<td>2</td>\n<td>1</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>7 태균은</td>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n</tbody>\n</table>\n</blockquote>\n<br>\n<ul>\n<li>\n<p><em>참고</em> > ngram<em>range(min</em>n = 1, max_n = 2)인 경우</p>\n<ul>\n<li>즉,  ngram_range=(1,2):unigram과 bigram 둘다 동시에 조회하는 경우</li>\n</ul>\n<br>\n</li>\n<li>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">count_model <span class=\"token operator\">=</span> CountVectorizer<span class=\"token punctuation\">(</span>ngram_range<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> count_model<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>docs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 문서에 사용된 사전을 조회</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>count_model<span class=\"token punctuation\">.</span>vocabulary_<span class=\"token punctuation\">)</span>\n  \nxc <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>T <span class=\"token operator\">*</span> x <span class=\"token comment\"># this is co-occurrence matrix in sparse csr format</span>\nxc<span class=\"token punctuation\">.</span>setdiag<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># sometimes you want to fill same word cooccurence to 0</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>xc<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>{'성진과': 5, '창욱은': 11, '야구장에': 8, '갔다': 0, '성진과 창욱은': 6, '창욱은 야구장에': 13, '야구장에 갔다': 9, '태균은': 14, '도서관에': 3, '성진과 태균은': 7, '태균은 도서관에': 15, '도서관에 갔다': 4, '공부를': 1, '좋아한다': 10, '창욱은 공부를': 12, '공부를 좋아한다': 2}</p>\n</blockquote>\n<blockquote>\n<p>[[0 0 1 2 1 0 1 1]\n[0 0 0 1 0 1 1 0]\n[1 0 0 1 0 0 0 1]\n[2 1 1 0 1 1 2 1]\n[1 0 0 1 0 0 1 0]\n[0 1 0 1 0 0 1 0]\n[1 1 0 2 1 1 0 0]\n[1 0 1 1 0 0 0 0]]</p>\n</blockquote>\n</li>\n</ul>\n<br>\n<h3 id=\"변수-정리--x--xt--xc\" style=\"position:relative;\"><a href=\"#%EB%B3%80%EC%88%98-%EC%A0%95%EB%A6%AC--x--xt--xc\" aria-label=\"변수 정리  x  xt  xc permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>변수 정리</em> > x / x.T / xc</h3>\n<ul>\n<li>x: 단어별 빈도</li>\n<li>x.T: Sparse 해주려고 x를 transpose함</li>\n<li>\n<p>xc : x와 x.T의 곱행렬이자, 처음에 쓸 땐 co-occurrence matrix 만들기 위한 csr 형태. </p>\n<ul>\n<li>여기에 </li>\n<li>xc.setdiag(0) 해주고, </li>\n<li>xc.toarray() 해주면</li>\n<li>co-occurrence matrix 완성</li>\n</ul>\n<br>\n</li>\n</ul>\n<h3 id=\"numpy를-이용한-svd-예시\" style=\"position:relative;\"><a href=\"#numpy%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-svd-%EC%98%88%EC%8B%9C\" aria-label=\"numpy를 이용한 svd 예시 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>numpy를 이용한 SVD 예시</h3>\n<ul>\n<li>Co-occurrence matrix를 SVD로 분해한다.</li>\n<li>C = <strong>U</strong> , <strong>S</strong>, <strong>VT</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\nC <span class=\"token operator\">=</span> xc<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nU<span class=\"token punctuation\">,</span> S<span class=\"token punctuation\">,</span> VT <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>svd<span class=\"token punctuation\">(</span>C<span class=\"token punctuation\">,</span> full_matrices <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># np.linalg.svd 써주면 U, S, VT로 자동 분배됨</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>U<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>S<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>VT<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[-0.44 -0.39 -0.58  0.41  0.35  0.   -0.   -0.19]\n[-0.24 -0.12  0.29  0.41 -0.24  0.65 -0.29  0.35]\n[-0.24 -0.12 -0.29 -0.41 -0.24 -0.29 -0.65  0.35]\n[-0.56  0.8   0.   -0.    0.19  0.    0.    0.02]\n[-0.27 -0.01 -0.   -0.   -0.7   0.   -0.   -0.66]\n[-0.24 -0.12  0.29  0.41 -0.24 -0.65  0.29  0.35]\n[-0.44 -0.39  0.58 -0.41  0.35 -0.    0.   -0.19]\n[-0.24 -0.12 -0.29 -0.41 -0.24  0.29  0.65  0.35]] </p>\n</blockquote>\n<blockquote>\n<p>[5.27 2.52 1.73 1.73 1.27 1.   1.   0.53] </p>\n</blockquote>\n<blockquote>\n<p>[[-0.44 -0.24 -0.24 -0.56 -0.27 -0.24 -0.44 -0.24]\n[ 0.39  0.12  0.12 -0.8   0.01  0.12  0.39  0.12]\n[-0.    0.5  -0.5  -0.    0.    0.5  -0.   -0.5 ]\n[-0.71  0.   -0.    0.    0.    0.    0.71 -0.  ]\n[-0.35  0.24  0.24 -0.19  0.7   0.24 -0.35  0.24]\n[-0.   -0.65  0.29 -0.    0.    0.65  0.   -0.29]\n[-0.    0.29  0.65 -0.    0.   -0.29 -0.   -0.65]\n[-0.19  0.35  0.35  0.02 -0.66  0.35 -0.19  0.35]] </p>\n</blockquote>\n<br>\n<ul>\n<li>\n<p>S를 <strong>정방행렬</strong>로 바꾼다.</p>\n<ul>\n<li>S</li>\n<li>정방행렬이므로, 같은 수의 행과 열을 가지는 행렬</li>\n<li>대각행렬이므로, 대각 성분을 제외한 원소는 모두 0 인 행렬</li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">s <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>diag<span class=\"token punctuation\">(</span>S<span class=\"token punctuation\">)</span> <span class=\"token comment\"># s는 대각행렬이자 정방행렬</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[5.27 0.   0.   0.   0.   0.   0.   0.  ]\n[0.   2.52 0.   0.   0.   0.   0.   0.  ]\n[0.   0.   1.73 0.   0.   0.   0.   0.  ]\n[0.   0.   0.   1.73 0.   0.   0.   0.  ]\n[0.   0.   0.   0.   1.27 0.   0.   0.  ]\n[0.   0.   0.   0.   0.   1.   0.   0.  ]\n[0.   0.   0.   0.   0.   0.   1.   0.  ]\n[0.   0.   0.   0.   0.   0.   0.   0.53]]</p>\n</blockquote>\n<br>\n<ul>\n<li>A = <strong>U.s.VT</strong>를 계산하고, <strong>A와 C가 일치</strong>하는지 확인한다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">A <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>U<span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> VT<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>C<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[ 0.  0.  1.  2.  1.  0.  1.  1.]\n[-0.  0.  0.  1.  0.  1.  1.  0.]\n[ 1. -0.  0.  1.  0. -0.  0.  1.]\n[ 2.  1.  1.  0.  1.  1.  2.  1.]\n[ 1.  0. -0.  1.  0.  0.  1. -0.]\n[ 0.  1.  0.  1.  0. -0.  1.  0.]\n[ 1.  1.  0.  2.  1.  1.  0. -0.]\n[ 1. -0.  1.  1. -0. -0. -0.  0.]]</p>\n</blockquote>\n<blockquote>\n<p>[[0 0 1 2 1 0 1 1]\n[0 0 0 1 0 1 1 0]\n[1 0 0 1 0 0 0 1]\n[2 1 1 0 1 1 2 1]\n[1 0 0 1 0 0 1 0]\n[0 1 0 1 0 0 1 0]\n[1 1 0 2 1 1 0 0]\n[1 0 1 1 0 0 0 0]]</p>\n</blockquote>\n<br>\n<br>\n<h3 id=\"sklearn을-이용한-svd-예시\" style=\"position:relative;\"><a href=\"#sklearn%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-svd-%EC%98%88%EC%8B%9C\" aria-label=\"sklearn을 이용한 svd 예시 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>sklearn을 이용한 SVD 예시</h3>\n<ul>\n<li>Co-occurrence matrix를 SVD로 분해한다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>decomposition <span class=\"token keyword\">import</span> TruncatedSVD</code></pre></div>\n<br>\n<ul>\n<li>특이값 (S)이 큰 4개를 주 성분으로 C의 차원을 축소한다. </li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">svd <span class=\"token operator\">=</span> TruncatedSVD<span class=\"token punctuation\">(</span>n_components<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> n_iter<span class=\"token operator\">=</span><span class=\"token number\">7</span><span class=\"token punctuation\">)</span>\nD <span class=\"token operator\">=</span> svd<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>xc<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># fit_transform : 학습 시키고 transpose도 한꺼번에 시킴 </span>\n\nU <span class=\"token operator\">=</span> D <span class=\"token operator\">/</span> svd<span class=\"token punctuation\">.</span>singular_values_ <span class=\"token comment\"># svd.singular_values_ : 대각 성분의 값 </span>\nS <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>diag<span class=\"token punctuation\">(</span>svd<span class=\"token punctuation\">.</span>singular_values_<span class=\"token punctuation\">)</span> <span class=\"token comment\"># np.diag: '대각행렬'로, 대각 성분의 값만을 행렬 형태로 추출한 것. 정방행렬의 형태를 띄고 있음 </span>\nVT <span class=\"token operator\">=</span> svd<span class=\"token punctuation\">.</span>components_</code></pre></div>\n<blockquote>\n<p><em>print(np.round(U, 2), '\\n')</em> ></p>\n<p>[[ 0.44 -0.39  0.41 -0.58]\n[ 0.24 -0.12  0.41  0.29]\n[ 0.24 -0.12 -0.41 -0.29]\n[ 0.56  0.8  -0.    0.  ]\n[ 0.27 -0.01 -0.   -0.  ]\n[ 0.24 -0.12  0.41  0.29]\n[ 0.44 -0.39 -0.41  0.58]\n[ 0.24 -0.12 -0.41 -0.29]] </p>\n</blockquote>\n<blockquote>\n<p><em>print(np.round(S, 2), '\\n')</em> ></p>\n<p>[[5.27 0.   0.   0.  ]\n[0.   2.52 0.   0.  ]\n[0.   0.   1.73 0.  ]\n[0.   0.   0.   1.73]] </p>\n</blockquote>\n<blockquote>\n<p><em>print(np.round(VT, 2), '\\n')</em> ></p>\n<p>[[ 0.44  0.24  0.24  0.56  0.27  0.24  0.44  0.24]\n[ 0.39  0.12  0.12 -0.8   0.01  0.12  0.39  0.12]\n[-0.71  0.   -0.    0.    0.    0.    0.71 -0.  ]\n[-0.    0.5  -0.5  -0.    0.    0.5  -0.   -0.5 ]] </p>\n</blockquote>\n<br>\n<ul>\n<li>\n<p>C를 4개 차원으로 축소: truncated (U * S)</p>\n<ul>\n<li>U * S * VT 하면 원래 C의 차원과 동일해 진다. </li>\n<li>U * S가 축소된 차원을 의미하고, </li>\n<li>V는 <strong>축소된 차원을 원래 차원으로 되돌리는</strong> 역할을 한다 (mapping back)</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>D<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[ 2.31 -0.97  0.71 -1.  ]\n[ 1.24 -0.3   0.71  0.5 ]\n[ 1.24 -0.3  -0.71 -0.5 ]\n[ 2.97  2.03 -0.    0.  ]\n[ 1.44 -0.03 -0.   -0.  ]\n[ 1.24 -0.3   0.71  0.5 ]\n[ 2.31 -0.97 -0.71  1.  ]\n[ 1.24 -0.3  -0.71 -0.5 ]]</p>\n</blockquote>\n</li>\n</ul>\n<br>\n<h3 id=\"변수-정리--c--d--vt\" style=\"position:relative;\"><a href=\"#%EB%B3%80%EC%88%98-%EC%A0%95%EB%A6%AC--c--d--vt\" aria-label=\"변수 정리  c  d  vt permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>변수 정리</em> > C / D / Vt</h3>\n<ul>\n<li>원래 행렬: C</li>\n<li>\n<p>차원축소: D = U*S</p>\n<ul>\n<li>이때, U, S는 중요한 부분만 추림 U(truncated), S(truncated))</li>\n</ul>\n</li>\n<li>Vt = S를 기준으로 Vt를 truncated함 </li>\n</ul>\n<br>\n<h3 id=\"code-classlanguage-textsvdcode--numpy--sklearn-비교\" style=\"position:relative;\"><a href=\"#code-classlanguage-textsvdcode--numpy--sklearn-%EB%B9%84%EA%B5%90\" aria-label=\"code classlanguage textsvdcode  numpy  sklearn 비교 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">SVD</code> : Numpy &#x26; sklearn 비교</h3>\n<ul>\n<li>Co-occurrence matrix를 SVD로 분해</li>\n<li>여기서 말하는 '차원 축소': 한 문장 내 다른 문장과 쓰이는 중요 단어만 추출함</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Numpy</th>\n<th>sklearn</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Code</td>\n<td>import numpy as np</td>\n<td>from sklearn.decomposition import TruncatedSVD</td>\n</tr>\n<tr>\n<td></td>\n<td>> <strong>C = U.S.VT</strong><br />C = xc.toarray()<br/>U, S, VT = np.linalg.svd(C, full_matrices = True)</td>\n<td>> <strong>특이값 (S)이 큰 4개를 주 성분으로 C의 차원을 축소</strong><br />svd = TruncatedSVD(n<em>components=4, n</em>iter=7)<br/>D = svd.fit<em>transform(xc.toarray())<br />U = D / svd.singular</em>values<em><br/>S = np.diag(svd.singular</em>values<em>)<br/>VT = svd.components</em></td>\n</tr>\n<tr>\n<td></td>\n<td>> <strong>S를 정방행렬로 바꾼다.</strong><br/>s = np.diag(S)</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>> <strong>A = U.s.VT를 계산하고, A와 C가 일치하는지 확인</strong><br/>A = np.dot(U, np.dot(s, VT))</td>\n<td></td>\n</tr>\n<tr>\n<td>특징</td>\n<td>알아서 주성분을 추출해 차원 축소할 수 있다.</td>\n<td>원하는 수의 주성분으로 차원을 축소할 수 있다.</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<ul>\n<li>U * S * VT 하면 원래 C의 차원과 동일해 진다. </li>\n<li>U * S가 축소된 차원을 의미하고, </li>\n<li>V는 <strong>축소된 차원을 원래 차원으로 되돌리는</strong> 역할(mapping back)을 한다</li>\n</ul>\n</blockquote>\n<br>\n<br>\n<hr>\n<br>\n<br>\n<h1 id=\"텍스트-유사도거리-측정\" style=\"position:relative;\"><a href=\"#%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%9C%A0%EC%82%AC%EB%8F%84%EA%B1%B0%EB%A6%AC-%EC%B8%A1%EC%A0%95\" aria-label=\"텍스트 유사도거리 측정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>텍스트 유사도(거리 측정)</h1>\n<br>\n<h2 id=\"step-1-word의-vector화\" style=\"position:relative;\"><a href=\"#step-1-word%EC%9D%98-vector%ED%99%94\" aria-label=\"step 1 word의 vector화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step 1. word의 vector화</h2>\n<ul>\n<li><code class=\"language-text\">TfidfVectorizer</code> 사용</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>feature_extraction<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> TfidfVectorizer\n\nsent <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다.\"</span><span class=\"token punctuation\">,</span> \n        <span class=\"token string\">\"폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니다.\"</span><span class=\"token punctuation\">)</span> \n\ntfidf_vectorizer <span class=\"token operator\">=</span> TfidfVectorizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntfidf_matrix <span class=\"token operator\">=</span> tfidf_vectorizer<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>sent<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>tfidf_matrix<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[0.    0.324 0.    0.    0.324 0.324 0.324 0.324 0.324 0.324 0.    0.231\n0.324 0.231 0.    0.    0.231]\n[0.365 0.    0.365 0.365 0.    0.    0.    0.    0.    0.    0.365 0.259</p>\n<ol start=\"0\">\n<li>0.259 0.365 0.365 0.259]]</li>\n</ol>\n</blockquote>\n<br>\n<ul>\n<li><code class=\"language-text\">HashingVectorizer</code> 사용</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>feature_extraction<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> HashingVectorizer\n\nsent <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다.\"</span><span class=\"token punctuation\">,</span> \n        <span class=\"token string\">\"폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니다.\"</span><span class=\"token punctuation\">)</span> \n\nVOCAB_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">20</span> <span class=\"token comment\"># 사용자가 직접 지정해야 하는 값</span>\nhvectorizer <span class=\"token operator\">=</span> HashingVectorizer<span class=\"token punctuation\">(</span>n_features<span class=\"token operator\">=</span>VOCAB_SIZE<span class=\"token punctuation\">,</span>norm<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>alternate_sign<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nhash_matrix <span class=\"token operator\">=</span> hvectorizer<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>sent<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>hash_matrix<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[0. 2. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 2. 2. 0. 1. 0. 0. 0. 0.]\n[0. 2. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0.]]</p>\n</blockquote>\n<br>\n<h2 id=\"code-classlanguage-text자카드-유사도code\" style=\"position:relative;\"><a href=\"#code-classlanguage-text%EC%9E%90%EC%B9%B4%EB%93%9C-%EC%9C%A0%EC%82%AC%EB%8F%84code\" aria-label=\"code classlanguage text자카드 유사도code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">자카드 유사도</code></h2>\n<ul>\n<li>문장 中 중복되는 단어의 개수를 센다.</li>\n<li>두 문장에 겹친 단어 개수 / 사전의 전체 단어 개수</li>\n<li>\n<p>code</p>\n<ul>\n<li>(수치화(vector)화 안 하고) 문장 간의 겹치는 단어만 세는 것도 가능하다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sent_1 <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>sent<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nsent_2 <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>sent<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>sent_1<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>sent_2<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 합집합과 교집합을 구한다.</span>\nhap_set <span class=\"token operator\">=</span> sent_1 <span class=\"token operator\">|</span> sent_2 <span class=\"token comment\"># | : or</span>\ngyo_set <span class=\"token operator\">=</span> sent_1 <span class=\"token operator\">&amp;</span> sent_2 <span class=\"token comment\"># &amp; : and</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>hap_set<span class=\"token punctuation\">,</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>gyo_set<span class=\"token punctuation\">,</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>\n\njaccard <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>gyo_set<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>hap_set<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>jaccard<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>{'폭염', '있습니다.', '비', '휴일', '을'} </p>\n</blockquote>\n<br>\n<ul>\n<li>(수치화(vector)화 하고) jaccard_score 패키지</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">count_model <span class=\"token operator\">=</span> CountVectorizer<span class=\"token punctuation\">(</span>ngram_range<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># bigram은 ngram_range=(1,2) : (from, to) = 1에서 2까지</span>\nx <span class=\"token operator\">=</span> count_model<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>sent<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> jaccard_score\njaccard_score<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>0.17647058823529413</p>\n</blockquote>\n</li>\n</ul>\n<br>\n<h2 id=\"code-classlanguage-text코사인-유사도code\" style=\"position:relative;\"><a href=\"#code-classlanguage-text%EC%BD%94%EC%82%AC%EC%9D%B8-%EC%9C%A0%EC%82%AC%EB%8F%84code\" aria-label=\"code classlanguage text코사인 유사도code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">코사인 유사도</code></h2>\n<ul>\n<li>코사인 유사도는 클수록 유사도가 높다</li>\n<li>코사인 거리는 작을수록 거리가 좁다</li>\n<li>\n<p>code</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics<span class=\"token punctuation\">.</span>pairwise <span class=\"token keyword\">import</span> cosine_similarity\nd <span class=\"token operator\">=</span> cosine_similarity<span class=\"token punctuation\">(</span>tfidf_matrix<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> tfidf_matrix<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[0.17952266]]</p>\n</blockquote>\n</li>\n</ul>\n<br>\n<h2 id=\"code-classlanguage-text유클리디안-거리code\" style=\"position:relative;\"><a href=\"#code-classlanguage-text%EC%9C%A0%ED%81%B4%EB%A6%AC%EB%94%94%EC%95%88-%EA%B1%B0%EB%A6%ACcode\" aria-label=\"code classlanguage text유클리디안 거리code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">유클리디안 거리</code></h2>\n<ul>\n<li>L2 - Distance</li>\n<li>\n<p>code</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics<span class=\"token punctuation\">.</span>pairwise <span class=\"token keyword\">import</span> euclidean_distances\neuclidean_distances<span class=\"token punctuation\">(</span>tfidf_matrix<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> tfidf_matrix<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>array([[1.28099753]])</p>\n</blockquote>\n</li>\n</ul>\n<br>\n<h2 id=\"code-classlanguage-text맨하탄-거리code\" style=\"position:relative;\"><a href=\"#code-classlanguage-text%EB%A7%A8%ED%95%98%ED%83%84-%EA%B1%B0%EB%A6%ACcode\" aria-label=\"code classlanguage text맨하탄 거리code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">맨하탄 거리</code></h2>\n<ul>\n<li>L1 - Distance</li>\n<li>유클리디안 거리와의 비교: 거리 값은 유클리디안 거리가 작게 나오지만, 대각선의 길을 선택할 수 있다는 건 현실성이 떨어지기 때문에 맨하탄 거리를 선택하는 경우도 있다. </li>\n<li>\n<p>code</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics<span class=\"token punctuation\">.</span>pairwise <span class=\"token keyword\">import</span> manhattan_distances\nd <span class=\"token operator\">=</span> manhattan_distances<span class=\"token punctuation\">(</span>tfidf_norm_l1<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> tfidf_norm_l1<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>[[0.77865927]]</p>\n</blockquote>\n</li>\n</ul>\n<br>\n<h2 id=\"code-classlanguage-text정규화codel1--l2\" style=\"position:relative;\"><a href=\"#code-classlanguage-text%EC%A0%95%EA%B7%9C%ED%99%94codel1--l2\" aria-label=\"code classlanguage text정규화codel1  l2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">정규화</code>(l1 &#x26; l2)</h2>\n<ul>\n<li>\n<p><code class=\"language-text\">l1</code></p>\n<ul>\n<li>유클리디안/맨하탄 거리는 '거리'라 값이 1이 넘어갈 수 있기 때문에 가시적인 효과를 위해 0~1 사이의 값을 갖도록 L1 정규화를 수행한 후, 각각의 유클리디안/맨하탄 거리를 수행할 수도 있다.</li>\n<li>함수</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">l1_normalize</span><span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     \t\t<span class=\"token keyword\">return</span> v <span class=\"token operator\">/</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span>\n  \n\t\ttfidf_norm_l1 <span class=\"token operator\">=</span> l1_normalize<span class=\"token punctuation\">(</span>tfidf_matrix<span class=\"token punctuation\">)</span>\n\t\td <span class=\"token operator\">=</span> euclidean_distances<span class=\"token punctuation\">(</span>tfidf_norm_l1<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> tfidf_norm_l1<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\t\t<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>numpy 패키지</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">L1_norm <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">ord</span><span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>L1_norm<span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n</li>\n<li>\n<p><code class=\"language-text\">l2</code></p>\n<ul>\n<li>l2 + HashingVectorizer 패키지</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">VOCAB_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\nhvectorizer <span class=\"token operator\">=</span> HashingVectorizer<span class=\"token punctuation\">(</span>n_features<span class=\"token operator\">=</span>VOCAB_SIZE<span class=\"token punctuation\">,</span>norm<span class=\"token operator\">=</span><span class=\"token string\">'l2'</span><span class=\"token punctuation\">,</span>alternate_sign<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nhash_matrix <span class=\"token operator\">=</span> hvectorizer<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>sent<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>hash_matrix<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>\n<p>numpy 패키지</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\nL2_norm <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">ord</span><span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span> L2_norm<span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n</ul>\n</li>\n</ul>\n<br>\n<br>\n<br>\n<br>\n<br>\n<ul>\n<li>\n<p>참고: </p>\n<blockquote>\n<ul>\n<li>아마추어 퀀트, blog.naver.com/chunjein</li>\n<li>코드 출처 및 내용 공부: 전창욱, 최태균, 조중현. 2019.02.15. 텐서플로와 머신러닝으로 시작하는 자연어 처리 - 로지스틱 회귀부터 트랜스포머 챗봇까지. 위키북스</li>\n</ul>\n</blockquote>\n</li>\n</ul>","excerpt":"one-hot 인코딩 categorical 변환 방법  Keras를 이용한 one-hot encoding '남자' '여자' '아빠' '엄마' '삼촌' '이모'\n'남자', '삼촌', '아빠', '엄마', '여자', '이모' [1. 0. 0. 0.…","tableOfContents":"<ul>\n<li>\n<p><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#one-hot-%EC%9D%B8%EC%BD%94%EB%94%A9\">one-hot 인코딩</a></p>\n<ul>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-textkerascode\"><code class=\"language-text\">keras</code></a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-textsklearncode\"><code class=\"language-text\">sklearn</code></a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-texthashcode\"><code class=\"language-text\">Hash</code></a></p>\n<ul>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#indexing\">Indexing</a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#hashing\">Hashing</a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#hashing%EC%9D%84-%EB%8B%A8%EC%96%B4-%ED%91%9C%ED%98%84%EC%97%90-%EC%A0%81%EC%9A%A9\">Hashing을 단어 표현에 적용</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#%EC%B9%B4%EC%9A%B4%ED%8A%B8-%EA%B8%B0%EB%B0%98-%EB%B0%A9%EB%B2%95code-classlanguage-textco-occurrence-matrixcode\">카운트 기반 방법(<code class=\"language-text\">Co-occurrence matrix</code>)</a></p>\n<ul>\n<li>\n<p><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-text%ED%8A%B9%EC%9D%B4%EA%B0%92-%EB%B6%84%ED%95%B4svd-%EC%B0%A8%EC%9B%90%EC%B6%95%EC%86%8Ccode-code\"><code class=\"language-text\">특이값 분해(SVD: 차원축소)</code> code</a></p>\n<ul>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#%EB%B3%80%EC%88%98-%EC%A0%95%EB%A6%AC--x--xt--xc\"><em>변수 정리</em> > x / x.T / xc</a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#numpy%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-svd-%EC%98%88%EC%8B%9C\">numpy를 이용한 SVD 예시</a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#sklearn%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-svd-%EC%98%88%EC%8B%9C\">sklearn을 이용한 SVD 예시</a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#%EB%B3%80%EC%88%98-%EC%A0%95%EB%A6%AC--c--d--vt\"><em>변수 정리</em> > C / D / Vt</a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-textsvdcode--numpy--sklearn-%EB%B9%84%EA%B5%90\"><code class=\"language-text\">SVD</code> : Numpy &#x26; sklearn 비교</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%9C%A0%EC%82%AC%EB%8F%84%EA%B1%B0%EB%A6%AC-%EC%B8%A1%EC%A0%95\">텍스트 유사도(거리 측정)</a></p>\n<ul>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#step-1-word%EC%9D%98-vector%ED%99%94\">Step 1. word의 vector화</a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-text%EC%9E%90%EC%B9%B4%EB%93%9C-%EC%9C%A0%EC%82%AC%EB%8F%84code\"><code class=\"language-text\">자카드 유사도</code></a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-text%EC%BD%94%EC%82%AC%EC%9D%B8-%EC%9C%A0%EC%82%AC%EB%8F%84code\"><code class=\"language-text\">코사인 유사도</code></a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-text%EC%9C%A0%ED%81%B4%EB%A6%AC%EB%94%94%EC%95%88-%EA%B1%B0%EB%A6%ACcode\"><code class=\"language-text\">유클리디안 거리</code></a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-text%EB%A7%A8%ED%95%98%ED%83%84-%EA%B1%B0%EB%A6%ACcode\"><code class=\"language-text\">맨하탄 거리</code></a></li>\n<li><a href=\"/NLP%ED%95%9C%EA%B8%80_1/#code-classlanguage-text%EC%A0%95%EA%B7%9C%ED%99%94codel1--l2\"><code class=\"language-text\">정규화</code>(l1 &#x26; l2)</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/NLP한글_1/"},"frontmatter":{"title":"NLP 카운트 기반 방법의 텍스트 유사도 측정","date":"Aug 05, 2020","tags":["NLP","SVD","거리 측정"],"keywords":["JyneeEarth","jynee"],"update":"Aug 18, 2020"}}},"pageContext":{"slug":"/NLP한글_1/","series":[{"slug":"/NLP한글_1/","title":"NLP 카운트 기반 방법의 텍스트 유사도 측정","num":1},{"slug":"/NLP한글_2/","title":"NLP Doc2Vec","num":2},{"slug":"/NLP한글_3/","title":"NLP Kaggle competition 우승자가 제안한 새로운 접근방법을 배워보자","num":3},{"slug":"/NLP한글_4/","title":"NLP Doc2Vec","num":4}],"lastmod":"2020-08-18"}},"staticQueryHashes":["3649515864","694178885"]}