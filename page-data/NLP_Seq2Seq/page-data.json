{"componentChunkName":"component---src-templates-post-tsx","path":"/NLP_Seq2Seq/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"nlp\" style=\"position:relative;\"><a href=\"#nlp\" aria-label=\"nlp permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>NLP</h1>\n<br>\n<br>\n<h2 id=\"code-classlanguage-textsequence-to-sequencecode\" style=\"position:relative;\"><a href=\"#code-classlanguage-textsequence-to-sequencecode\" aria-label=\"code classlanguage textsequence to sequencecode permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">Sequence to Sequence</code></h2>\n<ul>\n<li>NLP, Time Serise/Sin data 예측에 사용한다.<br></li>\n<li>\n<p>기법 종류:</p>\n<ul>\n<li>seq2seq (RNN) > SL(fine Tuning) → USL</li>\n<li>Attention: RNN 기반 > SL(fine Tuning) → USL</li>\n<li>Self Attention(TransFormer): RNN 제거하고 Attention만 사용 > SL(fine Tuning) → USL</li>\n<li>이유: 병렬 처리 곤란(1 Step 끝나고 다음 Step 진행하기 때문에), GV 발생</li>\n<li>BERT<br></li>\n</ul>\n</li>\n<li>RNN  Encoder - Decoder</li>\n<li>\n<p>Encoder : 발화자의 의도</p>\n<ul>\n<li>최종 출력 context vector : h, c</li>\n</ul>\n</li>\n<li>\n<p>Decoder : 청취자가 발화자의 의도 해석</p>\n<ul>\n<li>Decoder의 입력과 출력은 모두 Answer 문장이다.</li>\n<li>다만 여기서 입력은 태그로 &#x3C;start>가 붙고</li>\n<li>출력은 &#x3C;end>가 붙는다<br></li>\n</ul>\n</li>\n<li>\n<p>teacher forcing</p>\n<ul>\n<li>학습 시에는 입력값과 출력값을 모두 알기 때문에 한꺼번에 넣어 학습시킨다. 한 음절씩 입력할 필요가 없다.</li>\n<li>predict 할 때는 출력값을 모르기 때문에 &#x3C;start>만 넣고 1 step(음절)씩 출력되도록 for문을 돌린다. <br></li>\n</ul>\n</li>\n</ul>\n<p><img src=\"markdown-images/image-20200811115522365.png\" alt=\"image-20200811115522365\"></p>\n<blockquote>\n<p>그림 출처: 아마추어 퀀트, blog.naver.com/chunjein</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>설명</th>\n<th>특징</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>h</td>\n<td>i와 f를 통해 나온 <strong>결과값(출력값)을 얼만큼 사용할 것인가 조절</strong></td>\n<td>f와 i의 가중평균 형태</td>\n</tr>\n<tr>\n<td>c</td>\n<td><strong>이전(과거)과 현재 값들을 얼만큼 사용할 것인가 조절</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>i</td>\n<td><strong>이전</strong>의 C를 얼마나 반영할 것인지 조절</td>\n<td></td>\n</tr>\n<tr>\n<td>f</td>\n<td><strong>현재 입력값(x)과 이전의 출력값(h)</strong>를 얼마나 반영할 것인지 조절</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p><img src=\"markdown-images/image-20200811182503171.png\" alt=\"image-20200811182503171\"></p>\n<blockquote>\n<p>그림 출처: <a href=\"blog.naver.com/chunjein\">아마추어 퀀트</a></p>\n</blockquote>\n<br>\n<h2 id=\"code--원리\" style=\"position:relative;\"><a href=\"#code--%EC%9B%90%EB%A6%AC\" aria-label=\"code  원리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>code &#x26; 원리</h2>\n<ul>\n<li>입력 데이터가 2개, 출력 데이터는 1개로 총 3개의 데이터가 필요하다</li>\n<li>\n<table>\n<thead>\n<tr>\n<th>encoder</th>\n<th>decoder</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>many-to-one</td>\n<td>many-to-many</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n<br>\n<ul>\n<li>\n<p>return_state</p>\n<ul>\n<li>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Seq2Seq의 LSTM</th>\n<th>기존 LSTM</th>\n<th>차이</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>LSTM()</td>\n<td>LSTM(LSTM<em>HIDDEN, return</em>sequences=True, <strong>return_state = True</strong>)</td>\n<td>LSTM(LSTM<em>HIDDEN, return</em>sequences=True)</td>\n<td><em>return_state = True</em></td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n<blockquote>\n<p><em>return_state = True</em> : 사용하면, 중간 뉴런들 각각의 값을 뜻하는, 결과값으로서의 계산된 h와 c가 함께 출력되어 <strong>출력값이 3개</strong>가 나오게 된다.</p>\n</blockquote>\n<br>\n</li>\n<li>\n<p>decoder는 입력을 한꺼번에 받았으나, chat module에선 한 단어씩 입력받아야 한다. 따라서 입력부분의 shape이 달라진다. </p>\n<blockquote>\n<p>n개 → 1</p>\n</blockquote>\n<ul>\n<li>그래도 네트워크의 파라미터는 동일하다.</li>\n<li>순서:</li>\n<li><code class=\"language-text\">encoder</code> &#x26; <code class=\"language-text\">decoder</code> 네트워크를 구성한다.</li>\n<li><code class=\"language-text\">encoder</code>: many-to-one으로 구성한다. 중간 출력은 필요 없고 decoder로 전달할 h와 c만 필요하다. h와 c를 얻기 위해 <code class=\"language-text\">return_state = True</code>를 설정한다.</li>\n<li><code class=\"language-text\">decoder</code>: many-to-many로 구성한다. target을 학습하기 위해서는 중간 출력이 필요하다. 그리고 초기 h와 c는 encoder에서 출력한 값을 사용한다</li>\n<li><code class=\"language-text\">chatting 용 모델</code> <strong>따로</strong> 빌드: <em>\"</em> 학습 모델(encoder &#x26; decoder)에서 나온 결과(w값)를 적용한다. <em>\"</em> </li>\n</ul>\n<br>\n<ul>\n<li><em>chatting 용 모델</em> > 사용자가 있는 ChatBot으로서 <strong>실사용할 것.</strong></li>\n<li>\n<p>네트워크 구성</p>\n<ul>\n<li>\n<p><code class=\"language-text\">encoder</code> &#x26; <code class=\"language-text\">decoder</code>  만들기.</p>\n<p>학습 때와 달리 문장 전체를 받아 recurrent하는 것이 아니라, <strong>단어 1개씩 입력 받아서 다음 예상</strong> 단어를 확인한다</p>\n<p>따라서, input shape의 변화 말고는 가중치를 뽑아내기 위해 실행했었던 '6-2. 파일' 속 encoder &#x26; decoder의 구성방식(층 개수, 정규화 했다면 정규화, loss 등)과 전부 같아야 한다.<br></p>\n</li>\n<li>\n<p><code class=\"language-text\">Chatting용 model</code> 만듦</p>\n<ul>\n<li>Chatting용 model은 encoder&#x26;decoder랑 달리 네트워크를 만드는 게 아니라, </li>\n</ul>\n<p>실제 사용할 model을 만들므로 Encoder 및 decoder의 <strong>w를 써야하므로 그 둘을 합쳐준다는 의미</strong>에서 model을 만든다.</p>\n<ul>\n<li>\n<p>따라서 Encoder의 출력을 입력으로 받기 위한 입력 input(예: ih1, ic1)을 만들어준다.</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">ih1 <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>batch_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> LSTM_HIDDEN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nic1 <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>batch_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> LSTM_HIDDEN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nih2 <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>batch_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> LSTM_HIDDEN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nic2 <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>batch_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> LSTM_HIDDEN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>\n<p>Decoder에 넣으면 변하는 부분을 만든다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">dec_output1<span class=\"token punctuation\">,</span> dh1<span class=\"token punctuation\">,</span> dc1 <span class=\"token operator\">=</span> decLSTM1<span class=\"token punctuation\">(</span>decEMB<span class=\"token punctuation\">,</span> initial_state <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>ih1<span class=\"token punctuation\">,</span> ic1<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> </code></pre></div>\n</li>\n</ul>\n<blockquote>\n<p>앞에서 encoder&#x26;decoder model을 만들었으니, </p>\n<p>바로 위 code 中 Encoder의 입력 값(ih1, ic1)에서 w가 나올 텐데,  </p>\n<p>decoder의 가중치 값으로 쓴다(initial_state).</p>\n</blockquote>\n<br>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Question을 입력받아 Answer를 생성 해주는 알고리즘 작성(함수 만들기)</p>\n<ul>\n<li>\n<p>궁금한 부분 &#x26; 해소:</p>\n<p>\"챗봇의 Answer에서 '그 사람도 그럴 거예요' 中 '거예요' 다음에 문장이 또 나올 수 있지 않나? 어떻게 멈추는 거지?\"</p>\n<blockquote>\n<p>답변: 챗봇 알고리즘을 다음 예상 단어가 &#x3C;END>이거나 &#x3C;PADDING>이면 더 이상 예상할 게 없도록 만들었기 때문.</p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>\n</li>\n</ul>\n<h1 id=\"argmax로-해당-단어를-채택한다\" style=\"position:relative;\"><a href=\"#argmax%EB%A1%9C-%ED%95%B4%EB%8B%B9-%EB%8B%A8%EC%96%B4%EB%A5%BC-%EC%B1%84%ED%83%9D%ED%95%9C%EB%8B%A4\" aria-label=\"argmax로 해당 단어를 채택한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>argmax로 해당 단어를 채택한다.</h1>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">  nextWord = np.argmax(dY[0, 0])\n\n  # 예상 단어가 &lt;END&gt;이거나 &lt;PADDING&gt;이면 더 이상 예상할 게 없다.\n  if nextWord == word2idx[&#39;&lt;END&gt;&#39;] or nextWord == word2idx[&#39;&lt;PADDING&gt;&#39;]:</code></pre></div>\n<p>  break</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n</li>\n<li>\n<p>Chatting 실행하는 함수 작성</p>\n<ul>\n<li>글 쓰는 input과 글 나오는 output이 부분을 만듦</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<br>\n<h3 id=\"smt\" style=\"position:relative;\"><a href=\"#smt\" aria-label=\"smt permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SMT</h3>\n<ul>\n<li>\n<p>Answer는 One-Hot encoding 형태로 출력</p>\n<ul>\n<li>따라서 softmax 사용</li>\n</ul>\n</li>\n<li>\n<p>이전 단어들의 Sequence로 예측할 단어를 구함</p>\n<ul>\n<li>식에선 이전 단어가 첫 번째로 위치할 확률 등을 구함</li>\n</ul>\n</li>\n</ul>\n<br>\n<br>\n<br>\n<br>\n<h2 id=\"code-classlanguage-textseq2seqcode--code-classlanguage-textattentioncode-메커니즘\" style=\"position:relative;\"><a href=\"#code-classlanguage-textseq2seqcode--code-classlanguage-textattentioncode-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98\" aria-label=\"code classlanguage textseq2seqcode  code classlanguage textattentioncode 메커니즘 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">Seq2Seq</code> &#x26; <code class=\"language-text\">Attention</code> 메커니즘</h2>\n<blockquote>\n<p>입력 문장이 긴 상황에서는 번역 품질이 떨어지는 현상이 나타났고, 이런 현상을 보정하기 위해 <strong>중요한 단어에 집중</strong>하여 Decoder에 바로 전달하는 Attention 기법이 등장했습니다. 기존 방식보다 <strong>훨씬 더 많은 데이터를 Decoder에 전달</strong>합니다.</p>\n<ul>\n<li>출처: [glee1228][https://glee1228.tistory.com/3]</li>\n</ul>\n</blockquote>\n<br>\n<ul>\n<li>그림:</li>\n</ul>\n<p><img src=\"markdown-images/image-20200812105423228.png\" alt=\"image-20200812105423228\"></p>\n<blockquote>\n<p>t = 단어 하나</p>\n</blockquote>\n<br>\n<ul>\n<li>\n<p>원리 및 작동 순서:</p>\n<blockquote>\n<p><img src=\"https://blog.kakaocdn.net/dn/dpU0Vu/btqCgQ0OkMG/EIEGd3xjvQaKfL3NJycww0/img.png\" alt=\"img\"></p>\n<p><img src=\"https://blog.kakaocdn.net/dn/k15cI/btqCevJR3nq/TRZBKaQyjylYdem3GZDjG0/img.png\" alt=\"img\"></p>\n<p>위 그림을 바탕으로 어떻게 Attention이 작용하는지 설명해보겠습니다.</p>\n<blockquote>\n<p>우선, Attention Decoder에서 나오는 첫 단어(위의 Je)를 만들기 위해 두가지를 준비해야합니다.</p>\n<p>하나는 Attention Vector, 나머지 하나는 Step 5번째의 Decoder(빨간색)에서 나오는 hidden state입니다.</p>\n<p>우선 Attention Decoder에 전달할 Context Vector를 만들어봅니다.</p>\n<ol>\n<li>Encoder의 hidden state(h1,h2,h3,h4h1,h2,h3,h4)들을 step별로 구합니다.</li>\n<li>각각 step의 hidden state(h1,h2,h3,h4h1,h2,h3,h4)에 이전 step 디코더의 hidden state인 si−1si−1 를 각각 dot-product하거나 다른 socre 함수들을 사용해서 점수를 부여합니다.이 점수가 바로 Attention Score입니다.</li>\n<li>점수를 softmax합니다.(점수 합이 1)</li>\n<li>Softmax된 점수에 해당하는 각각의 hidden state들을 곱해줍니다.</li>\n<li>점수에 곱해진 Vector들을 Sum up 해줍니다. => Context Vector</li>\n</ol>\n<p>Step 5번째의 첫 Decoder의 hidden state를 준비해줍니다.</p>\n<p>여기까지 다 되었다면, 위 Je라는 Attention Decoder의 첫 hidden state를 내보낼 준비가 되었습니다.</p>\n</blockquote>\n<p>어텐션의 기본 아이디어는 <strong>디코더(Decoder)에서 출력 단어를 예측하는 매 시점(time-step)마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점</strong> 입니다. 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중해서 보게됩니다. 이 내용을 알고 Decoder의 단계로 넘어갑니다.</p>\n<ul>\n<li>출처: <a href=\"https://glee1228.tistory.com/3\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">glee1228</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<br>\n<h3 id=\"code\" style=\"position:relative;\"><a href=\"#code\" aria-label=\"code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>code</h3>\n<ul>\n<li>\n<p>순서</p>\n<ol>\n<li>단어 목록 dict를 읽어온다.</li>\n<li>학습 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 읽어온다.</li>\n<li>평가 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 만든다.</li>\n<li>\n<p>이때 쓸 attention layer 및 attention score 구하기</p>\n<ol>\n<li>Encoder 출력과 decoder 출력으로 <code class=\"language-text\">attention value</code>를 생성하고,\ndecoder 출력 + attention value를 <code class=\"language-text\">concatenate</code>한다.</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># LSTM time step = 4, SMB_SIZE = 3</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">Attention</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># x : encoder 출력, y : decoder 출력</span>\n    <span class=\"token comment\"># step-1:</span>\n    <span class=\"token comment\"># decoder의 매 시점마다 encoder의 전체 시점과 dot-product을 수행한다.</span>\n    score <span class=\"token operator\">=</span> Dot<span class=\"token punctuation\">(</span>axes<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>                   <span class=\"token comment\"># (1, 4, 4)</span>\n    \n    <span class=\"token comment\"># step-2:</span>\n    <span class=\"token comment\"># dot-product 결과를 확률분포로 만든다 (softmax)</span>\n    <span class=\"token comment\"># 이것이 attention score이다.</span>\n    dist <span class=\"token operator\">=</span> Activation<span class=\"token punctuation\">(</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>score<span class=\"token punctuation\">)</span>                <span class=\"token comment\"># (1, 4, 4)</span>\n\n    <span class=\"token comment\"># step-3:   </span>\n    <span class=\"token comment\"># encoder 출력과 attention score를 각각 곱하는 단계 </span>\n    <span class=\"token comment\"># encoder의 전체 시점에 위의 확률 분포를 적용해서 가중 평균한다.</span>\n    <span class=\"token comment\"># 직접 계산이 어렵기 때문에 dist를 확장하고, 열을 복제해서</span>\n    <span class=\"token comment\"># Dot 연산이 가능하도록 trick을 쓴다.</span>\n    <span class=\"token comment\"># 이것이 attention value이다.</span>\n    <span class=\"token comment\"># dist_exp = K.expand_dims(dist, 2)                   # (1, 4, 1, 4)</span>\n    <span class=\"token comment\"># dist_rep = K.repeat_elements(dist_exp, EMB_SIZE, 2) # (1, 4, 3, 4)                                       </span>\n    <span class=\"token comment\"># dist_dot = Dot(axes=(3, 1))([dist_rep, x])          # (1, 4, 3, 3)</span>\n    <span class=\"token comment\"># attention = K.mean(dist_dot, axis = 2)              # (1, 4, 3)</span>\n\n    <span class=\"token comment\"># step-4:</span>\n    <span class=\"token comment\"># 교재의 step-3을 계산하지 않고 step-4를 직접 계산했다.</span>\n    attention <span class=\"token operator\">=</span> Dot<span class=\"token punctuation\">(</span>axes<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>dist<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># step-5:</span>\n    <span class=\"token comment\"># decoder 출력과 attention (score)을 concatenate 한다.</span>\n    <span class=\"token keyword\">return</span> Concatenate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">,</span> attention<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\"># (1, 4, 6)</span></code></pre></div>\n</li>\n</ol>\n <br>\n<ol start=\"4\">\n<li>워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.</li>\n<li>\n<p>공동으로 사용함을 가정</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">K<span class=\"token punctuation\">.</span>clear_session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nwordEmbedding <span class=\"token operator\">=</span> Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span>VOCAB_SIZE<span class=\"token punctuation\">,</span> output_dim<span class=\"token operator\">=</span>EMB_SIZE<span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n</ol>\n <br>\n</li>\n<li>\n<p>Encoder</p>\n<ul>\n<li>many-to-many로 구성한다. Attention value를 계산하기 위해 중간 출력이 필요하고 (return_sequences=True), </li>\n<li>decoder로 전달할 h와 c도 필요하다 (return_state = True)</li>\n</ul>\n <br>\n</li>\n<li>\n<p>Decoder</p>\n<ul>\n<li>many-to-many로 구성한다. target을 학습하고 Attention을 위해서는 <strong>중간 출력이 필요</strong>하다. </li>\n<li>그리고 초기 h와 c는 encoder에서 출력한 값을 사용한다(initial_state). </li>\n<li>최종 출력은 vocabulary의 인덱스인 one-hot 인코더이다.</li>\n<li>\n<p>Attention 함수를 삽입한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">att_dy2 <span class=\"token operator\">=</span> Attention<span class=\"token punctuation\">(</span>ey2<span class=\"token punctuation\">,</span> dy2<span class=\"token punctuation\">)</span> <span class=\"token comment\"># ey2: encoder 출력값 # dy2: decoder 출력값</span></code></pre></div>\n</li>\n<li>\n<p>activation='softmax'를 사용한다</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">decOutput <span class=\"token operator\">=</span> TimeDistributed<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span>VOCAB_SIZE<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n</ul>\n</li>\n</ul>\n  <br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">7. Model\n\n   * loss=&#39;sparse_categorical_crossentropy&#39;</code></pre></div>\n  <br>\n<ol start=\"8\">\n<li>\n<p>학습 (teacher forcing)</p>\n<ul>\n<li>\n<p>주의:</p>\n<p>loss = sparse<em>categorical</em>crossentropy이기 때문에 target을 one-hot으로 변환할 필요 없이 integer인 trainYD를 그대로 넣어 준다. trainYD를 one-hot으로 변환해서 categorical_crossentropy로 처리하면 out-of-memory 문제가 발생할 수 있다.</p>\n</li>\n</ul>\n</li>\n</ol>\n  <br>\n<ol start=\"9\">\n<li>\n<p>학습 결과를 저장한다</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>save_weights<span class=\"token punctuation\">(</span>MODEL_PATH<span class=\"token punctuation\">)</span></code></pre></div>\n <br>\n</li>\n</ol>\n<br>\n<br>\n<br>\n<ul>\n<li>\n<p>참고:</p>\n<blockquote>\n<p>아마추어 퀀트, blog.naver.com/chunjein</p>\n<p>ckdgus1433. 2019. 8. 7. \"Attention Mechanism(seq2seq)\". <a href=\"http://blog.naver.com/ckdgus1433/221608376139\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://blog.naver.com/ckdgus1433/221608376139</a>. 튜토리얼로 익히는 머신러닝/딥러닝</p>\n<p>ratsgo. 2017.05.12. \"Sequence-to-Sequence 모델로 뉴스 제목 추출하기\". <a href=\"https://ratsgo.github.io/natural\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://ratsgo.github.io/natural</a> language processing/2017/03/12/s2s/. ratsgo's blog for textmining</p>\n</blockquote>\n</li>\n</ul>","excerpt":"NLP  NLP, Time Serise/Sin data 예측에 사용한다. 기법 종류: seq2seq (RNN) > SL(fine Tuning) → USL Attention: RNN 기반 > SL(fine Tuning) → USL Self…","tableOfContents":"<ul>\n<li>\n<p><a href=\"/NLP_Seq2Seq/#nlp\">NLP</a></p>\n<ul>\n<li><a href=\"/NLP_Seq2Seq/#code-classlanguage-textsequence-to-sequencecode\"><code class=\"language-text\">Sequence to Sequence</code></a></li>\n<li>\n<p><a href=\"/NLP_Seq2Seq/#code--%EC%9B%90%EB%A6%AC\">code &#x26; 원리</a></p>\n<ul>\n<li><a href=\"/NLP_Seq2Seq/#smt\">SMT</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/NLP_Seq2Seq/#code-classlanguage-textseq2seqcode--code-classlanguage-textattentioncode-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98\"><code class=\"language-text\">Seq2Seq</code> &#x26; <code class=\"language-text\">Attention</code> 메커니즘</a></p>\n<ul>\n<li><a href=\"/NLP_Seq2Seq/#code\">code</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/NLP_Seq2Seq/"},"frontmatter":{"title":"NLP Sequence to Sequence","date":"Aug 15, 2020","tags":["NLP","seq2seq"],"keywords":["JyneeEarth","jynee"],"update":"Aug 18, 2020"}}},"pageContext":{"slug":"/NLP_Seq2Seq/","series":[],"lastmod":"2020-08-18"}},"staticQueryHashes":["3649515864","694178885"]}