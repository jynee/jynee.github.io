{"componentChunkName":"component---src-templates-post-tsx","path":"/GAN_2/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"gan\" style=\"position:relative;\"><a href=\"#gan\" aria-label=\"gan permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GAN</h1>\n</br>\n<ul>\n<li>1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다.</br></li>\n<li>fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등)</br></li>\n<li>\n<p>Discrimi의 loss는 max[log(Dx) + log(1 - DGz)]이고, Generator의 loss는 min[log(Dx + log(1 - DGz))]이다. </br></p>\n</br>\n</li>\n<li>\n<p>Tensorflow에서는 이 loss 함수를 이용하여 직접 GAN을 학습할 수 있지만, </br></p>\n<p>Keras에서는 model.fit(), model.train<em>on</em>batch() 함수에서 target 값을 지정해야 하기 때문에 이 loss로 GAN을 학습할 수 없다 <strong>Keras는 기본적으로 Supervised learning 목적이다.</strong></br></p>\n<ul>\n<li>Keras에서는 supervised learning 방식으로 바꿔 binary_crossentropy loss 함수를 써서 GAN을 학습하는 것이 보통이다.</br></li>\n</ul>\n<br>\n</li>\n<li>\n<p>이 코드는 아래 자료를 참조해서 응용했다.</br></p>\n<ol>\n<li>Rowel Atienza, 2018, Advanced Deep Learning with Keras. Chap 4. p.107 ~ p.113</br></li>\n<li>아마추어 퀀트, blog.naver.com/chunjein,  2020.04.08</br></li>\n</ol>\n</li>\n<li>함수들의 기능을 파악하기 쉽도록 순서를 변경하였다.</br></li>\n</ul>\n</br>\n</br>\n<h2 id=\"basic-code\" style=\"position:relative;\"><a href=\"#basic-code\" aria-label=\"basic code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Basic CODE</h2>\n</br>\n<ul>\n<li>Keras를 이용하여 기본 GAN 모델을 연습한다.</br></li>\n<li>file: 딥러닝 8-2.GAN(Kears)</br></li>\n</ul>\n</br>\n<h4 id=\"step1-정규분포로부터-데이터를-샘플링한다br\" style=\"position:relative;\"><a href=\"#step1-%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC%EB%A1%9C%EB%B6%80%ED%84%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%83%98%ED%94%8C%EB%A7%81%ED%95%9C%EB%8B%A4br\" aria-label=\"step1 정규분포로부터 데이터를 샘플링한다br permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step1. 정규분포로부터 데이터를 샘플링한다</br></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">realData <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>normal<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\nrealData <span class=\"token operator\">=</span> realData<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>realData<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n</br>\n<h4 id=\"step2-network-빌드\" style=\"position:relative;\"><a href=\"#step2-network-%EB%B9%8C%EB%93%9C\" aria-label=\"step2 network 빌드 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step2. Network 빌드</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">nDInput <span class=\"token operator\">=</span> realData<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># nDInput.shape[1] = 1</span>\nnDHidden <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nnDOutput <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\nnGInput <span class=\"token operator\">=</span> <span class=\"token number\">16</span>\nnGHidden <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nnGOutput <span class=\"token operator\">=</span> nDInput\n\n<span class=\"token comment\">## nDInput와 nGOutput는 값이 같아야 함</span></code></pre></div>\n</br>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">getNoise</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">,</span> n<span class=\"token operator\">=</span>nGInput<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    z <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>uniform<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> z</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">MyOptimizer</span><span class=\"token punctuation\">(</span>a <span class=\"token operator\">=</span> <span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> RMSprop<span class=\"token punctuation\">(</span>lr <span class=\"token operator\">=</span> a<span class=\"token punctuation\">)</span></code></pre></div>\n</br>\n<h4 id=\"step3-모델-그림\" style=\"position:relative;\"><a href=\"#step3-%EB%AA%A8%EB%8D%B8-%EA%B7%B8%EB%A6%BC\" aria-label=\"step3 모델 그림 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step3. 모델 그림</h4>\n<ul>\n<li>Generator --> Discriminator를 연결한 모델을 생성한다.</li>\n<li>아래 네트워크로 z가 들어가면 DGz = 1이 나오도록 G를 학습한다.</li>\n<li>D 네트워크는 업데이트하지 않고, G 네트워크만 업데이트한다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"mermaid\"><pre class=\"language-mermaid\"><code class=\"language-mermaid\">graph LR\nz[z] --&gt;B{trainable}\n    B --&gt;|trainable| C[G]\n    C --&gt;|Gz| D[D]\n    B --&gt;|NOT trainable| D\n\tD --&gt; DGz</code></pre></div>\n</br>\n</br>\n<h4 id=\"step4-객체지향-함수-정의\" style=\"position:relative;\"><a href=\"#step4-%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-%ED%95%A8%EC%88%98-%EC%A0%95%EC%9D%98\" aria-label=\"step4 객체지향 함수 정의 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step4. (객체지향) 함수 정의</h4>\n<p><strong>0. K.clear_session()</br></strong></p>\n<h5 id=\"1-discriminator--builddiscriminatorbr\" style=\"position:relative;\"><a href=\"#1-discriminator--builddiscriminatorbr\" aria-label=\"1 discriminator  builddiscriminatorbr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Discriminator = BuildDiscriminator()</br></h5>\n<h5 id=\"2-generator--buildgeneratorbr\" style=\"position:relative;\"><a href=\"#2-generator--buildgeneratorbr\" aria-label=\"2 generator  buildgeneratorbr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Generator = BuildGenerator()</br></h5>\n<h5 id=\"3-gan--buildgandiscriminator-generatorbr\" style=\"position:relative;\"><a href=\"#3-gan--buildgandiscriminator-generatorbr\" aria-label=\"3 gan  buildgandiscriminator generatorbr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. GAN = BuildGAN(Discriminator, Generator)</br></h5>\n</br>\n</br>\n<h4 id=\"step5-학습-세팅\" style=\"position:relative;\"><a href=\"#step5-%ED%95%99%EC%8A%B5-%EC%84%B8%ED%8C%85\" aria-label=\"step5 학습 세팅 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step5. 학습 세팅</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">nBatchCnt <span class=\"token operator\">=</span> <span class=\"token number\">3</span>       <span class=\"token comment\"># Mini-batch를 위해 input 데이터를 n개 블록으로 나눈다. # 333개, 333개, 334개로 쪼개짐 </span>\nnBatchSize <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>realData<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> nBatchCnt<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 블록 당 Size # nBatchSize: 333개, 333개, 334개 순으로 들어감 </span>\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Mini-batch 방식으로 학습한다</span>\n    <span class=\"token keyword\">for</span> n <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>nBatchCnt<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># input 데이터를 Mini-batch 크기에 맞게 자른다</span>\n        nFrom <span class=\"token operator\">=</span> n <span class=\"token operator\">*</span> nBatchSize <span class=\"token comment\">#for문 다 돌면 nFrom= 666</span>\n        nTo <span class=\"token operator\">=</span> n <span class=\"token operator\">*</span> nBatchSize <span class=\"token operator\">+</span> nBatchSize <span class=\"token comment\">#for문 다 돌면 nTo=1000</span>\n        \n        <span class=\"token comment\"># 마지막 루프이면 nTo는 input 데이터의 끝까지. </span>\n        <span class=\"token comment\">## 왜 써주냐면 , n=2(마지막)일때 nTo = n * nBatchSize + nBatchSize는 999로 1000이 안되기 땜에.</span>\n        <span class=\"token keyword\">if</span> n <span class=\"token operator\">==</span> nBatchCnt <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            nTo <span class=\"token operator\">=</span> realData<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></code></pre></div>\n</br>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">        <span class=\"token comment\"># 학습 데이터를 준비한다</span>\n        bx <span class=\"token operator\">=</span> realData<span class=\"token punctuation\">[</span>nFrom <span class=\"token punctuation\">:</span> nTo<span class=\"token punctuation\">]</span> <span class=\"token comment\">#진짜 data 형성</span>\n        bz <span class=\"token operator\">=</span> getNoise<span class=\"token punctuation\">(</span>m<span class=\"token operator\">=</span>bx<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> n<span class=\"token operator\">=</span>nGInput<span class=\"token punctuation\">)</span> <span class=\"token comment\"># bx.shape[0]=333->333->334, nGInput=16</span>\n        Gz <span class=\"token operator\">=</span> Generator<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>bz<span class=\"token punctuation\">)</span> <span class=\"token comment\">#진짜 data shape 맞춰서 noise 써가지고 가짜 data 형성(fake data)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 410px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/300cd66c5e4a62c747237923b76d20a9/d68e4/image-20200715110832016.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 102.7027027027027%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsSAAALEgHS3X78AAADGUlEQVQ4y4VU2XKbQBDk/38p5Tw4kQ/FkqwbgUBC3OhE6LKjqvb0IGw5FScPU8Ay29PT07vGYRcjX8+wWc1w3Cc4HVK8HDMcdgn2RQz+v459Eb2/M7+Kas2Ypw7Mfh1xMELoDzW8SQ9FHgh4dgGVQrIp3/g47pL3Yvnax1bW1ksPu22k60YaW1jOXamSYrWYKtM4HCGJLA0CFVLZSyzEqymihYuDgAWzoUYSWnDsZ/izgXZmLOcTXWg+3aLVuMVY3gkaBSayZAxr+ISB00JvUIfZqyNIx4iysXRkCoFyb5GH2hnlMkjbc7vaP6mT5W4bqgTbTYDR4BdsrwvbaaMhRa1JB/O1hyyykcY22q0a7mrfMOg9qkTGZuXBlE1kwxaZxKqRADJY5CiVXWl5EPThhEOcTwtMhQT3kAj32KOWMjU44YlUpx4Tp6P6UdNANKmml0tizXzETb8GU0AJGIt2gTfA2GrpXhanAwyiWmZDqZO2Y7d0csFF5MomSym8FSkKCX5Tr/PrAr6AkkBlI4MDKAXNVDMGk1mV76X3JJk+K8rgt9pEALrtex0gXaIM2fJQfMhFsmKwAHUkYNl22fr+3eDl9+tpjrXMgIN9Oc5LH/Jj6nY0gdNlu3zOxNz8d30KDleAzGHx2bQn0deOyNygTWjuLHHgy49F5uopIWOy/xsgp06pSKTV/KG5BCYZg06nNZ6bP1F/+I6H+xuxj61TzFdfAO5LQErDvNA3laXahgzpv1iCnswSW9th0pcML4BkxUGQEC1HzS8+LDUkIMHOr0ut/hWgaihAJOLK8OhH+lc1LMUdqsDUIpR33+urYSvbXF9dBKps9HLK0BXvroTIbzG7AjKRBuZPts+hUFwO5lObtAnNzFwORf67cgwbnTtMIhNzAeXVZlSVaWZr1NDTQn991kzuQgEYC0DTbSJdTjBLbWWXi36RyOMKaCFmNw5/mJUSXN/K19GZtnFn1eHEJmI5bryBHJGGt83Ik0u5+AT472DLvGzPciLYMrWMhelUbqFxNMSCFqta/n98HL2K/cdNFOj6SazEvDfbQBgvvvdP4gAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20200715110832016\"\n        title=\"image-20200715110832016\"\n        src=\"/static/300cd66c5e4a62c747237923b76d20a9/d68e4/image-20200715110832016.png\"\n        srcset=\"/static/300cd66c5e4a62c747237923b76d20a9/12f09/image-20200715110832016.png 148w,\n/static/300cd66c5e4a62c747237923b76d20a9/e4a3f/image-20200715110832016.png 295w,\n/static/300cd66c5e4a62c747237923b76d20a9/d68e4/image-20200715110832016.png 410w\"\n        sizes=\"(max-width: 410px) 100vw, 410px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n</br>\n<h5 id=\"discriminator--builddiscriminator\" style=\"position:relative;\"><a href=\"#discriminator--builddiscriminator\" aria-label=\"discriminator  builddiscriminator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Discriminator = BuildDiscriminator()</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    \t<span class=\"token comment\">### &lt; Discriminator를 학습한다. > ###</span>\n        <span class=\"token comment\"># Real data가 들어가면 Discriminator의 출력이 '1'이 나오도록 학습하고,</span>\n        <span class=\"token comment\"># Fake data (Gz)가 들어가면 Discriminator의 출력이 '0'이 나오도록 학습한다.</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"target data 만들기\"\"\"</span>\n        target <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>bx<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        target<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span> bx<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.9</span>     <span class=\"token comment\"># '1' 대신 0.9로 함</span>\n        target<span class=\"token punctuation\">[</span>bx<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>     <span class=\"token comment\"># '0' 대신 0.1로 함</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"target data 형성 완료\"\"\"</span>\n        \n        bx_Gz <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>bx<span class=\"token punctuation\">,</span> Gz<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># D 학습 </span>\n        Dloss <span class=\"token operator\">=</span> Discriminator<span class=\"token punctuation\">.</span>train_on_batch<span class=\"token punctuation\">(</span>bx_Gz<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span> \n        <span class=\"token comment\">#real data &amp; fake data 모두가 D를 거치게 한다. </span>\n        <span class=\"token comment\">##참고: fit 함수보다 train_on_batch 쓰는 게 더 속도가 빨라서 이거 씀</span>\n </code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 310px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/98081371ab2415f2244c7b50905f4563/5fad2/image-20200715110841184.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 85.8108108108108%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsSAAALEgHS3X78AAAC2UlEQVQ4y2VUaXeaUBDl//+Mfm97emo/tGlimibGeFww7iiKuIAI4sbiktzOjGBM+uEdYHjvzr13Zp4SbCwEWwtxYCOiFW5tbDdTiQX05Nh2PcEumCFKYiE9eQUX36d3CwoHGMy0NcwXQwE7hA524UyWvxzhEDmw3D5Wq7GAMgA/0yRRQojJKIzKG2xvIAcaZg1PegntcQN1o4q7dh4VQ0VrVMeS/gs7OrMm1s7CkISb9RSOZ8h5JTxntHGMXVS6JXz9k0G2lEWufIdiNYcf+Z/wfJMYOyKL2YycLr5XbpCh9SmXwb1WEPlKqp99Yr9Wngm9UxY5LP0Yz6FrKhbEIAptOcT7eS+zZJvmxHTD50+STx4e6fDLzsXSG6LfUyXBwjUQk49GvyZx8TXxjYmwXJfA9hQPkwIpMW2YzHU8dgpQyTNvYaJefUSNpGavM1jSNwNqwzrMWRe59hNsKtCeCrVcjsWKU3eckijsS9/SyIssrpsP6Jh1dJpFVEp/MRm1xDPTaGDuDuCvx9AmLTJ/ImxdfyjgzDpIAVMP2QPsPfgkrcceEoOVPxLZzHhFTOOz5DdG6/VbKwlg2jYhNyhRXxCTQv4GA70KvVvBxGyh2XiSRCxNikJrR+8Dq4MZtVt8jltvbZNOhU/VHA5qeD36wvLlsKDvugAyQ+kI2suFYE+n5P8uKcpZcph0+uvOE2kMyP5Zk86HKjsid59M0pT8qw5UKVDwXrJNnT4Uww1aIypCo5bH71/fUCzcot9V4c5pkshnl6qqT9vSozOyp0f7GVzuBJbMGXlkvhSv8Ll0hZvGPZrtokjkSj+rDzD0ZwE0Zz2U9bKsF2p4l5raoDtAPPwomX+ylJjbqFel2FR8BFYCyN4eCCQdvSjx8vLC+M9DmRoC5LYx+s9UZZXGroJOqySTE14cDJPxiz7Ezm2TtkNEfeY6Ouyphg1lX9N4pWDpnvd34MX9SFj/AOky8Iew8ES7AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20200715110841184\"\n        title=\"image-20200715110841184\"\n        src=\"/static/98081371ab2415f2244c7b50905f4563/5fad2/image-20200715110841184.png\"\n        srcset=\"/static/98081371ab2415f2244c7b50905f4563/12f09/image-20200715110841184.png 148w,\n/static/98081371ab2415f2244c7b50905f4563/e4a3f/image-20200715110841184.png 295w,\n/static/98081371ab2415f2244c7b50905f4563/5fad2/image-20200715110841184.png 310w\"\n        sizes=\"(max-width: 310px) 100vw, 310px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n</br>\n<h6 id=\"def-builddiscriminator\" style=\"position:relative;\"><a href=\"#def-builddiscriminator\" aria-label=\"def builddiscriminator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>def BuildDiscriminator()</h6>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Discriminator를 G. D 각각 생성한다</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">BuildDiscriminator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    x <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>batch_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> nDInput<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    h <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>nDHidden<span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    Dx <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>nDOutput<span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>h<span class=\"token punctuation\">)</span> <span class=\"token comment\">#0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 </span>\n    model <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> Dx<span class=\"token punctuation\">)</span>\n    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss <span class=\"token operator\">=</span> <span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span> optimizer <span class=\"token operator\">=</span> MyOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> \n    <span class=\"token comment\">#sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 </span>\n    \n    <span class=\"token keyword\">return</span> model</code></pre></div>\n</br>\n</br>\n<h5 id=\"gan--buildgandiscriminator-generator\" style=\"position:relative;\"><a href=\"#gan--buildgandiscriminator-generator\" aria-label=\"gan  buildgandiscriminator generator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GAN = BuildGAN(Discriminator, Generator)</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">### &lt; Generator를 학습한다. > ###</span>\n<span class=\"token comment\"># Fake data (z --> Gz --> DGz)가 들어가도 Discriminator의 출력이 '1'이 나오도록 Generator를 학습한다.</span>\n<span class=\"token triple-quoted-string string\">\"\"\"target data 만들기\"\"\"</span>\ntarget <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>bx<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ntarget<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.9</span>\n<span class=\"token triple-quoted-string string\">\"\"\"target data 형성 완료\"\"\"</span>\n        \nGloss <span class=\"token operator\">=</span> GAN<span class=\"token punctuation\">.</span>train_on_batch<span class=\"token punctuation\">(</span>bz<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span> \n<span class=\"token comment\">## GAN 함수 참고: D는 위에서 학습해서 여기선 학습 안 하고 G만 학습 </span>\n<span class=\"token comment\"># 어떤 학습? 가짜 data가 들어가면 target이 전부 1로 출력되도록(Discriminator가 전부 진짜로 판별하도록)! </span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 448px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/97569fb6e53b4464c4b19ffaa74c0241/33b38/image-20200715110850214.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 59.45945945945946%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABsElEQVQoz11T2VLCQBDM/3+Gj/oNPmhpiSAhIEeICSHk2oT7Ri1rnJ6wIfCwtdmdmZ7uno1x2KV03Gd0OmS8K8L5dFC03ya0XoZ8VhKb5R6tFhP6OU0ljjvk6oV87AZAZvlI1nzq024TC9DY69CgV6c0dmiqPDI/nsnuN8jn+1nmkUoc2qzCM5AqyRjo6DoWdaxXGnTrtJwHNHIt8pwW9T7fOdaiwO/yd43B2txgKDkAbzaeyDJfhIAmYxR0Uz4UEtEJctLIJsduilTE3aFJYdA/W5Ixu0hiOLcY9OH+TuJG1YfjvvACoFj6GzvkbdexyEPu9zEvm0/ZgjDoicfGrbFIgiRIiyZ9ypVbgqA4Zz/BPGEFeni410NlwEQkaUAE0A2+wZcJf0OeZh2HAwH03bZ4puvKKV8Y6m5KgGpvjzLlJLSlcDzqyITBGKBgj3s9Xb2uAAsflXiRqy/6+51L8XYdiQ0YGp6RAAZVQHUNWJWMhMVsTF+2yT4NhZUuxCCiyUDeIGzRkq8e9i1DvcAK3uE5lQUMCpYYCJpW5WpSxuXJVAFVOYRbjzTTy69XlazoHzpngHnz2qseAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20200715110850214\"\n        title=\"image-20200715110850214\"\n        src=\"/static/97569fb6e53b4464c4b19ffaa74c0241/33b38/image-20200715110850214.png\"\n        srcset=\"/static/97569fb6e53b4464c4b19ffaa74c0241/12f09/image-20200715110850214.png 148w,\n/static/97569fb6e53b4464c4b19ffaa74c0241/e4a3f/image-20200715110850214.png 295w,\n/static/97569fb6e53b4464c4b19ffaa74c0241/33b38/image-20200715110850214.png 448w\"\n        sizes=\"(max-width: 448px) 100vw, 448px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n</br>\n<h6 id=\"def-buildgand-g\" style=\"position:relative;\"><a href=\"#def-buildgand-g\" aria-label=\"def buildgand g permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>def BuildGAN(D, G)</h6>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">BuildGAN</span><span class=\"token punctuation\">(</span>D<span class=\"token punctuation\">,</span> G<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># 전체 NETWORK Build </span>\n    D<span class=\"token punctuation\">.</span>trainable <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>     <span class=\"token comment\"># Discriminator는 업데이트하지 않는다= 학습하지 않는다. 왜냐면 자체적으로 위에서 학습했으니까. 따라서 G만 학습됨 </span>\n    z <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>batch_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> nGInput<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    Gz <span class=\"token operator\">=</span> G<span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span>\n    DGz <span class=\"token operator\">=</span> D<span class=\"token punctuation\">(</span>Gz<span class=\"token punctuation\">)</span>\n    \n    model <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">,</span> DGz<span class=\"token punctuation\">)</span> <span class=\"token comment\">#z가 들어가면 최종적으로 DGz가 나온다. </span>\n    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss <span class=\"token operator\">=</span> <span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span> optimizer <span class=\"token operator\">=</span> MyOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.0005</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># binary_crossentropy: 출력값이 0 아니면 1 나오도록</span>\n    <span class=\"token keyword\">return</span> model</code></pre></div>\n</br>\n<h6 id=\"def-builddiscriminator--discriminator\" style=\"position:relative;\"><a href=\"#def-builddiscriminator--discriminator\" aria-label=\"def builddiscriminator  discriminator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>def BuildDiscriminator() = Discriminator</h6>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Discriminator를 G. D 각각 생성한다</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">BuildDiscriminator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    x <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>batch_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> nDInput<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    h <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>nDHidden<span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    Dx <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>nDOutput<span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>h<span class=\"token punctuation\">)</span> <span class=\"token comment\">#0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 </span>\n    model <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> Dx<span class=\"token punctuation\">)</span>\n    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss <span class=\"token operator\">=</span> <span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span> optimizer <span class=\"token operator\">=</span> MyOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> \n    <span class=\"token comment\">#sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 </span>\n    \n    <span class=\"token keyword\">return</span> model</code></pre></div>\n</br>\n<h6 id=\"def-buildgenerator--generator\" style=\"position:relative;\"><a href=\"#def-buildgenerator--generator\" aria-label=\"def buildgenerator  generator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>def BuildGenerator() = Generator</h6>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Generator를 생성한다 </span>\n<span class=\"token comment\"># G는 여기서 학습 안 하므로 '.complie' 안 함 </span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">BuildGenerator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> \n    z <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>batch_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> nGInput<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    h <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>nGHidden<span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span>\n    Gz <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>nGOutput<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'linear'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>h<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> Model<span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">,</span> Gz<span class=\"token punctuation\">)</span></code></pre></div>\n</br>\n<h5 id=\"kd--klraldata-fakedata\" style=\"position:relative;\"><a href=\"#kd--klraldata-fakedata\" aria-label=\"kd  klraldata fakedata permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>kd = KL(ralData, fakeData)</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    <span class=\"token keyword\">if</span> epoch <span class=\"token operator\">%</span> <span class=\"token number\">10</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        z <span class=\"token operator\">=</span> getNoise<span class=\"token punctuation\">(</span>m<span class=\"token operator\">=</span>realData<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> n<span class=\"token operator\">=</span>nGInput<span class=\"token punctuation\">)</span>\n        fakeData <span class=\"token operator\">=</span> Generator<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span>  \n        <span class=\"token comment\"># Generator = BuildGenerator()에서 만든 Model(z, Gz)를 활용하여, </span>\n        <span class=\"token comment\"># \"model.predict(z=노이즈 data)\" 하라는 뜻 </span>\n        kd <span class=\"token operator\">=</span> KL<span class=\"token punctuation\">(</span>realData<span class=\"token punctuation\">,</span> fakeData<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"epoch = %d, D-Loss = %.3f, G-Loss = %.3f, KL divergence = %.3f\"</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>epoch<span class=\"token punctuation\">,</span> Dloss<span class=\"token punctuation\">,</span> Gloss<span class=\"token punctuation\">,</span> kd<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Dloss: 0.6932636 , Gloss: 0.6933405 , kd: 0.2189525518812676 = 분산이 적다</span></code></pre></div>\n</br>\n<h6 id=\"def-kl\" style=\"position:relative;\"><a href=\"#def-kl\" aria-label=\"def kl permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>def KL</h6>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 두 분포 (P, Q)의 KL divergence를 계산한다.</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">KL</span><span class=\"token punctuation\">(</span>P<span class=\"token punctuation\">,</span> Q<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># 두 데이터의 분포를 계산한다</span>\n    histP<span class=\"token punctuation\">,</span> binsP <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>histogram<span class=\"token punctuation\">(</span>P<span class=\"token punctuation\">,</span> bins<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n    histQ<span class=\"token punctuation\">,</span> binsQ <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>histogram<span class=\"token punctuation\">(</span>Q<span class=\"token punctuation\">,</span> bins<span class=\"token operator\">=</span>binsP<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 두 분포를 pdf로 만들기 위해 normalization한다.</span>\n    histP <span class=\"token operator\">=</span> histP <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>histP<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span>\n    histQ <span class=\"token operator\">=</span> histQ <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>histQ<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># KL divergence를 계산한다</span>\n    kld <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>histP <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>histP <span class=\"token operator\">+</span> <span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>histQ <span class=\"token operator\">+</span> <span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> kld</code></pre></div>\n</br>\n</br>\n<h4 id=\"plt\" style=\"position:relative;\"><a href=\"#plt\" aria-label=\"plt permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>plt</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># real data 분포 (p)와 fake data 분포 (q)를 그려본다</span>\nz <span class=\"token operator\">=</span> getNoise<span class=\"token punctuation\">(</span>m<span class=\"token operator\">=</span>realData<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> n<span class=\"token operator\">=</span>nGInput<span class=\"token punctuation\">)</span>\nfakeData <span class=\"token operator\">=</span> Generator<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nsns<span class=\"token punctuation\">.</span>set_style<span class=\"token punctuation\">(</span><span class=\"token string\">'whitegrid'</span><span class=\"token punctuation\">)</span>\nsns<span class=\"token punctuation\">.</span>kdeplot<span class=\"token punctuation\">(</span>realData<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> bw<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Real'</span><span class=\"token punctuation\">)</span>\nsns<span class=\"token punctuation\">.</span>kdeplot<span class=\"token punctuation\">(</span>fakeData<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> bw<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Fake'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Distibution of real and fake data'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 487px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c2ef4c0767c4f98f9747be8c0cb92d40/7b439/image-20200809130155797.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 64.86486486486486%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABtUlEQVQ4y3VTDbObIBD0///GtvNeGicaH6h8iICwPY5Ikr5Wh1G55W5v9+xijDiO422llPg5jiP6vseXEJimO+7TiGEYeN97z7hEOB8zQqh5OmstB1+TlfUslJBThPkcsNw0Mt3vxQ9o4XC7DphniW7bNsoeWqKycs4teQZwLAryaiB/CWwm0k7mQowhbN4dnDWwlIsZviYsyVpCOlSu9VMQOCMai/mieC89GDK+lKBnOd9prf/fciYWbof8mBFZrwDxU1CssiuYU8fyXta3lk+GMR7MRI0W7ktVFkjQ/QK7+KbliT+N7IwxT8de1sEMQYwkUnGQ9cxw84blulZt47Ojs8Nu3/fm6LsxCVYFrBfJTJsktGwvucA/GZ4a/s2wsFl/zwhqYzbNBHoPYqV9yw4zPj9HqXPOsYZn9eJsOeQ1tfYhqqOl+gujgyTYbxNr+q3l5nIJoI5AucSPO7VcxT8PsKuPghsZtV5qwYqp8cYwB49ArNzqiJmEnVRjd2rUpuAx8OqmYK4S3ngilXjYebBj+R81BUcJMyievT14Zn6KXszjwo/vQLFIv2TcPJww0LrgA/4A4XP6fxf+uRsAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20200809130155797\"\n        title=\"image-20200809130155797\"\n        src=\"/static/c2ef4c0767c4f98f9747be8c0cb92d40/7b439/image-20200809130155797.png\"\n        srcset=\"/static/c2ef4c0767c4f98f9747be8c0cb92d40/12f09/image-20200809130155797.png 148w,\n/static/c2ef4c0767c4f98f9747be8c0cb92d40/e4a3f/image-20200809130155797.png 295w,\n/static/c2ef4c0767c4f98f9747be8c0cb92d40/7b439/image-20200809130155797.png 487w\"\n        sizes=\"(max-width: 487px) 100vw, 487px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<hr>\n<hr>\n</br>\n</br>\n<h2 id=\"cnn-gan-dcgan-code\" style=\"position:relative;\"><a href=\"#cnn-gan-dcgan-code\" aria-label=\"cnn gan dcgan code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CNN GAN (DCGAN) CODE</h2>\n</br>\n<ul>\n<li>\n<p>사용한 함수 총 5개:</br></p>\n<ol>\n<li>def build<em>generator(inputs, image</em>size)</br></li>\n<li>def build_discriminator(inputs)</br></li>\n<li>def train(models, x_train, params)</br></li>\n<li>def build<em>and</em>train<em>models(load</em>W = False, train_steps = 100)</br></li>\n<li>def plot_images():</br></li>\n</ol>\n</li>\n</ul>\n</br>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4867ffac049680dfe4dd33daef7986d9/573d3/image-20200809130207635.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.10810810810811%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABnklEQVQoz3VTS67CMBDrwTkBF+A8bNiwYc8CEC08+qOl/1/m2UNSFSQijRoRx/Z4gic/ljFGDDfDIH1VSVXXUvGL6vv+A7dcnl78VURMk1R5LhmKZF3XaY0QGsfxkxRfb1b6duh+w6XYD8S/3STLMilBWjeNVgviGWtJPQMHhkptJxPaYnsDvgZgFlWropAIhNH9LsH5LOnjAUyjcRi0bxZOPdO2YmgfilUYSRRFkj+f0pMQQCXmOaoDNsZ5Ese6n2iG95t2QWhb7KCUI6c7XKRpKg0EXEZcbI8YCr5eL2ks4fdwdChlWWrgSZLI5XKRMAylQJszITCcLH87nU4qWtupFyBnVLNDtkeCB3K5ISff99UFRZYOSRij1TMyJCFdspM/7HOLV0Jnmy1yio6Q6gNyc4tPxRFSmPG4uxOINE/N0PZOBy1yoTrBJHMgYy/QFc8pSAPD4i3OD/v7H7JarWS73eqeLt0Q6JC5Ubiz72+z2ch6vZb3cx3fDhk0W2XR2W63k+PxqAO6Xq9ajCEIgrl4xswOh4Ps93vd13Yw/zXqn4f5hoHcAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20200809130207635\"\n        title=\"image-20200809130207635\"\n        src=\"/static/4867ffac049680dfe4dd33daef7986d9/fcda8/image-20200809130207635.png\"\n        srcset=\"/static/4867ffac049680dfe4dd33daef7986d9/12f09/image-20200809130207635.png 148w,\n/static/4867ffac049680dfe4dd33daef7986d9/e4a3f/image-20200809130207635.png 295w,\n/static/4867ffac049680dfe4dd33daef7986d9/fcda8/image-20200809130207635.png 590w,\n/static/4867ffac049680dfe4dd33daef7986d9/efc66/image-20200809130207635.png 885w,\n/static/4867ffac049680dfe4dd33daef7986d9/c83ae/image-20200809130207635.png 1180w,\n/static/4867ffac049680dfe4dd33daef7986d9/573d3/image-20200809130207635.png 1650w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n</br>\n<h4 id=\"base\" style=\"position:relative;\"><a href=\"#base\" aria-label=\"base permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Base</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># load MNIST dataset</span>\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> _<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>_<span class=\"token punctuation\">,</span> _<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\" 비지도 방법으로 사용 \"\"\"</span>\n\n<span class=\"token comment\"># reshape data for CNN as (28, 28, 1) and normalize </span>\n<span class=\"token triple-quoted-string string\">\"\"\" 2D CNN \"\"\"</span>\nimage_size <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># x_train.shape (60000, 28, 28)</span>\nx_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> image_size<span class=\"token punctuation\">,</span> image_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># x_train.shape = (60000, 28, 28, 1)</span>\nx_train <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">255</span> <span class=\"token comment\"># 표준화</span>\n\n<span class=\"token comment\"># the latent or z vector is 100-dim</span>\nlatent_size <span class=\"token operator\">=</span> <span class=\"token number\">100</span> <span class=\"token comment\">#latent: KNN 가기 전 층들</span></code></pre></div>\n</br>\n</br>\n<h4 id=\"step-1-build_generator\" style=\"position:relative;\"><a href=\"#step-1-build_generator\" aria-label=\"step 1 build_generator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step 1. build_generator</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">build_generator</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> image_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># latent 층에 씀 </span>\n    image_resize <span class=\"token operator\">=</span> image_size <span class=\"token operator\">//</span> <span class=\"token number\">4</span>\n    \n    <span class=\"token comment\"># network parameters </span>\n    kernel_size <span class=\"token operator\">=</span> <span class=\"token number\">5</span>\n    layer_filters <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n\n    x <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>image_resize <span class=\"token operator\">*</span> image_resize <span class=\"token operator\">*</span> layer_filters<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> Reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>image_resize<span class=\"token punctuation\">,</span> image_resize<span class=\"token punctuation\">,</span> layer_filters<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">for</span> filters <span class=\"token keyword\">in</span> layer_filters<span class=\"token punctuation\">:</span> <span class=\"token comment\"># hidden 층을 for문으로 써줌(쫙 쌓아주는 것)</span>\n        <span class=\"token comment\"># first two convolution layers use strides = 2</span>\n        <span class=\"token comment\"># the last two use strides = 1</span>\n        <span class=\"token keyword\">if</span> filters <span class=\"token operator\">></span> layer_filters<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            strides <span class=\"token operator\">=</span> <span class=\"token number\">2</span> <span class=\"token comment\"># 따라서 layer_filters의 뒤에서 2번째까진 strides = 2</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            strides <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n        x <span class=\"token operator\">=</span> BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Activation<span class=\"token punctuation\">(</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2DTranspose<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>filters<span class=\"token punctuation\">,</span>\n                            kernel_size<span class=\"token operator\">=</span>kernel_size<span class=\"token punctuation\">,</span>\n                            strides<span class=\"token operator\">=</span>strides<span class=\"token punctuation\">,</span>\n                            padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token comment\"># data 양 뿔려줌 </span>\n\n    x <span class=\"token operator\">=</span> Activation<span class=\"token punctuation\">(</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    generator <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'generator'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 모방 모델이므로 y 자리엔 x 학습 결과를 써줌 </span>\n    <span class=\"token keyword\">return</span> generator <span class=\"token comment\"># 요렇게 fake data 만들어서 전에 모델처럼 Discriminator에 넣어줌 </span></code></pre></div>\n</br>\n</br>\n<h4 id=\"step-2-build_discriminator\" style=\"position:relative;\"><a href=\"#step-2-build_discriminator\" aria-label=\"step 2 build_discriminator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step 2. build_discriminator</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">build_discriminator</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    kernel_size <span class=\"token operator\">=</span> <span class=\"token number\">5</span>\n    layer_filters <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">]</span>\n\n    x <span class=\"token operator\">=</span> inputs\n    <span class=\"token keyword\">for</span> filters <span class=\"token keyword\">in</span> layer_filters<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># first 3 convolution layers use strides = 2</span>\n        <span class=\"token comment\"># last one uses strides = 1</span>\n        <span class=\"token comment\"># 따라서 Discriminator를 더 많이 학습하게 됨 </span>\n        <span class=\"token keyword\">if</span> filters <span class=\"token operator\">==</span> layer_filters<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            strides <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            strides <span class=\"token operator\">=</span> <span class=\"token number\">2</span>\n        x <span class=\"token operator\">=</span> LeakyReLU<span class=\"token punctuation\">(</span>alpha<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>filters<span class=\"token punctuation\">,</span>\n                   kernel_size<span class=\"token operator\">=</span>kernel_size<span class=\"token punctuation\">,</span>\n                   strides<span class=\"token operator\">=</span>strides<span class=\"token punctuation\">,</span>\n                   padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n    x <span class=\"token operator\">=</span> Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> Activation<span class=\"token punctuation\">(</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    discriminator <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'discriminator'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> discriminator</code></pre></div>\n</br>\n</br>\n<h4 id=\"step-3-buildandtrain_models\" style=\"position:relative;\"><a href=\"#step-3-buildandtrain_models\" aria-label=\"step 3 buildandtrain_models permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step 3. build<em>and</em>train_models</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">build_and_train_models</span><span class=\"token punctuation\">(</span>load_W <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> train_steps <span class=\"token operator\">=</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    model_name <span class=\"token operator\">=</span> <span class=\"token string\">\"dcgan_mnist\"</span>\n    \n    <span class=\"token comment\"># network parameters</span>\n    batch_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\n    lr <span class=\"token operator\">=</span> <span class=\"token number\">2e</span><span class=\"token operator\">-</span><span class=\"token number\">4</span>\n    decay <span class=\"token operator\">=</span> <span class=\"token number\">6e</span><span class=\"token operator\">-</span><span class=\"token number\">8</span>\n    input_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image_size<span class=\"token punctuation\">,</span> image_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># build discriminator model</span>\n    inputs <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span>input_shape<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'discriminator_input'</span><span class=\"token punctuation\">)</span>\n    discriminator <span class=\"token operator\">=</span> build_discriminator<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># [1] or original paper uses Adam, </span>\n    <span class=\"token comment\"># but discriminator converges easily with RMSprop</span>\n    optimizer <span class=\"token operator\">=</span> RMSprop<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span>lr<span class=\"token punctuation\">,</span> decay<span class=\"token operator\">=</span>decay<span class=\"token punctuation\">)</span>\n    discriminator<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span>\n                          optimizer<span class=\"token operator\">=</span>optimizer<span class=\"token punctuation\">,</span>\n                          metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    discriminator<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 저장된 discriminator 모델을 읽어온다.</span>\n    <span class=\"token keyword\">if</span> load_W<span class=\"token punctuation\">:</span>\n        discriminator<span class=\"token punctuation\">.</span>load_weights<span class=\"token punctuation\">(</span><span class=\"token string\">\"dataset/dcgan_D.h5\"</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># build generator model</span>\n    input_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>latent_size<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">)</span>\n    inputs <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span>input_shape<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'z_input'</span><span class=\"token punctuation\">)</span>\n    generator <span class=\"token operator\">=</span> build_generator<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> image_size<span class=\"token punctuation\">)</span>\n    generator<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 저장된 generator 모델을 읽어온다.</span>\n    <span class=\"token keyword\">if</span> load_W<span class=\"token punctuation\">:</span>\n        generator<span class=\"token punctuation\">.</span>load_weights<span class=\"token punctuation\">(</span><span class=\"token string\">\"dataset/dcgan_G.h5\"</span><span class=\"token punctuation\">)</span>\n        \n    <span class=\"token comment\"># build adversarial model</span>\n    optimizer <span class=\"token operator\">=</span> RMSprop<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span>lr <span class=\"token operator\">*</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> decay<span class=\"token operator\">=</span>decay <span class=\"token operator\">*</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># freeze the weights of discriminator during adversarial training</span>\n    discriminator<span class=\"token punctuation\">.</span>trainable <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n    \n    <span class=\"token comment\"># adversarial = generator + discriminator</span>\n    adversarial <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> \n                        discriminator<span class=\"token punctuation\">(</span>generator<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                        name<span class=\"token operator\">=</span>model_name<span class=\"token punctuation\">)</span>\n    adversarial<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span>\n                        optimizer<span class=\"token operator\">=</span>optimizer<span class=\"token punctuation\">,</span>\n                        metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    adversarial<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#adversarial: 최종모델</span>\n\n    <span class=\"token comment\"># train discriminator and adversarial networks</span>\n    models <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>generator<span class=\"token punctuation\">,</span> discriminator<span class=\"token punctuation\">,</span> adversarial<span class=\"token punctuation\">)</span>\n    params <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> latent_size<span class=\"token punctuation\">,</span> train_steps<span class=\"token punctuation\">,</span> model_name<span class=\"token punctuation\">)</span>\n    train<span class=\"token punctuation\">(</span>models<span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">,</span> params<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 모델을 저장해 둔다</span>\n    discriminator<span class=\"token punctuation\">.</span>save_weights<span class=\"token punctuation\">(</span><span class=\"token string\">\"dataset/dcgan_D.h5\"</span><span class=\"token punctuation\">)</span>\n    generator<span class=\"token punctuation\">.</span>save_weights<span class=\"token punctuation\">(</span><span class=\"token string\">\"dataset/dcgan_G.h5\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n</br>\n</br>\n<h4 id=\"step-4-train\" style=\"position:relative;\"><a href=\"#step-4-train\" aria-label=\"step 4 train permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step 4. train</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">train</span><span class=\"token punctuation\">(</span>models<span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">,</span> params<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># the GAN component models</span>\n    generator<span class=\"token punctuation\">,</span> discriminator<span class=\"token punctuation\">,</span> adversarial <span class=\"token operator\">=</span> models \n    \n    \n    <span class=\"token comment\"># network parameters</span>\n    batch_size<span class=\"token punctuation\">,</span> latent_size<span class=\"token punctuation\">,</span> train_steps<span class=\"token punctuation\">,</span> model_name <span class=\"token operator\">=</span> params \n    \n    \n    <span class=\"token comment\"># number of elements in train dataset</span>\n    train_size <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>train_steps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># train the discriminator for 1 batch</span>\n        <span class=\"token comment\"># 1 batch of real (label=1.0) and fake images (label=0.0)</span>\n        <span class=\"token comment\"># randomly pick real images from dataset</span>\n        rand_indexes <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> train_size<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span>batch_size<span class=\"token punctuation\">)</span>\n        real_images <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">[</span>rand_indexes<span class=\"token punctuation\">]</span>\n        \n        <span class=\"token comment\"># generate fake images from noise using generator </span>\n        <span class=\"token comment\"># generate noise using uniform distribution(모든 확률변수에 대해 균일한 확률을 가짐)</span>\n        noise <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>uniform<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span>\n                                  <span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span>\n                                  size<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>batch_size<span class=\"token punctuation\">,</span> latent_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># generate fake images</span>\n        fake_images <span class=\"token operator\">=</span> generator<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>noise<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token comment\"># real + fake images = 1 batch of train data</span>\n        x <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>real_images<span class=\"token punctuation\">,</span> fake_images<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        \n        <span class=\"token comment\"># label real and fake images</span>\n        <span class=\"token comment\"># real images label is 1.0</span>\n        y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span> <span class=\"token operator\">*</span> batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        \n        <span class=\"token comment\"># fake images label is 0.0</span>\n        y<span class=\"token punctuation\">[</span>batch_size<span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.0</span>\n        \n        <span class=\"token comment\"># train discriminator network, log the loss and accuracy</span>\n        loss<span class=\"token punctuation\">,</span> acc <span class=\"token operator\">=</span> discriminator<span class=\"token punctuation\">.</span>train_on_batch<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> \n        <span class=\"token triple-quoted-string string\">\"\"\"Q. loss: 인덱스??? \"\"\"</span>\n        log <span class=\"token operator\">=</span> <span class=\"token string\">\"%d: [D-loss: %.4f, acc: %.4f]\"</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">,</span> acc<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># train the adversarial network for 1 batch</span>\n        <span class=\"token comment\"># 1 batch of fake images with label=1.0</span>\n        <span class=\"token comment\"># since the discriminator weights </span>\n        <span class=\"token comment\"># are frozen in adversarial network(adversarial network: 적대적 신경망(경쟁 속 반대편에 놓인 신경망))</span>\n        <span class=\"token comment\"># only the generator is trained</span>\n        <span class=\"token comment\"># generate noise using uniform distribution</span>\n        noise <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>uniform<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span>\n                                  <span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> \n                                  size<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>batch_size<span class=\"token punctuation\">,</span> latent_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        \n        <span class=\"token comment\"># label fake images as real or 1.0</span>\n        y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># train the adversarial network </span>\n        <span class=\"token comment\"># note that unlike in discriminator training, </span>\n        <span class=\"token comment\"># we do not save the fake images in a variable</span>\n        <span class=\"token comment\"># the fake images go to the discriminator input of the adversarial</span>\n        <span class=\"token comment\"># for classification</span>\n        <span class=\"token comment\"># log the loss and accuracy</span>\n        loss<span class=\"token punctuation\">,</span> acc <span class=\"token operator\">=</span> adversarial<span class=\"token punctuation\">.</span>train_on_batch<span class=\"token punctuation\">(</span>noise<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> \n        <span class=\"token triple-quoted-string string\">\"\"\"Q. adversarial 뜻???\"\"\"</span>\n        log <span class=\"token operator\">=</span> <span class=\"token string\">\"%s [G-loss: %.4f, acc: %.4f]\"</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">,</span> acc<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">)</span>\n   \n    <span class=\"token comment\"># save the model after training the generator</span>\n    <span class=\"token comment\"># the trained generator can be reloaded for </span>\n    <span class=\"token comment\"># future MNIST digit generation</span>\n    generator<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>model_name <span class=\"token operator\">+</span> <span class=\"token string\">\".h5\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n</br>\n</br>\n<h4 id=\"step-5-fake-data를-화면에-표시\" style=\"position:relative;\"><a href=\"#step-5-fake-data%EB%A5%BC-%ED%99%94%EB%A9%B4%EC%97%90-%ED%91%9C%EC%8B%9C\" aria-label=\"step 5 fake data를 화면에 표시 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>step 5. fake data를 화면에 표시</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Generator가 생성한 이미지(fake data)를 화면에 표시한다.</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">plot_images</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    inputs <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>latent_size<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'z_input'</span><span class=\"token punctuation\">)</span>\n    generator <span class=\"token operator\">=</span> build_generator<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> image_size<span class=\"token punctuation\">)</span>\n    generator<span class=\"token punctuation\">.</span>load_weights<span class=\"token punctuation\">(</span><span class=\"token string\">\"dataset/dcgan_G.h5\"</span><span class=\"token punctuation\">)</span>\n    \n    noise_input <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>uniform<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> latent_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    images <span class=\"token operator\">=</span> generator<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>noise_input<span class=\"token punctuation\">)</span> <span class=\"token comment\"># Generator 통해 나온 fake data</span>\n    plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    num_images <span class=\"token operator\">=</span> images<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    \n    noise_input <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>uniform<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">100</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    rows <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>noise_input<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_images<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span>rows<span class=\"token punctuation\">,</span> rows<span class=\"token punctuation\">,</span> i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        image <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>image _size<span class=\"token punctuation\">,</span> image_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> \n        <span class=\"token triple-quoted-string string\">\"\"\"why 3차원 reshape???\"\"\"</span>\n        plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span>\n        plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n</br>\n</br>\n<h4 id=\"final\" style=\"position:relative;\"><a href=\"#final\" aria-label=\"final permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Final</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 이미 학습된 weights를 읽어오고, 추가로 학습한다.</span>\nbuild_and_train_models<span class=\"token punctuation\">(</span>load_W <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> train_steps <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># train_steps 만큼 반복 학습</span>\n\n<span class=\"token comment\"># Generator가 생성한 이미지를 화면에 표시한다.</span>\nplot_images<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n</br>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/fa51182f7404b07162d67390997b0e5b/f6b72/image-20200714193936268.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.27027027027027%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABe0lEQVQoz5WSW28TMRCF9///Jp5QhVBFKoRACEqTkmUTmna7V9u7vn3MuApQ9amWjsYzts/xGbtCRgiRZXGC5QW8D7RtS9P84tA0WGtZ17WsnaOxDmNMQaXFvu9JKZOF/AXcSE6RlDNJ8mQHkpskl7nUY/D03SPb7Zbj8UjlRLHrelY7MXcnzNBiH/YsY0sY74j1FVFtPO5gPMB0hyzy/yiCAucclVroB1EVpegX4jKTpnvi6Rr34wJXf8Qcv2Nu3mN2l6zbd4T2lhgDmHuYRSCFQqz2K+3POIqtzPNRNknRPEBzRer2pHaH//YGW3/C/dxgr9+W3HsPrmNx0kNl7bpOCPNznHuYEzmGszno9/D7M+wvSfUGf/iCvd0UAac3VN/6KK8a3jz1cRVkEWs+wOkrq9y0SikxSA/1piGEv1GF/uVe7Lhi7SlKffVCEFn1e5kB72xpXVXaJaT6OHpgnucSp2kqUf+WEtd1XWqaK6nuszLXc1b+oUJrfwDgd7kdNL4X5wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20200714193936268\"\n        title=\"image-20200714193936268\"\n        src=\"/static/fa51182f7404b07162d67390997b0e5b/fcda8/image-20200714193936268.png\"\n        srcset=\"/static/fa51182f7404b07162d67390997b0e5b/12f09/image-20200714193936268.png 148w,\n/static/fa51182f7404b07162d67390997b0e5b/e4a3f/image-20200714193936268.png 295w,\n/static/fa51182f7404b07162d67390997b0e5b/fcda8/image-20200714193936268.png 590w,\n/static/fa51182f7404b07162d67390997b0e5b/f6b72/image-20200714193936268.png 615w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/924334ab46f3f70fd22ca0d3fb7204b7/0a47e/image-20200714193941200.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABoElEQVQoz3WSbY+bMAzH+f6fam/25t5s0m7XHdf2Cm2a0kILJBAICb8ltJWmabNk+SG2Y/vvZBgG/sfWWq7XK1mWIYT4R8y4yK43aK0XPdFKMQPeGnwrcYPCzzPee1zgKL1zf8gne2ZnmaYJ1dbsdjvKsiTp+55IVlU4+RoUvdjMPn7D3zQ/5FRLOrG6+x4NNE1DEtuejGb78wX54wuukcym4SrWtHJ9z+6v4EY63TKHCSJVh5RL+vKo3sWqtG1LYkKH6pyzWae8f//K8XNFfjzxEeztxxvzJcUUG/xlTb5Zcc5TaASHLNjv3xirPUeRh490KKjCDrseGRznQlIWgto4fp0UBymp65o0XfFRtBz2O/I8o1AWcTwgpSA7XXjb7hE3Q61DYwGPJCJTdY5Sj7T9iB4musBm8lg3k1U9ojahqAr+cZmwaAyfF0V4pgkNxJymt2j1GNn5mX6cwmLnZcE8OKIc7cFO1N29WFx+pFINATe/wGQnt8QuoHRdt9zQON5v6na7YYxZ7BgQx7BBj3Hx7XmDcR3PvCirqmIMd/sbQ+20LI/AryoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20200714193941200\"\n        title=\"image-20200714193941200\"\n        src=\"/static/924334ab46f3f70fd22ca0d3fb7204b7/fcda8/image-20200714193941200.png\"\n        srcset=\"/static/924334ab46f3f70fd22ca0d3fb7204b7/12f09/image-20200714193941200.png 148w,\n/static/924334ab46f3f70fd22ca0d3fb7204b7/e4a3f/image-20200714193941200.png 295w,\n/static/924334ab46f3f70fd22ca0d3fb7204b7/fcda8/image-20200714193941200.png 590w,\n/static/924334ab46f3f70fd22ca0d3fb7204b7/0a47e/image-20200714193941200.png 600w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n</tr>\n</tbody>\n</table>","excerpt":"GAN 1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다. fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등) Discrimi의 loss는 maxlog(Dx) + log…","tableOfContents":"<ul>\n<li>\n<p><a href=\"/GAN_2/#gan\">GAN</a></p>\n<ul>\n<li><a href=\"/GAN_2/#basic-code\">Basic CODE</a></li>\n<li><a href=\"/GAN_2/#cnn-gan-dcgan-code\">CNN GAN (DCGAN) CODE</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/GAN_2/"},"frontmatter":{"title":"GAN 실전 응용","date":"Aug 08, 2020","tags":["DL","GAN"],"keywords":["JyneeEarth","jynee"],"update":"Aug 08, 2020"}}},"pageContext":{"slug":"/GAN_2/","series":[{"slug":"/GAN_1/","title":"GAN 이론","num":1},{"slug":"/GAN_2/","title":"GAN 실전 응용","num":2}],"lastmod":"2020-08-08"}},"staticQueryHashes":["3649515864","694178885"]}