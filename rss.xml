<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[JyneeEarth | Feed]]></title><description><![CDATA[jynee's lab]]></description><link>https://jynee.github.io/tags#1st</link><generator>GatsbyJS</generator><lastBuildDate>Tue, 18 Aug 2020 16:44:44 GMT</lastBuildDate><item><title><![CDATA[GAN 이론]]></title><description><![CDATA[GAN 비지도학습(UL) 방식의 이미지, 문서, 음성 등의 데이터를 생성(모방)하는 알고리즘 비모수적방법으로도 비교적 정확한 sampling이 가능함  위조 데이터 생성 및 판별에 사용 
EX…]]></description><link>https://jynee.github.io/tags#1st/GAN_1/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/GAN_1/</guid><pubDate>Sat, 08 Aug 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;gan&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#gan&quot; aria-label=&quot;gan permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GAN&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;비지도학습(UL) 방식의 이미지, 문서, 음성 등의 데이터를 &lt;strong&gt;생성(모방)하는 알고리즘&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;비모수적방법&lt;/strong&gt;으로도 비교적 정확한 &lt;strong&gt;sampling이 가능&lt;/strong&gt;함 &lt;/li&gt;
&lt;li&gt;위조 데이터 생성 및 판별에 사용
EX) 이미지 색깔(색칠) 해주는 프로그램, 딥페이크 영상&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/ff466a3851f29e6c207a88c4333ce60e/32056/image-20200728184326510.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABgklEQVQoz31Su0oDURC9iBZaWfgZfomIH2BroYVEJCAWYqdfIGgKwcLaSkHsBEXUwsJCELNJ1GiMicnmscnexx5n7j7cQOKBKfbOzpk5Z0ZgBIIgsMHQxkDqvwhzSPLpf8V/hAxjAvSlTt4VEfaib005qQOYFLGI2YdFUqQ0+sqg1pa2uOlJ+z5M0dAJFXXlAi5mIl/p5J2D2mDv0sV87guHN23kv2VSayfk4jjiydLoSYWur+GRVNdTlnDrtA6x/ILxjIPZ3XcUaj1rhVAm9ISnYPMrrsT22Q8e3vp4rkrsnDfwWPbISyIkUpZLziJ7QoRLecxsvmLxqIpqyw8J7dYQSmN8ugpitYCpbAnTGyWawsF1vhtNaqwKpTUunjyS28JHUw2oESoirHckTWmok8JYpoiJNQeT6wWIFQe3BY9tp5y0ltQ7/sgzs4Qqui1GuSExt1/BwVULx/cdLOQquCt2kyK2hqXxkuOTSV+GXQrfGRvPkb65GOm8JTPBwK2mF/kL+MP0X/SgmJAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image 20200728184326510&quot;
        title=&quot;image 20200728184326510&quot;
        src=&quot;/static/ff466a3851f29e6c207a88c4333ce60e/fcda8/image-20200728184326510.png&quot;
        srcset=&quot;/static/ff466a3851f29e6c207a88c4333ce60e/12f09/image-20200728184326510.png 148w,
/static/ff466a3851f29e6c207a88c4333ce60e/e4a3f/image-20200728184326510.png 295w,
/static/ff466a3851f29e6c207a88c4333ce60e/fcda8/image-20200728184326510.png 590w,
/static/ff466a3851f29e6c207a88c4333ce60e/32056/image-20200728184326510.png 602w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;출처: &lt;a href=&quot;https://www.naverlabs.com/storyDetail/44&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.naverlabs.com/storyDetail/44&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;그림-보충-설명&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EA%B7%B8%EB%A6%BC-%EB%B3%B4%EC%B6%A9-%EC%84%A4%EB%AA%85&quot; aria-label=&quot;그림 보충 설명 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;그림 보충 설명:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Real&lt;/code&gt;: 실제 데이터(이미지, 음성 등)&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Input&lt;/code&gt;: 랜덤 데이터. &lt;strong&gt;노이즈 섞인 것&lt;/strong&gt;. 	&lt;em&gt;But,&lt;/em&gt; Generator 통과하면, Real data 같은 것으로 변환돼 나온다.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Generator(network)&lt;/code&gt;: 생성자. &lt;strong&gt;진짜 같은 가짜(Fake) 생성&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Discriminator(network)&lt;/code&gt;: 판별자. &lt;strong&gt;실제 데이터(Real)와 가짜 데이터(Fake)를 판별&lt;/strong&gt;함&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;즉-총-2개의-네트워크-사용&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%A6%89-%EC%B4%9D-2%EA%B0%9C%EC%9D%98-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%82%AC%EC%9A%A9&quot; aria-label=&quot;즉 총 2개의 네트워크 사용 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;즉, 총 2개의 네트워크 사용:&lt;/strong&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Discriminator&lt;/code&gt;: real or fake 판별자&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Generator&lt;/code&gt;: fake 생성자&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;gan의-loss-function&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#gan%EC%9D%98-loss-function&quot; aria-label=&quot;gan의 loss function permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gan의 loss function:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;minGmaxDV(D,G) = logD(x) + log(1-D(G(z)))&lt;code class=&quot;language-text&quot;&gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;학습을 반복하여 (Pg = Pdata가 되어) Discriminator가 구별 불가능인 상태(‘D(x)=0.5’)로 수렴하도록
→ 마치 Generator가 x를 만들어낸 것처럼 됨 &lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Discriminator&lt;/th&gt;
&lt;th&gt;Generator&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;엔트로피 최대화&lt;/td&gt;
&lt;td&gt;엔트로피 최소화&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;엔트로피: 정보의 가치(정보량)과 ~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt;  &lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;Discriminator&lt;/code&gt;&lt;/strong&gt;(network): &lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;maxV(D, G)&lt;/code&gt;&lt;/strong&gt;로 학습. D(x) = 1 and D(G(z)) = 0일 때 최대&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;why?&lt;/em&gt; D(G(z))가 1이 되고, D(x)가 1이 되니까&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;Generator&lt;/code&gt;&lt;/strong&gt; network: &lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;minV(G)&lt;/code&gt;&lt;/strong&gt;로 학습. D(G(z)) = 1 일 때 최소. 이때(D(x)는 상관 X)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;why?&lt;/em&gt; D(G(z))가 0이 되니까&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&quot;원리&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%9B%90%EB%A6%AC&quot; aria-label=&quot;원리 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;원리:&lt;/h3&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/6be073ef6d6fa9dd4ff79d7d459669c9/32056/image-20200728185621472.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 41.891891891891895%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABSUlEQVQoz31R2W7DMAzL//9c99Khd9cka27ncNw0jm1OUtECG4oZIGg7MUVK0Xr9idXqA7vdHpvNFvv9QXA8nnA4HBHHiezP5y85Z1kGXiEEwd8V1XWN7XaHJElR5AX4bG433O93zPMsPE0TbnI3wzn3EnuHiFW5MuN6zVCVFS7kSDUK42jIUS7gb22rRPi/FbGq1hpVVSMnh6ppoIhb4kYpctxgtuwswJiFXDsS9QJrA7n3AmO8/BMtyyKC4zii7TqJ+4zHcbUeoUdNDyYMw0OMmQWee2atHZaFBPkRNzxJv5FTtPwSIzmdpJdFUYrzYRhE2Dn/6pX34X1k7/2vaU3kriQhYwwJaWEehLUefR/ozqPrHBVcoNTDFUfl+FwkqskBT5h7pahn7KQnRx3F7/seHaPrpS3MPKgQWNQiTSc0zYyynIWtdfgBzhpml1rCyu4AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image 20200728185621472&quot;
        title=&quot;image 20200728185621472&quot;
        src=&quot;/static/6be073ef6d6fa9dd4ff79d7d459669c9/fcda8/image-20200728185621472.png&quot;
        srcset=&quot;/static/6be073ef6d6fa9dd4ff79d7d459669c9/12f09/image-20200728185621472.png 148w,
/static/6be073ef6d6fa9dd4ff79d7d459669c9/e4a3f/image-20200728185621472.png 295w,
/static/6be073ef6d6fa9dd4ff79d7d459669c9/fcda8/image-20200728185621472.png 590w,
/static/6be073ef6d6fa9dd4ff79d7d459669c9/32056/image-20200728185621472.png 602w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;출처: Goodfellow 논문 공식&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Discriminator&lt;/code&gt;를 k번 학습시키고, &lt;code class=&quot;language-text&quot;&gt;Generator&lt;/code&gt;를 1번 학습시킨다.&lt;/p&gt;
&lt;p&gt;→ D가 G보다 더 많이 학습된다.    * D: Discriminator / * G: Generator&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;em&gt;이에 따라&lt;/em&gt; &gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Real Data와 Fake Data를 구별해내는 &lt;code class=&quot;language-text&quot;&gt;D loss&lt;/code&gt;는 점점 더 작아져 영향력이 줄어들고,&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;D&lt;/code&gt;와 &lt;code class=&quot;language-text&quot;&gt;G&lt;/code&gt;는 점점 더 비슷해지며,&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;KL&lt;/code&gt;이 적어지고,   &lt;strong&gt;*&lt;/strong&gt;KL: G와 D의 정보량의 차이/분산의 차이&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;p&gt;&lt;em&gt;이럴수록&lt;/em&gt; &gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	3-1) G가 더 많은 영향력을 행사하고(역할을 하고),&lt;/p&gt;
&lt;p&gt;​	3-2) &lt;code class=&quot;language-text&quot;&gt;D loss&lt;/code&gt;를 계산하는 공식 中 [-log4 + 2JSD(Pdata+||Pg)]에서 -log4의 값이 더욱더 1.38에 가까워진다.
​    *[2JSD(Pdata+||Pg) ] : KL이라 보면 됨. (KL이 작아진다) = (D와 G의 분산이 적다) = (D loss가 1.38에 가깝다)&lt;/p&gt;
   &lt;br&gt;
&lt;p&gt;   &lt;em&gt;따라서&lt;/em&gt;  &gt;&lt;/p&gt;
&lt;p&gt;   분별할 수 없이 실제와 가까운 Fake Data가 생성된다.&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;위 원리에 따라,&lt;/p&gt;
&lt;p&gt;&lt;em&gt;학습이 안 된 상태에선&lt;/em&gt; &gt;&lt;/p&gt;
&lt;p&gt;G(z) ( = Fake Data. 이때 ‘z’는 input에서 들어온 random data임)의 분포가 오른쪽으로 치우친 상태로서 D(x)는 1에 가까운 값이 출력되고 D(G(z))는 0에 가까운 값이 출력된다.&lt;/p&gt;
&lt;p&gt;&lt;sup id=&quot;fnref-1&quot;&gt;&lt;a href=&quot;#fn-1&quot; class=&quot;footnote-ref&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;: 이때 D와 G는 아래 함수와 같은 상태임&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 377px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/7329e5014c8de29c438849a8359f8ee5/6146e/image-20200728190633284.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 16.216216216216214%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsSAAALEgHS3X78AAAAnUlEQVQI1z1PSwqFMBDz/sfxAuJKwR/oQt2KC0EQaj/W/iLTPt4iZCaESSYzxkNrB2LOLYDwA6LGWNKex0WEECClw31bKJU02oVInC2LQp5faFuBpuE4jhf7riOmSaKuOaqKoygY1lXFI+MoUZYs+vteYBgEuk5gnhUyakHG901NKZmObZvGeZrY8rpM1K31cM7De//3UwC1o+9o/gBXXeO5Ghev+wAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200728190633284&quot;
        title=&quot;image-20200728190633284&quot;
        src=&quot;/static/7329e5014c8de29c438849a8359f8ee5/6146e/image-20200728190633284.png&quot;
        srcset=&quot;/static/7329e5014c8de29c438849a8359f8ee5/12f09/image-20200728190633284.png 148w,
/static/7329e5014c8de29c438849a8359f8ee5/e4a3f/image-20200728190633284.png 295w,
/static/7329e5014c8de29c438849a8359f8ee5/6146e/image-20200728190633284.png 377w&quot;
        sizes=&quot;(max-width: 377px) 100vw, 377px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/112ffbe40ca0e7e655685f848da8bdb7/32056/image-20200728190622855.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 9.45945945945946%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsSAAALEgHS3X78AAAAbklEQVQI1yWMSwqAMAxEvf/1ClYENy3oQvBTbVqbyEji4jHhZZLOe0IIFfvOxrI86HuCcxnjSIixYp4f4zgY01Rsp1772lU3DH92KmsVbFvDujakxLhvMYgEpQhae3FdYg9yFpwnm2d+7VZn9Zofk++YH5r8gOMAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200728190622855&quot;
        title=&quot;image-20200728190622855&quot;
        src=&quot;/static/112ffbe40ca0e7e655685f848da8bdb7/fcda8/image-20200728190622855.png&quot;
        srcset=&quot;/static/112ffbe40ca0e7e655685f848da8bdb7/12f09/image-20200728190622855.png 148w,
/static/112ffbe40ca0e7e655685f848da8bdb7/e4a3f/image-20200728190622855.png 295w,
/static/112ffbe40ca0e7e655685f848da8bdb7/fcda8/image-20200728190622855.png 590w,
/static/112ffbe40ca0e7e655685f848da8bdb7/32056/image-20200728190622855.png 602w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;즉, D는 진짜 (X)와 가짜 G(z)를 잘 구별하고, &lt;code class=&quot;language-text&quot;&gt;G&lt;/code&gt;는 진짜 같은 가짜를 잘 못 만든다&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;em&gt;학습이 진행되면&lt;/em&gt; &gt; &lt;/p&gt;
&lt;p&gt;가짜 데이터 G(z)의 분포가 점점 Real Data( = X)의 분포와 유사해지고 D(G(z)) 값도 점차 커져서 D(x)값은 점차 작아진다 &lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;em&gt;학습이 완료되면&lt;/em&gt; &gt; &lt;/p&gt;
&lt;p&gt;Real data와 G(z)의 분포가 잘 일치하고 “D(x) = D(G(z)) = 0.5 “로 수렴한다.&lt;/p&gt;
&lt;p&gt;즉, 임의의 random data를 G에 입력해 나온 Fake data는 Real data와 유사한 분포 특성을 갖는 데이터가 출력된다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/4fb82e1ce3bea1e96e8be416befbd8a0/32056/image-20200728190502482.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 31.756756756756754%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAABCElEQVQY00VR2XKDMAzM//9d+tRMkpeUI4AhYGMDPthq3ZBqZse2jtVKPu37DoK2LAuMMZjnGdZaOOfQdR3Ksvz4CN4ZI0IIOIw8p+NCSykJqYP3HjFERnIBwRjzQgyffPqtnTMO4tMRJAkVar2hKGtoMwlpkrcULDaTJ+lBxSH4TOrcgn54oVM9nHXiS38K2Z2E3ktHt6IbRihJ5GhaVtAMCmY2mKYJqioxjeN7RRvUS6MXBB//R6YyFvN8tjW+LxfUdYvNb3gUD5zPX7LbOZNeb1dU9fNN6HC/31AUP0iiLo9MkuMDqFJrjaqqpIFBjBFKqTwmp1jXVRrVGXwH2XPTNGjbNsdovxtm0E5Ax17BAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image 20200728190502482&quot;
        title=&quot;image 20200728190502482&quot;
        src=&quot;/static/4fb82e1ce3bea1e96e8be416befbd8a0/fcda8/image-20200728190502482.png&quot;
        srcset=&quot;/static/4fb82e1ce3bea1e96e8be416befbd8a0/12f09/image-20200728190502482.png 148w,
/static/4fb82e1ce3bea1e96e8be416befbd8a0/e4a3f/image-20200728190502482.png 295w,
/static/4fb82e1ce3bea1e96e8be416befbd8a0/fcda8/image-20200728190502482.png 590w,
/static/4fb82e1ce3bea1e96e8be416befbd8a0/32056/image-20200728190502482.png 602w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;참고:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; &lt;a href=&quot;http://blog.skby.net/gan-generative-adversarial-networks/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://blog.skby.net/gan-generative-adversarial-networks/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;footnotes&quot;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&quot;fn-1&quot;&gt;
&lt;p&gt;&apos;D(x)는 1에 가까운 값이 출력되고 D(G(z))는 0에 가까운 값이 출력된다&apos;&lt;/p&gt;
&lt;a href=&quot;#fnref-1&quot; class=&quot;footnote-backref&quot;&gt;↩&lt;/a&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content:encoded></item><item><title><![CDATA[GAN 실전 응용]]></title><description><![CDATA[GAN 1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다. fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등) Discrimi의 loss는 maxlog(Dx) + log…]]></description><link>https://jynee.github.io/tags#1st/GAN_2/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/GAN_2/</guid><pubDate>Sat, 08 Aug 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;gan&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#gan&quot; aria-label=&quot;gan permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GAN&lt;/h1&gt;
&lt;/br&gt;
&lt;ul&gt;
&lt;li&gt;1D 정규분포에서 샘플링한 데이터를 모방하여, fake data를 생성한다.&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;fake data는 정규분포의 특성을 갖는다. (KL divergence, 평균, 분산, 왜도, 첨도 등)&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Discrimi의 loss는 max[log(Dx) + log(1 - DGz)]이고, Generator의 loss는 min[log(Dx + log(1 - DGz))]이다. &lt;/br&gt;&lt;/p&gt;
&lt;/br&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tensorflow에서는 이 loss 함수를 이용하여 직접 GAN을 학습할 수 있지만, &lt;/br&gt;&lt;/p&gt;
&lt;p&gt;Keras에서는 model.fit(), model.train&lt;em&gt;on&lt;/em&gt;batch() 함수에서 target 값을 지정해야 하기 때문에 이 loss로 GAN을 학습할 수 없다 &lt;strong&gt;Keras는 기본적으로 Supervised learning 목적이다.&lt;/strong&gt;&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Keras에서는 supervised learning 방식으로 바꿔 binary_crossentropy loss 함수를 써서 GAN을 학습하는 것이 보통이다.&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 코드는 아래 자료를 참조해서 응용했다.&lt;/br&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Rowel Atienza, 2018, Advanced Deep Learning with Keras. Chap 4. p.107 ~ p.113&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;아마추어 퀀트, blog.naver.com/chunjein,  2020.04.08&lt;/br&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;함수들의 기능을 파악하기 쉽도록 순서를 변경하였다.&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h2 id=&quot;basic-code&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#basic-code&quot; aria-label=&quot;basic code permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic CODE&lt;/h2&gt;
&lt;/br&gt;
&lt;ul&gt;
&lt;li&gt;Keras를 이용하여 기본 GAN 모델을 연습한다.&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;file: 딥러닝 8-2.GAN(Kears)&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step1-정규분포로부터-데이터를-샘플링한다br&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step1-%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC%EB%A1%9C%EB%B6%80%ED%84%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%83%98%ED%94%8C%EB%A7%81%ED%95%9C%EB%8B%A4br&quot; aria-label=&quot;step1 정규분포로부터 데이터를 샘플링한다br permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step1. 정규분포로부터 데이터를 샘플링한다&lt;/br&gt;&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;realData &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;normal&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
realData &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; realData&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;reshape&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;realData&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step2-network-빌드&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step2-network-%EB%B9%8C%EB%93%9C&quot; aria-label=&quot;step2 network 빌드 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step2. Network 빌드&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;nDInput &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; realData&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# nDInput.shape[1] = 1&lt;/span&gt;
nDHidden &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;32&lt;/span&gt;
nDOutput &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;
nGInput &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;
nGHidden &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;32&lt;/span&gt;
nGOutput &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nDInput

&lt;span class=&quot;token comment&quot;&gt;## nDInput와 nGOutput는 값이 같아야 함&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;getNoise&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;m&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; n&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;nGInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    z &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uniform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;m&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; n&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; z&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;MyOptimizer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;a &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; RMSprop&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;lr &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; a&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step3-모델-그림&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step3-%EB%AA%A8%EB%8D%B8-%EA%B7%B8%EB%A6%BC&quot; aria-label=&quot;step3 모델 그림 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step3. 모델 그림&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;py&quot;&gt;&lt;pre class=&quot;language-py&quot;&gt;&lt;code class=&quot;language-py&quot;&gt;Generator &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; Discriminator를 연결한 모델을 생성한다&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;
아래 네트워크로 z가 들어가면 DGz &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;이 나오도록 G를 학습한다&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;
D 네트워크는 업데이트하지 않고&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; G 네트워크만 업데이트한다&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;

        &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;   Gz   &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;
  z &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; G &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; D &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; DGz
        &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;        &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;
      trainable   &lt;span class=&quot;token keyword&quot;&gt;not&lt;/span&gt; trainable&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step4-객체지향-함수-정의&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step4-%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-%ED%95%A8%EC%88%98-%EC%A0%95%EC%9D%98&quot; aria-label=&quot;step4 객체지향 함수 정의 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step4. (객체지향) 함수 정의&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;0. K.clear_session()&lt;/br&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&quot;1-discriminator--builddiscriminatorbr&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#1-discriminator--builddiscriminatorbr&quot; aria-label=&quot;1 discriminator  builddiscriminatorbr permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Discriminator = BuildDiscriminator()&lt;/br&gt;&lt;/h5&gt;
&lt;h5 id=&quot;2-generator--buildgeneratorbr&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#2-generator--buildgeneratorbr&quot; aria-label=&quot;2 generator  buildgeneratorbr permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Generator = BuildGenerator()&lt;/br&gt;&lt;/h5&gt;
&lt;h5 id=&quot;3-gan--buildgandiscriminator-generatorbr&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#3-gan--buildgandiscriminator-generatorbr&quot; aria-label=&quot;3 gan  buildgandiscriminator generatorbr permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. GAN = BuildGAN(Discriminator, Generator)&lt;/br&gt;&lt;/h5&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step5-학습-세팅&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step5-%ED%95%99%EC%8A%B5-%EC%84%B8%ED%8C%85&quot; aria-label=&quot;step5 학습 세팅 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step5. 학습 세팅&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;nBatchCnt &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;       &lt;span class=&quot;token comment&quot;&gt;# Mini-batch를 위해 input 데이터를 n개 블록으로 나눈다. # 333개, 333개, 334개로 쪼개짐 &lt;/span&gt;
nBatchSize &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;realData&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; nBatchCnt&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;token comment&quot;&gt;# 블록 당 Size # nBatchSize: 333개, 333개, 334개 순으로 들어감 &lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; epoch &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;# Mini-batch 방식으로 학습한다&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; n &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nBatchCnt&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# input 데이터를 Mini-batch 크기에 맞게 자른다&lt;/span&gt;
        nFrom &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; n &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; nBatchSize &lt;span class=&quot;token comment&quot;&gt;#for문 다 돌면 nFrom= 666&lt;/span&gt;
        nTo &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; n &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; nBatchSize &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; nBatchSize &lt;span class=&quot;token comment&quot;&gt;#for문 다 돌면 nTo=1000&lt;/span&gt;
        
        &lt;span class=&quot;token comment&quot;&gt;# 마지막 루프이면 nTo는 input 데이터의 끝까지. &lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;## 왜 써주냐면 , n=2(마지막)일때 nTo = n * nBatchSize + nBatchSize는 999로 1000이 안되기 땜에.&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; n &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; nBatchCnt &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            nTo &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; realData&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;        &lt;span class=&quot;token comment&quot;&gt;# 학습 데이터를 준비한다&lt;/span&gt;
        bx &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; realData&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;nFrom &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; nTo&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#진짜 data 형성&lt;/span&gt;
        bz &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; getNoise&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;m&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;bx&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; n&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;nGInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# bx.shape[0]=333-&gt;333-&gt;334, nGInput=16&lt;/span&gt;
        Gz &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;predict&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bz&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#진짜 data shape 맞춰서 noise 써가지고 가짜 data 형성(fake data)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 410px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/300cd66c5e4a62c747237923b76d20a9/d68e4/image-20200715110832016.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 102.7027027027027%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsSAAALEgHS3X78AAADGUlEQVQ4y4VU2XKbQBDk/38p5Tw4kQ/FkqwbgUBC3OhE6LKjqvb0IGw5FScPU8Ay29PT07vGYRcjX8+wWc1w3Cc4HVK8HDMcdgn2RQz+v459Eb2/M7+Kas2Ypw7Mfh1xMELoDzW8SQ9FHgh4dgGVQrIp3/g47pL3Yvnax1bW1ksPu22k60YaW1jOXamSYrWYKtM4HCGJLA0CFVLZSyzEqymihYuDgAWzoUYSWnDsZ/izgXZmLOcTXWg+3aLVuMVY3gkaBSayZAxr+ISB00JvUIfZqyNIx4iysXRkCoFyb5GH2hnlMkjbc7vaP6mT5W4bqgTbTYDR4BdsrwvbaaMhRa1JB/O1hyyykcY22q0a7mrfMOg9qkTGZuXBlE1kwxaZxKqRADJY5CiVXWl5EPThhEOcTwtMhQT3kAj32KOWMjU44YlUpx4Tp6P6UdNANKmml0tizXzETb8GU0AJGIt2gTfA2GrpXhanAwyiWmZDqZO2Y7d0csFF5MomSym8FSkKCX5Tr/PrAr6AkkBlI4MDKAXNVDMGk1mV76X3JJk+K8rgt9pEALrtex0gXaIM2fJQfMhFsmKwAHUkYNl22fr+3eDl9+tpjrXMgIN9Oc5LH/Jj6nY0gdNlu3zOxNz8d30KDleAzGHx2bQn0deOyNygTWjuLHHgy49F5uopIWOy/xsgp06pSKTV/KG5BCYZg06nNZ6bP1F/+I6H+xuxj61TzFdfAO5LQErDvNA3laXahgzpv1iCnswSW9th0pcML4BkxUGQEC1HzS8+LDUkIMHOr0ut/hWgaihAJOLK8OhH+lc1LMUdqsDUIpR33+urYSvbXF9dBKps9HLK0BXvroTIbzG7AjKRBuZPts+hUFwO5lObtAnNzFwORf67cgwbnTtMIhNzAeXVZlSVaWZr1NDTQn991kzuQgEYC0DTbSJdTjBLbWWXi36RyOMKaCFmNw5/mJUSXN/K19GZtnFn1eHEJmI5bryBHJGGt83Ik0u5+AT472DLvGzPciLYMrWMhelUbqFxNMSCFqta/n98HL2K/cdNFOj6SazEvDfbQBgvvvdP4gAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200715110832016&quot;
        title=&quot;image-20200715110832016&quot;
        src=&quot;/static/300cd66c5e4a62c747237923b76d20a9/d68e4/image-20200715110832016.png&quot;
        srcset=&quot;/static/300cd66c5e4a62c747237923b76d20a9/12f09/image-20200715110832016.png 148w,
/static/300cd66c5e4a62c747237923b76d20a9/e4a3f/image-20200715110832016.png 295w,
/static/300cd66c5e4a62c747237923b76d20a9/d68e4/image-20200715110832016.png 410w&quot;
        sizes=&quot;(max-width: 410px) 100vw, 410px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/br&gt;
&lt;h5 id=&quot;discriminator--builddiscriminator&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#discriminator--builddiscriminator&quot; aria-label=&quot;discriminator  builddiscriminator permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Discriminator = BuildDiscriminator()&lt;/h5&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;    	&lt;span class=&quot;token comment&quot;&gt;### &amp;lt; Discriminator를 학습한다. &gt; ###&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# Real data가 들어가면 Discriminator의 출력이 &apos;1&apos;이 나오도록 학습하고,&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# Fake data (Gz)가 들어가면 Discriminator의 출력이 &apos;0&apos;이 나오도록 학습한다.&lt;/span&gt;
        &lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;target data 만들기&quot;&quot;&quot;&lt;/span&gt;
        target &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;zeros&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bx&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        target&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; bx&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.9&lt;/span&gt;     &lt;span class=&quot;token comment&quot;&gt;# &apos;1&apos; 대신 0.9로 함&lt;/span&gt;
        target&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;bx&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;     &lt;span class=&quot;token comment&quot;&gt;# &apos;0&apos; 대신 0.1로 함&lt;/span&gt;
        &lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;target data 형성 완료&quot;&quot;&quot;&lt;/span&gt;
        
        bx_Gz &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;concatenate&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;bx&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Gz&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# D 학습 &lt;/span&gt;
        Dloss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Discriminator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;train_on_batch&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bx_Gz&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; target&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;token comment&quot;&gt;#real data &amp;amp; fake data 모두가 D를 거치게 한다. &lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;##참고: fit 함수보다 train_on_batch 쓰는 게 더 속도가 빨라서 이거 씀&lt;/span&gt;
 &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 310px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/98081371ab2415f2244c7b50905f4563/5fad2/image-20200715110841184.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 85.8108108108108%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsSAAALEgHS3X78AAAC2UlEQVQ4y2VUaXeaUBDl//+Mfm97emo/tGlimibGeFww7iiKuIAI4sbiktzOjGBM+uEdYHjvzr13Zp4SbCwEWwtxYCOiFW5tbDdTiQX05Nh2PcEumCFKYiE9eQUX36d3CwoHGMy0NcwXQwE7hA524UyWvxzhEDmw3D5Wq7GAMgA/0yRRQojJKIzKG2xvIAcaZg1PegntcQN1o4q7dh4VQ0VrVMeS/gs7OrMm1s7CkISb9RSOZ8h5JTxntHGMXVS6JXz9k0G2lEWufIdiNYcf+Z/wfJMYOyKL2YycLr5XbpCh9SmXwb1WEPlKqp99Yr9Wngm9UxY5LP0Yz6FrKhbEIAptOcT7eS+zZJvmxHTD50+STx4e6fDLzsXSG6LfUyXBwjUQk49GvyZx8TXxjYmwXJfA9hQPkwIpMW2YzHU8dgpQyTNvYaJefUSNpGavM1jSNwNqwzrMWRe59hNsKtCeCrVcjsWKU3eckijsS9/SyIssrpsP6Jh1dJpFVEp/MRm1xDPTaGDuDuCvx9AmLTJ/ImxdfyjgzDpIAVMP2QPsPfgkrcceEoOVPxLZzHhFTOOz5DdG6/VbKwlg2jYhNyhRXxCTQv4GA70KvVvBxGyh2XiSRCxNikJrR+8Dq4MZtVt8jltvbZNOhU/VHA5qeD36wvLlsKDvugAyQ+kI2suFYE+n5P8uKcpZcph0+uvOE2kMyP5Zk86HKjsid59M0pT8qw5UKVDwXrJNnT4Uww1aIypCo5bH71/fUCzcot9V4c5pkshnl6qqT9vSozOyp0f7GVzuBJbMGXlkvhSv8Ll0hZvGPZrtokjkSj+rDzD0ZwE0Zz2U9bKsF2p4l5raoDtAPPwomX+ylJjbqFel2FR8BFYCyN4eCCQdvSjx8vLC+M9DmRoC5LYx+s9UZZXGroJOqySTE14cDJPxiz7Ezm2TtkNEfeY6Ouyphg1lX9N4pWDpnvd34MX9SFj/AOky8Iew8ES7AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200715110841184&quot;
        title=&quot;image-20200715110841184&quot;
        src=&quot;/static/98081371ab2415f2244c7b50905f4563/5fad2/image-20200715110841184.png&quot;
        srcset=&quot;/static/98081371ab2415f2244c7b50905f4563/12f09/image-20200715110841184.png 148w,
/static/98081371ab2415f2244c7b50905f4563/e4a3f/image-20200715110841184.png 295w,
/static/98081371ab2415f2244c7b50905f4563/5fad2/image-20200715110841184.png 310w&quot;
        sizes=&quot;(max-width: 310px) 100vw, 310px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/br&gt;
&lt;h6 id=&quot;def-builddiscriminator&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#def-builddiscriminator&quot; aria-label=&quot;def builddiscriminator permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;def BuildDiscriminator()&lt;/h6&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Discriminator를 G. D 각각 생성한다&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;BuildDiscriminator&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;batch_shape &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; nDInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    h &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nDHidden&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;relu&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    Dx &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nDOutput&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;sigmoid&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;h&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 &lt;/span&gt;
    model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Dx&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;binary_crossentropy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; optimizer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; MyOptimizer&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;token comment&quot;&gt;#sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 &lt;/span&gt;
    
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h5 id=&quot;gan--buildgandiscriminator-generator&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#gan--buildgandiscriminator-generator&quot; aria-label=&quot;gan  buildgandiscriminator generator permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GAN = BuildGAN(Discriminator, Generator)&lt;/h5&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;### &amp;lt; Generator를 학습한다. &gt; ###&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# Fake data (z --&gt; Gz --&gt; DGz)가 들어가도 Discriminator의 출력이 &apos;1&apos;이 나오도록 Generator를 학습한다.&lt;/span&gt;
&lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;target data 만들기&quot;&quot;&quot;&lt;/span&gt;
target &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;zeros&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bx&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
target&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.9&lt;/span&gt;
&lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;target data 형성 완료&quot;&quot;&quot;&lt;/span&gt;
        
Gloss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; GAN&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;train_on_batch&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bz&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; target&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;token comment&quot;&gt;## GAN 함수 참고: D는 위에서 학습해서 여기선 학습 안 하고 G만 학습 &lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# 어떤 학습? 가짜 data가 들어가면 target이 전부 1로 출력되도록(Discriminator가 전부 진짜로 판별하도록)! &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 448px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/97569fb6e53b4464c4b19ffaa74c0241/33b38/image-20200715110850214.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 59.45945945945946%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABsElEQVQoz11T2VLCQBDM/3+Gj/oNPmhpiSAhIEeICSHk2oT7Ri1rnJ6wIfCwtdmdmZ7uno1x2KV03Gd0OmS8K8L5dFC03ya0XoZ8VhKb5R6tFhP6OU0ljjvk6oV87AZAZvlI1nzq024TC9DY69CgV6c0dmiqPDI/nsnuN8jn+1nmkUoc2qzCM5AqyRjo6DoWdaxXGnTrtJwHNHIt8pwW9T7fOdaiwO/yd43B2txgKDkAbzaeyDJfhIAmYxR0Uz4UEtEJctLIJsduilTE3aFJYdA/W5Ixu0hiOLcY9OH+TuJG1YfjvvACoFj6GzvkbdexyEPu9zEvm0/ZgjDoicfGrbFIgiRIiyZ9ypVbgqA4Zz/BPGEFeni410NlwEQkaUAE0A2+wZcJf0OeZh2HAwH03bZ4puvKKV8Y6m5KgGpvjzLlJLSlcDzqyITBGKBgj3s9Xb2uAAsflXiRqy/6+51L8XYdiQ0YGp6RAAZVQHUNWJWMhMVsTF+2yT4NhZUuxCCiyUDeIGzRkq8e9i1DvcAK3uE5lQUMCpYYCJpW5WpSxuXJVAFVOYRbjzTTy69XlazoHzpngHnz2qseAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200715110850214&quot;
        title=&quot;image-20200715110850214&quot;
        src=&quot;/static/97569fb6e53b4464c4b19ffaa74c0241/33b38/image-20200715110850214.png&quot;
        srcset=&quot;/static/97569fb6e53b4464c4b19ffaa74c0241/12f09/image-20200715110850214.png 148w,
/static/97569fb6e53b4464c4b19ffaa74c0241/e4a3f/image-20200715110850214.png 295w,
/static/97569fb6e53b4464c4b19ffaa74c0241/33b38/image-20200715110850214.png 448w&quot;
        sizes=&quot;(max-width: 448px) 100vw, 448px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/br&gt;
&lt;h6 id=&quot;def-buildgand-g&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#def-buildgand-g&quot; aria-label=&quot;def buildgand g permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;def BuildGAN(D, G)&lt;/h6&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;BuildGAN&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;D&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; G&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 전체 NETWORK Build &lt;/span&gt;
    D&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;trainable &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;     &lt;span class=&quot;token comment&quot;&gt;# Discriminator는 업데이트하지 않는다= 학습하지 않는다. 왜냐면 자체적으로 위에서 학습했으니까. 따라서 G만 학습됨 &lt;/span&gt;
    z &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;batch_shape&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; nGInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    Gz &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; G&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    DGz &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; D&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Gz&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
    model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;z&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; DGz&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#z가 들어가면 최종적으로 DGz가 나온다. &lt;/span&gt;
    model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;binary_crossentropy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; optimizer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; MyOptimizer&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.0005&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# binary_crossentropy: 출력값이 0 아니면 1 나오도록&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;h6 id=&quot;def-builddiscriminator--discriminator&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#def-builddiscriminator--discriminator&quot; aria-label=&quot;def builddiscriminator  discriminator permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;def BuildDiscriminator() = Discriminator&lt;/h6&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Discriminator를 G. D 각각 생성한다&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;BuildDiscriminator&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;batch_shape &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; nDInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    h &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nDHidden&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;relu&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    Dx &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nDOutput&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;sigmoid&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;h&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#0이면 가짜, 1이면 진짜로 하려고 sigmoid를 출력값으로 &lt;/span&gt;
    model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Dx&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;binary_crossentropy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; optimizer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; MyOptimizer&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;token comment&quot;&gt;#sigmoid 짝꿍 binary_crossentropy를 loss에 넣어서 1과 0 값이 출력되게 함 &lt;/span&gt;
    
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;h6 id=&quot;def-buildgenerator--generator&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#def-buildgenerator--generator&quot; aria-label=&quot;def buildgenerator  generator permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;def BuildGenerator() = Generator&lt;/h6&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Generator를 생성한다 &lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# G는 여기서 학습 안 하므로 &apos;.complie&apos; 안 함 &lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;BuildGenerator&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; 
    z &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;batch_shape &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; nGInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    h &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nGHidden&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;relu&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    Gz &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nGOutput&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;linear&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;h&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;z&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Gz&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;h5 id=&quot;kd--klraldata-fakedata&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#kd--klraldata-fakedata&quot; aria-label=&quot;kd  klraldata fakedata permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;kd = KL(ralData, fakeData)&lt;/h5&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; epoch &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        z &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; getNoise&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;m&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;realData&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; n&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;nGInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        fakeData &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;predict&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;  
        &lt;span class=&quot;token comment&quot;&gt;# Generator = BuildGenerator()에서 만든 Model(z, Gz)를 활용하여, &lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# &quot;model.predict(z=노이즈 data)&quot; 하라는 뜻 &lt;/span&gt;
        kd &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; KL&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;realData&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; fakeData&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;epoch = %d, D-Loss = %.3f, G-Loss = %.3f, KL divergence = %.3f&quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;epoch&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Dloss&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Gloss&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; kd&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# Dloss: 0.6932636 , Gloss: 0.6933405 , kd: 0.2189525518812676 = 분산이 적다&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;h6 id=&quot;def-kl&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#def-kl&quot; aria-label=&quot;def kl permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;def KL&lt;/h6&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# 두 분포 (P, Q)의 KL divergence를 계산한다.&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;KL&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Q&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;# 두 데이터의 분포를 계산한다&lt;/span&gt;
    histP&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; binsP &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;histogram&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; bins&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    histQ&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; binsQ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;histogram&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Q&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; bins&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;binsP&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# 두 분포를 pdf로 만들기 위해 normalization한다.&lt;/span&gt;
    histP &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; histP &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;histP&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1e&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    histQ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; histQ &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;histQ&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1e&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;token comment&quot;&gt;# KL divergence를 계산한다&lt;/span&gt;
    kld &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;histP &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;log&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;histP &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1e&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;log&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;histQ &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1e&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; kld&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;plt&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#plt&quot; aria-label=&quot;plt permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;plt&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# real data 분포 (p)와 fake data 분포 (q)를 그려본다&lt;/span&gt;
z &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; getNoise&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;m&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;realData&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; n&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;nGInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
fakeData &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;predict&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;figure&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;figsize&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
sns&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;set_style&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;whitegrid&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
sns&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;kdeplot&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;realData&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; color&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;blue&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; bw&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; label&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;Real&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
sns&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;kdeplot&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;fakeData&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; color&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;red&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; bw&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; label&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;Fake&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;legend&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;title&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;Distibution of real and fake data&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;show&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 487px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/c2ef4c0767c4f98f9747be8c0cb92d40/7b439/image-20200809130155797.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 64.86486486486486%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABtUlEQVQ4y3VTDbObIBD0///GtvNeGicaH6h8iICwPY5Ikr5Wh1G55W5v9+xijDiO422llPg5jiP6vseXEJimO+7TiGEYeN97z7hEOB8zQqh5OmstB1+TlfUslJBThPkcsNw0Mt3vxQ9o4XC7DphniW7bNsoeWqKycs4teQZwLAryaiB/CWwm0k7mQowhbN4dnDWwlIsZviYsyVpCOlSu9VMQOCMai/mieC89GDK+lKBnOd9prf/fciYWbof8mBFZrwDxU1CssiuYU8fyXta3lk+GMR7MRI0W7ktVFkjQ/QK7+KbliT+N7IwxT8de1sEMQYwkUnGQ9cxw84blulZt47Ojs8Nu3/fm6LsxCVYFrBfJTJsktGwvucA/GZ4a/s2wsFl/zwhqYzbNBHoPYqV9yw4zPj9HqXPOsYZn9eJsOeQ1tfYhqqOl+gujgyTYbxNr+q3l5nIJoI5AucSPO7VcxT8PsKuPghsZtV5qwYqp8cYwB49ArNzqiJmEnVRjd2rUpuAx8OqmYK4S3ngilXjYebBj+R81BUcJMyievT14Zn6KXszjwo/vQLFIv2TcPJww0LrgA/4A4XP6fxf+uRsAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200809130155797&quot;
        title=&quot;image-20200809130155797&quot;
        src=&quot;/static/c2ef4c0767c4f98f9747be8c0cb92d40/7b439/image-20200809130155797.png&quot;
        srcset=&quot;/static/c2ef4c0767c4f98f9747be8c0cb92d40/12f09/image-20200809130155797.png 148w,
/static/c2ef4c0767c4f98f9747be8c0cb92d40/e4a3f/image-20200809130155797.png 295w,
/static/c2ef4c0767c4f98f9747be8c0cb92d40/7b439/image-20200809130155797.png 487w&quot;
        sizes=&quot;(max-width: 487px) 100vw, 487px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;hr&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h2 id=&quot;cnn-gan-dcgan-code&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#cnn-gan-dcgan-code&quot; aria-label=&quot;cnn gan dcgan code permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CNN GAN (DCGAN) CODE&lt;/h2&gt;
&lt;/br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;사용한 함수 총 5개:&lt;/br&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;def build&lt;em&gt;generator(inputs, image&lt;/em&gt;size)&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;def build_discriminator(inputs)&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;def train(models, x_train, params)&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;def build&lt;em&gt;and&lt;/em&gt;train&lt;em&gt;models(load&lt;/em&gt;W = False, train_steps = 100)&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;def plot_images():&lt;/br&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/br&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/4867ffac049680dfe4dd33daef7986d9/573d3/image-20200809130207635.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 58.10810810810811%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABnklEQVQoz3VTS67CMBDrwTkBF+A8bNiwYc8CEC08+qOl/1/m2UNSFSQijRoRx/Z4gic/ljFGDDfDIH1VSVXXUvGL6vv+A7dcnl78VURMk1R5LhmKZF3XaY0QGsfxkxRfb1b6duh+w6XYD8S/3STLMilBWjeNVgviGWtJPQMHhkptJxPaYnsDvgZgFlWropAIhNH9LsH5LOnjAUyjcRi0bxZOPdO2YmgfilUYSRRFkj+f0pMQQCXmOaoDNsZ5Ese6n2iG95t2QWhb7KCUI6c7XKRpKg0EXEZcbI8YCr5eL2ks4fdwdChlWWrgSZLI5XKRMAylQJszITCcLH87nU4qWtupFyBnVLNDtkeCB3K5ISff99UFRZYOSRij1TMyJCFdspM/7HOLV0Jnmy1yio6Q6gNyc4tPxRFSmPG4uxOINE/N0PZOBy1yoTrBJHMgYy/QFc8pSAPD4i3OD/v7H7JarWS73eqeLt0Q6JC5Ubiz72+z2ch6vZb3cx3fDhk0W2XR2W63k+PxqAO6Xq9ajCEIgrl4xswOh4Ps93vd13Yw/zXqn4f5hoHcAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200809130207635&quot;
        title=&quot;image-20200809130207635&quot;
        src=&quot;/static/4867ffac049680dfe4dd33daef7986d9/fcda8/image-20200809130207635.png&quot;
        srcset=&quot;/static/4867ffac049680dfe4dd33daef7986d9/12f09/image-20200809130207635.png 148w,
/static/4867ffac049680dfe4dd33daef7986d9/e4a3f/image-20200809130207635.png 295w,
/static/4867ffac049680dfe4dd33daef7986d9/fcda8/image-20200809130207635.png 590w,
/static/4867ffac049680dfe4dd33daef7986d9/efc66/image-20200809130207635.png 885w,
/static/4867ffac049680dfe4dd33daef7986d9/c83ae/image-20200809130207635.png 1180w,
/static/4867ffac049680dfe4dd33daef7986d9/573d3/image-20200809130207635.png 1650w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/br&gt;
&lt;h4 id=&quot;base&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#base&quot; aria-label=&quot;base permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Base&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# load MNIST dataset&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x_train&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; _&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;_&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; _&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; mnist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_data&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot; 비지도 방법으로 사용 &quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;# reshape data for CNN as (28, 28, 1) and normalize &lt;/span&gt;
&lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot; 2D CNN &quot;&quot;&quot;&lt;/span&gt;
image_size &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; x_train&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# x_train.shape (60000, 28, 28)&lt;/span&gt;
x_train &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;reshape&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x_train&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# x_train.shape = (60000, 28, 28, 1)&lt;/span&gt;
x_train &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; x_train&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;astype&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;float32&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;255&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 표준화&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;# the latent or z vector is 100-dim&lt;/span&gt;
latent_size &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#latent: KNN 가기 전 층들&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step-1-build_generator&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step-1-build_generator&quot; aria-label=&quot;step 1 build_generator permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step 1. build_generator&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;build_generator&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_size&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# latent 층에 씀 &lt;/span&gt;
    image_resize &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; image_size &lt;span class=&quot;token operator&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# network parameters &lt;/span&gt;
    kernel_size &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;
    layer_filters &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;image_resize &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; image_resize &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; layer_filters&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Reshape&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;image_resize&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_resize&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; layer_filters&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; filters &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; layer_filters&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# hidden 층을 for문으로 써줌(쫙 쌓아주는 것)&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# first two convolution layers use strides = 2&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# the last two use strides = 1&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; filters &lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; layer_filters&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            strides &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 따라서 layer_filters의 뒤에서 2번째까진 strides = 2&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            strides &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;
        x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; BatchNormalization&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Activation&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;relu&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Conv2DTranspose&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;filters&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;filters&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            kernel_size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;kernel_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            strides&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;strides&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            padding&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# data 양 뿔려줌 &lt;/span&gt;

    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Activation&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;sigmoid&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    generator &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;generator&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 모방 모델이므로 y 자리엔 x 학습 결과를 써줌 &lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; generator &lt;span class=&quot;token comment&quot;&gt;# 요렇게 fake data 만들어서 전에 모델처럼 Discriminator에 넣어줌 &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step-2-build_discriminator&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step-2-build_discriminator&quot; aria-label=&quot;step 2 build_discriminator permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step 2. build_discriminator&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;build_discriminator&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    kernel_size &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;
    layer_filters &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; inputs
    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; filters &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; layer_filters&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# first 3 convolution layers use strides = 2&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# last one uses strides = 1&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# 따라서 Discriminator를 더 많이 학습하게 됨 &lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; filters &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; layer_filters&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            strides &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            strides &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;
        x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; LeakyReLU&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;alpha&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Conv2D&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;filters&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;filters&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                   kernel_size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;kernel_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                   strides&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;strides&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                   padding&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Flatten&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Activation&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;sigmoid&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    discriminator &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;discriminator&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; discriminator&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step-3-buildandtrain_models&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step-3-buildandtrain_models&quot; aria-label=&quot;step 3 buildandtrain_models permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step 3. build&lt;em&gt;and&lt;/em&gt;train_models&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;build_and_train_models&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;load_W &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; train_steps &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    model_name &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;dcgan_mnist&quot;&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# network parameters&lt;/span&gt;
    batch_size &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;64&lt;/span&gt;
    lr &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2e&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;
    decay &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;6e&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;
    input_shape &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;image_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;token comment&quot;&gt;# build discriminator model&lt;/span&gt;
    inputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;shape&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;input_shape&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;discriminator_input&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    discriminator &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; build_discriminator&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# [1] or original paper uses Adam, &lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;# but discriminator converges easily with RMSprop&lt;/span&gt;
    optimizer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; RMSprop&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;lr&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;lr&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; decay&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;decay&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    discriminator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;loss&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;binary_crossentropy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                          optimizer&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;optimizer&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                          metrics&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;accuracy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    discriminator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;summary&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# 저장된 discriminator 모델을 읽어온다.&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; load_W&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        discriminator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;dataset/dcgan_D.h5&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;token comment&quot;&gt;# build generator model&lt;/span&gt;
    input_shape &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;latent_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    inputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;shape&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;input_shape&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;z_input&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    generator &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; build_generator&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_size&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;summary&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;token comment&quot;&gt;# 저장된 generator 모델을 읽어온다.&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; load_W&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;dataset/dcgan_G.h5&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;token comment&quot;&gt;# build adversarial model&lt;/span&gt;
    optimizer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; RMSprop&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;lr&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;lr &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; decay&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;decay &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# freeze the weights of discriminator during adversarial training&lt;/span&gt;
    discriminator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;trainable &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# adversarial = generator + discriminator&lt;/span&gt;
    adversarial &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; 
                        discriminator&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;generator&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                        name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;model_name&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    adversarial&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;loss&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;binary_crossentropy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                        optimizer&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;optimizer&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                        metrics&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;accuracy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    adversarial&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;summary&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#adversarial: 최종모델&lt;/span&gt;

    &lt;span class=&quot;token comment&quot;&gt;# train discriminator and adversarial networks&lt;/span&gt;
    models &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;generator&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; discriminator&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; adversarial&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    params &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; latent_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; train_steps&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; model_name&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    train&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;models&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x_train&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; params&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# 모델을 저장해 둔다&lt;/span&gt;
    discriminator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;save_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;dataset/dcgan_D.h5&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;save_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;dataset/dcgan_G.h5&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step-4-train&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step-4-train&quot; aria-label=&quot;step 4 train permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step 4. train&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;models&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x_train&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; params&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;# the GAN component models&lt;/span&gt;
    generator&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; discriminator&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; adversarial &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; models 
    
    
    &lt;span class=&quot;token comment&quot;&gt;# network parameters&lt;/span&gt;
    batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; latent_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; train_steps&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; model_name &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; params 
    
    
    &lt;span class=&quot;token comment&quot;&gt;# number of elements in train dataset&lt;/span&gt;
    train_size &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; x_train&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_steps&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# train the discriminator for 1 batch&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# 1 batch of real (label=1.0) and fake images (label=0.0)&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# randomly pick real images from dataset&lt;/span&gt;
        rand_indexes &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;randint&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; train_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;batch_size&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        real_images &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; x_train&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;rand_indexes&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;token comment&quot;&gt;# generate fake images from noise using generator &lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# generate noise using uniform distribution(모든 확률변수에 대해 균일한 확률을 가짐)&lt;/span&gt;
        noise &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uniform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                                  &lt;span class=&quot;token number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                                  size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; latent_size&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# generate fake images&lt;/span&gt;
        fake_images &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;predict&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;noise&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;token comment&quot;&gt;# real + fake images = 1 batch of train data&lt;/span&gt;
        x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;concatenate&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;real_images&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; fake_images&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;token comment&quot;&gt;# label real and fake images&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# real images label is 1.0&lt;/span&gt;
        y &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;ones&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;token comment&quot;&gt;# fake images label is 0.0&lt;/span&gt;
        y&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;batch_size&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.0&lt;/span&gt;
        
        &lt;span class=&quot;token comment&quot;&gt;# train discriminator network, log the loss and accuracy&lt;/span&gt;
        loss&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; acc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; discriminator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;train_on_batch&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;Q. loss: 인덱스??? &quot;&quot;&quot;&lt;/span&gt;
        log &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;%d: [D-loss: %.4f, acc: %.4f]&quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; loss&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; acc&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;token comment&quot;&gt;# train the adversarial network for 1 batch&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# 1 batch of fake images with label=1.0&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# since the discriminator weights &lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# are frozen in adversarial network(adversarial network: 적대적 신경망(경쟁 속 반대편에 놓인 신경망))&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# only the generator is trained&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# generate noise using uniform distribution&lt;/span&gt;
        noise &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uniform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                                  &lt;span class=&quot;token number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; 
                                  size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; latent_size&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;token comment&quot;&gt;# label fake images as real or 1.0&lt;/span&gt;
        y &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;ones&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# train the adversarial network &lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# note that unlike in discriminator training, &lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# we do not save the fake images in a variable&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# the fake images go to the discriminator input of the adversarial&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# for classification&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# log the loss and accuracy&lt;/span&gt;
        loss&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; acc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; adversarial&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;train_on_batch&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;noise&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;Q. adversarial 뜻???&quot;&quot;&quot;&lt;/span&gt;
        log &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;%s [G-loss: %.4f, acc: %.4f]&quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;log&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; loss&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; acc&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;log&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
   
    &lt;span class=&quot;token comment&quot;&gt;# save the model after training the generator&lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;# the trained generator can be reloaded for &lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;# future MNIST digit generation&lt;/span&gt;
    generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;save&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;model_name &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;.h5&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;step-5-fake-data를-화면에-표시&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#step-5-fake-data%EB%A5%BC-%ED%99%94%EB%A9%B4%EC%97%90-%ED%91%9C%EC%8B%9C&quot; aria-label=&quot;step 5 fake data를 화면에 표시 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;step 5. fake data를 화면에 표시&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Generator가 생성한 이미지(fake data)를 화면에 표시한다.&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;plot_images&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    inputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;shape&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;latent_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;z_input&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    generator &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; build_generator&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_size&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;dataset/dcgan_G.h5&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
    noise_input &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uniform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; latent_size&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    images &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; generator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;predict&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;noise_input&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# Generator 통해 나온 fake data&lt;/span&gt;
    plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;figure&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;figsize&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    num_images &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; images&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
    
    noise_input &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uniform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    rows &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;sqrt&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;noise_input&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;num_images&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;subplot&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;rows&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; rows&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        image &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;reshape&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;images&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;image _size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_size&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;why 3차원 reshape???&quot;&quot;&quot;&lt;/span&gt;
        plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;imshow&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;image&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; cmap&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;gray&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;axis&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;off&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    plt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;show&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;h4 id=&quot;final&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#final&quot; aria-label=&quot;final permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Final&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# 이미 학습된 weights를 읽어오고, 추가로 학습한다.&lt;/span&gt;
build_and_train_models&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;load_W &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; train_steps &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# train_steps 만큼 반복 학습&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;# Generator가 생성한 이미지를 화면에 표시한다.&lt;/span&gt;
plot_images&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/br&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/fa51182f7404b07162d67390997b0e5b/f6b72/image-20200714193936268.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 45.27027027027027%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABe0lEQVQoz5WSW28TMRCF9///Jp5QhVBFKoRACEqTkmUTmna7V9u7vn3MuApQ9amWjsYzts/xGbtCRgiRZXGC5QW8D7RtS9P84tA0WGtZ17WsnaOxDmNMQaXFvu9JKZOF/AXcSE6RlDNJ8mQHkpskl7nUY/D03SPb7Zbj8UjlRLHrelY7MXcnzNBiH/YsY0sY74j1FVFtPO5gPMB0hyzy/yiCAucclVroB1EVpegX4jKTpnvi6Rr34wJXf8Qcv2Nu3mN2l6zbd4T2lhgDmHuYRSCFQqz2K+3POIqtzPNRNknRPEBzRer2pHaH//YGW3/C/dxgr9+W3HsPrmNx0kNl7bpOCPNznHuYEzmGszno9/D7M+wvSfUGf/iCvd0UAac3VN/6KK8a3jz1cRVkEWs+wOkrq9y0SikxSA/1piGEv1GF/uVe7Lhi7SlKffVCEFn1e5kB72xpXVXaJaT6OHpgnucSp2kqUf+WEtd1XWqaK6nuszLXc1b+oUJrfwDgd7kdNL4X5wAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200714193936268&quot;
        title=&quot;image-20200714193936268&quot;
        src=&quot;/static/fa51182f7404b07162d67390997b0e5b/fcda8/image-20200714193936268.png&quot;
        srcset=&quot;/static/fa51182f7404b07162d67390997b0e5b/12f09/image-20200714193936268.png 148w,
/static/fa51182f7404b07162d67390997b0e5b/e4a3f/image-20200714193936268.png 295w,
/static/fa51182f7404b07162d67390997b0e5b/fcda8/image-20200714193936268.png 590w,
/static/fa51182f7404b07162d67390997b0e5b/f6b72/image-20200714193936268.png 615w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/924334ab46f3f70fd22ca0d3fb7204b7/0a47e/image-20200714193941200.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 43.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABoElEQVQoz3WSbY+bMAzH+f6fam/25t5s0m7XHdf2Cm2a0kILJBAICb8ltJWmabNk+SG2Y/vvZBgG/sfWWq7XK1mWIYT4R8y4yK43aK0XPdFKMQPeGnwrcYPCzzPee1zgKL1zf8gne2ZnmaYJ1dbsdjvKsiTp+55IVlU4+RoUvdjMPn7D3zQ/5FRLOrG6+x4NNE1DEtuejGb78wX54wuukcym4SrWtHJ9z+6v4EY63TKHCSJVh5RL+vKo3sWqtG1LYkKH6pyzWae8f//K8XNFfjzxEeztxxvzJcUUG/xlTb5Zcc5TaASHLNjv3xirPUeRh490KKjCDrseGRznQlIWgto4fp0UBymp65o0XfFRtBz2O/I8o1AWcTwgpSA7XXjb7hE3Q61DYwGPJCJTdY5Sj7T9iB4musBm8lg3k1U9ojahqAr+cZmwaAyfF0V4pgkNxJymt2j1GNn5mX6cwmLnZcE8OKIc7cFO1N29WFx+pFINATe/wGQnt8QuoHRdt9zQON5v6na7YYxZ7BgQx7BBj3Hx7XmDcR3PvCirqmIMd/sbQ+20LI/AryoAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200714193941200&quot;
        title=&quot;image-20200714193941200&quot;
        src=&quot;/static/924334ab46f3f70fd22ca0d3fb7204b7/fcda8/image-20200714193941200.png&quot;
        srcset=&quot;/static/924334ab46f3f70fd22ca0d3fb7204b7/12f09/image-20200714193941200.png 148w,
/static/924334ab46f3f70fd22ca0d3fb7204b7/e4a3f/image-20200714193941200.png 295w,
/static/924334ab46f3f70fd22ca0d3fb7204b7/fcda8/image-20200714193941200.png 590w,
/static/924334ab46f3f70fd22ca0d3fb7204b7/0a47e/image-20200714193941200.png 600w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</content:encoded></item><item><title><![CDATA[처음 방문했다면 블로그 소개를]]></title><description><![CDATA[안녕하세요. 이곳엔 다양한 포스팅이 올라옵니다. 태그로 동일 관심분야를 검색해주세요. 안하면 모를테고, 하면 늘겠지 싶은 마음으로 일단 파고들었던 모든 것들을 이곳에 올릴 예정입니다. 이런 것까지...?  이런 것까지... 올라올 거예요.]]></description><link>https://jynee.github.io/tags#1st/main/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/main/</guid><pubDate>Sun, 02 Aug 2020 00:00:00 GMT</pubDate><content:encoded>&lt;br&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;JyneeEarth git blog&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;batch&quot;&gt;&lt;pre class=&quot;language-batch&quot;&gt;&lt;code class=&quot;language-batch&quot;&gt;&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;ML&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;DL&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;NLP&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;Contents&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;Japanese&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;etc&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;p&gt;안녕하세요.&lt;/p&gt;
&lt;p&gt;이곳엔 다양한 포스팅이 올라옵니다.&lt;/p&gt;
&lt;h1 id=&quot;태그로-동일-관심분야를-검색해주세요&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%ED%83%9C%EA%B7%B8%EB%A1%9C-%EB%8F%99%EC%9D%BC-%EA%B4%80%EC%8B%AC%EB%B6%84%EC%95%BC%EB%A5%BC-%EA%B2%80%EC%83%89%ED%95%B4%EC%A3%BC%EC%84%B8%EC%9A%94&quot; aria-label=&quot;태그로 동일 관심분야를 검색해주세요 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;태그로 동일 관심분야를 검색해주세요.&lt;/h1&gt;
&lt;br&gt;
&lt;br&gt;
&lt;blockquote&gt;
&lt;p&gt;안하면 모를테고, 하면 늘겠지&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;싶은 마음으로 일단 파고들었던 모든 것들을 이곳에 올릴 예정입니다.&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;em&gt;이런 것까지...?&lt;/em&gt; &lt;/p&gt;
&lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;이런 것까지... 올라올 거예요.&lt;/p&gt;
&lt;br&gt;</content:encoded></item><item><title><![CDATA[TQT(The question I asked the teacher today)]]></title><description><![CDATA[pre-training & fine-tuning  설명 pre-training Weight와 Bias를 초기화 시키는 방법 fine-tuning…]]></description><link>https://jynee.github.io/tags#1st/TQT(The question I asked the teacher today.)/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/TQT(The question I asked the teacher today.)/</guid><pubDate>Sat, 01 Aug 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;pre-training--fine-tuning&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#pre-training--fine-tuning&quot; aria-label=&quot;pre training  fine tuning permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;pre-training &amp;#x26; fine-tuning&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;설명&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;pre-training&lt;/td&gt;
&lt;td&gt;Weight와 Bias를 초기화 시키는 방법&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fine-tuning&lt;/td&gt;
&lt;td&gt;기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적(나의 이미지 데이터에 맞게)변형하고 이미 학습된 모델 Weights로 부터 학습을 업데이트하는 방법&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;출처: 꾸준희. 2017.08.17. &quot;[Deep Learning] pre-training 과 fine-tuning (파인튜닝)&quot;. &lt;a href=&quot;https://eehoeskrap.tistory.com/186&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://eehoeskrap.tistory.com/186&lt;/a&gt;. Enough is not enough&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;wweights&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#wweights&quot; aria-label=&quot;wweights permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;W(weights)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;네트워크 및 model build까지 완성해서 실행되어 역전파 되었을 때 형성된다.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;compile에서 w&lt;/code&gt;: 네트워크 만들고 난 후 model build하는 과정. optimizer &amp;#x26; loss 값을 정의해주는 부분임. w는 만들어져있지 않다.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;fit에서 w&lt;/code&gt;: fit은 train data 사용. A 다음 B가 &lt;strong&gt;나온다고 저장&lt;/strong&gt; &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;predict에서 w&lt;/code&gt;: predict(예측)는 test data 사용. 예측 모델 기준으로 A를 넣으면 B가 &lt;strong&gt;나오게 하는&lt;/strong&gt; 어떤 것(Thing)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;hyper-parameter&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#hyper-parameter&quot; aria-label=&quot;hyper parameter permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hyper parameter&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;weight decay&lt;/code&gt;(annealing): epoch(alpha)를 처음에는 적당히 높게 했다가, 점차 줄여 나가는 방법&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;dense&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#dense&quot; aria-label=&quot;dense permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dense&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt;: fully connected&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;ANN(FNN)&lt;/code&gt;에서는 여러 &lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt;를 써도 되지만, &lt;code class=&quot;language-text&quot;&gt;RNN(LSTM)&lt;/code&gt;에선 마지막 층에서만 &lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt;를 써야함.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;CNN&lt;/code&gt;에서는 여러 &lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt; 써도 될까?&lt;/li&gt;
&lt;li&gt;=&gt; 일단... &lt;code class=&quot;language-text&quot;&gt;lstm&lt;/code&gt;에서 &lt;code class=&quot;language-text&quot;&gt;lstm() → Dense → lstm()&lt;/code&gt;은 &lt;code class=&quot;language-text&quot;&gt;lstm 네트워크가 2개&lt;/code&gt; 만들어진다고 보면 된다. &lt;code class=&quot;language-text&quot;&gt;lstm() → Dense&lt;/code&gt; 했을 때, &lt;code class=&quot;language-text&quot;&gt;1개의 네트워크&lt;/code&gt;가 형성된 것&lt;/li&gt;
&lt;li&gt;=&gt; 그리고 &lt;code class=&quot;language-text&quot;&gt;CNN&lt;/code&gt;은 일종의 잘 짜여진 레시피라서 &lt;code class=&quot;language-text&quot;&gt;con1D → pooling → Dense → con1D → pooling&lt;/code&gt;은 위 &lt;code class=&quot;language-text&quot;&gt;lstm&lt;/code&gt;처럼 좀 이상한 네트워크 구조가 되는 거라 생각함...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dense(1, activation=&apos;sigmoid&apos;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSTM에서 FNN으로 보내는 마지막 Dense에선 relu 쓰면 안됨&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;fnn순방향-신경망&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#fnn%EC%88%9C%EB%B0%A9%ED%96%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D&quot; aria-label=&quot;fnn순방향 신경망 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FNN(순방향 신경망)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;↔ RNN&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;hidden 층에서&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dense(4, &lt;code class=&quot;language-text&quot;&gt;activation&lt;/code&gt; = &apos;sigmoid&apos;, &lt;code class=&quot;language-text&quot;&gt;kernel_regularizer&lt;/code&gt;=regularizers.l2(0.0001), activation=&apos;relu&apos;)&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Dropout&lt;/code&gt;(rate=0.5)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;BatchNormalization&lt;/code&gt;(momentum=0.9, epsilon=0.005, center=True, scale=True, moving&lt;em&gt;variance&lt;/em&gt;initializer=&apos;ones&apos;)&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;predict&lt;/code&gt;까지 끝낸 &lt;strong&gt;연속형&lt;/strong&gt; &lt;code class=&quot;language-text&quot;&gt;yHat&lt;/code&gt; 값을, &lt;code class=&quot;language-text&quot;&gt;np.where&lt;/code&gt; 써줘서 &lt;strong&gt;바이너리 형태&lt;/strong&gt;로 변환 &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;where&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;yHat &lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기_커스텀loss.py&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;history&lt;/code&gt; 활용&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;hist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;history&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;loss&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
hist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;history&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;val_loss&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기.py&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;학습/평가/예측용 model로 나누었을 때 &lt;strong&gt;평가 데이터 활용&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;trainX&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; trainY&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; validation_data&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;evlX&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; evlY&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; epochs&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; batch_size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;lstm&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#lstm&quot; aria-label=&quot;lstm permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LSTM&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;long term(장기기억, 전체적 흐름), short term(단기기억, 최근의 흐름)&lt;/li&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;설명&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2층&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;lstm()&lt;/code&gt;을 2번 써준다&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;양방향&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;bidirectional&lt;/code&gt; + &lt;code class=&quot;language-text&quot;&gt;merge_mode = ‘concat’&lt;/code&gt; &lt;br /&gt;FNN, BFN 값을 merge_mode 형태로 합쳐서 list형으로 되돌려줌&lt;br /&gt;단방향(FBN)은 ‘이후’만 기억, 양방향(FBN+BFN)은 ‘이전’+’이후’ 모두 기억&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;many-to-many&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;return-sequences = True&lt;/code&gt;&lt;br /&gt;LSTM 뉴런 &lt;strong&gt;각각의 중간 스텝에서 나오는 각각의 출력(h)&lt;/strong&gt;을 (바로 위 뉴런으로도) 사용(전파)한다는 뜻&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;timedistributed&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;timedistributed()&lt;/code&gt;&lt;br /&gt; &lt;strong&gt;FFN으로 가기 전&lt;/strong&gt; LSTM 마지막 층에서 각 뉴런의 각 지점에서 계산한 오류를 다음 층으로 전파&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LSTM이 many-to-many 상태에서 FNN으로 가면 각각의 Output 값이 나온다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NLP의 챗봇, 기계번역 등에서 사용함.&lt;/li&gt;
&lt;li&gt;Input &gt; 안녕 만나서 반가워&lt;/li&gt;
&lt;li&gt;Output &gt; 저도 반갑습니다&lt;/li&gt;
&lt;li&gt;3개의 출력층. 비어 있는 1개는 padding &lt;/li&gt;
&lt;li&gt;Q. ... padding은 어디로?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LSTM에서 사용되는 h와 c&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;역할&lt;/th&gt;
&lt;th&gt;특징&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;h&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;위, 왼쪽&lt;/strong&gt; 전파&lt;/td&gt;
&lt;td&gt;LSTM이 1층일 땐 c랑 똑같이 왼쪽으로 밖에 전파 못한다.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;왼쪽&lt;/strong&gt; 전파&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;h와 c 둘다 처음엔 0으로 시작한다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;cnn&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#cnn&quot; aria-label=&quot;cnn permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CNN&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;이미지를 대표할 수 있는 특성들을 도출해서 FNN에 넣어줌&lt;/li&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;th&gt;설명&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;Input&lt;/code&gt;(batch_shape = (None, nStep, nFeature, nChannel))&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;Conv2D&lt;/code&gt;(filters=30, kernel_size=(8,3), strides=1, padding = &apos;same&apos;, activation=&apos;relu&apos;)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;MaxPooling2D&lt;/code&gt;(pool_size=(2,1), strides=1, padding=&apos;valid&apos;)&lt;/td&gt;
&lt;td&gt;- 경우에 따라 conv2D, pooling 더 써줄 수 있음&lt;br /&gt;- &lt;code class=&quot;language-text&quot;&gt;GlobalMaxPooling1D()&lt;/code&gt;도 있음&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;Flatten()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;2D는 4차원이라 shape 맞추려고 보통 flatten을 써줌&lt;br /&gt;1d는 안 써도 되는 듯(?)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt;(nOutput, activation=&apos;linear&apos;)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;lstm과-cnn의-차이&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#lstm%EA%B3%BC-cnn%EC%9D%98-%EC%B0%A8%EC%9D%B4&quot; aria-label=&quot;lstm과 cnn의 차이 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LSTM과 CNN의 차이&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;둘다 (흐름을 보는)시계열 데이터에 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;LSTM과 CNN1D는 기능은 비슷하지만 CNN1D는 table 中 &lt;strong&gt;(colum 전체+n row)아래 방향으로의 흐름&lt;/strong&gt;을 보는 거고, &lt;/li&gt;
&lt;li&gt;LSTM은 bidirectional 을 사용해서 table 中 &lt;strong&gt;위/아래로 흐름&lt;/strong&gt;을 이동시켜서 볼 수 있다.&lt;/li&gt;
&lt;li&gt;CNN2D는 kernel_size, pooling 등을 통해 tabel 中 &lt;strong&gt;(n colum(일부분) + n row(일부분) = 내가 focus를 맞춰 보고 싶은 부분)에 따라 그 흐름을 볼 수 있다는 데&lt;/strong&gt;서 차이가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/05265afca2b82133a555e66d16254a73/108f8/image-20200805122723206.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 63.51351351351351%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABmUlEQVQ4y5WTW1ODMBCF+///W1860xkdb22tCpYCuZMQOO4GUlHbBxmYwMnm25PNshpB1zjS/feZpv6nrxIM168c9B99lR2azxPa93eIokBzPMILkYLsqULz9gbJOo2ubpIelELz9Az58Ij29RW6mfQJOMQk+nONUUooApuqSgHySBBKxrotPyE/iqSbooR6fkG8u4cvy2TmG6gryLrCMAyTK2PgOk/OeyjRIoSQdO89NM3RBGxbJ/fQGlFpyLZdAD0LNWIGWgvrOnLuoUj3ob8AlSbgGGElAedEkUomaQcLoCFgswCaGRgI2BAw/ASCgIKAzk3Avv8FDDZZjjFO9aFt2Y6A0UG3Z4R+0nnrOgEpqTjDcVI+AjLyE6hOEFVxaR/n5i33BuL0kd65JbgUeaEp96m+2XlzOWWmDFR8KSi7TovqukbXTdn5EFpyz3oeE8SZFCeovRj27XBuUra93W6x2+3+dP9+v8dms0lOcmx2tl6vcTgcFo3Ni+bF7Cq3yBLKOjvLoKzzN0N7OpSsra79SsvvW3O39C+NMPfX+fR5GQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200805122723206&quot;
        title=&quot;image-20200805122723206&quot;
        src=&quot;/static/05265afca2b82133a555e66d16254a73/fcda8/image-20200805122723206.png&quot;
        srcset=&quot;/static/05265afca2b82133a555e66d16254a73/12f09/image-20200805122723206.png 148w,
/static/05265afca2b82133a555e66d16254a73/e4a3f/image-20200805122723206.png 295w,
/static/05265afca2b82133a555e66d16254a73/fcda8/image-20200805122723206.png 590w,
/static/05265afca2b82133a555e66d16254a73/108f8/image-20200805122723206.png 777w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;activation&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#activation&quot; aria-label=&quot;activation permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;activation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;activation(비선형 함수)&lt;/th&gt;
&lt;th&gt;loss&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;softmax&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;sparse_categorical_crossentropy&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;sigmoid&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;binary_crossentropy&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;linear&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;mse&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;relu&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;← Hidden layer에 씀. 기울기가 0이기 때문에 뉴런이 죽을 수 있는 단점 有&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leakly ReLU&lt;/td&gt;
&lt;td&gt;뉴런이 죽을 수 있는 현상 해결&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PReLU&lt;/td&gt;
&lt;td&gt;x&amp;#x3C;0 에서 학습 가능&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;granger causality&lt;/td&gt;
&lt;td&gt;통제된 상황에서 인과관계가 가능하다고 말할 수 있음. 시계열 데이터에서 쓰일 수 있음&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;sparse&lt;em&gt;categorical&lt;/em&gt;crossentropy&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;encoderX&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; decoderX&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; outputY&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;optimizer&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;optimizers&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Adam&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;lr&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; loss&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;sparse_categorical_crossentropy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;sparse 안 쓸 거면 위에 &apos;outputY&apos;를 to&lt;em&gt;categorical()로 변형 후, loss 함수로 &quot;categorical&lt;/em&gt;crossentropy&quot; 사용&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;target이 one-hot encoding되어 있으면 categorical&lt;em&gt;crossentropy,
target이 integer로 되어 있으면 sparse&lt;/em&gt;categorical&lt;em&gt;crossentropy를 쓴다.
sparse&lt;/em&gt;categorical&lt;em&gt;entropy는 integer인 target을 one-hot으로 바꾼 후에 categorical&lt;/em&gt;entropy를 수행한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;딥러닝 네트워크(DN)의 노드는 입력값을 전부 더한 후, 활성화 함수(Activation function)를 통과시켜 다음 노드에 전달한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이때 사용하는 활성화 함수는 비선형 함수를 쓴다. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;softmax---sigmoid&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#softmax---sigmoid&quot; aria-label=&quot;softmax   sigmoid permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;softmax - sigmoid&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;구분&lt;/th&gt;
&lt;th&gt;함수&lt;/th&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;회귀&lt;/td&gt;
&lt;td&gt;항등함수(출력값을 그대로 반환)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;분류(0/1)&lt;/td&gt;
&lt;td&gt;sigmoid&lt;/td&gt;
&lt;td&gt;# 시험 데이터로 학습 성능을 평가한다&lt;br/&gt;predicted = model.predict(test&lt;em&gt;input)&lt;br/&gt;test&lt;/em&gt;pred = np.where(predicted &gt; 0.5, 1, 0)&lt;br/&gt;accuracy = (test&lt;em&gt;label == test&lt;/em&gt;pred).mean()&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;분류(multiple)&lt;/td&gt;
&lt;td&gt;softmax&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt; Cross-Entropy : 예측한 값과 실제값의 차를 계산. entropy 값이 감소하는 방향으로 진행하다 보면 최저 값을 찾을 수 있다. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;출처: sshkim Sh.TK. 2017. 8. 23. &quot;[모두의딥러닝] Softmax Regression (Multinomial Logistic Regression)&quot;. &quot;&lt;a href=&quot;https://sshkim.tistory.com/146&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://sshkim.tistory.com/146&lt;/a&gt;&quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt; argmax 을 사용하면 2라는 값이 나온다. 가장 큰 값의 위치가 2번째에 있는 1이기 때문&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;출처: JINSOL KIM. 2017. 12. 24. &quot;Softmax vs Sigmoid&quot;. &lt;a href=&quot;https://blog.naver.com/infoefficien/221170205067&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://blog.naver.com/infoefficien/221170205067&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;relu&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#relu&quot; aria-label=&quot;relu permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ReLu&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;히든층에 자주 쓰임&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그냥 CNN이든 LSTM이든 출력층 Dense에 Relu 쓰지 말자&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSTM에선 Relu 안 쓰는 게 좋음. 특히 출력층엔 쓰면 안 됨.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;학습compile-예측predict&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%ED%95%99%EC%8A%B5compile-%EC%98%88%EC%B8%A1predict&quot; aria-label=&quot;학습compile 예측predict permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;학습(compile), 예측(predict)&lt;/h1&gt;
&lt;h2 id=&quot;optimizer&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#optimizer&quot; aria-label=&quot;optimizer permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;optimizer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;종류(빈도순)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;adam&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adadelta, RMSprop, Adagrad&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;momentum&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GD, NAG&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;최적화가 잘 안 되면 글로벌 minmun을 찾지 못하고 로컬 minimum에 빠진다. 이때 로컬 minimum을 &lt;strong&gt;어떻게 빨리&lt;/strong&gt; 탈출할 수 있을지 U턴 메소드를 쓸지, 다른 1차 미분방법(GD)를 쓸 지 결정하게 된다. &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;epoch&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#epoch&quot; aria-label=&quot;epoch permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;epoch&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;epoch&lt;/code&gt; 수치가 커지면 &lt;code class=&quot;language-text&quot;&gt;optimizer&lt;/code&gt;가 일을 해서 local이 아닌 global을 찾아간다.&lt;/li&gt;
&lt;li&gt;그런데 너무 크면 overfitting&lt;/li&gt;
&lt;li&gt;따라서 적당한 &lt;code class=&quot;language-text&quot;&gt;epoch&lt;/code&gt; 설정이 필요 &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;batch_size&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#batch_size&quot; aria-label=&quot;batch_size permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Batch_size&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;data가 크면 &lt;code class=&quot;language-text&quot;&gt;batch_size&lt;/code&gt;도 크게&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;25,000개의 raw data라면 &lt;code class=&quot;language-text&quot;&gt;batch_size&lt;/code&gt; = 20 보다 300 이 정도로 설정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;nlp--dl&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#nlp--dl&quot; aria-label=&quot;nlp  dl permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP &amp;#x26; DL&lt;/h1&gt;
&lt;h2 id=&quot;sgns&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#sgns&quot; aria-label=&quot;sgns permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SGNS&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;용어&lt;/th&gt;
&lt;th&gt;설명&lt;/th&gt;
&lt;th&gt;CODE&lt;/th&gt;
&lt;th&gt;참고&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;pre-trained&lt;/td&gt;
&lt;td&gt;SGNS에서 학습한 We를 적용&lt;/td&gt;
&lt;td&gt;model.layers[1]&lt;strong&gt;.set_weights&lt;/strong&gt;(We)&lt;/td&gt;
&lt;td&gt;해당 code 적용 후 model fit 진행&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fine-training&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SGNS에 모델 학습(fit) 시, 학습을 따로 시키는 이유?&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# 학습&lt;/span&gt;
hist &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; X&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; X&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; 
               batch_size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;BATCH_SIZE&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
               epochs&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;NUM_EPOCHS&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;각기 연결된 가중치 선이 구분되어 있기 때문에&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SGNS 모델 만들 때 dot을 한다면, &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;axis=2&lt;/strong&gt;    &lt;em&gt;@2&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; → 후에&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;reshape&lt;strong&gt;(())&lt;/strong&gt;    &lt;em&gt;@괄호 두 개&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SGNS로 만든 Embedding의 w(가중치)를 basic한 word data에 적용할 때, load_weights 사용하는 방법도 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;근데 이땐 shape을 맞춰줘야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;w &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; encoder&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;model_w.h5&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 가중치(w) 불러온 후,&lt;/span&gt;
emb &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Embedding&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;max_features&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; embedding_dims&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; load_weights &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; w&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;xInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# embedding layer에 바로 적용&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;보통 이런 느낌으로 씀&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;weights &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; load_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
embedding_layer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Embedding&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;input_dim&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;V&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            output_dim&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;embedding_dim&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            input_length&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;input_length&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            trainable&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            weights&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;weights&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;embedding&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;embedding--pad_sequences&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#embedding--pad_sequences&quot; aria-label=&quot;embedding  pad_sequences permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Embedding &amp;#x26; pad_sequences&lt;/h2&gt;
&lt;h3 id=&quot;word2vec-기준&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#word2vec-%EA%B8%B0%EC%A4%80&quot; aria-label=&quot;word2vec 기준 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;word2vec 기준&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;word2vec&lt;/th&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;th&gt;input&lt;/th&gt;
&lt;th&gt;output&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;tokenizer&lt;/td&gt;
&lt;td&gt;tokenizer = Tokenizer()&lt;br /&gt;tokenizer.fit&lt;em&gt;on&lt;/em&gt;texts(clean&lt;em&gt;train&lt;/em&gt;review)&lt;br /&gt;train&lt;em&gt;sequences = tokenizer.texts&lt;/em&gt;to&lt;em&gt;sequences(clean&lt;/em&gt;train_review)&lt;/td&gt;
&lt;td&gt;[안녕, 만나서, 반가워]&lt;/td&gt;
&lt;td&gt;[13, 4, 3]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pad_sequences&lt;/td&gt;
&lt;td&gt;train&lt;em&gt;inputs = pad&lt;/em&gt;sequences(train&lt;em&gt;sequences, maxlen=MAX&lt;/em&gt;SEQUENCE_LENGTH, padding=&apos;post&apos;)&lt;/td&gt;
&lt;td&gt;[13, 4, 3]&lt;/td&gt;
&lt;td&gt;([0,0...1,..],[0,0,0,1,0,...],[0,0,1,...])&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Embedding&lt;/td&gt;
&lt;td&gt;embedding&lt;em&gt;layer = Embedding(input&lt;/em&gt;dim=VOCAB&lt;em&gt;SIZE, output&lt;/em&gt;dim=EMB_SIZE)&lt;/td&gt;
&lt;td&gt;([0,0...1,..],[0,0,0,1,0,...],[0,0,1,...])&lt;/td&gt;
&lt;td&gt;[0,0...1,..] -&gt; ANN layer&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;embedding&lt;em&gt;layer 는 결국 pad&lt;/em&gt;sequence된 단어들끼리 모임. 즉, 1개 문장에 대한 임베딩 행렬이 됨 &lt;/p&gt;
&lt;p&gt;1개 단어 = 1개 임베딩 레이어=벡터값&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;doc2vec-기준&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#doc2vec-%EA%B8%B0%EC%A4%80&quot; aria-label=&quot;doc2vec 기준 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;doc2vec 기준&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;doc2vec&lt;/th&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;th&gt;input&lt;/th&gt;
&lt;th&gt;output&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TaggedDocument&lt;/td&gt;
&lt;td&gt;documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)]&lt;/td&gt;
&lt;td&gt;[...,&apos;laughabl&apos;, &apos;horror&apos;], ...]&lt;/td&gt;
&lt;td&gt;TaggedDocument(words=[&apos;move&apos;, &apos;last&apos;, ... &apos;horror&apos;], tags=[999])&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Embedding&lt;/td&gt;
&lt;td&gt;model = Doc2Vec(vector&lt;em&gt;size=300, alpha=0.025, min&lt;/em&gt;alpha=0.00025, min_count=10, workers=4, dm =1)&lt;/td&gt;
&lt;td&gt;TaggedDocument(words=[&apos;move&apos;, &apos;last&apos;, ... &apos;horror&apos;], tags=[999])&lt;/td&gt;
&lt;td&gt;[벡터값]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;tags=[999] : 999번 째 문장&lt;/p&gt;
&lt;p&gt;Embedding은 model.build_vocab, model.train 거치면 한 문장에 대한 하나의 벡터가 나온다.&lt;/p&gt;
&lt;p&gt;(word2vec의 경우 한 문장에 있는 각각의 단어 수만큼 벡터가 나온다.)&lt;/p&gt;
&lt;p&gt;1개 문장 = 1개 임베딩 레이어 = 1개 벡터값&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;chatbot&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#chatbot&quot; aria-label=&quot;chatbot permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ChatBot&lt;/h1&gt;
&lt;h2 id=&quot;sequence-to-sequence&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#sequence-to-sequence&quot; aria-label=&quot;sequence to sequence permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sequence to Sequence&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;encoder&lt;/th&gt;
&lt;th&gt;decoder&lt;/th&gt;
&lt;th&gt;가능/불가능&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1층&lt;/td&gt;
&lt;td&gt;2층&lt;/td&gt;
&lt;td&gt;&lt;em&gt;불가능&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1층&lt;/td&gt;
&lt;td&gt;1층&lt;/td&gt;
&lt;td&gt;가능&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2층&lt;/td&gt;
&lt;td&gt;1층&lt;/td&gt;
&lt;td&gt;가능&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2층&lt;/td&gt;
&lt;td&gt;2층&lt;/td&gt;
&lt;td&gt;가능&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&quot;굳이 2층으로 할 필요가 있는가?&quot;&lt;/p&gt;
&lt;p&gt;→ 1층으로 하는 건 선형의 개념. 2층은 비선형의 개념이다.&lt;/p&gt;
&lt;p&gt;비선형이 분류를 더 잘해낼 수도 있지만, overfitting의 위험이 있다. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;기타&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EA%B8%B0%ED%83%80&quot; aria-label=&quot;기타 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;기타&lt;/h1&gt;
&lt;h2 id=&quot;유클리디안-거리&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%9C%A0%ED%81%B4%EB%A6%AC%EB%94%94%EC%95%88-%EA%B1%B0%EB%A6%AC&quot; aria-label=&quot;유클리디안 거리 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;유클리디안 거리&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;거리 계산할 때, 비교하고 싶은 건 &lt;code class=&quot;language-text&quot;&gt;[]&lt;/code&gt;를 쳐서 넣어주기  &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;euclidean_distances&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;father&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; mother&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;가중치-저장save&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EA%B0%80%EC%A4%91%EC%B9%98-%EC%A0%80%EC%9E%A5save&quot; aria-label=&quot;가중치 저장save permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;가중치 저장(Save)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Embedding (left side) layer의 W를 저장할 때, [2]를 저장한단 사실 알아두기&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;data/embedding_W.pickle&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;wb&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;as&lt;/span&gt; f&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  pickle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;dump&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;layers&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; f&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; pickle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;HIGHEST_PROTOCOL&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;영역별-code--논문-참고하기-좋은-site&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%98%81%EC%97%AD%EB%B3%84-code--%EB%85%BC%EB%AC%B8-%EC%B0%B8%EA%B3%A0%ED%95%98%EA%B8%B0-%EC%A2%8B%EC%9D%80-site&quot; aria-label=&quot;영역별 code  논문 참고하기 좋은 site permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;영역별 code &amp;#x26; 논문 참고하기 좋은 site&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SOTA site&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://paperswithcode.com/sota&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://paperswithcode.com/sota&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[(NLP 기초) 문장 구조 분석]]></title><description><![CDATA[NLP 형식언어 이론 Context-free Grammar Context-sensitive Grammar Natural Language 문장 구조 분석 Word-salad…]]></description><link>https://jynee.github.io/tags#1st/NLP기초_4/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/NLP기초_4/</guid><pubDate>Fri, 17 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;nlp&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#nlp&quot; aria-label=&quot;nlp permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;형식언어 이론&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Context-free Grammar&lt;/li&gt;
&lt;li&gt;Context-sensitive Grammar&lt;/li&gt;
&lt;li&gt;Natural Language&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;문장-구조-분석&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%AC%B8%EC%9E%A5-%EA%B5%AC%EC%A1%B0-%EB%B6%84%EC%84%9D&quot; aria-label=&quot;문장 구조 분석 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;문장 구조 분석&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Word-salad(말비빔): 문법적으로는 완벽히 맞지만 의미가 없는 문장&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&quot;형식언어-이론--formal-language-theory&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%ED%98%95%EC%8B%9D%EC%96%B8%EC%96%B4-%EC%9D%B4%EB%A1%A0--formal-language-theory&quot; aria-label=&quot;형식언어 이론  formal language theory permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;형식언어 이론 : Formal Language Theory&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;언어란?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(형식적 측면) 유한개의 철자로 무한개의 단어와 문장을 조합한 것&lt;/li&gt;
&lt;li&gt;(의미적 측면) 무한한 의미를 생성할 수 있는 것 &lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;촘스키의 계층 구조 (Chomsky Hierarchy)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;==의미 없이 문장이 형성되는 과정을 형식으로 설명 : &lt;code class=&quot;language-text&quot;&gt;형식언어(formal language theory)&lt;/code&gt;==&lt;/li&gt;
&lt;li&gt;groucho_grammar = &lt;code class=&quot;language-text&quot;&gt;nltk.CFG.fromstring(&amp;quot;&amp;quot;&amp;quot; V와 T로 문법 정의 &amp;quot;&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;V : &lt;code class=&quot;language-text&quot;&gt;Variable&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;T : &lt;code class=&quot;language-text&quot;&gt;erminal&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/8b4ae6878c54bf9a99808b8ed1d87ec0/c211c/image-20200717161151561.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 33.78378378378378%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABY0lEQVQozzVQTU/DMBTb/z/tAEgTvwQu2yQ2ceKE4MDQoF3XZk3SJG3TjzU172UikuWmyXNsL6pKozIa47XHPAfMuGEKU9wH4jDP4HW9XmGMgXMO1lrUdR3P+HRmJizWeom1uMNTusS+XmEj77ElvPpH7OwKu/oBcvyOgt63EELgfD7jUhTQZQmjNRT944f6vsfiy73gvVjjLXnGwe1vsDf+kBt86i2EyVFpi5YEeTkaZsG2bTF5j6GqEKYJ/TBg0TcTatNFeDeitT0ahunxc0ghMgVrBjRNEx262kFJCUWClyxDScxVcNyBBeuGLigZwV0qraArFb+T9BeFyCmOR0nxWLTruuhQ0T4nwYa6NEphJodRkLPz5TzPY8maOmHw8Ol0QklupLQ4Ho/EEhMNeop6od46EguEgWKHENBxh/yiEAXSNI3CSZIgy86EDAXF8b4jV0McGMcxgmfYDYtz3H9m/AH4sxFfc3H05QAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200717161151561&quot;
        title=&quot;image-20200717161151561&quot;
        src=&quot;/static/8b4ae6878c54bf9a99808b8ed1d87ec0/fcda8/image-20200717161151561.png&quot;
        srcset=&quot;/static/8b4ae6878c54bf9a99808b8ed1d87ec0/12f09/image-20200717161151561.png 148w,
/static/8b4ae6878c54bf9a99808b8ed1d87ec0/e4a3f/image-20200717161151561.png 295w,
/static/8b4ae6878c54bf9a99808b8ed1d87ec0/fcda8/image-20200717161151561.png 590w,
/static/8b4ae6878c54bf9a99808b8ed1d87ec0/efc66/image-20200717161151561.png 885w,
/static/8b4ae6878c54bf9a99808b8ed1d87ec0/c83ae/image-20200717161151561.png 1180w,
/static/8b4ae6878c54bf9a99808b8ed1d87ec0/c211c/image-20200717161151561.png 1502w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Context-free grammar에서, 우변 -&gt; 좌변(Variable, Terminal)일 때 &apos;-&gt;&apos;하는 과정 : &lt;code class=&quot;language-text&quot;&gt;derivation&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Unrestricted: 자연어(사람 말)&lt;/li&gt;
&lt;li&gt;Context-sensitive부터 Regualr까지 오토마타(Automata)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;code-classlanguage-text오토마타automatacode&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#code-classlanguage-text%EC%98%A4%ED%86%A0%EB%A7%88%ED%83%80automatacode&quot; aria-label=&quot;code classlanguage text오토마타automatacode permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code class=&quot;language-text&quot;&gt;오토마타(Automata)&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;어떤 Language가 어떤 Grammar에 따르는지 그래서 Accept할지, Reject할지 Check하는 추상적인 기계(장치)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/2155c3d58976ed6f8c483ba96855fe24/6a6e9/image-20200717161524521.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 56.75675675675676%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABZ0lEQVQoz41T2XKDMAzM//9hAy2Z5CEdDnPZxoBB3ZVLpnlJ4xmNbElerdZwEqxpmqTvO3HOibWjjOMgXdfBjxobhh75ZHVdo8ZKj3zfD3p333fCqD8dh2Mti8i2PYVknuXlIsZhT4Ax7mLMJE0T/oBtUpYjWEZ5Z53SyF7CvGC8CMAWgByV5xlAQaqqlrb1YL+oDDTvPXJJGsrC2IbRFHBEwtoJfgVYo4XeR9iGBg4MS+ydgjBPHalnWVbyfb+jWauxNcYE+N9a1/fG1ZHnEB4v2DQG3Yyy4Jjsytgx6sGee770jNcacI8MWfMAtNCAgNSDSZoxJu0Ri+uqADyrXipRAuQ91j4AVUN0ZJKeCRbTnPPirNNGjPObY+zlyOz+9fklt9tNLkWhPs9zybJMiuIi1+tVzucP9VmWa45Mq6pSZumRKj0zrt8h2QWMvgI8BOx/zzQyoyc7Gl+a7A8drf5NFvFJ634AhzBU95kCaCYAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200717161524521&quot;
        title=&quot;image-20200717161524521&quot;
        src=&quot;/static/2155c3d58976ed6f8c483ba96855fe24/fcda8/image-20200717161524521.png&quot;
        srcset=&quot;/static/2155c3d58976ed6f8c483ba96855fe24/12f09/image-20200717161524521.png 148w,
/static/2155c3d58976ed6f8c483ba96855fe24/e4a3f/image-20200717161524521.png 295w,
/static/2155c3d58976ed6f8c483ba96855fe24/fcda8/image-20200717161524521.png 590w,
/static/2155c3d58976ed6f8c483ba96855fe24/6a6e9/image-20200717161524521.png 826w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Unrestricted(Natural Language)&lt;/code&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Type-0 : Recognized by Turing Machine&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Context-sensitive&lt;/code&gt; &lt;/li&gt;
&lt;li&gt;Type-1 : Accepted by Linear Bound Automata&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Context-free&lt;/code&gt; &lt;/li&gt;
&lt;li&gt;Type-2 : Accepted by Push Down Automata (PDA)&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Regular&lt;/code&gt; &lt;/li&gt;
&lt;li&gt;Type-3 : Accepted by Finite State Automata (FSA)&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&quot;regular-grammar&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#regular-grammar&quot; aria-label=&quot;regular grammar permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Regular Grammar&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;결정적 유한 오토마타(Deterministic finite automaton, DFA)&lt;/li&gt;
&lt;li&gt;Regular 언어에서 오토마타는, 어떤 게 어디 속하는지에 관한 문제인 membership porblem 판별장치&lt;/li&gt;
&lt;li&gt;print(FSA(&apos;aabbb&apos;)):&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;derivation&lt;/th&gt;
&lt;th&gt;a*b+&lt;/th&gt;
&lt;th&gt;Automata&lt;/th&gt;
&lt;th&gt;Grammar&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;a&lt;strong&gt;s&lt;/strong&gt; -&gt; &lt;br /&gt;aa&lt;strong&gt;s&lt;/strong&gt; -&gt; &lt;br /&gt;aaa&lt;strong&gt;s&lt;/strong&gt; -&gt; &lt;br /&gt;aaaa&lt;strong&gt;A&lt;/strong&gt; -&gt; &lt;br /&gt;aaaab&lt;strong&gt;B&lt;/strong&gt; -&gt; &lt;br /&gt;aaaabb&lt;strong&gt;B&lt;/strong&gt; -&gt; &lt;br /&gt;aaaabbb&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;S -&gt; aS&lt;br /&gt;S -&gt; aA&lt;br /&gt;A -&gt; bB&lt;br /&gt;B -&gt; b&lt;br /&gt;&lt;br /&gt;-S -&gt; as | aA&lt;br /&gt;A -&gt; bB | b&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt; Chomsky Hierarchy 中 &lt;strong&gt;Regular&lt;/strong&gt; Grammar&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/78f4386870e42543747b38f523244fb1/0ad97/image-20200718020646135.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 8.783783783783782%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsSAAALEgHS3X78AAAAbUlEQVQI102M2wrDIBBE8/9faPLQFkxafNK1KhtvU91A6MCyzBk4CzMjhIAZ5whEhBijdO89SinIOcNaJ1vvTf5MaxX7rscdY7fCln+h1hpKKRhjbmGtFV9PON4fbOsK5lP4JWwifDxfSCkJ+wHT15mzV85PoAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200718020646135&quot;
        title=&quot;image-20200718020646135&quot;
        src=&quot;/static/78f4386870e42543747b38f523244fb1/fcda8/image-20200718020646135.png&quot;
        srcset=&quot;/static/78f4386870e42543747b38f523244fb1/12f09/image-20200718020646135.png 148w,
/static/78f4386870e42543747b38f523244fb1/e4a3f/image-20200718020646135.png 295w,
/static/78f4386870e42543747b38f523244fb1/fcda8/image-20200718020646135.png 590w,
/static/78f4386870e42543747b38f523244fb1/0ad97/image-20200718020646135.png 717w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;정규언어 (Regular language) 와 유한상태 인식기 (Accepted by Finite state acceptor : &lt;strong&gt;FSA&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;init_state &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;
final_state &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
trap_state &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;
delta &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;b&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; 
     &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;b&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;
{현재상태 0 {&apos;a&apos; 들어가면: 다음 상태는 0, &apos;b&apos; 들어가면: 다음 상태는 1}}
{현재상태 1 {&apos;a&apos; 들어가면: 다음 상태는 2, &apos;b&apos; 들어가면: 다음 상태는 1}}
&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;FSA&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;string&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  state &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; init_state  &lt;span class=&quot;token comment&quot;&gt;# 초기상태 = 0&lt;/span&gt;
  &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; s &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; string&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; 	&lt;span class=&quot;token comment&quot;&gt;# &apos;a&apos; 들어가고 &apos;a&apos; 들어가고 &apos;b&apos; 들어가는 등 하나씩 for문에 입력됨! &lt;/span&gt;
      state &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; delta&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;state&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;s&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; state &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; trap_state&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# state가 2가 되면 멈춤. 즉, 1상태에서 &apos;a&apos;가 들어오면 멈춤&lt;/span&gt;
          					&lt;span class=&quot;token comment&quot;&gt;# 즉, 문자열을 읽어가다가 trap state에 빠지면 reject 됨 &lt;/span&gt;
          &lt;span class=&quot;token keyword&quot;&gt;break&lt;/span&gt;

  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; state &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; final_state &lt;span class=&quot;token comment&quot;&gt;# state값이 final_state에 있으면 True, 없으면 False&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;FSA&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;aabbb&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# True&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;FSA&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;aabba&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# False&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;FSA&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;aabbc&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# error&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;FSA&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;     &lt;span class=&quot;token comment&quot;&gt;# False&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;context-free-grammar&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#context-free-grammar&quot; aria-label=&quot;context free grammar permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Context-free Grammar&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Accepted by Push Down Automata, PDA&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;{a의 n승 b의 n승, n&gt;=1}가 aaaabbbb라는 오토마타 형태(뭐다음 뭐 나와야 하고, 뭐 다음 뭐 나와야 하는 것)을
기계는 기억하지 못함.
ex: N의 n승 N의 n승 -&gt; the cat(N) the dog(N) chased(V) run(V)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이때, 과거 데이터를 기억하는 오토마타의 장치: Stack&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Chomsky Hierarchy 中 &lt;strong&gt;Context-free&lt;/strong&gt; Grammar&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/6ab1151ec3b9f194878813b6a6e89e89/d6331/image-20200718021947962.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 8.108108108108107%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsSAAALEgHS3X78AAAAc0lEQVQI1zWM4QrDIAyE+/6vuP6wDnFVWxRRI53eTGCBkNzl8m05Z/ROCCHAOYf7utb0eJ4vYoyYc657RykFtVbR/52LtdYa1trlNWwMpNbEOA6F8/yswBtEHSkleSAigXOPMQTIHlGDMQavfUfwHkop/ACZqZj7NPEGngAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200718021947962&quot;
        title=&quot;image-20200718021947962&quot;
        src=&quot;/static/6ab1151ec3b9f194878813b6a6e89e89/fcda8/image-20200718021947962.png&quot;
        srcset=&quot;/static/6ab1151ec3b9f194878813b6a6e89e89/12f09/image-20200718021947962.png 148w,
/static/6ab1151ec3b9f194878813b6a6e89e89/e4a3f/image-20200718021947962.png 295w,
/static/6ab1151ec3b9f194878813b6a6e89e89/fcda8/image-20200718021947962.png 590w,
/static/6ab1151ec3b9f194878813b6a6e89e89/d6331/image-20200718021947962.png 702w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;context-sensitive-grammar&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#context-sensitive-grammar&quot; aria-label=&quot;context sensitive grammar permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Context-sensitive Grammar&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;좌우 문맥에 따라 달라지는 경우&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;S -&gt; NP VP&lt;/li&gt;
&lt;li&gt;aSb -&gt; NP VP&lt;/li&gt;
&lt;li&gt;cSd -&gt; NP PP&lt;/li&gt;
&lt;li&gt;aSb -&gt; aS by&lt;/li&gt;
&lt;li&gt;bSa -&gt; aA bb&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Accepted by Linear Bound Automata&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&apos;한글모아쓰기&apos;에 활용되기도 함&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Chomsky Hierarchy 中 &lt;strong&gt;Context-sensitive&lt;/strong&gt; Grammar&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/004fde0e19268798eb56e4b9ef291c8e/d2cbc/image-20200718022925812.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 10.81081081081081%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsSAAALEgHS3X78AAAAcUlEQVQI1z1M2w7CIBTb/38hD55kM8jCJdEBB8IEqhDdS9v0tvTekXNGCAEpJcQYL47M03+fJ5gjrLUopXw1o9YK5xyIbhBCQGuN8bUM+B9Ya7Btd+y7gpQSD6XgvZ/l4Rsz8hXP1zE3RPTL1tlvreEDabyXsnuJGEgAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200718022925812&quot;
        title=&quot;image-20200718022925812&quot;
        src=&quot;/static/004fde0e19268798eb56e4b9ef291c8e/fcda8/image-20200718022925812.png&quot;
        srcset=&quot;/static/004fde0e19268798eb56e4b9ef291c8e/12f09/image-20200718022925812.png 148w,
/static/004fde0e19268798eb56e4b9ef291c8e/e4a3f/image-20200718022925812.png 295w,
/static/004fde0e19268798eb56e4b9ef291c8e/fcda8/image-20200718022925812.png 590w,
/static/004fde0e19268798eb56e4b9ef291c8e/d2cbc/image-20200718022925812.png 705w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;unrestricted-grammar-natural-language&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#unrestricted-grammar-natural-language&quot; aria-label=&quot;unrestricted grammar natural language permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Unrestricted Grammar (Natural Language)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Recognized by Turing Machine&lt;/li&gt;
&lt;li&gt;의미는 틀려도 되고, 아무 단어나 막 조합해도 되는 것&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;참고: &lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;아마추어 퀀트, blog.naver.com/chunjein&lt;/li&gt;
&lt;li&gt;코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[(NLP 기초) 문서 정보 추출]]></title><description><![CDATA[NLP 정규표현식 청킹 칭킹  문서 정보 추출  정해진 패턴을 사용해서 패턴에 일치하는 데이터 검색을 지원하는 표현식 정규표현식에 쓰이는 특수문자  : 아무 문자나 여러 개   : } { 안의 내용 제외     =  읽어보기 DEVHolic…]]></description><link>https://jynee.github.io/tags#1st/NLP기초_3/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/NLP기초_3/</guid><pubDate>Fri, 17 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;nlp&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#nlp&quot; aria-label=&quot;nlp permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;정규표현식&lt;/li&gt;
&lt;li&gt;청킹&lt;/li&gt;
&lt;li&gt;칭킹&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&quot;문서-정보-추출&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%AC%B8%EC%84%9C-%EC%A0%95%EB%B3%B4-%EC%B6%94%EC%B6%9C&quot; aria-label=&quot;문서 정보 추출 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;문서 정보 추출&lt;/h2&gt;
&lt;br&gt;
&lt;h3 id=&quot;code-classlanguage-text정규표현식code&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#code-classlanguage-text%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9Dcode&quot; aria-label=&quot;code classlanguage text정규표현식code permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code class=&quot;language-text&quot;&gt;정규표현식&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;정해진 패턴을 사용해서 패턴에 일치하는 데이터 검색을 지원하는 표현식&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;정규표현식에 쓰이는 특수문자&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;lt;.*&amp;gt;+&lt;/code&gt; : 아무 문자나 여러 개 &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;} {&lt;/code&gt; : } { 안의 내용 제외   &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;quot;\\n&amp;quot;&lt;/code&gt; = &lt;code class=&quot;language-text&quot;&gt;r&amp;quot;\n&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;읽어보기&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.devholic.net/1000238351600&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;DEVHolic. &quot;정규표현식에 쓰이는 특수문자&quot;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://jungwoon.github.io/python/2018/03/15/Data-Analysis-With-Python-2/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Jungwoon. &quot;파이썬으로 데이터 분석하기 #2&quot;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&quot;re-모듈-함수&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#re-%EB%AA%A8%EB%93%88-%ED%95%A8%EC%88%98&quot; aria-label=&quot;re 모듈 함수 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;re 모듈 함수&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;읽어보기&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://devanix.tistory.com/296&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;devanix. &quot;파이썬 – 정규식표현식(Regular Expression) 모듈&quot;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&quot;code-classlanguage-text청킹chunkingcode&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#code-classlanguage-text%EC%B2%AD%ED%82%B9chunkingcode&quot; aria-label=&quot;code classlanguage text청킹chunkingcode permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code class=&quot;language-text&quot;&gt;청킹(Chunking)&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;여러 개의 품사로 &lt;strong&gt;구(pharase)를 만드는 것을 Chunking&lt;/strong&gt;이라 하고, 이 &lt;strong&gt;구(pharase)를 chunk&lt;/strong&gt;라 한다.&lt;/li&gt;
&lt;li&gt;문장을 각 품사로 구분하고, Chunking에 의해 구로 구분하면 문장의 의미를 파악하기 용이해 진다.&lt;/li&gt;
&lt;li&gt;문장에서 (DT + JJ + NN), (DT + JJ + JJ + NN), (JJ + NN), 등의 시퀀스는 모두 명사구 (NP : Noun phrase)로 판단한다&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If a tag pattern matches at overlapping locations, the leftmost match takes precedence&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/91725a6b5ce90c6adcd2f98f8c1b0f13/d5bfb/image-20200816015803693.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 30.405405405405407%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAAA70lEQVQY01VQya6DMBDL/39ay6mtEALKvu8gtgN0ii1FfS+SFU/i8SyqaRqJ41iSJJGqqmTbNlnXlTGQ57mkaUpkWfaPA1qDG17K930xTVNs25bn40FTJNzud4miiMWCICB0clmW5Mh9v10au67LWEEAopM9z6PYcRzp+17qupZhGMjP85R5nmWaJjmOg+9AGIb8zy4v1batGIYhlmWxZYwLwLzrOgq1Icxezxe14Nqw63pqi6IQhWSMgAd0oM++70zSBQDsF7pxHMmXZSF01+BK/hyMCnOsAbtEV9UV4w3Vy7LiCvAH1NdE0Hw+P48v0RTBy1N5gb0AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200816015803693&quot;
        title=&quot;image-20200816015803693&quot;
        src=&quot;/static/91725a6b5ce90c6adcd2f98f8c1b0f13/fcda8/image-20200816015803693.png&quot;
        srcset=&quot;/static/91725a6b5ce90c6adcd2f98f8c1b0f13/12f09/image-20200816015803693.png 148w,
/static/91725a6b5ce90c6adcd2f98f8c1b0f13/e4a3f/image-20200816015803693.png 295w,
/static/91725a6b5ce90c6adcd2f98f8c1b0f13/fcda8/image-20200816015803693.png 590w,
/static/91725a6b5ce90c6adcd2f98f8c1b0f13/efc66/image-20200816015803693.png 885w,
/static/91725a6b5ce90c6adcd2f98f8c1b0f13/d5bfb/image-20200816015803693.png 1072w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;순서&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;grammar 정의&lt;/li&gt;
&lt;li&gt;딕셔너리 정의:
cp = nltk.RegexpParser(grammar)&lt;/li&gt;
&lt;li&gt;sentence data 불러오기(혹은 테스트를 위해서라면 만들기)&lt;/li&gt;
&lt;li&gt;딕셔너리에 따라 sentence 분석:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; cp.parse(sentence)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Base code&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; nltk
grammar &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; 
&lt;span class=&quot;token triple-quoted-string string&quot;&gt;&quot;&quot;&quot;
NP: {&amp;lt;DT|PP\$&gt;?&amp;lt;JJ&gt;*&amp;lt;NN&gt;}	  # rule 1
  {&amp;lt;NNP&gt;+}                  # rule 2
&quot;&quot;&quot;&lt;/span&gt;

cp &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;RegexpParser&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;grammar&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;


sentence &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Rapunzel&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;NNP&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;let&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;VBD&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;down&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;token string&quot;&gt;&quot;RP&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;her&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;PP$&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;long&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;JJ&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;golden&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;JJ&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;hair&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;NN&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;


cp&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;parse&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sentence&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;(S
(NP Rapunzel/NNP)
let/VBD
down/RP
(NP her/PP$ long/JJ golden/JJ hair/NN))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;result&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;draw&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/37b649a5ebb98901961a3a423f912dca/ea7fb/image-20200816015725145.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 37.83783783783784%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABeElEQVQoz2WQi26rMAyGef8X2gtMm7TpaOvZKF1ZoZBASLkTLhkr+Y+Duuux9Ml2bP+x7EgpURQFhMgwzzOsGWM++bCPcDkbSDkjSWeU5TuWxfyoO/OscT6/wXpjli8hY/4Tt1gB1b1D1Rp9v1wEv+pOUShw3uGU92gaRU0K4zCgaTtkeYVh6OntG5SPfYcxS9GPA5RSP3A4y+G7KbxtgohJiCzDkTG4+1f89XwkQoAlCWLCxjLPcaLztFGEpqpQEXVdf3qno4abxxcIzug2Ag+hh+vdA/Y8xK3/iM1xh6Is0TYtShrK6OYsPOLqZgPJU6imQdu26AjrHZEJBGEInjLkZYGiKlfKusKJciti40hw+PERUcLh+Xs8b7fYeC4CHhMMYcKoP4dz9/pEW3i4PzwjSGP6qVtXtzR1s24WZZw232LHDnAjEot9RJLh7vC0vh1o7k/g4oUHcKZxxDRNeJs0NPmR8t9MI9W1XrG906VPX2KLXuc1/gEar1yjr1coqAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200816015725145&quot;
        title=&quot;image-20200816015725145&quot;
        src=&quot;/static/37b649a5ebb98901961a3a423f912dca/fcda8/image-20200816015725145.png&quot;
        srcset=&quot;/static/37b649a5ebb98901961a3a423f912dca/12f09/image-20200816015725145.png 148w,
/static/37b649a5ebb98901961a3a423f912dca/e4a3f/image-20200816015725145.png 295w,
/static/37b649a5ebb98901961a3a423f912dca/fcda8/image-20200816015725145.png 590w,
/static/37b649a5ebb98901961a3a423f912dca/ea7fb/image-20200816015725145.png 788w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&quot;code-classlanguage-text칭킹chinkingcode&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#code-classlanguage-text%EC%B9%AD%ED%82%B9chinkingcode&quot; aria-label=&quot;code classlanguage text칭킹chinkingcode permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code class=&quot;language-text&quot;&gt;칭킹(Chinking)&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;특정 부분을 chunk 밖으로 빼내는 것을 chinking이라 한다.
Chink는 문장에서 chunk를 제외한 나머지 부분을 의미한다&lt;/li&gt;
&lt;li&gt;문장 전체를 chunk로 정의하고, 특정 부분을 chinking하면 나머지 부분이 chunk가 된다.
Chinking을 이용해서 chunking을 할 수도 있다&lt;/li&gt;
&lt;li&gt;code:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;grammar &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; 
 &lt;span class=&quot;token triple-quoted-string string&quot;&gt;r&quot;&quot;&quot;
NP:
{&amp;lt;.*&gt;+}              # Chunk everything
}&amp;lt;VBD|IN&gt;+{          # Chink sequences of VBD and IN(빼내는 부분)
&quot;&quot;&quot;&lt;/span&gt;

sentence &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;the&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;DT&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;little&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;JJ&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;yellow&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;JJ&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;dog&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;NN&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;barked&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;VBD&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;at&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;IN&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;the&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;DT&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;cat&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;NN&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

cp &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;RegexpParser&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;grammar&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
cp&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;parse&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sentence&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 509px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/ae605cdbfc74eca908f77aacdbe33727/71554/image-20200717135504838.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 33.108108108108105%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABMElEQVQoz5WR2W6DQAxF+f8/6w9ELQ2QhIQdhhAgswCnBqS0D3mpJcvj7c617Snl+J8s76PLHvfK0rFq2zqq2tE0jmGYyDMjcUsl2j2mLb/WqQ5UO6OkLs8tt5uhrt0L1MtSSxBoUrGHw0gcGx79TFbOXJKJopjoB6TRcY01548TKh/Iq4VPX/yzlY+mX8CVRRBqTpHmGBgOvoW6gksEnWIcH8Iyxzm9z+aecFfQ1uJYrPjGjJLfWXor3Sh8EgsbugaaQoqloS43v+9a/DCUEVvpd8xCd2kkn6RosccwIjgGsqZhB0wSg+8/JW85BwNpPPIY4ZrNfH0bGV2qamHTNCxKgPpeWLq3p9lGvt/Xhcue+oksd3KAmUHehSw8Sw2FHGLWmmWaXjde9u4N4K+u8gPyqRyDaGVTjQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200717135504838&quot;
        title=&quot;image-20200717135504838&quot;
        src=&quot;/static/ae605cdbfc74eca908f77aacdbe33727/71554/image-20200717135504838.png&quot;
        srcset=&quot;/static/ae605cdbfc74eca908f77aacdbe33727/12f09/image-20200717135504838.png 148w,
/static/ae605cdbfc74eca908f77aacdbe33727/e4a3f/image-20200717135504838.png 295w,
/static/ae605cdbfc74eca908f77aacdbe33727/71554/image-20200717135504838.png 509w&quot;
        sizes=&quot;(max-width: 509px) 100vw, 509px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h3 id=&quot;chunk의-구조---code-classlanguage-textiob-tagscode&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#chunk%EC%9D%98-%EA%B5%AC%EC%A1%B0---code-classlanguage-textiob-tagscode&quot; aria-label=&quot;chunk의 구조   code classlanguage textiob tagscode permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Chunk의 구조 - &lt;code class=&quot;language-text&quot;&gt;IOB tags&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Chunk내의 각 품사의 위치에 따라 B (Begin), I (Inside), O (Outside)를 붙인다 (chunk tag). &lt;/li&gt;
&lt;li&gt;B-NP는 NP chunk의 시작 부분을 의미하고, I-NP는 NP chunk의 내부 부분을 의미한다. &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Chunk 구조는 IOB tags로 표현할 수도 있고, 트리 구조로 표현할 수도 있다. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NLTK에서는 트리 구조를 사용한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/1a4c6d3cae131a3c34596f46edaa2150/16068/image-20200717142504374.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 39.189189189189186%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABAklEQVQoz4WRB46FMAxEuf8lAdF778U/z6sg/mqltTQEJ/FkxnbWdZVhGGQcR8nSVKIokizLJEkSSU3etu3P+TTKsixC3Pf9BbtHOBC4rqsEFhBCUtWVNG0jZVmK7/tS1/WfhG84XIrjWJUAyFA2z7MSWYV5nss0TfJfOHwo7rpO19nYotASsV9Vle5t26b/iOC8aRoFbTuOQ+FY7wSHe99/vUhvPc+TMAx1BUEQaI4b64iW4PQhhN0zvZzMplzX02QGgXXUF0WheW8eBdYB6lFO/hCe5ymZ6dNeFiRidV+GnGJW7rwnDRmuvnr4HjsvnRQwsV/T3PddgQr6xz+ubNh7H9Bgaq9Q77OBAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200717142504374&quot;
        title=&quot;image-20200717142504374&quot;
        src=&quot;/static/1a4c6d3cae131a3c34596f46edaa2150/fcda8/image-20200717142504374.png&quot;
        srcset=&quot;/static/1a4c6d3cae131a3c34596f46edaa2150/12f09/image-20200717142504374.png 148w,
/static/1a4c6d3cae131a3c34596f46edaa2150/e4a3f/image-20200717142504374.png 295w,
/static/1a4c6d3cae131a3c34596f46edaa2150/fcda8/image-20200717142504374.png 590w,
/static/1a4c6d3cae131a3c34596f46edaa2150/efc66/image-20200717142504374.png 885w,
/static/1a4c6d3cae131a3c34596f46edaa2150/c83ae/image-20200717142504374.png 1180w,
/static/1a4c6d3cae131a3c34596f46edaa2150/16068/image-20200717142504374.png 1451w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;code&lt;/em&gt; &gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;conll2000&lt;strong&gt;.iob_sents&lt;/strong&gt;(&apos;train.txt&apos;)[99]&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;[(&apos;Over&apos;, &apos;IN&apos;, &apos;B-PP&apos;), (&apos;a&apos;, &apos;DT&apos;, &apos;B-NP&apos;), (&apos;cup&apos;, &apos;NN&apos;, &apos;I-NP&apos;), (&apos;of&apos;, &apos;IN&apos;, &apos;B-PP&apos;), (&apos;coffee&apos;, &apos;NN&apos;, &apos;B-NP&apos;), (&apos;,&apos;, &apos;,&apos;, &apos;O&apos;), (&apos;Mr.&apos;, &apos;NNP&apos;, &apos;B-NP&apos;), (&apos;Stone&apos;, &apos;NNP&apos;, &apos;I-NP&apos;), (&apos;told&apos;, &apos;VBD&apos;, &apos;B-VP&apos;), (&apos;his&apos;, &apos;PRP$&apos;, &apos;B-NP&apos;), (&apos;story&apos;, &apos;NN&apos;, &apos;I-NP&apos;), (&apos;.&apos;, &apos;.&apos;, &apos;O&apos;)]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;절(Clause)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;문법에 clause (절)를 정의하면 문장을 아래와 같이 분석 (chunking) 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recursion in Linguistic Structure&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;grammar &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token triple-quoted-string string&quot;&gt;r&quot;&quot;&quot;
NP: {&amp;lt;DT|JJ|NN.*&gt;+} # Chunk sequences of DT, JJ, NN
PP: {&amp;lt;IN&gt;&amp;lt;NP&gt;} # Chunk prepositions followed by NP
VP: {&amp;lt;VB.*&gt;&amp;lt;NP|PP|CLAUSE&gt;+$} # Chunk verbs and their arguments
CLAUSE: {&amp;lt;NP&gt;&amp;lt;VP&gt;} # Chunk NP, VP
&quot;&quot;&quot;&lt;/span&gt;
cp &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;RegexpParser&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;grammar&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
sentence &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Mary&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;NN&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;saw&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;VBD&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;the&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;DT&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;cat&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;NN&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;sit&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;VB&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;on&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;IN&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;the&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;DT&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;mat&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;NN&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;cp&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;parse&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sentence&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;(S
(NP Mary/NN)
saw/VBD
(CLAUSE
(NP the/DT cat/NN)
(VP sit/VB (PP on/IN (NP the/DT mat/NN)))))&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/3a7b4110bece42fe0ededfeba5b0cd1c/18872/image-20200717162332408.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 62.16216216216216%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABjUlEQVQoz2VT7ZKDIAz0/d/v7s/ddK49r1VbP6AogsBeEktrW2YykEQ2myUWoJVSwvMesSwLtotzd9vEXlfxDgZcrw5aj5imBOfi28Wt/5ortsEQEoEFWBvJVjbjGMjYtzidjmia5o3xFuPOkDvUOkhiWRKxi0+VlbJkA+p6INbpTYp8FoZceVATMntmxGx5zfOMw6Ek/wFuzEzAtRR+bV0AtZ4RY9xcCHdA5wLadpJzjFmaSGxn0dgYi77vnhlygvFylS2g9wmXS3hiYUxEHoJp8gRot4Cr8Lk6Bxkw+5xjP7fnfRQ/fzsR+bpq7ywLFm62uZ0kWpFsN2EAS+y9f8TYz+Ac8y4JS61XygUrd2xa0UX0NCMq8kU/H9ArgyvFukETkJd91TPg0lGMGHRqxKnpYZ0jQKVw/v5CvD2jOZ/Rlr/rKBmDkeZu0gpDVREbB0UTsQJG6IZemnoe6wrd/gd2GKjlvxL4+JRBlEaqE81RtZ470qUseQxIqJqel9o6Hh9/BxWR3GEP7HZy7x/3Cay49ayrUgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200717162332408&quot;
        title=&quot;image-20200717162332408&quot;
        src=&quot;/static/3a7b4110bece42fe0ededfeba5b0cd1c/fcda8/image-20200717162332408.png&quot;
        srcset=&quot;/static/3a7b4110bece42fe0ededfeba5b0cd1c/12f09/image-20200717162332408.png 148w,
/static/3a7b4110bece42fe0ededfeba5b0cd1c/e4a3f/image-20200717162332408.png 295w,
/static/3a7b4110bece42fe0ededfeba5b0cd1c/fcda8/image-20200717162332408.png 590w,
/static/3a7b4110bece42fe0ededfeba5b0cd1c/18872/image-20200717162332408.png 608w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;.RegexpParser()&lt;/code&gt;에 &lt;strong&gt;loop = 2&lt;/strong&gt;를 지정하면 아래와 같이 clause 안에 또 다른 clause를 재귀적(recursion)으로 분석한다.
이와 같이 문장에 맞게 트리를 깊게 구성하는 것을 &lt;code class=&quot;language-text&quot;&gt;cascaded chunking (계단식 chunk)&lt;/code&gt; 이라 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;cp &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;RegexpParser&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;grammar&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; loop&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;cp&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;parse&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sentence&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;loop 걸어주면 절 속의 절이 들어가는 형태로 구분해준다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;(S
(NP John/NNP)
thinks/VBZ
(CLAUSE
(NP Mary/NN)
(VP
saw/VBD
(CLAUSE
(NP the/DT cat/NN)
(VP sit/VB (PP on/IN (NP the/DT
mat/NN)))))))&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/3cd8a0b8ad7f7393b9784a480984c6be/c1c45/image-20200717162643660.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 59.45945945945946%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABh0lEQVQoz21T7XLDIAzj/R+yP9Zes16bNITPQECzccjardxxMY6RJQGq1goe/RtCxLYV/B38/2/tp6FeC9a1QutEoKXNlDY45ygOb8Cf4gOwJ0upMGZroLIGYtxwv094zobyhZinN7afGO+AdWdUCaTLlbjsyxgTxtEQaP1nxWsTJVJBYAKYcy9Aa8LAPDkvdcD4mDAM34fXr2xVSpmkxrbwvjTpPKwNzcPOlsFLYU8DAbM1meJENemNreJT1YvdT/gXcJoWYpVbzDJjrPTN5Kk+ALxfMc+e9mVqIKQUe8RSGEgkdv9EdveSQVm2MWIBswmhX7VMBCzligA21lWAxTM0wM42SvNW55zkmHw/wET7nk+HlexTMTJtA+d980ckbu2q8HDOY1lcY8S+LmRPXBPF/ngIITCGxawt1BoDzKLhjEHwTgCJitHiVWiNBDBybG07CO/s/hgizZX2L9TE0LXhjcMAnM/A9SqCOXc6SUyN8Bjlpt9ufFpMG0QJlXPUhGNcLsDXGT8IxK97fx2OOwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200717162643660&quot;
        title=&quot;image-20200717162643660&quot;
        src=&quot;/static/3cd8a0b8ad7f7393b9784a480984c6be/fcda8/image-20200717162643660.png&quot;
        srcset=&quot;/static/3cd8a0b8ad7f7393b9784a480984c6be/12f09/image-20200717162643660.png 148w,
/static/3cd8a0b8ad7f7393b9784a480984c6be/e4a3f/image-20200717162643660.png 295w,
/static/3cd8a0b8ad7f7393b9784a480984c6be/fcda8/image-20200717162643660.png 590w,
/static/3cd8a0b8ad7f7393b9784a480984c6be/c1c45/image-20200717162643660.png 824w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&quot;named-entity-recognition-code-classlanguage-textnercode---개체명-인식&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#named-entity-recognition-code-classlanguage-textnercode---%EA%B0%9C%EC%B2%B4%EB%AA%85-%EC%9D%B8%EC%8B%9D&quot; aria-label=&quot;named entity recognition code classlanguage textnercode   개체명 인식 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Named Entity Recognition (&lt;code class=&quot;language-text&quot;&gt;NER&lt;/code&gt;) - 개체명 인식&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;NER 붙여놓으면 Q&amp;#x26;A 가능하다(답을 찾아 제시해주는 챗봇 같은 거 만들 수 있음)&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;sent &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;corpus&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;treebank&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;tagged_sents&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;ne_chunk&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sent&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; binary&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;(S
The/DT
(&lt;strong&gt;NE&lt;/strong&gt; U.S./NNP)
is/VBZ
one/CD
of/IN
...
according/VBG
to/TO
(&lt;strong&gt;NE&lt;/strong&gt; Brooke/NNP)
T./NNP
...
the/DT
(&lt;strong&gt;NE&lt;/strong&gt; University/NNP)
of/IN
(&lt;strong&gt;NE&lt;/strong&gt; Vermont/NNP College/NNP)
of/IN
(&lt;strong&gt;NE&lt;/strong&gt; Medicine/NNP)
./.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;binary=True&lt;/code&gt; 안 쓰고 그냥하면 &lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;ne_chunk&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sent&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;(S
The/DT
(&lt;strong&gt;GPE&lt;/strong&gt; U.S./NNP)
is/VBZ
one/CD
of/IN
...
according/VBG
to/TO
(&lt;strong&gt;PERSON&lt;/strong&gt; Brooke/NNP T./NNP Mossman/NNP)
...
the/DT
(&lt;strong&gt;ORGANIZATION&lt;/strong&gt; University/NNP)
of/IN
(&lt;strong&gt;PERSON&lt;/strong&gt; Vermont/NNP College/NNP)
of/IN
(&lt;strong&gt;GPE&lt;/strong&gt; Medicine/NNP)
./.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;reference: &lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;아마추어 퀀트, blog.naver.com/chunjein&lt;/li&gt;
&lt;li&gt;코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[(NLP 기초) 품사 태깅]]></title><description><![CDATA[NLP 품사 태깅 원리 HMM 품사 태깅 : 문장의 N, V, ad, av 판별 문장만 보고 품사를 붙여주는 기계:   문맥 = '문장 내' 주변 단어 =  현재 NLP 상에선 문장 간, 절 간 Context는 불가 "NLP…]]></description><link>https://jynee.github.io/tags#1st/NLP기초_2/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/NLP기초_2/</guid><pubDate>Thu, 16 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;nlp&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#nlp&quot; aria-label=&quot;nlp permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;품사 태깅 원리&lt;/li&gt;
&lt;li&gt;HMM&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;품사-태깅&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%ED%92%88%EC%82%AC-%ED%83%9C%EA%B9%85&quot; aria-label=&quot;품사 태깅 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;품사 태깅&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;품사 태깅&lt;/code&gt;&lt;/strong&gt;: 문장의 N, V, ad, av 판별&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;문장만 보고 품사를 붙여주는 기계:  &lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;pos tagger&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;문맥 = &apos;문장 내&apos; 주변 단어 = &lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;Context&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;현재 NLP 상에선 문장 간, 절 간 Context는 불가&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&quot;NLP 분석 시, 몇 개의 Context를 창조할 것인가?&quot;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;n-gram&lt;/code&gt;&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;1개: &lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;unigram&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2개: **&lt;code class=&quot;language-text&quot;&gt;Bigram&lt;/code&gt; **&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ex: (I love) , (love you)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3개: &lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;Trigram&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;4개: ...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;분석할 문장의 올바른 품사를 결정하기 위해선(올바른 tagger 기계를 만들기 위해선) 사전에 올바른 품사가 정의된 문서 코퍼스(말뭉치)가 있어야 한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nltk: 영어용&lt;/li&gt;
&lt;li&gt;konlpy: 한글용 &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&quot;tagging-거치는-원리&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#tagging-%EA%B1%B0%EC%B9%98%EB%8A%94-%EC%9B%90%EB%A6%AC&quot; aria-label=&quot;tagging 거치는 원리 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tagging 거치는 원리&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;사람이 학습 문서에 품사를 태깅해 놓았음: Tagged Corpora  &lt;code class=&quot;language-text&quot;&gt;trainX&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;학습  &lt;code class=&quot;language-text&quot;&gt;model.fit&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;모델 파라미터  &lt;code class=&quot;language-text&quot;&gt;machine&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;POS Tagger 완성 &lt;/li&gt;
&lt;li&gt;추후 input text 입력 시  &lt;code class=&quot;language-text&quot;&gt;test X&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;POS Tagger 거치면 &lt;code class=&quot;language-text&quot;&gt;model.predict(testX)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Tagging 돼서 출력됨 &lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;hmm&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#hmm&quot; aria-label=&quot;hmm permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HMM&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;히든 마코프 모델(HMM): sequence를 분석&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;1차 Markov Chain:&lt;/p&gt;
&lt;p&gt;: 현재 상태는 직전 상태에만 의존한다&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2차 Markov Chain:&lt;/p&gt;
&lt;p&gt;: 현재 상태는 전전 상태에만 의존한다&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Hidden Markov Model(HMM)&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;관측데이터(주가, 수익률, 거래량 ,변동성, 등...)에 직접 나타나지 않는 히든 상태(Hidden State)가 있다&lt;/li&gt;
&lt;li&gt;이때, &lt;strong&gt;HMM은 관찰 데이터를 가지고 Hidden 상태를 추론하는 것&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;MLE 개념 사용&lt;/li&gt;
&lt;li&gt;용어 정리: &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;초기상태&lt;/code&gt; = &lt;code class=&quot;language-text&quot;&gt;초기확률&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Hidden State에서 행동 변화가 일어날 확률 &lt;code class=&quot;language-text&quot;&gt;천이확률&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;상태 변화가 일어나는 확률: &lt;code class=&quot;language-text&quot;&gt;출력확률&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;알고리즘 정리:&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Forward 알고리즘&lt;/code&gt;: X가 나올 확률 계산&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Viterbi decoding 알고리즘&lt;/code&gt;: Z 추정&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;Forward 알고리즘&lt;/code&gt;은 &apos;확률&apos; 계산이고, &lt;code class=&quot;language-text&quot;&gt;Viterbi decoding 알고리즘&lt;/code&gt;은 &apos;시퀀스&apos; 추정임&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Baum Welch 알고리즘&lt;/code&gt;: Z 추정&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;Viterbi 알고리즘&lt;/code&gt; 과의 차이점: &lt;code class=&quot;language-text&quot;&gt;Baum Welch 알고리즘&lt;/code&gt;는 사전에 주어진 게 X 밖에 없음&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h4 id=&quot;code-classlanguage-textforward-알고리즘code&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#code-classlanguage-textforward-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98code&quot; aria-label=&quot;code classlanguage textforward 알고리즘code permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code class=&quot;language-text&quot;&gt;Forward 알고리즘&lt;/code&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Evaluation Question 문제에서 활용&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;초기 확률(초기 상태)&lt;/code&gt;, &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Transition 확률(천이확률)&lt;/code&gt;, &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Emission 확률(출력확률)&lt;/code&gt;이 주어졌을 때, &lt;/li&gt;
&lt;li&gt;관측 데이터가 발생할 &lt;strong&gt;확률&lt;/strong&gt;을 &lt;code class=&quot;language-text&quot;&gt;Forward 알고리즘&lt;/code&gt;으로 계산(추정)한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Forward알고리즘은 &apos;확률&apos; 계산이고, Viterbi decoding 알고리즘은 &apos;시퀀스&apos; 추정임&lt;/strong&gt;	&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;token keyword&quot;&gt;as&lt;/span&gt; np
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; hmmlearn &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; hmm&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;히든 상태 정의&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;states &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Rainy&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Sunny&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
nState &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;states&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;관측 데이터 정의&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;observations &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Walk&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Shop&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Clean&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# nObervation = len(observations)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;HMM 모델 빌드&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; hmm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;MultinomialHMM&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;n_components&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;nState&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# n_components = 2개 &lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;startprob_ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 초기확률(상태)&lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;transmat_ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 천이확률 Transition &lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;emissionprob_ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 출력확률 Emission&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt; Multinomial(다항분포): 여러 개의 값을 가질 수 있는 독립 확률변수들에 대한 확률분포&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;X&lt;/code&gt;: 관측 데이터 시퀀스(Observations Sequence) &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&apos;&apos;이렇게 X가 나오도록 Z 값&apos;&apos; 계산하라 中 &apos;&apos;이렇게 X가 나오도록&apos;&apos; 담당 &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;X &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;T  &lt;span class=&quot;token comment&quot;&gt;# Walk(0) -&gt; Clean(2) -&gt; Shop(1)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Forward 알고리즘&lt;/code&gt;: &lt;code class=&quot;language-text&quot;&gt;&amp;#39;.score()&amp;#39;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;x가 관측될 likely probability(가능성, 확률) 계산&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;logL &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;score&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# Forward 알고리즘. sequnce 값이 커지면 확률값이 굉장히 작아져 &apos;0.00..&apos; 등으로 나오니까 defaulf로 log 함수를 취해줌 &lt;/span&gt;
p &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;exp&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;logL&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#log를 exp 씌워주면 일반 확률로 변환됨 &lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\nProbability of [Walk, Clean, Shop] = %.4f%s&quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;p&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;%&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Probability of [Walk, Clean, Shop] = 3.1038%&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h4 id=&quot;code-classlanguage-textviterbi-알고리즘code&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#code-classlanguage-textviterbi-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98code&quot; aria-label=&quot;code classlanguage textviterbi 알고리즘code permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code class=&quot;language-text&quot;&gt;Viterbi 알고리즘&lt;/code&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Decoding Question 에서 활용&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;초기 확률(초기 상태)&lt;/code&gt;, &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Transition 확률(천이확률)&lt;/code&gt;, &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Emission 확률(출력확률)&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;관측 데이터 시퀀스(X)&lt;/code&gt;가 주어졌을 때, &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;히든 상태의 시퀀스(Z)&lt;/code&gt;&lt;/strong&gt; 을    &lt;code class=&quot;language-text&quot;&gt;Viterbi decoding 알고리즘&lt;/code&gt;으로 계산(추정)한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Forward알고리즘은 &apos;확률&apos; 계산이고, Viterbi decoding 알고리즘은 &apos;시퀀스&apos; 추정임&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;token keyword&quot;&gt;as&lt;/span&gt; np
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; hmmlearn &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; hmm&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;히든 상태 정의&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;states &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Rainy&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Sunny&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
nState &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;states&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;관측 데이터 정의&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;observations &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Walk&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Shop&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Clean&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# nObervation = len(observations)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;HMM 모델 빌드&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; hmm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;MultinomialHMM&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;n_components&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;nState&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# n_components = 2개 &lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;startprob_ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 초기확률(상태)&lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;transmat_ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 천이확률 Transition &lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;emissionprob_ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 출력확률 Emission&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt; Multinomial(다항분포): 여러 개의 값을 가질 수 있는 독립 확률변수들에 대한 확률분포&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;X&lt;/code&gt;: 관측 데이터 시퀀스(Observations Sequence) &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&apos;&apos;이렇게 X가 나오도록 Z 값&apos;&apos; 계산하라 中 &lt;code class=&quot;language-text&quot;&gt;이렇게 X가 나오도록&lt;/code&gt; 담당 &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;X &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;T &lt;span class=&quot;token comment&quot;&gt;# walk -&gt; clean -&gt; shop -&gt; walk&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Viterbi 알고리즘&lt;/code&gt;: &lt;code class=&quot;language-text&quot;&gt;&amp;#39;.decode( , algorithm=&amp;quot;viterbi&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Z가 관측될 likely probability(가능성, 확률) 계산&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;logprob&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Z &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;decode&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; algorithm&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;viterbi&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 여기서 Z는 Z가 될 확률값&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;결과 출력&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\n  Obervation Sequence :&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;join&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; observations&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; X&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Hidden State Sequence :&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;join&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; states&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Probability = %.6f&quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;exp&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;logprob&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Obervation Sequence : Walk, Walk, Shop, Shop, Walk, Walk, Walk, Walk, Walk, Walk, Walk, Clean, Walk, ...&lt;/p&gt;
&lt;p&gt;Hidden State Sequence : Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Sunny, Rainy, ...&lt;/p&gt;
&lt;p&gt;Probability = 0.000000&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h4 id=&quot;code-classlanguage-textbaum-welch-알고리즘code&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#code-classlanguage-textbaum-welch-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98code&quot; aria-label=&quot;code classlanguage textbaum welch 알고리즘code permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code class=&quot;language-text&quot;&gt;Baum Welch 알고리즘&lt;/code&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;X만 주어진 경우: &lt;code class=&quot;language-text&quot;&gt;Learning Question&lt;/code&gt; 문제&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;초기 확률(초기 상태)&lt;/code&gt;, &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Transition 확률(천이확률)&lt;/code&gt;, &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Emission 확률(출력확률)&lt;/code&gt;을 추정,&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; 1-3 까지 &lt;code class=&quot;language-text&quot;&gt;Baum Welch 알고리즘&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&quot;4&quot;&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;히든 데이터 시퀀스(Z)&lt;/code&gt;까지 찾아낸다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; 4는 &lt;code class=&quot;language-text&quot;&gt;Viterbi 알고리즘&lt;/code&gt;까지 쓴다면&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;활용: 어떤 사람의 행위를 통해 초기 상태와 천이 확률, 그리고 출력 확률을 먼저 추정한 후 Z를 추정한다 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;관찰만으로 전부 추정하는 알고리즘 &lt;/li&gt;
&lt;li&gt;아래 code 내에선 정확도도 꽤 괜찮은 편&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;token keyword&quot;&gt;as&lt;/span&gt; np
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; hmmlearn &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; hmm
np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;set_printoptions&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;precision&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# np.set_printoptions: numpy float 출력옵션 변경. 소수점 몇자리까지만 보고 싶은 경우&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;나무랑 w(가중치) 세팅&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;nState &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;
pStart &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
pTran &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
pEmit &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;해당 code는 추후 &lt;code class=&quot;language-text&quot;&gt;Baum Welch&lt;/code&gt;을 통해 나온 결과값과의 정확도를 보기 위한 것으로, Data를 임의로 설정해주는 부분임에 유의&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;걍 가짜로 X data, Z data 만들어내는 부분&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;주어진 확률 분포대로 관측 데이터 시퀀스를 생성한다. &lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# 히든 상태 선택. 확률 = [0.6, 0.4]&lt;/span&gt;
s &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;argmax&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;multinomial&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; pStart&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# {1, pStart=[0.6, 0.4]} 3개 중 가장 큰 수(np.argmax) 따라서 s = 1&lt;/span&gt;
X &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;      &lt;span class=&quot;token comment&quot;&gt;# Obervation 시퀀스&lt;/span&gt;
Z &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;      &lt;span class=&quot;token comment&quot;&gt;# 히든 상태 시퀀스&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;# Walk, Shop, Clean ?&lt;/span&gt;
    a &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;argmax&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;multinomial&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; pEmit&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;s&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# pEmit[s] = [0.6, 0.3, 0.1]&lt;/span&gt;
    X&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;append&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;a&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    Z&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;append&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;s&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;token comment&quot;&gt;# 히든 상태 천이&lt;/span&gt;
    s &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;argmax&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;multinomial&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; pTran&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;s&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

X &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
X &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;reshape&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
Z &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;따라서 현재는 X만 아는 상태 &lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Q. Z는 왜 만드는 것?? 바움 알고리즘은 X만 가지고 예측하는 건데???
A: 지금 있는 기본 data x랑 나중에 model 만든 거를 합치면 predict z가 나오는데(yHat) 그거랑 찐 z랑 비교하려고&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Forward 알고리즘&lt;/code&gt; -&gt; &lt;code class=&quot;language-text&quot;&gt;Baum Welch 알고리즘&lt;/code&gt; 사용&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1) &lt;code class=&quot;language-text&quot;&gt;Forward 알고리즘&lt;/code&gt; 활용: Observation 시퀀스만을 이용하여, 초기 확률, Transition, Emmision 확률을 추정한다&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;zHat &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;zeros&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
minprob &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;999999999&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#3의 큰 수로 줘버림&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; k &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; hmm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;MultinomialHMM&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;n_components&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;nState&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; tol&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; n_iter&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
  model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 가짜 data인 x로 학습(fit)&lt;/span&gt;
  predZ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;predict&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
  logprob &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;score&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# forword 알고리즘 # 원래 값이 음수가 나와서 앞에 &apos;-&apos; 붙여줌으로서 양수로 변환&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;logprob = -6349.458034174618&lt;/p&gt;
&lt;p&gt;**EM 알고리즘은 local optimum에 빠질 수 있으므로, 5번 반복하여 로그 우도값이 가장 작은 결과를 채택한다.
(그게 가장 큰 결과가 되니까 작은 결과 채택).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;Step 2) &lt;code class=&quot;language-text&quot;&gt;Baum Welch 알고리즘&lt;/code&gt; 활용 : Z를 추정&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;Viterbi 알고리즘&lt;/code&gt; 과의 차이점: &lt;code class=&quot;language-text&quot;&gt;Baum Welch 알고리즘&lt;/code&gt;는 사전에 주어진 게 X 밖에 없음&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; logprob &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; minprob&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
      zHat &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; predZ
      T &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;transmat_
      E &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;emissionprob_
      minprob &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; logprob
  &lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;k = %d, logprob = %.2f&quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;k&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; logprob&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;k = 4, logprob = -6349.46&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;찐 Data 세팅 단계&lt;/code&gt;에서 생성한 &lt;code class=&quot;language-text&quot;&gt;Z&lt;/code&gt;와 위 알고리즘들을 통해 추정한 &lt;code class=&quot;language-text&quot;&gt;zHat&lt;/code&gt;의 &lt;strong&gt;정확도를 측정&lt;/strong&gt;한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;accuracy &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Z &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; zHat&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; accuracy &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 정확도가 0.5보다 작다면 순서를 바꿔주는 부분 &lt;/span&gt;
    T &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fliplr&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;flipud&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;T&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# np.fliplr: 좌우 순서 변경&lt;/span&gt;
    E &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;flipud&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;E&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# np.flipud: 상하 순서 변경&lt;/span&gt;
    zHat &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; zHat
    &lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;flipped&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    
accuracy &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Z &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; zHat&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Z&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\naccuracy = %.2f %s&quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;accuracy &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;%&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;accuracy = 76.78 %&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;추정 결과를 출력한다&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\nlog prob = %.2f&quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; minprob&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\nstart prob :\n&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;startprob_&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\ntrans prob :\n&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;T&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\nemiss prob :\n&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; E&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\niteration = &quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;monitor_&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;log prob = 5339.32&lt;/li&gt;
&lt;li&gt;start prob :
[6.93e-72 1.00e+00]&lt;/li&gt;
&lt;li&gt;trans prob :
[[0.74 0.26]
[0.15 0.85]]&lt;/li&gt;
&lt;li&gt;emiss prob :
[[0.11 0.41 0.48]
[0.58 0.3  0.12]]&lt;/li&gt;
&lt;li&gt;iteration =  246&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;model.monitor&lt;em&gt;.iter: for문 몇 번 돌렸단 뜻. 여기서 위에 &quot;model = hmm.MultinomialHMM(n&lt;/em&gt;components=nState, tol=0.0001, &lt;strong&gt;n_iter=10000&lt;/strong&gt;)&quot; 라 설정했는데 model.monitor.iter가 10000이라 뜨면 값을 못 찾았다는 거라 20000정도로도 늘려보아야 함 &lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;hmm-참고&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#hmm-%EC%B0%B8%EA%B3%A0&quot; aria-label=&quot;hmm 참고 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HMM 참고&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Bigram POS tagging과 시험 데이터를 이용한 평가.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;trade-off between accuracy and coverage&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Bigram에서는 만약 NNS VBG 시퀀스가 학습 데이터에 없다면,&lt;/li&gt;
&lt;li&gt;P(VBG|NNS)=0, &lt;code class=&quot;language-text&quot;&gt;*해석: VBG 안에 NNS가 없음&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;sparse problem 이므로&lt;/li&gt;
&lt;li&gt;그 이후의 모든 시퀀스에 악영향을 미쳐 평가 결과가 낮다.&lt;/li&gt;
&lt;li&gt;N-gram의 N이 클수록 accuracy는 낮지만 문맥의 coverage는 좋다.  따라서 학습용 데이터를 늘리면 약간 개선되기는 함.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;N-Gram tagging - Combining Tagger (Backoff Tagger)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bigram tagging을 시도하고 P(tag2 | tag1) = 0 (tag1 tag2 시퀀스가 없으면)이면, Unigram을 적용한다 P(tag2).&lt;/li&gt;
&lt;li&gt;만약 이것도 없으면 default tag를 적용한다. &lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;t0 &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;DefaultTagger&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;NN&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
t1 &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;UnigramTagger&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_sents&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; backoff &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; t0&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
t2 &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;BigramTagger&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_sents&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; backoff &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; t1&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
t2&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;evaluate&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;test_sents&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;참고 : &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;nltk.pos_tag()&lt;/code&gt;&lt;/strong&gt;는 PerceptronTagger로 Penn Treebank (Wall Street Journal) &lt;strong&gt;데이터를 사전에 학습&lt;/strong&gt;해 놓은 것을 사용한다. &lt;/p&gt;
&lt;p&gt;반면에 UngramTagger나 BigramTagger는 사전에 학습해 놓은 것을 사용하는 것이 아니라 직접 학습해서 사용하는 것이다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;품사 태깅 : N-Gram tagging - Unknown word&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tagger가 학습 데이터에서 경험하지 못한 단어를 보면 어떻게 태깅해야 하나?&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;text &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;I go to school in the klaldkf&quot;&lt;/span&gt; 
token &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; text&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;split&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;unigram_tagger&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;tag&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;token&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;[(&apos;I&apos;, &apos;PPSS&apos;), (&apos;go&apos;, &apos;VB&apos;), (&apos;to&apos;, &apos;TO&apos;), (&apos;school&apos;, &apos;NN&apos;), (&apos;in&apos;, &apos;IN&apos;), (&apos;the&apos;, &apos;AT&apos;), (&apos;klaldkf&apos;, None)]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bigram_tagger&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;tag&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;token&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;[(&apos;I&apos;, &apos;PPSS&apos;), (&apos;go&apos;, &apos;VB&apos;), (&apos;to&apos;, &apos;TO&apos;), &lt;strong&gt;(&apos;school&apos;, None), (&apos;in&apos;, None), (&apos;the&apos;, None), (&apos;klaldkf&apos;, None)&lt;/strong&gt;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;pos_tag&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;token&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;[(&apos;I&apos;, &apos;PRP&apos;), (&apos;go&apos;, &apos;VBP&apos;), (&apos;to&apos;, &apos;TO&apos;), (&apos;school&apos;, &apos;NN&apos;), (&apos;in&apos;, &apos;IN&apos;), (&apos;the&apos;, &apos;DT&apos;), (&apos;klaldkf&apos;, &apos;NN&apos;)]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Unigram Tagger&lt;/code&gt;는 unknown word에만 영향을 미침. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-text&quot;&gt;Bigram Tagger&lt;/code&gt;&lt;/strong&gt;는 unknown word가 다른 단어에도 영향을 미침.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;nltk.pos_tag()&lt;/code&gt;는 unknown word를 명사로 태깅하고 있음.&lt;/li&gt;
&lt;li&gt;단, &lt;code class=&quot;language-text&quot;&gt;Unigram과 Bigram&lt;/code&gt;은 충분한 데이터로 학습한 결과가 아니며, &lt;code class=&quot;language-text&quot;&gt;nltk.pos_tag()&lt;/code&gt;은 충분한 데이터로 사전에 학습된 것임.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;시험 데이터로 태깅 성능을 측정할 때는 &lt;code class=&quot;language-text&quot;&gt;nltk.ConfusionMatrix&lt;/code&gt;를 이용한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Confusion Matrix &lt;/span&gt;
test_tags &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;tag &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; sent &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; brown&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;sents&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;categories&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;editorial&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;word&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; tag&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; t2&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;tag&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sent&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; 
gold_tags &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;tag &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;word&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; tag&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; brown&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;tagged_words&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;categories&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;editorial&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; 
cm &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nltk&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;ConfusionMatrix&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;gold_tags&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_tags&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
cm&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;NN&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;NN&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;cm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;pretty_format&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;truncate&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; sort_by_count&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;참고: &lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;아마추어 퀀트, blog.naver.com/chunjein&lt;/li&gt;
&lt;li&gt;코드 출처: 크리슈나 바브사 외. 2019.01.31. 자연어 처리 쿡북 with 파이썬 [파이썬으로 NLP를 구현하는 60여 가지 레시피]. 에이콘&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[딥러닝 LSTM&CNN]]></title><description><![CDATA[딥러닝 DL RNN CNN 순환 신경망(RNN) hidden 층에서 서로 값을 기억해 순환한다. 지금까진 FNN(feed forward neword) + 순서가 필요 없는 data를 써서 모델이 기억할 필요가 없었지만, 문장 같은 data…]]></description><link>https://jynee.github.io/tags#1st/딥러닝_2/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/딥러닝_2/</guid><pubDate>Tue, 14 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;딥러닝-dl&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%94%A5%EB%9F%AC%EB%8B%9D-dl&quot; aria-label=&quot;딥러닝 dl permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;딥러닝 DL&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;RNN&lt;/li&gt;
&lt;li&gt;CNN&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;순환-신경망rnn&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%88%9C%ED%99%98-%EC%8B%A0%EA%B2%BD%EB%A7%9Drnn&quot; aria-label=&quot;순환 신경망rnn permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;순환 신경망(RNN)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;hidden 층에서 서로 값을 기억해 순환한다.&lt;/li&gt;
&lt;li&gt;지금까진 FNN(feed forward neword) + 순서가 필요 없는 data를 써서 모델이 기억할 필요가 없었지만, 문장 같은 data를 쓸 땐 &lt;strong&gt;순서가 중요한 data(Sequence Data)를 가지고 미래를 예측해야 한다.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;학습(트레이닝) 방법: 순서가 있는 data를 모델이 ‘기억’하게 만드는 것&lt;/li&gt;
&lt;li&gt;RNN 기본 입력은 3d 형태. D1=time, d2=feature, d0=data&lt;/li&gt;
&lt;li&gt;RNN 문제점: 기울기 소실 문제(vanishing gradient)가 FFN보다 더 심해짐&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&quot;lstm&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#lstm&quot; aria-label=&quot;lstm permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LSTM&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;RNN의 vanishing gradient 해결을 위해 고안. C 추가&lt;br&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;f와 i의 가중평균 형태&lt;br&gt;&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;batch&quot;&gt;&lt;pre class=&quot;language-batch&quot;&gt;&lt;code class=&quot;language-batch&quot;&gt;&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;f&lt;/span&gt;: forget date. 이전의 C를 얼마나 반영할 것인지 조절&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;i&lt;/span&gt;: input or ignore. 현재 입력값(x&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;과 이전의 출력값&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;h&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;를 얼마나 반영할 것인지 조절

* h는 위, 왼쪽 / c는 왼쪽으로 전파. 둘다 처음엔 0으로 시작함&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;GRU: LSTM 구조를 간결하게 만듦. 속도도 더 빠르지만 성능도 안 떨어짐 &lt;br&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;학습 유형: 단방향(FNN,BFN) / 양방향(FNN+BFN) 모두 적용 가능.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 572px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/1fd151e537c9dbae72645f58985cffd3/a805e/image-20200816004535796.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 31.08108108108108%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAABTklEQVQY0yWRic7aMBCEef9Xq0T+ltAAIYdz2jkIgRAgB1/X1JJljz2amd3dlGVJGMVM05umbTmdA+JYYZcxWu4x2pgvfr1epGnCOQhJ0oxlXRmf4xfbbaqKTdMNhHkv9A9x0eMcG/ZBy3uamN4v+tuDc3plnmcew4PbfcQNLvwIL9VXEXyyO1/47bfk1Y1N23WovBC9D7mp8MTJV4kknmkuNWmRooqSZV6oGkOhc46R4m8QUUlFTxH8jyVh09iENYmJbEBxSNiFW47JnmVZCAsf5/RL/kM+60fePf6EjpwubuSg24JxHDkI3sc/X7zpxaVSilWKbrOUWmuufS8JJ6o4Ijt41IliFoMyCMgFGxVzkcqGYWB8DBT+idzz6GwP+7qmjSIbkM4SZQC2L9M8Ufs+meN8/1dh6MOBbLulEWzF7JDG+x3tupS7HZ0M+B8z5r8n/iUOUQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;image-20200816004535796&quot;
        title=&quot;image-20200816004535796&quot;
        src=&quot;/static/1fd151e537c9dbae72645f58985cffd3/a805e/image-20200816004535796.png&quot;
        srcset=&quot;/static/1fd151e537c9dbae72645f58985cffd3/12f09/image-20200816004535796.png 148w,
/static/1fd151e537c9dbae72645f58985cffd3/e4a3f/image-20200816004535796.png 295w,
/static/1fd151e537c9dbae72645f58985cffd3/a805e/image-20200816004535796.png 572w&quot;
        sizes=&quot;(max-width: 572px) 100vw, 572px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Many to one: 둘다 정보량이 TIME이 증가할수록 높아진다. 따라서 높은 정보량끼리 마지막에 합친다&lt;/li&gt;
&lt;li&gt;Many to many&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;FNN 정보량이 TIME이 증가할수록 높아진다. &lt;/p&gt;
&lt;p&gt;BFN 정보량이 TIME이 증가할수록 낮아진다.&lt;/p&gt;
&lt;p&gt;따라서 각 뉴런에서 latent layer로 이어지는 정보량(마지막에 FNN정보량+BFN정보량)은 같다&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;One to many&lt;/li&gt;
&lt;li&gt;Many to many&lt;br&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;단방향은 ‘이후’만 기억, 양방향은 ‘이전’+’이후’ 모두 기억&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;어떻게? 단방향은 FBN만 사용, 양방향은 FBN+BFN 사용하기 떄문.&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;양방향(FNN+BFN) 진행 순서: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;모델(code)에서(RNN층 내) FNN 진행 후 정보량 모아두고, &lt;/li&gt;
&lt;li&gt;BFN 진행 후 정보량 모아두고,&lt;/li&gt;
&lt;li&gt;CONCAT(합침)해서 &lt;/li&gt;
&lt;li&gt;error를 역전파 시킴 &lt;br&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;FNN VS BFN:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FNN : TIME이 낮-&gt;높&lt;/li&gt;
&lt;li&gt;BFN : TIME이 높-&gt;낮&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;cnn&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#cnn&quot; aria-label=&quot;cnn permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CNN&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;사람의 시각인지 과정을 모방해서 피드포워드 신경망에 추가&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이미지를 분류한다 치면, 이미지의 부분적 특성에 주목해 분류하여 FFN에 넣는 것 &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이미지 분석에 활용: 이미지를 대표할 수 있는 특성들을 도출해서 신경망에 넣어준다.&lt;/p&gt;
&lt;br&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;순서 &lt;/p&gt;
&lt;p&gt;특성 추출 → 클래스 분류
→ &lt;strong&gt;컨볼루션&lt;/strong&gt; 또는 필터링 과정
→ &lt;strong&gt;특성지도&lt;/strong&gt; 출력
→ 서브샘플링(subsampling) 또는 &lt;strong&gt;풀링&lt;/strong&gt;(pooling)
→ 다시 컨볼루션, 활성화, 서브샘플링을 수행
→ 최종 특성지도는 피드포워드 신경망에 입력되어 분류 작업을 시행&lt;br&gt;&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;batch&quot;&gt;&lt;pre class=&quot;language-batch&quot;&gt;&lt;code class=&quot;language-batch&quot;&gt;컨볼루션: 
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;image&lt;/span&gt; data의 경우&lt;/span&gt;
→ filter&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;kernel&lt;/span&gt;: image data와의 convolution(cross-correlation&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 진행&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
→ feature map 생성&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;기호에 따라 zero padding, ReLU와 같은 활성함수 적용 가능&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
→ &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;token parameter attr-name&quot;&gt;/mean&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; pooling 
→ feature map 생성&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;출력&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
→ flatten&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;: 1D구조로 만듦&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; 
→ FNN&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;ol&gt;
&lt;li&gt;입력된 이미지로부터 이미지의 고유한 특징을 부각시킨 특성지도(feature map)를 새로 만듦&lt;/li&gt;
&lt;li&gt;그 이미지는 피드포워드 신경망에 입력되어 이미지가 어떤 클래스 라벨에 속하는지 분류&lt;/li&gt;
&lt;li&gt;학습: (grid serch) 수평 엣지 필터, 수직 엣지 필터 컨볼루션&lt;/li&gt;
&lt;li&gt;ReLU와 같은 활성함수를 거쳐 특성지도 출력&lt;/li&gt;
&lt;li&gt;서브샘플링(subsampling) 또는 풀링(pooling) 통해 활성화된 특성지도들의 크기를 줄임&lt;/li&gt;
&lt;li&gt;(저차원적인 특성부터 시작해서 고차원적인 특성을 도출)이 특성지도들에 다시 컨볼루션, 활성화, 서브샘플링을 수행하여 로컬한 특성지도로부터 글로벌한 특성지도를 만들어간다.&lt;/li&gt;
&lt;li&gt;이 과정을 여러번 반복하여 얻어진 최종 특성지도는 fully-connected layer, 즉 피드포워드 신경망에 입력되어 분류 작업을 시행&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;용어&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;feature map&lt;/code&gt;: 이미지의 부분적 특징을 모아놓은 것의 집합&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;padding&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;convolution layer&lt;/code&gt;: convolution(cross-correlation) 진행되는 곳 &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;upsampling&lt;/code&gt;: pooling layer와 달리 차원을 줄이는 게 아니라 차원을 늘림. Autoencoder의 decoder와 같은 곳에서 원래 데이터로 복원할 때 사용됨. Zero padding은 가생이를 0으로 채우는데 sampling은 무슨 계산을 해서 채우는 듯하다.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&quot;코딩-용어-설명&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%BD%94%EB%94%A9-%EC%9A%A9%EC%96%B4-%EC%84%A4%EB%AA%85&quot; aria-label=&quot;코딩 용어 설명 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;코딩 용어 설명&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;컨볼루션 레이어 단계&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Filters&lt;/code&gt;: 출력 모양의 깊이(depth) 를 결정&lt;br&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;kernel_size&lt;/code&gt;: &lt;/li&gt;
&lt;li&gt;w(연결선, 가중치)이자, filter의 size.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;연산을 수행할 때 윈도우의 크기&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2D에서 kernel_size=(8,1)이면 8행+1열(이때 1열은 feature)&lt;/li&gt;
&lt;li&gt;1D에서 kernel_sizw=8이면 자동 8행+전체열(1D에서 필터는 아래 방향으로 밖에 이동 못함)&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;strides&lt;/code&gt;: 필터 적용 시 한 번에 얼마나 움직일지(이동 크기) 이동할 칸 수. 보통 1을 씀. &lt;br&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;padding&lt;/code&gt;: &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;컨볼루션 레이어(합성곱) 혹은 풀링 연산을 수행하는 레이어에 파라미터로 설정&lt;/p&gt;
&lt;p&gt;convolution과 pooling 연산은 파라미터의 수를 줄여나가는 과정이다. 하지만 이러한 과정에서 지나치게 데이터가 축소되어 정보가 소실되는 것을 방지하기 위해 데이터에 0으로 이루어진 패딩을 주는 경우가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;‘원본’(사이즈)을 조정. filter를 거치면 이미지 사이즈가 원본과 달리 작아지는데, 이를 피하기 위해 작아지는 사이즈가 원본 사이즈만큼 되도록 원본 사이즈 크기를 늘림. 이때, Zero padding 기법을 사용. 수치(?)가 없는 부분 즉, 가생이(모서리)을 ‘0’으로 채움(가생이 아니고 중간 부분 채워도 zero-padding)&lt;br&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;padding = &amp;#39;same&amp;#39;&lt;/code&gt;: 원본 사이즈 유지시킴(차원 유지)&lt;/li&gt;
&lt;li&gt;원리: 필터의 사이즈가 k이면 사방으로 k/2 만큼의 패딩을 준다.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;padding = &amp;#39;valid&amp;#39;&lt;/code&gt;: 패딩 사용하지 않음 &lt;br&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;activation: ‘ReLu’&lt;/code&gt;가 default. CNN에선 ReLu 사용을 권장한다고 함 &lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;pooling&lt;/code&gt; 단계&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;원본이미지에서 특징 추출해서 feature map의 크기를 줄여주는 과정. &lt;/li&gt;
&lt;li&gt;(1) Max pooling, (2) mean pooling이 있음 &lt;/li&gt;
&lt;li&gt;pool&lt;em&gt;size: strides가 미리 설정되지 않을 경우 pool&lt;/em&gt;size와 동일하게 설정된다. &lt;br&gt;&lt;/li&gt;
&lt;li&gt;strides&lt;/li&gt;
&lt;li&gt;padding&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Flatten&lt;/code&gt; 단계&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flatten&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;output&lt;/code&gt; 단계&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dense(n, activation = )&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
 &lt;br&gt;
&lt;h2 id=&quot;차원-참고&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%B0%A8%EC%9B%90-%EC%B0%B8%EA%B3%A0&quot; aria-label=&quot;차원 참고 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;차원 참고&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1차원 벡터: shape(2,)&lt;/li&gt;
&lt;li&gt;2차원 Matrix : shape(행,열)&lt;/li&gt;
&lt;li&gt;3차원: shape(면, 행, 열) = D0, D1, D2&lt;/li&gt;
&lt;li&gt;4차원: shape (samples, rows, cols, channels) = D0, D1, D2 ,D3 &lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
&lt;br&gt;
 &lt;br&gt;
&lt;br&gt;
&lt;blockquote&gt;
&lt;p&gt;참고: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;아마퀀트. 2019. 7. 19. &quot;Keras LSTM** 유형 정리 (2/5) – 단층-단방향 &amp;#x26; many-to-many 유형&quot;. &lt;a href=&quot;http://blog.naver.com/chunjein/221589624838&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://blog.naver.com/chunjein/221589624838&lt;/a&gt;. 아마추어 퀀트 (Amateur Quant).&lt;/li&gt;
&lt;li&gt;chrisysl. 2018. 9. 10. &quot;3. Convolutional Networks / L2. Convolutional Neural Networks - Convolutional Layers in Keras&quot;. &lt;a href=&quot;https://kevinthegrey.tistory.com/141&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://kevinthegrey.tistory.com/141&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;심교훈. 2019. 3. 1. &quot;딥러닝 알고리즘의 대세, 컨볼루션 신경망(convolutional neural network, CNN)&quot;. &lt;a href=&quot;https://bskyvision.com/412?category=635506b&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://bskyvision.com/412?category=635506b&lt;/a&gt;. 스카이비전&lt;/li&gt;
&lt;li&gt;Seongyun Byeon. 2018.01.23. 딥러닝에서 사용되는 여러 유형의 Convolution 소개&quot;. &lt;a href=&quot;https://zzsza.github.io/data/2018/02/23/introduction-convolution/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://zzsza.github.io/data/2018/02/23/introduction-convolution/&lt;/a&gt;. 어쩐지 오늘은&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;</content:encoded></item><item><title><![CDATA[딥러닝 기초]]></title><description><![CDATA[딥러닝 DL optimaizer kerass optimizers 이차방정식 계수 추정 방법들: : 움직임  : 미분해서 움직임 : 지수이동평균법으로 움직임 : 관성 방향으로 이동 후 그 지점에서 GD 방향으로 움직임  가중치(알파 or lr…]]></description><link>https://jynee.github.io/tags#1st/딥러닝_1/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/딥러닝_1/</guid><pubDate>Fri, 03 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;딥러닝-dl&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%94%A5%EB%9F%AC%EB%8B%9D-dl&quot; aria-label=&quot;딥러닝 dl permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;딥러닝 DL&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;optimaizer&lt;/li&gt;
&lt;li&gt;kerass&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;optimizers&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#optimizers&quot; aria-label=&quot;optimizers permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;optimizers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이차방정식 계수 추정 방법들:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;SGD&lt;/code&gt;: 움직임&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;GD&lt;/code&gt; : 미분해서 움직임&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;momentum&lt;/code&gt;: 지수이동평균법으로 움직임&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;NAG&lt;/code&gt;: 관성 방향으로 이동 후 그 지점에서 GD 방향으로 움직임 &lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;가중치(알파 or lr) 조정 알고리즘&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Adagrad&lt;/code&gt;: 업데이트 多~작은 알파 / 업데이트 小~큰 알파&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;RMSprop&lt;/code&gt;: Adagrad에서 반복할수록 과도하게 작아진다는 알파값 보완 &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Adadelta&lt;/code&gt;: RMSprop와 같은데 알파값이 자동조절됨&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Adam&lt;/code&gt;: RMSprop + momentum&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;keras&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#keras&quot; aria-label=&quot;keras permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Keras&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sequential 모델: &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;From tensorflow&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;keras&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;layes &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; Dense
From tensorflow&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;keras&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;models &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; Sequential
Model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Sequential&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#그래프 생성(모델 생성)&lt;/span&gt;
Model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;add&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; input_dim &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#layer(dense), 노드 1개, 그 노드에 2개가 들어온다고 알려줌&lt;/span&gt;
Model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;complile&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;loss&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;’mse’&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; optimizer&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;optimizers&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Adam&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;lr&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
Model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;dataX&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; epochs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#학습&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;더 간단한 모델: &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;From tensorflow&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;keras&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;layes &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Dense
From tensorflow&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;keras&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;models &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; Model
xInput &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;batch_shape&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#그래프 생성(모델 생성)&lt;/span&gt;
yInput &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;xInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;xInput&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; yOutput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#xinput 들어가서 yinput나오는 model&lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;complie&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;loss&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;’mse’&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; optimizer&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;optimizers&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Adam&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;lr&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;dataX&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;y&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;epochs&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#학습&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;잔차 계산 방법들:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Stochastic GD update: 그때그때 error 계산, a, b, c 업데이트&lt;/li&gt;
&lt;li&gt;Batch update: 한꺼번에 error 계산하고 a, b , c 업뎃&lt;/li&gt;
&lt;li&gt;Mini-batch update: 일부 error 계산하고 그때마다 a, b, c 를 업데이트. Stochastic GD update, Batch update의 중간 특성&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Model 의 기본적인 code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;.fit&lt;/code&gt; : train data를 만들어둔 model로 학습시킴&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;.predict&lt;/code&gt;: test data를 만들어둔 model로 궁예해봄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
 &lt;br&gt;
&lt;br&gt;
&lt;br&gt;</content:encoded></item><item><title><![CDATA[머신러닝 분석 방법들, 두 번째]]></title><description><![CDATA[머신러닝(ML) K-Means 클러스터링 H-clustering DBSAN 앙상블 연관규칙 분석 k-means 클러스터링 비지도학습 비계층적 군집분석 k-means 클러스터링은 데이터를 k개의 클러스터(cluster…]]></description><link>https://jynee.github.io/tags#1st/머신러닝_2/</link><guid isPermaLink="false">https://jynee.github.io/tags#1st/머신러닝_2/</guid><pubDate>Tue, 30 Jun 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;머신러닝ml&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9Dml&quot; aria-label=&quot;머신러닝ml permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;머신러닝(ML)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;K-Means 클러스터링&lt;/li&gt;
&lt;li&gt;H-clustering&lt;/li&gt;
&lt;li&gt;DBSAN&lt;/li&gt;
&lt;li&gt;앙상블&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;연관규칙 분석&lt;/p&gt;
&lt;br&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&quot;k-means-클러스터링&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#k-means-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81&quot; aria-label=&quot;k means 클러스터링 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;k-means&lt;/strong&gt; 클러스터링&lt;/h2&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;Grid search&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; 
    Init &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ‘k&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;means&lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;’
    n_init&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;
    max_iter&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;300&lt;/span&gt;
    tol&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;le&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;04&lt;/span&gt;
    random_state&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;비지도학습&lt;/li&gt;
&lt;li&gt;비계층적 군집분석&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k-means 클러스터링은 데이터를 k개의 클러스터(cluster, 무리)로 분류&lt;/p&gt;
&lt;br&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;EM알고리즘&lt;/code&gt;: 중점을 할당한 후, 각 중점까지의 거리의 합을 최소화하는 알고리즘&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;알고리즘(작동 원리):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;사용자로부터 입력받은 k의 값에 따라, 임의로 클러스터 중심(centroid) k개를 설정해준다.&lt;/li&gt;
&lt;li&gt;k개의 클러스터 중심으로부터 모든 데이터가 얼마나 떨어져 있는지 계산한 후에, 가장 가까운 클러스터 중심을 각 데이터의 클러스터로 정해준다. &lt;/li&gt;
&lt;li&gt;각 클러스터에 속하는 데이터들의 &lt;strong&gt;평균&lt;/strong&gt;을 계산함으로 클러스터 중심을 &lt;strong&gt;옮겨준다&lt;/strong&gt;. &lt;/li&gt;
&lt;li&gt;보정된 클러스터 중심을 기준으로 2, 3단계를 반복한다.&lt;/li&gt;
&lt;li&gt;더이상 클러스터 중심이 이동하지 않으면 알고리즘을 종료한다. &lt;/li&gt;
&lt;/ol&gt;
 &lt;br&gt;
&lt;/li&gt;
&lt;li&gt;new data 입력(발생) 시엔 각 중점과의 거리만 비교해서 가장 가까운 곳에 있는 군집에 속한다고 파악&lt;/li&gt;
&lt;li&gt;초기값에 따라 전역이 아닌 지역 최소 값을 찾을 수 있음&lt;/li&gt;
&lt;li&gt;r에 따라 {0,1} 이면 명목형, 확률이면 연속형(GMM 모델)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;적합한 k 개수를 찾고 검증하는 모델들&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;k-means-elbow-method&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#k-means-elbow-method&quot; aria-label=&quot;k means elbow method permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;K-Means Elbow Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;“k는 얼마가 적합할까?” 적합한 k개수 찾는 성격인 듯하다.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Grid search: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;n_clusters 조절&lt;/li&gt;
&lt;li&gt;error: 군집 속 중점과의 거리의 합 &amp;#x3C;- 이라고 개념을 설정해두고(왜냐면 k-means는 비지도학습이라 정답이 없어서 label이나 target, class 등이 없어서 확인 못함) 군집화가 잘 된 경우라면 error가 작을 것.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;따라서 k가 증가할 때 줄어드는 ‘폭’이 작아지는 지점의 k값이 최적 군집 개수&lt;/li&gt;
&lt;li&gt;거리의 합 != 거리가 줄어드는 폭.&lt;/li&gt;
&lt;li&gt;엘보우는 거리가 줄어드는 폭을 봄&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;실루엣silhouette&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%8B%A4%EB%A3%A8%EC%97%A3silhouette&quot; aria-label=&quot;실루엣silhouette permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;실루엣(Silhouette)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;“군집화가 잘 됐나?” &amp;#x3C;- 약간 검증하는 성격인 듯하다.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;잘 된 군집화: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;군집 간 거리(b) &gt; 군집 내 거리(a) &lt;/li&gt;
&lt;li&gt;cohesion(응집도:군집 내) &amp;#x3C; separation(분리도:군집 간) &lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;실루엣 계수는 원형 군집이 아닌 경우 잘 맞지 않음&lt;/li&gt;
&lt;li&gt;0~1값을 가짐&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&quot;k-means군집clustering&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#k-means%EA%B5%B0%EC%A7%91clustering&quot; aria-label=&quot;k means군집clustering permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;K-Means++군집(clustering)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;local optimum 해결 위해 초기 중점을 좀 더 합리적으로 설정하는 방법&lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
 &lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;h-clustering&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#h-clustering&quot; aria-label=&quot;h clustering permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;H-clustering&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;계층적 군집분석&lt;/li&gt;
&lt;li&gt;덴드로그램&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k-menas 와의 차이점:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;k-means는 &lt;strong&gt;사전에 그룹수(k)&lt;/strong&gt; 결정, &lt;/li&gt;
&lt;li&gt;H-clutering은 한 개의 그룹이 남을 때까지 &lt;strong&gt;그룹을 다 나눈 후&lt;/strong&gt; 몇 개 선택할지 두 개의 feature를 갖는 2차원의 덴드로그램으로 결정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
 &lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;dbscan&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#dbscan&quot; aria-label=&quot;dbscan permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DBSCAN&lt;/h2&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;Grid search&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    eps &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.2&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 앱실론: 특정 ‘반경’&lt;/span&gt;
    min_samples&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 0.2 반경에 샘플 5개가 있어야 함&lt;/span&gt;
    metric &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ‘euclidean’&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;계층적 군집분석&lt;/li&gt;
&lt;li&gt;밀집도 기반의 군집 알고리즘: core point(핵심 샘플), border point(경계 샘플), noise point(잡음 샘플)&lt;/li&gt;
&lt;li&gt;noise point는 분류하지 않는다&lt;/li&gt;
&lt;li&gt;K-means or 다른 군집분석과의 차이점: 모든 샘플을 클러스터에 할당하지 않고 잡음 샘플을 구분하는 능력이 있다&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;앙상블-기법&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%95%99%EC%83%81%EB%B8%94-%EA%B8%B0%EB%B2%95&quot; aria-label=&quot;앙상블 기법 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;앙상블 기법&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;다수의 결과를 예측하여 종합하고 분류함&lt;/li&gt;
&lt;li&gt;여러 알고리즘을 사용한 후 결과를 종합하여 정확도, 일반화 특성을 증가시킴&lt;/li&gt;
&lt;li&gt;classification_report(~~)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;배깅bagging-or-bootstrap-aggregation&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%B0%B0%EA%B9%85bagging-or-bootstrap-aggregation&quot; aria-label=&quot;배깅bagging or bootstrap aggregation permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;배깅(Bagging or Bootstrap Aggregation)&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;BaggingClassifier&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; Hyper parameter &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    base_estimatior &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; m
    n_estimators &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;
    bootstrap &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; prob &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; bag&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;predict_proba&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;testX&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; predY &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;argmax&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;prob&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;token comment&quot;&gt;# axis=1 하는 이유: 안 하면 하나의 값인 int가 나와서 밑에 testY랑 mean하려면 array 형태로 나와야 함&lt;/span&gt;
&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; accuracy &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;testY &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; predY&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;mean&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;BootStrap(단순복원 임의추출)을 통해 샘플 뽑아내 서브 데이터 만듦&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;각각의 서브 데이터 크기 = 원본 훈련 데이터 크기 &lt;/li&gt;
&lt;li&gt;why? 데이터 중복 허용해서 분산(변동)이 감소하고 overfitting 방지&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;부스팅boosting-증폭-가속&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%B6%80%EC%8A%A4%ED%8C%85boosting-%EC%A6%9D%ED%8F%AD-%EA%B0%80%EC%86%8D&quot; aria-label=&quot;부스팅boosting 증폭 가속 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;부스팅(Boosting): 증폭, 가속.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;잘못 분류된 데이터에 가중치 두어 다시 뽑고 다시 분류하는 알고리즘&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;서브 훈련 샘플 만듦&lt;/li&gt;
&lt;li&gt;처음 샘플링은 가중치를 두어 샘플링함 -&gt; 분류 잘못된 데이터는 가중치 높이고 다시 샘플링. 이때 잘못 분류된 패턴이 선택될 확률이 높음. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; → 분류가 어려운 패턴에 더욱 집중하여 정확도를 높이는 방법&lt;/p&gt;
&lt;p&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;adaboostadaptive-boosting&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#adaboostadaptive-boosting&quot; aria-label=&quot;adaboostadaptive boosting permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AdaBoost(Adaptive Boosting)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;약한 분류기&lt;/strong&gt; 사용. 잘못 분류한 데이터 샘플에 가중치를 두어 더 많이 샘플링하여 정확도 높임&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;서브 데이터로만 만듦(잔차 등으로 만드는 거 아님)&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;AdaBoostClassifier&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
Hyper parameter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  base_estimator&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;svm
  n_estimators&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;#100번 재조합한단 뜻(오분류한 거에 가중치둬서)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4 id=&quot;gradient-boostingfor-regression&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#gradient-boostingfor-regression&quot; aria-label=&quot;gradient boostingfor regression permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gradient Boosting(for regression)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;target 데이터의 &lt;strong&gt;잔차&lt;/strong&gt;를 줄이도록 학습. 학습할수록 residual(잔차)가 계속 작아짐. 잔차가 더 이상 줄어들지 않을 떄까지 tree 생성하며 학습+추정치 업데이트&lt;/li&gt;
&lt;li&gt;residual 계산법 : 변수-(평균+학습률(알파. 0~1사이 값. 아무렇게나 줘도 됨. 보통 0.1)*tree의 leaf 평균&lt;/li&gt;
&lt;li&gt;선형회귀라 dataset도 연속형 변수인 boston 집값을 보도록 한다.&lt;/li&gt;
&lt;li&gt;선형회귀라 MSE 대신 r2 사용해도 OK&lt;/li&gt;
&lt;li&gt;MSE: 선형, 로지스틱 회귀 둘다 쓰여도 OK. 다만 선형에선 R2를, 로지스틱에선 BCE(바이너리일 떄) 더 잘 쓰임..(?)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;GradientBoostingRegressor&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
Hyper parameter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    Loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ‘ls’           	&lt;span class=&quot;token comment&quot;&gt;# lest square = MSE 사용&lt;/span&gt;
    Learning_rate &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;     &lt;span class=&quot;token comment&quot;&gt;# 알파. 가중치&lt;/span&gt;
    n_estimators &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;      &lt;span class=&quot;token comment&quot;&gt;# 잔차(tree) 100개 만들라&lt;/span&gt;
    max_depth&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt; 			&lt;span class=&quot;token comment&quot;&gt;# 얕은 depth&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4 id=&quot;gradient-boostingfor-classification&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#gradient-boostingfor-classification&quot; aria-label=&quot;gradient boostingfor classification permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gradient Boosting(for classification)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Regression과 동일하나, 추정치를 위해 odds, logs(odds), probability 개념 사용&lt;/li&gt;
&lt;li&gt;binary cross entropy(BCE)를 loss함수로 사용&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;GradientBoostingClassifier&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
Hyper parameter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ‘devianve’&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;      &lt;span class=&quot;token comment&quot;&gt;#로지스틱 함수 + CE 쓰라는 뜻&lt;/span&gt;
    learning_rate &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;     &lt;span class=&quot;token comment&quot;&gt;#학습률, 가중치, 알파값&lt;/span&gt;
    n_estimators&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;      &lt;span class=&quot;token comment&quot;&gt;#잔차(tree) 수&lt;/span&gt;
    max_depth&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4 id=&quot;xgboostextreme-gradient-boostingfor-regression&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#xgboostextreme-gradient-boostingfor-regression&quot; aria-label=&quot;xgboostextreme gradient boostingfor regression permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;XGBoost(Extreme Gradient Boosting)(for regression)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;정규화와 가지치기를 통해 &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;overfitting을 줄이고 &lt;/li&gt;
&lt;li&gt;일반화 특성을 좋게 만듦&lt;/li&gt;
&lt;li&gt;특히 대용량 data의 경우에 속도도 SOSO&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Similarity, output 값 사용: Similarity를 사용해서 잔차와 IG 계산하고 마지막에 output 계산해서 마지막 잔차 계산&lt;/li&gt;
&lt;li&gt;데이터 大 ~ similarity(유사도) 小 why? 상쇄되는 값이 많아서.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;py&quot;&gt;&lt;pre class=&quot;language-py&quot;&gt;&lt;code class=&quot;language-py&quot;&gt;XGBRegressor&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
Hyper parameter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; 
	Objective &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;’reg&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;squarederror’     &lt;span class=&quot;token comment&quot;&gt;#regression 사용하고 MSE 사용한단 뜻. regression이니 r2 사용&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4 id=&quot;xgboostextreme-gradient-boostingfor-classification&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#xgboostextreme-gradient-boostingfor-classification&quot; aria-label=&quot;xgboostextreme gradient boostingfor classification permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;XGBoost(Extreme Gradient Boosting)(for classification)&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;잔차 계산 시, output value를 사용한다는 데서 Gradient Boost랑 차이가 있음&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;Hyper parameter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;chapter &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; XGBClassifier&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; Objective &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;’binary&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;logistic’        &lt;span class=&quot;token comment&quot;&gt;#바이너리 변수고 logistic함수(sigmoid) 사용&lt;/span&gt;
    
&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;chapter &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; XGBClassifier&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; Param – &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;‘eta’ &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; 
  ‘max_depth’ &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; 
  ‘objective’ &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; ‘multi&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;softprob’      &lt;span class=&quot;token comment&quot;&gt;#softmas 사용한단 뜻&lt;/span&gt;
  ‘num_class’ &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;            		  &lt;span class=&quot;token comment&quot;&gt;#클래스 개수&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;랜덤포레스트random-forest&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8random-forest&quot; aria-label=&quot;랜덤포레스트random forest permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;랜덤포레스트(Random Forest)&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;RandomForestClassifier&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
Hyper parameter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    max_depth&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;
    estimaors&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;DT(Decision Tree)를 앙상블함 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;트리마다 서로 다른 feature 사용&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;샘플링 함&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;다수결-알고리즘majority-voting&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EB%8B%A4%EC%88%98%EA%B2%B0-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98majority-voting&quot; aria-label=&quot;다수결 알고리즘majority voting permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;다수결 알고리즘(Majority Voting)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;배깅/부스팅과의 차이점: 학습데이터를 서브data에 sampling 하느냐/안 하느냐&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;다수결 알고리즘은 배깅/부스팅처럼 서브데이터로 나눈 게 아니라 그 자체를 쓴다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;isolation-forestiforest&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#isolation-forestiforest&quot; aria-label=&quot;isolation forestiforest permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Isolation Forest(iForest):&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;Model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; IsolationForest
Hyper parameter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    n_estimators &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;   &lt;span class=&quot;token comment&quot;&gt;#100개의 트리&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;이상데이터 검출하는 알고리즘 (ex: 카드 불법 사용 색출에 활용)&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Keyword: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이진검색트리&lt;/li&gt;
&lt;li&gt;Anomaly score(이상치 수치)&lt;/li&gt;
&lt;li&gt;recall, precison 사용&lt;/li&gt;
&lt;li&gt;특히 recall 써서 실제 정상(T)인데 비정상(F)으로 예측했다던가, 실제 비정상(F)인데 정상(T)로 예측한 비율 찾아냄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
 &lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&quot;연관규칙-분석&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%97%B0%EA%B4%80%EA%B7%9C%EC%B9%99-%EB%B6%84%EC%84%9D&quot; aria-label=&quot;연관규칙 분석 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;연관규칙 분석&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;장바구니 분석. 고객들의 구매 성향을 분석할 수 있음&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;지지도: y가 독립변수인지 종속변수인지 불명확함&lt;/li&gt;
&lt;li&gt;신뢰도: y에 대한 영향을 무시한단 단점이 있음&lt;/li&gt;
&lt;li&gt;향상도: 1에 가까우면 X와 Y는 서로 독립적. 1보다 크면 양의 상관성, 1보다 작으면 음의 상관성. 리프트가 1보다 클수록 X→Y 규칙의 의미가 커짐&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;지지도/신뢰도/향상도 특징:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;인과관계가 아닌 상관관계&lt;/li&gt;
&lt;li&gt;얼마나 빈번하게 나타나는지 측정&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;이진행렬 구성&lt;/li&gt;
&lt;li&gt;지/신/향 모두 임계치 이상인 모든 규칙을 찾기엔 Brute Force 방식을 써서 조합이 너무 많아짐. 따라서 이 조합을 줄일 수 있는 알고리즘이 Apriori 알고리즘.&lt;/li&gt;
&lt;li&gt;항목을 줄이는 게 관건&lt;/li&gt;
&lt;li&gt;한 항목 집합이 반발하면, 그것의 모든 부분 집합이 반발한단 뜻에서 지지도 기반 가지치기&lt;/li&gt;
&lt;li&gt;연관성이 높다 = lift가 높다&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;Hyper parameter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    Frequent_itemsets &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; apriori&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; min_support &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; use_columname&lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# Item sparse matrix생성&lt;/span&gt;
    rules &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; association_rules&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;frequent_itemsets&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; metric&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;”lift”&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; min_threshold&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 모델 생성&lt;/span&gt;
    Rules &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; association_rules&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;by&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;‘lift&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;’&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ascendin&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# Lift가 작은 것부터 sort&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;blockquote&gt;
&lt;p&gt;참고: 심교훈. 2019. 10. 9. “가장 간단한 군집 알고리즘, k-means 클러스터링&quot;. &lt;a href=&quot;https://bskyvision.com/564&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://bskyvision.com/564&lt;/a&gt;. b스카이비전&lt;/p&gt;
&lt;/blockquote&gt;</content:encoded></item></channel></rss>