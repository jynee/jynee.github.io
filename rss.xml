<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[JyneeEarth | Feed]]></title><description><![CDATA[jynee's lab]]></description><link>https://jynee.github.io</link><generator>GatsbyJS</generator><lastBuildDate>Fri, 07 Aug 2020 06:41:50 GMT</lastBuildDate><item><title><![CDATA[TQT(The question I asked the teacher today)]]></title><description><![CDATA[Hyper parameter (annealing): epoch(alpha)를 처음에는 적당히 높게 했다가, 점차 줄여 나가는 방법 Dense : fully connected…]]></description><link>https://jynee.github.io/TQT(The question I asked the teacher today.)/</link><guid isPermaLink="false">https://jynee.github.io/TQT(The question I asked the teacher today.)/</guid><pubDate>Sat, 01 Aug 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;hyper-parameter&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#hyper-parameter&quot; aria-label=&quot;hyper parameter permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hyper parameter&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;weight decay&lt;/code&gt;(annealing): epoch(alpha)를 처음에는 적당히 높게 했다가, 점차 줄여 나가는 방법&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;dense&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#dense&quot; aria-label=&quot;dense permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dense&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt;: fully connected&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;ANN(FNN)&lt;/code&gt;에서는 여러 &lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt;를 써도 되지만, &lt;code class=&quot;language-text&quot;&gt;RNN(LSTM)&lt;/code&gt;에선 마지막 층에서만 &lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt;를 써야함.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;CNN&lt;/code&gt;에서는 여러 &lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt; 써도 될까?&lt;/li&gt;
&lt;li&gt;=&gt; 일단... &lt;code class=&quot;language-text&quot;&gt;lstm&lt;/code&gt;에서 &lt;code class=&quot;language-text&quot;&gt;lstm() → Dense → lstm()&lt;/code&gt;은 &lt;code class=&quot;language-text&quot;&gt;lstm 네트워크가 2개&lt;/code&gt; 만들어진다고 보면 된다. &lt;code class=&quot;language-text&quot;&gt;lstm() → Dense&lt;/code&gt; 했을 때, &lt;code class=&quot;language-text&quot;&gt;1개의 네트워크&lt;/code&gt;가 형성된 것&lt;/li&gt;
&lt;li&gt;=&gt; 그리고 &lt;code class=&quot;language-text&quot;&gt;CNN&lt;/code&gt;은 일종의 잘 짜여진 레시피라서 &lt;code class=&quot;language-text&quot;&gt;con1D → pooling → Dense → con1D → pooling&lt;/code&gt;은 위 &lt;code class=&quot;language-text&quot;&gt;lstm&lt;/code&gt;처럼 좀 이상한 네트워크 구조가 되는 거라 생각함...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dense(1, activation=&apos;sigmoid&apos;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSTM에서 FNN으로 보내는 마지막 Dense에선 relu 쓰면 안됨&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;fnn순방향-신경망&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#fnn%EC%88%9C%EB%B0%A9%ED%96%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D&quot; aria-label=&quot;fnn순방향 신경망 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FNN(순방향 신경망)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;↔ RNN&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;hidden 층에서&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dense(4, &lt;code class=&quot;language-text&quot;&gt;activation&lt;/code&gt; = &apos;sigmoid&apos;, &lt;code class=&quot;language-text&quot;&gt;kernel_regularizer&lt;/code&gt;=regularizers.l2(0.0001), activation=&apos;relu&apos;)&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Dropout&lt;/code&gt;(rate=0.5)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;BatchNormalization&lt;/code&gt;(momentum=0.9, epsilon=0.005, center=True, scale=True, moving&lt;em&gt;variance&lt;/em&gt;initializer=&apos;ones&apos;)&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;predict&lt;/code&gt;까지 끝낸 &lt;strong&gt;연속형&lt;/strong&gt; &lt;code class=&quot;language-text&quot;&gt;yHat&lt;/code&gt; 값을, &lt;code class=&quot;language-text&quot;&gt;np.where&lt;/code&gt; 써줘서 &lt;strong&gt;바이너리 형태&lt;/strong&gt;로 변환 &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;where&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;yHat &lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기_커스텀loss.py&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;history&lt;/code&gt; 활용&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;hist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;history&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;loss&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
hist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;history&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;val_loss&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# 딥러닝_파일: 4-4.ANN(Credit_Keras)_직접 해보기.py&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;학습/평가/예측용 model로 나누었을 때 &lt;strong&gt;평가 데이터 활용&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;trainX&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; trainY&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; validation_data&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;evlX&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; evlY&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; epochs&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; batch_size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;lstm&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#lstm&quot; aria-label=&quot;lstm permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LSTM&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;설명&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2층&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;lstm()&lt;/code&gt;을 2번 써준다&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;양방향&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;bidirectional&lt;/code&gt; + &lt;code class=&quot;language-text&quot;&gt;merge_mode = ‘concat’&lt;/code&gt; &lt;br /&gt;FNN, BFN 값을 merge_mode 형태로 합쳐서 list형으로 되돌려줌&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;many-to-many&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;return-sequences = True&lt;/code&gt;&lt;br /&gt;LSTM의 중간 스텝의 출력을 모두 사용&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;timedistributed&lt;/code&gt;&lt;br /&gt; FFN으로 가기 전 LSTM 마지막 층에서 각 뉴런의 각 지점에서 계산한 오류를 다음 층으로 전파&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;cnn&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#cnn&quot; aria-label=&quot;cnn permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CNN&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;이미지를 대표할 수 있는 특성들을 도출해서 FNN에 넣어줌&lt;/li&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;th&gt;설명&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;Input&lt;/code&gt;(batch_shape = (None, nStep, nFeature, nChannel))&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;Conv2D&lt;/code&gt;(filters=30, kernel_size=(8,3), strides=1, padding = &apos;same&apos;, activation=&apos;relu&apos;)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;MaxPooling2D&lt;/code&gt;(pool_size=(2,1), strides=1, padding=&apos;valid&apos;)&lt;/td&gt;
&lt;td&gt;- 경우에 따라 conv2D, pooling 더 써줄 수 있음&lt;br /&gt;- &lt;code class=&quot;language-text&quot;&gt;GlobalMaxPooling1D()&lt;/code&gt;도 있음&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;Flatten()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;2D는 4차원이라 shape 맞추려고 보통 flatten을 써줌&lt;br /&gt;1d는 안 써도 되는 듯(?)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;Dense&lt;/code&gt;(nOutput, activation=&apos;linear&apos;)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;lstm과-cnn의-차이&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#lstm%EA%B3%BC-cnn%EC%9D%98-%EC%B0%A8%EC%9D%B4&quot; aria-label=&quot;lstm과 cnn의 차이 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LSTM과 CNN의 차이&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;둘다 (흐름을 보는)시계열 데이터에 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;LSTM과 CNN1D는 기능은 비슷하지만 CNN1D는 table 中 &lt;strong&gt;(colum 전체+n row)아래 방향으로의 흐름&lt;/strong&gt;을 보는 거고, &lt;/li&gt;
&lt;li&gt;LSTM은 bidirectional 을 사용해서 table 中 &lt;strong&gt;위/아래로 흐름&lt;/strong&gt;을 이동시켜서 볼 수 있다.&lt;/li&gt;
&lt;li&gt;CNN2D는 kernel_size, pooling 등을 통해 tabel 中 &lt;strong&gt;(n colum(일부분) + n row(일부분) = 내가 focus를 맞춰 보고 싶은 부분)에 따라 그 흐름을 볼 수 있다는 데&lt;/strong&gt;서 차이가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;../../../../Dropbox/%25EB%25A9%2580%25ED%258B%25B0%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4%2520nlp%2520%25EA%25B3%25BC%25EC%25A0%2595/md/markdown-images/image-20200805122723206.png&quot; alt=&quot;image-20200805122723206&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;activation&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#activation&quot; aria-label=&quot;activation permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;activation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;activation(비선형 함수)&lt;/th&gt;
&lt;th&gt;loss&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;softmax&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;sparse_categorical_crossentropy&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;sigmoid&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;binary_crossentropy&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;linear&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;mse&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;relu&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;← Hidden layer에 씀. 기울기가 0이기 때문에 뉴런이 죽을 수 있는 단점 有&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leakly ReLU&lt;/td&gt;
&lt;td&gt;뉴런이 죽을 수 있는 현상 해결&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PReLU&lt;/td&gt;
&lt;td&gt;x&amp;#x3C;0 에서 학습 가능&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;granger causality&lt;/td&gt;
&lt;td&gt;통제된 상황에서 인과관계가 가능하다고 말할 수 있음. 시계열 데이터에서 쓰일 수 있음&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;딥러닝 네트워크(DN)의 노드는 입력값을 전부 더한 후, 활성화 함수(Activation function)를 통과시켜 다음 노드에 전달한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이때 사용하는 활성화 함수는 비선형 함수를 쓴다. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;softmax---sigmoid&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#softmax---sigmoid&quot; aria-label=&quot;softmax   sigmoid permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;softmax - sigmoid&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;구분&lt;/th&gt;
&lt;th&gt;함수&lt;/th&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;회귀&lt;/td&gt;
&lt;td&gt;항등함수(출력값을 그대로 반환)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;분류(0/1)&lt;/td&gt;
&lt;td&gt;sigmoid&lt;/td&gt;
&lt;td&gt;# 시험 데이터로 학습 성능을 평가한다&lt;br/&gt;predicted = model.predict(test&lt;em&gt;input)&lt;br/&gt;test&lt;/em&gt;pred = np.where(predicted &gt; 0.5, 1, 0)&lt;br/&gt;accuracy = (test&lt;em&gt;label == test&lt;/em&gt;pred).mean()&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;분류(multiple)&lt;/td&gt;
&lt;td&gt;softmax&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt; Cross-Entropy : 예측한 값과 실제값의 차를 계산. entropy 값이 감소하는 방향으로 진행하다 보면 최저 값을 찾을 수 있다. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sshkim Sh.TK. 2017. 8. 23. &quot;[모두의딥러닝] Softmax Regression (Multinomial Logistic Regression)&quot;. &quot;&lt;a href=&quot;https://sshkim.tistory.com/146&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://sshkim.tistory.com/146&lt;/a&gt;&quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt; argmax 을 사용하면 2라는 값이 나온다. 가장 큰 값의 위치가 2번째에 있는 1이기 때문&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JINSOL KIM. 2017. 12. 24. &quot;Softmax vs Sigmoid&quot;. &lt;a href=&quot;https://blog.naver.com/infoefficien/221170205067&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://blog.naver.com/infoefficien/221170205067&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;relu&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#relu&quot; aria-label=&quot;relu permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ReLu&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;히든층에 자주 쓰임&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그냥 CNN이든 LSTM이든 출력층 Dense에 Relu 쓰지 말자&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSTM에선 Relu 안 쓰는 게 좋음. 특히 출력층엔 쓰면 안 됨.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;학습compile-예측predict&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%ED%95%99%EC%8A%B5compile-%EC%98%88%EC%B8%A1predict&quot; aria-label=&quot;학습compile 예측predict permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;학습(compile), 예측(predict)&lt;/h1&gt;
&lt;h2 id=&quot;optimizer&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#optimizer&quot; aria-label=&quot;optimizer permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;optimizer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;종류(빈도순)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;adam&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adadelta, RMSprop, Adagrad&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;momentum&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GD, NAG&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;최적화가 잘 안 되면 글로벌 minmun을 찾지 못하고 로컬 minimum에 빠진다. 이때 로컬 minimum을 &lt;strong&gt;어떻게 빨리&lt;/strong&gt; 탈출할 수 있을지 U턴 메소드를 쓸지, 다른 1차 미분방법(GD)를 쓸 지 결정하게 된다. &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;epoch&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#epoch&quot; aria-label=&quot;epoch permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;epoch&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;epoch&lt;/code&gt; 수치가 커지면 &lt;code class=&quot;language-text&quot;&gt;optimizer&lt;/code&gt;가 일을 해서 local이 아닌 global을 찾아간다.&lt;/li&gt;
&lt;li&gt;그런데 너무 크면 overfitting&lt;/li&gt;
&lt;li&gt;따라서 적당한 &lt;code class=&quot;language-text&quot;&gt;epoch&lt;/code&gt; 설정이 필요 &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;batch_size&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#batch_size&quot; aria-label=&quot;batch_size permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Batch_size&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;data가 크면 &lt;code class=&quot;language-text&quot;&gt;batch_size&lt;/code&gt;도 크게&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;25,000개의 raw data라면 &lt;code class=&quot;language-text&quot;&gt;batch_size&lt;/code&gt; = 20 보다 300 이 정도로 설정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;nlp--dl&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#nlp--dl&quot; aria-label=&quot;nlp  dl permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP &amp;#x26; DL&lt;/h1&gt;
&lt;h2 id=&quot;sgns&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#sgns&quot; aria-label=&quot;sgns permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SGNS&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;용어&lt;/th&gt;
&lt;th&gt;설명&lt;/th&gt;
&lt;th&gt;CODE&lt;/th&gt;
&lt;th&gt;참고&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;pre-trained&lt;/td&gt;
&lt;td&gt;SGNS에서 학습한 We를 적용&lt;/td&gt;
&lt;td&gt;model.layers[1]&lt;strong&gt;.set_weights&lt;/strong&gt;(We)&lt;/td&gt;
&lt;td&gt;해당 code 적용 후 model fit 진행&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fine-training&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SGNS에 모델 학습(fit) 시, 학습을 따로 시키는 이유?&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# 학습&lt;/span&gt;
hist &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;X&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; X&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; X&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; 
               batch_size&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;BATCH_SIZE&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
               epochs&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;NUM_EPOCHS&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;각기 연결된 가중치 선이 구분되어 있기 때문에&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SGNS 모델 만들 때 dot을 한다면, &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;axis=2&lt;/strong&gt;    &lt;em&gt;@2&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; → 후에&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;reshape&lt;strong&gt;(())&lt;/strong&gt;    &lt;em&gt;@괄호 두 개&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SGNS로 만든 Embedding의 w(가중치)를 basic한 word data에 적용할 때, load_weights 사용하는 방법도 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;근데 이땐 shape을 맞춰줘야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;w &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; encoder&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;model_w.h5&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# 가중치(w) 불러온 후,&lt;/span&gt;
emb &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Embedding&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;max_features&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; embedding_dims&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; load_weights &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; w&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;xInput&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# embedding layer에 바로 적용&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;보통 이런 느낌으로 씀&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;weights &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; load_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
embedding_layer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Embedding&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;input_dim&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;V&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            output_dim&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;embedding_dim&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            input_length&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;input_length&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            trainable&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            weights&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;weights&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                            name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;embedding&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;embedding--pad_sequences&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#embedding--pad_sequences&quot; aria-label=&quot;embedding  pad_sequences permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Embedding &amp;#x26; pad_sequences&lt;/h2&gt;
&lt;h3 id=&quot;word2vec-기준&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#word2vec-%EA%B8%B0%EC%A4%80&quot; aria-label=&quot;word2vec 기준 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;word2vec 기준&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;word2vec&lt;/th&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;th&gt;input&lt;/th&gt;
&lt;th&gt;output&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;tokenizer&lt;/td&gt;
&lt;td&gt;tokenizer = Tokenizer()&lt;br /&gt;tokenizer.fit&lt;em&gt;on&lt;/em&gt;texts(clean&lt;em&gt;train&lt;/em&gt;review)&lt;br /&gt;train&lt;em&gt;sequences = tokenizer.texts&lt;/em&gt;to&lt;em&gt;sequences(clean&lt;/em&gt;train_review)&lt;/td&gt;
&lt;td&gt;[안녕, 만나서, 반가워]&lt;/td&gt;
&lt;td&gt;[13, 4, 3]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pad_sequences&lt;/td&gt;
&lt;td&gt;train&lt;em&gt;inputs = pad&lt;/em&gt;sequences(train&lt;em&gt;sequences, maxlen=MAX&lt;/em&gt;SEQUENCE_LENGTH, padding=&apos;post&apos;)&lt;/td&gt;
&lt;td&gt;[13, 4, 3]&lt;/td&gt;
&lt;td&gt;([0,0...1,..],&lt;br /&gt;[0,0,0,1,0,...],&lt;br /&gt;[0,0,1,...])&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Embedding&lt;/td&gt;
&lt;td&gt;embedding&lt;em&gt;layer = Embedding(input&lt;/em&gt;dim=VOCAB&lt;em&gt;SIZE, output&lt;/em&gt;dim=EMB_SIZE)&lt;/td&gt;
&lt;td&gt;([0,0...1,..],&lt;br /&gt;[0,0,0,1,0,...],&lt;br /&gt;[0,0,1,...])&lt;/td&gt;
&lt;td&gt;[0,0...1,..] -&gt; ANN layer&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;embedding&lt;em&gt;layer 는 결국 pad&lt;/em&gt;sequence된 단어들끼리 모임. 즉, 1개 문장에 대한 임베딩 행렬이 됨 &lt;/p&gt;
&lt;p&gt;1개 단어 = 1개 임베딩 레이어=벡터값&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;doc2vec-기준&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#doc2vec-%EA%B8%B0%EC%A4%80&quot; aria-label=&quot;doc2vec 기준 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;doc2vec 기준&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;doc2vec&lt;/th&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;th&gt;input&lt;/th&gt;
&lt;th&gt;output&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TaggedDocument&lt;/td&gt;
&lt;td&gt;documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)]&lt;/td&gt;
&lt;td&gt;[...,&apos;laughabl&apos;,&lt;br/&gt;  &apos;horror&apos;],&lt;br/&gt; ...]&lt;/td&gt;
&lt;td&gt;TaggedDocument(words=[&apos;move&apos;, &apos;last&apos;, ... &apos;horror&apos;], tags=[999])&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Embedding&lt;/td&gt;
&lt;td&gt;model = Doc2Vec(vector&lt;em&gt;size=300, alpha=0.025, min&lt;/em&gt;alpha=0.00025, min_count=10, workers=4, dm =1)&lt;/td&gt;
&lt;td&gt;TaggedDocument(words=[&apos;move&apos;, &apos;last&apos;, ... &apos;horror&apos;], tags=[999])&lt;/td&gt;
&lt;td&gt;[벡터값]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;tags=[999] : 999번 째 문장&lt;/p&gt;
&lt;p&gt;Embedding은 model.build_vocab, model.train 거치면 한 문장에 대한 하나의 벡터가 나온다.&lt;/p&gt;
&lt;p&gt;(word2vec의 경우 한 문장에 있는 각각의 단어 수만큼 벡터가 나온다.)&lt;/p&gt;
&lt;p&gt;1개 문장 = 1개 임베딩 레이어 = 1개 벡터값&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;기타&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EA%B8%B0%ED%83%80&quot; aria-label=&quot;기타 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;기타&lt;/h1&gt;
&lt;h2 id=&quot;유클리디안-거리&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EC%9C%A0%ED%81%B4%EB%A6%AC%EB%94%94%EC%95%88-%EA%B1%B0%EB%A6%AC&quot; aria-label=&quot;유클리디안 거리 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;유클리디안 거리&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;거리 계산할 때, 비교하고 싶은 건 &lt;code class=&quot;language-text&quot;&gt;[]&lt;/code&gt;를 쳐서 넣어주기  &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;euclidean_distances&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;father&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; mother&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;가중치-저장save&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#%EA%B0%80%EC%A4%91%EC%B9%98-%EC%A0%80%EC%9E%A5save&quot; aria-label=&quot;가중치 저장save permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;가중치 저장(Save)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Embedding (left side) layer의 W를 저장할 때, [2]를 저장한단 사실 알아두기&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;data/embedding_W.pickle&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;wb&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;as&lt;/span&gt; f&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  pickle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;dump&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;layers&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; f&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; pickle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;HIGHEST_PROTOCOL&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item></channel></rss>